## Notification Settings

# IBM


## Contents

**Notification Settings..............................................................................................**

**Index.................................................................................................................... 3**

**ii**


**Notification Settings**

```
Use the Notification Settings task of the z/OSMF Settings category to define configuration values that are
used for notifications for z/OSMF tasks and z/OS products.
The notification settings are presented on tabs.
```
**User tab**

```
In the User tab, you specify where you want to receive notifications, in addition to the z/OSMF
Notifications task.
Email
Select Email to indicate that notifications are to be sent to an email address of your choice.
If an email address is already defined for you in RACF, when you select Email , the field is populated
with your email address.
Email Address
Enter the email address for receiving your notifications.
If your email address is defined in RACF, this field is read-only.
```
```
Outgoing Email Configuration tab
Use the Outgoing Email Configuration tab to specify the following properties for the Simple Mail Transfer
Protocol (SMTP) outgoing mail server.
SMTP Outgoing Mail Server
SMTP mail server that you want to use for outbound connections.
SMTP User ID
Email address for your SMTP user ID.
SMTP Password
Password for your SMTP user ID.
SMTP Port
Port number to be used for SMTP connections.
Use Secure Socket Layer (SSL)
Indicate whether the mail server uses Secure Socket Layer (SSL) encryption for secure connections.
SSL is sometimes referred to as Transport-Layer Security or TLS.
If this option is selected, the SMTP outgoing mail server uses an SSL/TLS connection to send
notifications.
If this option is not selected, the SMTP outgoing mail server uses a standard SMTP connection to send
notifications. However, if the mail server supports the STARTTLS extension of SMTP, z/OSMF attempts
to negotiate an SSL/TLS connection with the mail server for privacy and authentication. Otherwise,
if the mail server does not support the STARTTLS extension, the mail server uses a standard SMTP
connection to send notifications.
Require Authentication
Indicate whether the mail server requires user authentication. If you select this option, z/OSMF uses
the AUTH command to verify that the user is permitted to the mail server.
If you do not select this option, the user receives email notifications without having to authenticate
with the mail server.
If the mail server does not use or support authentication, do not select this option.
Otherwise, the connection to the SMTP host fails with error message IZUG615E, error
type "AuthenticationFailed", and error text: "No authentication mechanisms are
supported by both the server and client."
```
```
Notification Settings   1
```

```
Authorization
For the related authorizations, see Appendix A in IBM z/OS Management Facility Configuration Guide.
```
**2** Notification Settings


## Index

**N**

Notification Settings 1

```
Index   3
```

IBM®


## Workflows task

# IBM


## Contents

- Workflows task.....................................................................................................
   - Workflows overview.....................................................................................................................................
      - About workflows.....................................................................................................................................
   - Workflows page..........................................................................................................................................
      - Workflow Settings................................................................................................................................
   - Viewing the properties of a workflow........................................................................................................
      - General properties of workflows.........................................................................................................
      - Category specific properties of workflows..........................................................................................
      - Generate Feedback Summary page.....................................................................................................
      - Notify Step Owners page......................................................................................................................
   - Modifying the information for a workflow.................................................................................................
   - Creating a workflow...................................................................................................................................
      - Resolving a conflict in variable definitions..........................................................................................
      - Workflow access type..........................................................................................................................
   - Upgrading a workflow................................................................................................................................
   - Reactivating a canceled workflow.............................................................................................................
   - Updating a workflow with custom steps...................................................................................................
   - Customizing the JOB statement for workflows on your system...............................................................
   - Working with archived workflows..............................................................................................................
      - Archiving an in-progress workflow......................................................................................................
      - Archived Workflows page.....................................................................................................................
   - Canceling an in-progress workflow...........................................................................................................
   - Managing the steps in a workflow.............................................................................................................
      - Viewing the properties of a step..........................................................................................................
      - Using the Export Workflow as a Printable Format dialog....................................................................
      - Managing assignees and ownership for a step....................................................................................
      - Using the Perform Automated Step dialog..........................................................................................
      - Using the Start Parallel Automation dialog..........................................................................................
      - Performing a step that calls another workflow...................................................................................
      - Changing the selected called workflow...............................................................................................
      - Using the Step Perform wizard............................................................................................................
      - Resolving a conflict in variable definitions in an output file..............................................................
      - Skipping a step in the workflow.........................................................................................................
      - Using the Override Complete action..................................................................................................
      - Adding notes to workflows................................................................................................................
      - Workflow history................................................................................................................................
- Index................................................................................................................


## Workflows task.....................................................................................................

```
Configuring components and products for your z/OS system can be a time-consuming and error-prone
process. Many interrelated steps might be involved, requiring work to be carried out by different members
of your organization. Such projects require careful planning and coordination with your team to ensure the
best results. To assist you with these projects, z/OSMF offers a solution, the Workflows task.
The Workflows task can help you by:
```
- Simplifying your software configuration efforts through guided, step-based workflows for common
    activities
- Ensuring that consistent methods and tools are used for software configuration on z/OS, including the
    instructions and interfaces that you use to perform this work
- Providing administrative functions for assigning workflow responsibilities and tracking progress.
More than merely a checklist of activities, the Workflows task provides a structured process for
accomplishing work on z/OS.

**Key features**

```
With the Workflows task, you can:
```
- Use a simplified interface for configuring the basic system constructs used in z/OS software
    configuration, such as directories, data sets, and jobs
- Follow a structured process for performing common activities on the system
- Perform project administrative functions for assigning workflow responsibilities to members of your
    team and tracking their progress.
To get started with the Workflows task, select and double-click the **Workflows** task from the z/OSMF
desktop. If the **Workflows** task is not displayed on the desktop, select it from the App Center in the
taskbar.

### Workflows overview.....................................................................................................................................

```
The z/OSMF Workflows task can help you guide the activities of system programmers, security
administrators, and others at your installation who are responsible for managing the configuration of
the system. The Workflows task provides a framework for these activities in the form of structured
procedures that are known as workflows.
Using the Workflows task, you can assign individual work items (the workflow " steps ") to performers and
track their progress. Depending on how the workflow is designed, the Workflows task can offer wizards to
assist with creating UNIX files and z/OS data sets, and submitting work to run on z/OS.
```
#### About workflows.....................................................................................................................................

```
This topic introduces the terminology and concepts that are helpful for you to understand as you use the
Workflows task.
In z/OSMF, a workflow is a guided set of steps that help you perform a common activity on z/OS, such
as configuring a software product or component. A workflow guides you through the complete set of
steps that are needed to accomplish a goal, and, when dependencies exist, controls the sequence for
performing those steps. In this way, a workflow can help to ensure that you perform the steps in the
correct order, and that prerequisites and dependencies are identified clearly.
Conceptually, a workflow encompasses both the work to be performed and its performers. By identifying
the individual steps to be performed, a workflow allows for these steps to be divided among different
areas of an organization, and different members of your team. With a workflow, a project owner can
delegate specific items to the team members best suited to carrying out particular tasks.
```
```
Workflows task   1
```

```
In short, a workflow:
```
- Is based on a structured set of steps that are designed by a _workflow author_. A z/OS organization can
    write its own workflows or obtain workflows from a third-party source (a _workflow provider_ ). z/OSMF
    includes samples for workflow authors to reference when they are creating workflows.
- Is described to z/OSMF through a _workflow definition file_. A workflow is created when a user imports the
    workflow definition file into z/OSMF.
- Identifies the individual steps to be performed and allows for these steps to be divided among different
    areas of an organization, helping to facilitate user activities on z/OS.
In z/OSMF, the Workflows task allows a z/OS installation to create and manage workflows for performing
activities on the z/OS system. The user who is responsible for the workflow and seeing that it gets
completed is the _workflow owner_. The workflow owner assigns workflow steps to users, making them
_assignees_ of the step. The user who accepts ownership of a step becomes the _step owner_.
In the Workflows task:
- The **Workflows** page displays the existing workflows for an installation, and provides the control point
    for creating and managing workflows.
- The **Steps** page displays the steps in a workflow, and provides the control point for managing the steps.
    From this page, you can select actions for the steps, such as assigning steps, changing ownership of
    steps, and performing steps.
The following topics provide more details on workflows and workflow steps:
- “Terms you should know” on page 2
- “Prerequisite steps and dependent steps” on page 4
- “Conditional steps” on page 5
- “Optional steps” on page 5
- “Steps and substeps” on page 5
- “Using a wizard or dialog to complete a step” on page 6
- “The states of a step” on page 6
- “Available actions for a step” on page 7
- “Parent steps and descendant leaf steps” on page 9.

```
Terms you should know
Users of the Workflows task should be familiar with the following terms.
Workflow
```
**1.** An activity that is associated with the z/OS system, such as configuring a component or product. **2.**
The instantiation of a workflow in z/OSMF, based on a workflow definition. A workflow consists of one
or more units of work to be performed on the z/OS system, as described by the workflow definition.
A workflow is created when the Workflows task is used to create an instance of a workflow from a
supplied workflow definition file.
**Workflow author**
The person, typically a programmer, who codes the workflow definition file in the XML tagging
language.
**Workflow category**
A classification of the activities to be performed in the workflow. The following values are valid:
**General**
All other workflows
**Configuration**
Workflows that are used to configure system software, such as a product or component

**2**   Workflows task


```
Provisioning
Workflows that are used to provision z/OS middleware, such as a Db2 or IMS. Provisioning
workflows are used with IBM Cloud Provisioning and Management for z/OS.
```
**Workflow definition**
The logical structure of a workflow, represented as a series of one or more steps. The workflow
definition identifies the various system objects and actions that constitute activities on z/OS and the
rules for performing those activities. The workflow definition includes all of the information that is
specified in, or referenced by, the primary XML file (the _workflow definition file_ ) and possibly other files
that are included by the workflow definition file. This content typically includes information about the
workflow (such as name and version), step definitions, variable definitions, file templates, and bundle
files.

**Workflow definition file**
The primary XML file for a workflow definition. A workflow is stored in z/OSMF when its workflow
definition file, and optionally, a workflow variable input file, is imported into the Workflows task.

**Workflow variable input file**
An optional file that supplies default values for one or more of the input variables that are defined in
the workflow definition file. The workflow variable input file is specified as input when the workflow
definition file is imported into the Workflows task. Typically, a workflow provider might supply a
workflow variable input file to save users from having to manually enter inputs when they perform
a workflow. By limiting user interaction, a workflow variable input file can help to simplify the user
experience of performing a workflow.

**Output file**
A file that is created by a step, as the result of running a program. Typically, the file holds the results of
a batch job, shell script, or REXX exec program. It can be used by other steps or workflow instances.

**Global variable**
A variable definition that is available to all workflow instances. The Workflows task saves global
variables in a repository that is called the global variables pool.

**Instance variable**
A variable definition that is available to only to instances of a particular workflow.

**Workflows task**
The task in the z/OSMF navigation area that allows users to interact with workflows on z/OS.

**Workflow owner**
The user who is given ownership of the workflow through the Workflows task. The workflow owner is
responsible for delegating the work in the workflow to users to perform (the step assignees).

**Workflow provider**
The source of the workflow definition file, which is typically IBM or a software vendor.

**Step**
A single, logical unit of work in a workflow. Consider each step to describe a specific activity to be
performed on the system. A step is available to be performed when the workflow owner assigns the
step to a user, and the user accepts ownership of the step.

**Step owner**
The user who accepts ownership of a step and therefore responsibility for performing the step.

**Automation processing**
The processing of a workflow that contains one or more automated steps. A workflow that is
comprised entirely of automated steps can complete with little or no user intervention. When
automation processing is started on the workflow, the workflow runs to completion or until it is
stopped by another condition, such as a user request or an error.

**Automated step**
A step can be designed to run automatically (without user interaction) when it is in Ready state. Such
a step is referred to as an _automated step_. A workflow that is comprised entirely of automated steps
can complete with little or no user intervention. In the Workflow Steps table, automated steps are
identified in the column Automated.

```
Workflows task   3
```

```
Parallel-steps workflow
A workflow with automated steps that can be run in parallel (concurrently). When a parallel-steps
workflow is started, the Workflows task locates all of the automated steps with Ready status, and
attempts to run these steps concurrently. The failure of an automated step does not stop automation
processing for the other automated steps. Processing continues until all of the automated steps are
completed or failed, or the user stops automation processing by using the Stop Automation action on
the Workflows page.
Called workflow
A workflow that is started by another workflow for execution. Conceptually, a called workflow is a step
in the workflow that calls it (the calling workflow).
Conditional step
A step that can be performed when a logical condition is satisfied on the z/OS system or in the
Workflows task. For example, a conditional step might become eligible to be performed if a job that is
run by another step ends with a particular return code. A conditional step remains unavailable to be
performed as long as the condition is not satisfied.
Feedback step
A step that includes a feedback form with questions for the step owner to answer at the conclusion of
a step.
Immediate execution step
A template step that runs an executable program in real time, such as a REXX exec or UNIX shell
script. Contrast with a batch execution step , which is a template step that runs a program as a batch
job.
REST step
A step that issues a REST API request, such as a GET or PUT request.
Template step
A step that is designed to run an executable program, such as a JCL job, a REXX exec, or a UNIX shell
script. On completion, the results can be made available to other steps, in the form of variables or
an output property file. Depending on how the program is processed, a template step is either of the
following:
```
- _Immediate execution step_ , which runs a program in real time
- _Batch execution step_ , which runs a program as a batch job.
**Archived workflow**
When a workflow is archived, its information is saved in z/OSMF for future reference. The workflow is
no longer active, but its information can be viewed by the workflow owner, using the Workflows table
action **Open Archived Workflows**. When an archived workflow is no longer needed, it can be deleted
from z/OSMF by the workflow owner.

```
Prerequisite steps and dependent steps
Some steps have dependencies on other steps in the workflow. A step that cannot be performed until
another step is completed is said to depend on a prerequisite step. When prerequisite steps exist, the
Workflows task displays the steps for you to see and act on.
To satisfy a prerequisite step, you must either complete the step or skip it. A step is considered complete
when it is performed (through the Perform action) or overridden (through the Override Complete action).
If you decide to skip a step, you can select it with the Skip action. The Workflows task treats skipped
steps as completed.
Through the enforcement of state changes, Workflows task ensures that prerequisite steps are satisfied
(completed or skipped) before dependent steps can be performed.
If a prerequisite step is a parent step (has substeps), z/OSMF treats all of the substeps in the parent step
as prerequisites.
```
**4**   Workflows task


**Conditional steps**

A _conditional step_ is available to be performed based on whether a logical condition is satisfied. For
example, a conditional step might become eligible to be performed if a job that is run by another step
ends with a particular return code. A conditional step remains unavailable to be performed while the
condition is not satisfied. A conditional step, which depends on a logical condition, is different from a
dependent step, which depends on a particular step being completed.

**Optional steps**

A step might be indicated in the workflow as an _optional step_ ; the text (optional) is added as a prefix to
the step title. The optional designation means that the step might not be applicable to your environment.
For an optional step, you must determine whether the step is to be completed or skipped.

To ensure that a workflow is followed to completion, z/OSMF does not allow a workflow to reach 100
percent complete unless all of its steps are completed or skipped. If you determine that a particular step
is not applicable to your environment, you can skip the step (through the Skip action). Doing so removes
the step from the Percent Complete calculation for the workflow so that the omission of the step does not
prevent the workflow from reaching 100-percent completion.

**Steps and substeps**

Each step can contain substeps, which can also contain substeps. Up to five levels of nesting are possible.
A workflow can contain up to 500 steps and substeps (a combined total).

In the **Steps** page, step titles are numbered to indicate the sequence in which steps are to be performed.
The first step in the Workflow Steps table starts with number 1.

Substeps are shown with indented titles. A substep shares the numerical value with its parent, but with
_'.x'_ appended to its step number, where _'x'_ is a numerical value that starts with 1. For a substep nested
five levels deep, for example, the step number is indicated in the form _'x.x.x.x.x'_.

**Step automation in the Workflows task**

A step can be designed to run without user intervention. Such a step is referred to as an _automated step_.
When an automated step is present in a workflow, the step owner can allow the step to run automatically,
or can choose to perform the step manually.

A workflow might have both automated steps and non-automated (manually performed) steps. A
workflow with at least one automated step is considered to be an _automated workflow_.

In the Workflow Steps table, automated steps are identified in the column Automated. When automated
steps are ordered consecutively in a workflow, a request to run the first automated step begins a process
in which each subsequent automated step can run to completion, or until one of the steps encounters a
condition that stops the processing of steps. A workflow that is comprised entirely of automated steps can
run to completion without user intervention.

When automation processing is started on the workflow, the workflow runs to completion or until it is
stopped by another condition, such as an error. Specifically, a workflow with automated steps can run
until one of the following conditions occurs:

- Completion of all steps.
- Processing reaches a non-automated step.
- Processing reaches an automated step for which one or more required variables are not satisfied.
- Processing reaches an automated step for which variable conflicts exist, and the user is prompted to
    resolve the conflict.
- Processing reaches an automated step that is not currently eligible for automatic processing. That is,
    the step is _Unassigned_ , _Assigned_ , _Not Ready_ , or _Submitted_.
- Processing reaches an automated step that is suspended.

```
Workflows task   5
```

- Processing reaches a step that is not owned by the user who started automation processing for the
    workflow.
- Processing is stopped through a user request.
- An error is encountered.
For workflows that contain automated steps, z/OSMF creates notifications to inform step owners of the
automation progress. At the completion of an automated step or a sequence of automated steps, z/OSMF
creates a notification to inform the step owner of the step status. If processing reaches a manual step
that requires user interaction before the workflow can continue, z/OSMF creates a notification for the step
owner to prompt for action.
During the processing of an automated step, z/OSMF updates the workflow history to indicate the
following checkpoints in the workflow progress:
- Completion of the automated step
- Completion of all automated steps in the workflow
- Automation is started through request
- Automation is stopped through user request
- Automation is stopped at a suspended step
- An error is encountered during the processing of an automated step.

```
Using a wizard or dialog to complete a step
For each step, the Workflows task includes a tab that is called Perform. When you click the Perform tab,
the Workflows task displays a wizard or dialog to guide you in the completion of the step. Depending on
whether the step is automated or manual (requires user action), the Workflows task responds, as follows:
```
- For an automated step, the Workflows task displays a dialog, called the _Perform Automated Step_ dialog
    to confirm your selection for the step and any subsequent automated steps.
- For a manual step, the Workflows task displays a wizard, called the _Step Perform_ wizard to guide you
    in the completion of the step. The wizard contains instructions for you to follow, which are detailed
    directions for what you must do to perform the step to completion. Depending on the requirements of
    the step, the Workflows task might first prompt you for installation-specific values and then use these
    values to provide you with tailored instructions.
For a manual step, the wizard might consist of textual instructions only, such as describing a system
change that you must perform manually before you can return to the Workflows task. Or, the wizard might
also include guided assistance in performing some work that is necessary for completing the step, such as
submitting a batch job, shell script, or REXX exec. The Step Perform wizard can include none, one, or more
types of assistance, depending on the step definition within the workflow definition.
When you perform a step, follow the instructions (and actions, if any) and then press **Finish** on the
instructions page to have the step marked complete.

**The states of a step**

```
A step moves through different states during its lifecycle. The choice of actions that can be performed
against the step depend on its current state.
Every step must progress through at least the following states, in this sequence:
```
1. _Unassigned_ state
2. _Assigned_ state
3. _Not ready_ state
4. _Ready_ state
5. _In Progress_ state
6. _Complete_ state.

**6**   Workflows task


In addition, a step might progress through one or more of the following states:

- _Complete (Override)_ or _Skipped_ , instead of _Complete_
- _Conflicts_ , for a step that creates an output properties file
- _Submitted_ or _Failed_ , for a step that submits a job to run on z/OS.

Different users might be involved in the step at separate points in the step lifecycle. Figure 1 on page 7
shows the lifecycle of a step, as it moves from one state to another.

_Figure 1. Lifecycle of a step_

Throughout the step lifecycle, this flow might vary, depending on whether the step changes ownership or
is reset to a previous state. Through the enforcement of state changes and a history collection function,
the Workflows task allows users to track the step through each of these stages.

For any action that causes a state transition, the user can optionally provide a comment. The Workflows
task records comments as part of the state transition in the workflow history. Thus, each action can
have its own comment, with supplementary, user-supplied information. The commenting function in the
Workflows is present for all actions, with the exception that no comments are solicited for the Perform
action.

As with performing system changes manually, use caution in performing the steps of a workflow. Using
the Workflows task, you can repeat steps as needed, to correct mistakes. However, for some system
changes it might be necessary for you to manually undo a change on your system to correct mistakes.
In such cases, consult the workflow instructions from the workflow provider for recommendations about
undoing the results of a step.

**Available actions for a step**

A step is available to be performed when the workflow owner assigns the step to a user (the assignee),
the assignee accepts ownership of the step, thus becoming the _step owner_ , and the step has no
unsatisfied prerequisite steps.

Which actions can be taken on a step depend on the current state of the step and the identity of the
currently authenticated user. Table 1 on page 8 shows the available actions from the **Steps** page,
depending on the current state of the step.

```
Workflows task   7
```

```
Table 1. Available actions for a step
Action Description Applicable State Available to
Properties Display the Step Properties page so that you
can view the properties for the selected step. To
enable this action, select 1 step only.
```
```
All step states. All users.
```
```
Accept Display the Accept dialog so that you can accept
ownership of steps that are assigned to you.
```
```
Assigned state. Workflow owner
and the step
assignees.
Perform Display the Perform tab of the Step Properties
page so that you can perform the selected step.
To enable this action, select 1 step only.
```
```
Available when step state is:
```
- _Not Ready_
- _Ready_
- _In Progress_
- _Submitted_
- _Failed_
- _Complete_
- _Override Completed_
- _Skipped_.

```
Step owner.
```
```
Skip Display the Skip dialog so that you can bypass
the performing of a step.
```
```
All step states. Workflow owner
and the step
owner.
Status Display the Status tab of the Step Properties
page so that you can view the completion status
of the last job to be submitted when the step was
performed. To enable this action, select 1 step
only.
```
```
Available when step state is:
```
- _Submitted_
- _Failed_
- _Complete_.

```
Workflow owner
and the step
owner.
```
```
Override
Complete
```
```
Display the Override Complete page so that you
can mark a step as complete to indicate that the
work was performed outside of the Workflows
task.
```
```
All step states. Workflow owner
and the step
owner.
```
```
Resolve
Conflicts
```
```
Display the Input Variables tab of the Step
properties page so that you can resolve conflicts
between variables in the output file and existing
variables for the Workflows task.
```
```
Available when the step state is
Conflicts.
```
```
Workflow owner
and the step
owner.
```
```
Change
Called
Workflow
```
```
Display the Change Called Workflow dialog so
that you can modify the current selection of a
called workflow.
```
```
Available when the step state is
Conflicts.
```
```
Workflow owner
and the step
owner.
Add
Assignees
```
```
Display the Add Assignees page so that you can
assign one or more steps to users.
```
```
All step states. Workflow owner
and the step
owner.
Remove
Assignees
```
```
Display the Remove Assignees page so that you
can remove one or more assignees from a step.
This action is available only when the selected
steps have assignees.
```
```
All step states. Workflow owner
and the step
owner.
```
**8**   Workflows task


_Table 1. Available actions for a step (continued)_

**Action Description Applicable State Available to**

**Take
Ownership**

```
Display the Take Ownership dialog so that you
can assume ownership of a step from the current
step owner.
```
```
Available when the step state is:
```
- _Not Ready_
- _Ready_
- _In Progress_
- _Submitted_
- _Failed_
- _Complete_
- _Override Completed_
- _Skipped_.

```
Workflow owner
and the step
assignees.
```
**Return** Display the **Return** dialog so that you can cancel
your acceptance of a step, thus making the step
available for another assignee to accept.

```
Available when the step state is:
```
- _Not Ready_
- _Ready_
- _In Progress_
- _Submitted_
- _Failed_
- _Complete_
- _Override Completed_
- _Skipped_.

```
Step owner.
```
**Request
Assignmen
t**

```
Display the Request Assignment dialog so that
you can request to be assigned the selected
steps.
```
```
Available when the step state is:
```
- _Not Ready_
- _Ready_
- _In Progress_
- _Submitted_
- _Failed_
- _Complete_
- _Override Completed_
- _Skipped_.

```
Workflow owner
and the step
assignees.
```
**Parent steps and descendant leaf steps**

```
Two step types exist: parent steps and leaf steps. A parent step is one that consists of descendant steps
(substeps). A leaf step has no substeps; conceptually, it cannot be broken down further.
A leaf step can have any state in the Workflows task, however, a parent step is limited to the following
states:
```
- _Unassigned_
- _Not Ready_
- _In Progress_
- _Skipped_
- _Complete_
- _Override Complete_
- _Conflicts_.
To determine the state of a parent step, z/OSMF uses the states of its descendant leaf steps, as shown in
Table 2 on page 10.

```
Workflows task   9
```

```
Table 2. Parent step states based on descendant leaf states
When the descendant leaf steps are: The parent step is:
All in Unassigned state Unassigned
All in Ready state In Progress
All in Not Ready state Not Ready
All in Complete state Complete
All in Override Complete state Override Complete
All in Skipped state Skipped
All in Conflicts state Conflicts
A mix of Complete, Override Complete, or Skipped Complete
Any other combination of states. In Progress
```
```
When you select a parent step in the Workflow Steps table, you select all of its descendant steps. Actions
that are taken on the parent step, such as Assign, apply to the substeps, too.
The Perform tab and the Status tab in the properties page for a parent step are always disabled. Any
meaningful information from the workflow provider about the parent step is contained in the Description
field in the General tab of the Properties for Step page.
Observe the following considerations:
```
- If a step is in the _Assigned_ state, and all of its assignees are removed through the Remove Assignees
    action, the Workflows task resets the step to the _Unassigned_ state. Otherwise, the step remains in the
    _Assigned_ state as long as at least one user is assigned to it.
- The step changes to the _Ready_ state when its prerequisites are satisfied. If so, z/OSMF creates a
    notification to inform the step owner that the step is now ready to be performed.
- If a step is in the _Ready_ state and one of its prerequisite steps changes to an incomplete state, such
    as _In Progress_ , z/OSMF resets the _Ready_ step to _Not Ready_ to indicate that a prerequisite is no longer
    satisfied.

### Workflows page..........................................................................................................................................

```
You can use the Workflows page in the Workflows task to view, create, and manage workflows for the
systems in your sysplex. The Workflows table displays the workflows that are created on your system.
For a description of the columns in the Workflows table, see “Columns in the Workflows table” on page
10. For a description of the actions that you can take for workflows, see “Actions for Workflows” on page
14.
To view workflow settings, click on the Settings link.
Note: The Settings link is displayed for workflow administrators only.
For additional information about workflow settings, see “Workflow Settings” on page 18.
```
```
Columns in the Workflows table
The rows in the Workflows table are sorted alphabetically in ascending order, which is based on the
Workflow Name column.
In z/OSMF workflows that are used to configure system software such as a product or component are
configuration workflows. Workflows that are used to provision system software, such as Db2 or IMS, are
provisioning workflows. All other workflows are general workflows.
The columns in Table 3 on page 11 are displayed for all workflows, regardless of workflow type.
```
**10**   Workflows task


_Table 3. Columns in the Workflows table for all workflows_

**Column Description**

**Workflow Name** Descriptive name that identifies the workflow, as specified by the workflow owner.
By default, this column is the sort column, and the sort is ascending.

**Description** Description of the workflow. z/OSMF obtains this value from the workflow
definition file when the workflow is created.

**Version** Version of the workflow definition. z/OSMF obtains this value from the workflow
definition file when the workflow is created.

**Vendor** Name of the vendor that provided the workflow definition. z/OSMF obtains this
value from the workflow definition file when the workflow is created.

**Owner** User ID of the workflow owner. This value can be modified by the workflow owner
only.

**System** z/OS system on which the workflow is to be used. This value is specified when the
workflow is created.

**Access** Access type of the workflow. This value determines which users can view the
workflow steps and edit the step notes.
One of the following values is displayed:

```
Public
The workflow notes, steps, and step notes can be viewed by all z/OSMF users.
```
```
Restricted
The workflow notes, steps, and step notes can be viewed only by the workflow
owner, step owners, and step assignees.
```
```
Private
The workflow notes can be viewed by the workflow owner. The steps and step
notes can be viewed only by the step owner or step assignees for the particular
step.
```
**Status** Indication of the current workflow status. One of the following values is displayed:

```
In Progress
One or more steps in the workflow are started.
```
```
Automation in Progress
Workflow contains an automated step that is running.
```
```
Complete
Workflow is complete; all steps are marked complete or skipped.
```
```
Locked
Workflow is locked for an update operation.
```
```
Canceled
Workflow is canceled and cannot be performed. However, you can view its
properties or delete it.
```
```
Workflows task   11
```

```
Table 3. Columns in the Workflows table for all workflows (continued)
```
```
Column Description
```
```
Percent Complete Percentage of the workflow that is completed. z/OSMF calculates this value, which
is based on the number of steps in the workflow and the relative weighting value of
each step. The weight is a value that represents the relative difficulty of the step,
as estimated by the workflow provider. As an example, for a step in which the user
is required only to cut and paste a command, the weight might be low. For a more
complicated task, such as deploying a digital certificate, the weight might be high.
To determine the Percent Complete value, z/OSMF uses the calculation b divided
by c where:
```
- _b_ is the total weighting of the completed steps (that is, the steps that are marked
    as Complete or Override Complete)
- _c_ is the total weighting of the all of the steps in the workflow. This amount
    excludes any steps that were skipped.
A parent step does not have a weight of its own and is therefore not part of the
Percent Complete calculation.
z/OSMF updates the Percent Complete value whenever you cause the table data to
be refreshed, which occurs whenever you take any of the following actions:
- Go to this page from another workflow page
- Close a modal dialog when you view this page
- Click **Refresh** to refresh the contents of the table.
For a canceled workflow, the Percent Complete shows the percentage that was
completed at the time the workflow was canceled. Because a canceled workflow
cannot progress beyond this state, the Percent Complete value is disabled.

```
Date Created (GMT) Date and time on which the workflow instance was created, based on Greenwich
mean time (GMT). This value is displayed in the following format: yyyy-mm-dd
hh:mm:ss.
```
```
Called by Workflows For a called workflow, this column indicates which workflows can call the workflow
for processing. Otherwise, this column is blank. This column is hidden by default.
To display it, use the Configure Columns action.
```
```
Category Category of the workflow, which is one of the following:
General
All other workflows
Configuration
Workflows that are used to configure system software, such as a product or
component.
Provisioning
Workflows that are used to provision z/OS middleware, such as a Db2 or IMS.
Provisioning workflows are used with IBM Cloud Provisioning and Management
for z/OS.
z/OSMF obtains this value from the workflow definition file when the workflow
is created. This column is hidden by default. To display it, use the Configure
Columns action.
```
**12**   Workflows task


_Table 3. Columns in the Workflows table for all workflows (continued)_

**Column Description**

**Is Callable** Indicates whether the workflow can be called by another workflow, and, if so, the
callable range for the workflow. One of the following values is displayed:
**In the same system**
When called by another workflow, one instance of this workflow is used in
the local system. If an existing instance of the called workflow is not already
active, the Workflows task creates a new instance of the called workflow for
the system.
**In the same sysplex**
When called by another workflow, one instance of this workflow is used in the
sysplex. If an existing instance of the called workflow is not already active, the
Workflows task creates a new instance of the called workflow for the sysplex.
**Cannot be called by another workflow**
This workflow cannot be called by another workflow.
This column is hidden by default. To display it, use the **Configure Columns** action.

**Contains Parallel Steps** For a workflow with automated steps, this column indicates whether the
automated steps can be run in parallel (concurrently), thus possibly completing
more quickly. For a parallel-steps workflow, this column is _Yes_.
To start automation for a parallel-steps workflow, use the **Start Parallel
Automation** action in the Workflow Steps table.
Otherwise, if this column is _No_ , automated steps are run one by one in the
sequence in which they appear in the workflow, starting from the top of the
workflow definition.

```
The columns in Table 4 on page 13 are applicable only when the workflow category is Configuration. The
information in these columns is also included in the Properties page for a configuration workflow.
```
_Table 4. Columns in the Workflows table for configuration workflows_

**Column Description**

**Product Name** Name of the product or component that is being configured through the workflow.
z/OSMF obtains this value from the workflow definition file when the workflow
is created. This column is hidden by default. To display it, use the **Configure
Columns** action.
This column is blank for a general workflow.

**Product ID** Identifier of the product or component that is being configured through the
workflow, such as the product identifier (PID) or function modification identifier
(FMID). z/OSMF obtains this value from the workflow definition file when the
workflow is created. This column is hidden by default. To display it, use the
**Configure Columns** action.
This column is blank for a general workflow.

**Product Version** Version and release of the product or component that is configured through the
workflow. z/OSMF obtains this value from the workflow definition file when the
workflow is created. This column is hidden by default. To display it, use the
**Configure Columns** action.
This column is blank for a general workflow.

```
Workflows task   13
```

```
The columns in Table 5 on page 14 are applicable only when the workflow category is Provisioning. The
information in these columns is also included in the Properties page for a provisioning workflow.
```
```
Table 5. Columns in the Workflows table for provisioning workflows
```
```
Column Description
```
```
Product Name Name of the product or component that is being provisioned through the workflow.
z/OSMF obtains this value from the workflow definition file when the workflow
is created. This column is hidden by default. To display it, use the Configure
Columns action.
This column is blank for a general workflow.
```
```
Product ID Identifier of the product or component that is being provisioned through the
workflow, such as the product identifier (PID) or function modification identifier
(FMID). z/OSMF obtains this value from the workflow definition file when the
workflow is created. This column is hidden by default. To display it, use the
Configure Columns action.
This column is blank for a general workflow.
```
```
Product Version Version and release of the product or component that is provisioned through
the workflow. z/OSMF obtains this value from the workflow definition file when
the workflow is created. This column is hidden by default. To display it, use the
Configure Columns action.
This column is blank for a general workflow.
```
```
Software Type Type of software to be provisioned. z/OSMF obtains this value from the workflow
definition file when the workflow is created. This column is hidden by default. To
display it, use the Configure Columns action.
This column is blank for a general workflow or a configuration workflow.
```
```
Actions for Workflows
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.

```
Table 6. Targeted actions for the Workflows table
```
```
Action Description
```
```
View Properties Display the Workflow Properties page so that you can view the properties for the
selected workflow. To enable this action, select one workflow only.
```
```
Open Display the Steps page so that you can work with the selected workflow. To enable
this action, select one workflow only.
```
**14**   Workflows task


_Table 6. Targeted actions for the Workflows table (continued)_

**Action Description**

**Modify** Display the **Modify Workflow** dialog so that you can modify the properties of the
selected workflow. To enable this action, select one workflow only.
For a general workflow or configuration workflow, the ability to modify the
workflow is limited to the current workflow owner and members of the z/
OSMF workflow administrators group. For a provisioning workflow, the domain
administrator is also able to modify a workflow.
In z/OSMF, the following resource name is used to manage administrative access to
workflows:

```
<saf-prefix> .ZOSMF.WORKFLOW.ADMIN
```
```
Information about creating authorizations for z/OSMF is provided in IBM z/OS
Management Facility Configuration Guide.
This action is disabled for a workflow with the status Automation in Progress. That
is, it is not possible to modify the workflow while an automated step is running.
You must either allow the processing to complete, or you can stop the processing
through the Stop Automation action.
```
**Cancel** Display the **Cancel Workflow** dialog so that you can cancel the selected workflow.
You can select multiple workflows.
This action is available to the workflow owner only.
This action cancels an in-progress workflow, preventing any further progress.
Canceling a workflow does not undo any actions that were already performed on
the system as part of the workflow. If you cancel a workflow, you are responsible
for ensuring that any subsequent steps are performed or that the subsequent steps
are not necessary.
When canceled, the workflow cannot be performed. You can view the workflow
properties, but not change the properties. To delete the workflow, use the **Delete**
action.
This action is disabled for a workflow with the status _Automation in Progress_. That
is, it is not possible to cancel the workflow while an automated step is running.
You must either allow the processing to complete, or you can stop the processing
through the **Stop Automation** action.

```
Workflows task   15
```

```
Table 6. Targeted actions for the Workflows table (continued)
```
```
Action Description
```
```
Delete Display the Delete Workflow dialog so that you can permanently delete the
selected workflow from z/OSMF. You can select multiple workflows.
For a general workflow or configuration workflow, the ability to delete the workflow
is limited to the current workflow owner and members of the z/OSMF workflow
administrators group. For a provisioning workflow, the domain administrator is able
to delete a workflow, as well.
In z/OSMF, the following resource name is used to manage administrative access to
workflows:
```
```
<saf-prefix> .ZOSMF.WORKFLOW.ADMIN
```
```
Information about creating authorizations for z/OSMF is provided in IBM z/OS
Management Facility Configuration Guide.
This action deletes the selected workflow from z/OSMF, including any notes that
accompany the workflow and its steps, and the history log for the workflow.
Deleting a workflow does not undo any actions that were performed on the system
as part of the workflow. If you delete a workflow, you are responsible for undoing
manually any changes on the system that you no longer require. Ensure that all
applicable backout procedures are followed. See your workflow provider for this
information.
This action is disabled for a workflow with the status Automation in Progress. That
is, it is not possible to delete the workflow while an automated step is running.
You must either allow the processing to complete, or you can stop the processing
through the Stop Automation action.
```
```
Archive Select one of the following actions:
Archive the Workflow
Display the Archive Workflow dialog so that you can archive the selected
workflows. You are prompted to confirm your decision to archive the workflow.
Open Archived Workflows
Display the Archived Workflows page so that you can view the archived
workflows or delete them. If no workflows are archived, the Archived
Workflows page displays an empty list.
For more information, see help topic “Working with archived workflows” on page
41.
```
```
Stop Automation For a workflow with automated steps, stop the processing of the workflow. You
can select multiple workflows. Any in-progress steps are allowed to complete
before the workflow is stopped. Subsequently, any automated steps in a ready
state are not started. Automation can be started again by performing a subsequent
automated step that followed when automation was stopped.
This action is available only for a workflow with the status Automation in Progress.
```
```
Generate Feedback
Summary
```
```
For a workflow that includes feedback questions, the workflow owner is
responsible for collecting feedback from step owners. Select this action to see
which steps have incomplete feedback and send notifications to step owners who
have incomplete feedback.
```
**16**   Workflows task


_Table 6. Targeted actions for the Workflows table (continued)_

**Action Description**

**Create New Based on
Existing**

```
Display the Create New Based on Existing dialog so that you can upgrade the
selected workflow to a new level. You can use this action to apply functional
updates to the workflow without losing your changes in the current workflow. In
the dialog, you specify the version of the workflow definition file to be used, and
which data, if any, is to be passed to the upgraded workflow.
```
**Reactivate** Display the **Reactivate Workflow** dialog so that you can reactivate a workflow that
you canceled previously.
This action is available to the workflow owner only.

**Update Workflow Steps** Display the **Update Workflow Steps** dialog so that you can customize the selected
workflow with your own steps. You can use this action to tailor a workflow with
steps that you design specifically for your installation. You can use this dialog to
modify or delete your steps later, if necessary.

**Create Workflow** Display the **Create Workflow** dialog so that you can create a new workflow.

**Customize JOB
Statement**

```
Display the Select JOB Statement to Modify dialog so that you can view the
current JOB statement for workflows on this system. You can use the dialog to
modify the JOB statement or select another JOB statement to be used instead.
Your selection is applicable to all workflows on the system.
```
**Workflows View** Select one of the following actions:

```
Active
Display the active workflows on the system.
```
```
Archived
Display the Archived Workflows page so that you can view archived workflows
or delete them. If no workflows are archived, the Archived Workflows page
displays an empty list.
```
```
This action is also available through the Active|Archived ( | ) button on the
Workflows table.
For more information, see help topic “Working with archived workflows” on page
41.
```
_Table 7. Table actions for the Workflows table_

**Action Description**

**Select All** Select all of the items in the table.

**Deselect All** Clear all of the items in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Workflows task   17
```

```
Table 7. Table actions for the Workflows table (continued)
```
```
Action Description
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Workflow Settings................................................................................................................................

```
You can use the Workflow Settings page in the Workflows task to specify workflow settings. To display
the Workflow Settings page, select Settings on the Workflows page. This link is displayed for workflow
administrators only.
The following tabs are available on the Workflow Settings page:
```
- General
- Archive Automation
- Internal Job Statement

```
General tab
The General tab provides a way to update settings for the maximum number of active workflows and
maximum number of archived workflows, and signing the workflow keyLabel.
For a description of the fields, see Table 8 on page 18.
```
```
Table 8. Fields on the Workflow Settings General tab
```
```
Field Description
```
```
Maximum number of
active workflows
```
```
Minimum value of active workflows: 200
Maximum value of active workflows: 1000
If the number of active workflows is not within the permitted range, message
IZUWF0405E is displayed, stating the number is not valid.
The active workflow limit is checked when creating the workflow. If the maximum
limit is reached, the workflow creation fails.
```
```
Maximum number of
archived workflows
```
```
Minimum value of archived workflows: 200
Maximum value of archived workflows: 1000
If the number of active workflows is not within the permitted range, message
IZUWF0405E is displayed, stating the number is not valid.
The archive workflow limit is not checked during the archive. The archive can be
successful even if the maximum limit is exceeded, but the archive workflow UI
table displays only the maximum number of archived workflows.
```
```
Workflow signing
certificate
```
```
The label of the certificate that is used to sign the workflow steps.
```
**18**   Workflows task


```
Archive Automation tab
The Archive Automation tab provides Workflow Administrators a way to update settings for policy based
archive workflow management.
The following tabs are available on the Archive Automation tab:
```
- **Archive Policies** tab:
    Define policy rules for when workflows are to be automatically archived. You can add, modify or delete
    the policy rules. For a description of the fields on the **Archive Policies** tab, see Table 9 on page 19.
    To add a new policy rule, click **Add**. To modify a policy rule, select the policy in the table and click
    **Modify**. You can enter or update information in the following fields:
    **Wait Period**
       Use hours or days to specify the amount of time in which the workflow will be automatically
       archived upon completion. If you specify 0 for the value, the workflow is archived immediately when
       the archive conditions are met.
    **Condition**
       Workflows that meet this condition will be automatically archived. Only a workflow in completed
       status is currently supported.
    **Archive SAF ID**
       Specify the owner of the archived workflow (a z/OS user ID or group). The owner can view the
       workflow after it is archived. If you specify * for the value, the policy is used as the universal policy,
       which manages all workflows that do not comply with a predefined existing archive policy.
    **Archive Directory**
       Specify a z/OS UNIX directory on your system for archiving the workflow, beginning with a single
       forward slash ('/'). Ensure that only the z/OSMF server user ID (by default, IZUSVR) has the write
       permission to the directory and other users don’t. The z/OSMF server user ID also should have read
       and execute permission to the directory. Do not specify a location in the z/OSMF data directory
       (/global/zosmf/data) or configuration directory (/global/zosmf/configuration).
    **Comments**
       Specify information that you want to associate with this policy (up to 1,000 characters).
    To delete a policy rule, select the policy in the table and click **Delete**. The **Delete Archive Policies**
    confirmation page is displayed. Click **OK** to delete the policy.
- **Archive Directory History** tab
    View or delete archive directories that have been defined by all users.

_Table 9. Fields on the Archive Policies tab_

**Field Description**

**Archive SAF ID** SAF ID of the user or group who owns the archived workflow. If you specify * for
the value, the policy is used as the universal policy, which manages all workflows
that do not comply with a predefined existing archive policy.

**Automatically Archive** Upon completion, the workflow will be automatically archived after the specified
amount of time.

**Archive Directory** Directory where the workflow will be archived.

**Comments** Specify information that you want to associate with this policy (up to 1,000
characters).

```
Note: Workflow instances without an Archive SAF ID will not be managed by any workflow archive policy.
```
```
Workflows task   19
```

```
Internal Job Statement tab
The Internal Job Statement tab provides a way to customize the internal default job statement used on a
remote system.
You can customize the default job statement for the TSO-REXX step execution on a remote system.
In general, this field requires no updates. However, if an error occurs when the temporary dataset is
created during the TSO-REXX step execution on the remote system due to the job statement, you can
customize the job card here. If this field is not set, workflow engine uses the following job card as a
default:
```
```
//WFxxxxx JOB MSGLEVEL=(1,1)
```
```
The job name consists of the characters WF followed by five random digits.
Note: z/OSMF performs only limited validation of the JOB statement. Therefore, you must ensure that the
JOB statement contains valid values for your installation.
```
### Viewing the properties of a workflow........................................................................................................

```
You can use the Properties for Workflow page in the Workflows task to view the properties of a workflow.
The content of this page is organized in tabs, as follows:
```
- The **General** tab includes information about the workflow. This tab is available for all workflows.
- The **Category Specific** tab, if active, lists additional information about the workflow. This tab is available
    for configuration workflows and provisioning workflows only; it is disabled for general workflows.
In z/OSMF, a workflow category is a classification of the activities that are to be performed in a
particular workflow. A workflow can belong to the _general_ category, or to a specific category, such as the
_configuration_ or _provisioning_ category. The category is specified by the workflow author in the workflow
definition file. If no category is specified for the workflow, the workflow belongs to the general category.
The fields on the **Properties for Workflow** page are described in “General properties of workflows” on
page 20 and “Category specific properties of workflows” on page 23.

#### General properties of workflows.........................................................................................................

```
You can use the General tab on the Properties for Workflow page to view the general properties for the
workflow. The general properties include the workflow name and description, the vendor that supplied
the workflow, the workflow version, ID, and category, the workflow owner, the system on which the
workflow is being performed, and the percentage and number of steps that are complete.
For a description of the items that are displayed on the General tab, see Table 10 on page 20.
```
```
Tip: If you are the workflow owner, you can use the Modify Workflow dialog to change the workflow
name or workflow owner. For information, see help topic “Modifying the information for a workflow” on
page 26.
```
**General tab**

```
You can use the General tab on the Properties for Workflow page to view the properties of a workflow.
Table 10 on page 20 lists and describes the fields included on the General tab.
```
```
Table 10. Fields on the Properties for Workflow page for the General tab
```
```
Field Description
```
```
Workflow name Name of the workflow. This value is supplied by the workflow creator. The
workflow name can be modified through the Modify Workflow dialog.
```
**20**   Workflows task


_Table 10. Fields on the_ **_Properties for Workflow_** _page for the General tab (continued)_

**Field Description**

**Description** Description of the workflow. z/OSMF obtains this value from the workflow
definition file when the workflow is created.

**Vendor** Name of the vendor that provided the workflow definition file. z/OSMF obtains this
value from the workflow definition file when the workflow is created.

**Version** Version of the workflow definition file that was used to create the workflow. z/
OSMF obtains this value from the workflow definition file when the workflow is
created.

**Category** Category to which the workflow is assigned. z/OSMF obtains this value from the
workflow definition file when the workflow is created.

**Workflow ID** Identifier for the workflow. z/OSMF obtains this value from the workflow definition
file when the workflow is created.

**Archive SAF ID** SAF ID who will own the archived workflow after a workflow is archived to a user
specified directory.

**Owner** User ID of the workflow owner. This value is supplied by the workflow creator.

**System** z/OS system on which the workflow is to be performed. This value is specified
when the workflow is created.

**Status** Indicates the workflow status. One of the following values is displayed:

```
In Progress
One or more steps in the workflow are started.
```
```
Automation in Progress
Workflow contains an automated step that is running.
```
```
Complete
Workflow is complete; all steps are marked either complete or skipped.
```
```
Canceled
Workflow is canceled and cannot be performed. You can, however, view its
properties or delete it.
```
```
Archived
Workflow is archived and cannot be performed. The workflow owner can view
its properties or delete it.
```
```
Workflows task   21
```

```
Table 10. Fields on the Properties for Workflow page for the General tab (continued)
```
```
Field Description
```
```
Is Callable Indicates whether the workflow can be called by another workflow, and, if so, the
callable range for the workflow. One of the following values is displayed:
In the same system
When called by another workflow, one instance of this workflow is used in
the local system. If an existing instance of the called workflow is not already
active, the Workflows task creates a new instance of the called workflow for
the system.
In the same sysplex
When called by another workflow, one instance of this workflow is used in the
sysplex. If an existing instance of the called workflow is not already active, the
Workflows task creates a new instance of the called workflow for the sysplex.
Cannot be called by another workflow
This workflow cannot be called by another workflow.
This column is hidden by default. To display it, use the Configure Columns action.
```
```
Percent complete Percentage of the workflow that is completed. z/OSMF calculates this value based
on the number of steps in the workflow and the relative weighting value of each
step. The weight is a value that represents the relative difficulty of the step, as
estimated by the workflow provider. Example: For a step in which the user must
simply cut and paste a command, the weight might be low. For a more complicated
task, such as deploying a digital certificate, the weight might be high.
To determine the Percent Complete value, z/OSMF uses the calculation b divided
by c where:
```
- _b_ is the total weighting of the completed steps (that is, the steps that are marked
    as Complete or Override Complete)
- _c_ is the total weighting of the all of the steps in the workflow. This amount
    excludes any steps that are marked as Skipped.
A parent step does not have a weight of its own and is therefore not part of the
Percent complete calculation.
z/OSMF updates the Percent Complete value whenever the table data is refreshed,
which occurs whenever you take any of the following actions:
- Navigates to this page from another workflow page
- Close a modal dialog when you are viewing this page
- Click **Refresh** to refresh the contents of the table.

```
Steps complete Number of steps that are complete for the workflow. z/OSMF calculates this value
based on the number of steps that are marked as Complete or Override Complete,
and excludes any steps that are marked as Skipped.
This value is shown in the form x of y where:
```
- _x_ is the count of completed steps
- _y_ is the count of the steps in the workflow (except for those steps that are
    marked as Skipped).
A parent step does not have a weight of its own and is therefore not part of the
Steps complete calculation.

**22**   Workflows task


```
Table 10. Fields on the Properties for Workflow page for the General tab (continued)
```
```
Field Description
```
```
Called by workflows Indicates whether the workflow is called for execution by any other, currently
active workflows in the sysplex. If so, the calling (or primary) workflows are listed
in this column. Otherwise, this field is blank.
```
```
Access Indicates the access type for the workflow. For more information, see “Workflow
access type” on page 32.
```
```
Contains Parallel Steps For a workflow with automated steps, this column indicates whether the
automated steps can be run in parallel (concurrently), thus possibly completing
more quickly. For a parallel-steps workflow, this field is Yes.
To start automation for a parallel-steps workflow, use the Start Parallel
Automation action in the Workflow Steps table.
Otherwise, if this field is No , automated steps are run one by one in the sequence
in which they appear in the workflow, starting from the top of the workflow
definition.
```
```
Delete workflow on
completion
```
```
Indicates whether the workflow is automatically deleted from the Workflows task
when all of its steps are marked complete or skipped. After a workflow is deleted,
it no longer appears in the Workflows table.
Otherwise, if this field is No , the workflow is retained until the user explicitly
deletes it from the Workflow table.
Note: A called workflow cannot be deleted until all of its calling workflows are
either deleted or archived.
```
```
System of workflow
definition file
```
```
Indicates the system that contains the workflow definition file.
```
```
Jobs output directory The user-specified directory for saving job output files. This field is not shown if no
jobs output directory is specified for the workflow.
```
```
Workflow definition file The path and file name for the workflow definition file that was used to create the
current instance of the workflow.
```
```
Related reference
```
#### Category specific properties of workflows..........................................................................................

```
For a workflow with a descriptive category, such as Configuration or Provisioning , you can use the
Category Specific tab on the Properties for Workflow page to view additional properties of the workflow.
For a general workflow, this tab is disabled.
Generate Feedback Summary page
For a workflow that includes feedback questions, the workflow owner is responsible for collecting the
feedback. When the step owners have provided the required feedback, the workflow owner can save the
accumulated feedback into a feedback file, which can be sent to the workflow vender for evaluation.
Notify Step Owners page
On the Notify Step Owners page, the workflow owner can see which steps have incomplete feedback.
From this page, you can send a reminder notification to step owners to complete the feedback. Users who
own more than one step will receive only one notification.
```
#### Category specific properties of workflows

```
For a workflow with a descriptive category, such as Configuration or Provisioning , you can use the
Category Specific tab on the Properties for Workflow page to view additional properties of the workflow.
For a general workflow, this tab is disabled.
This topic is organized, as follows:
```
```
Workflows task   23
```

- “Category specific properties of a configuration workflow” on page 24
- “Category specific properties of a provisioning workflow” on page 24

```
Category specific properties of a configuration workflow
Workflows that are intended to help configure system software, such as a product or component,
are classified as Configuration workflows. For a configuration workflow (the workflow category is
Configuration ), you can use the Category Specific tab on the Properties for Workflow page to view
additional properties of the workflow.
For a description of the items displayed on the Category Specific tab, see Table 11 on page 24.
```
```
Table 11. Fields on the Properties page for a configuration workflow
```
```
Field Description
```
```
Product name Name of the product or component that is being configured through the workflow.
z/OSMF obtains this value from the workflow definition file when the workflow is
created.
```
```
Product version Version of the product or component that is being configured through the
workflow. z/OSMF obtains this value from the workflow definition file when the
workflow is created.
```
```
Product ID Identifier of the product or component that is being configured through the
workflow, such as the product identifier (PID) or function modification identifier
(FMID). z/OSMF obtains this value from the workflow definition file when the
workflow is created.
```
**Category specific properties of a provisioning workflow**

```
Workflows that are intended to help provision z/OS middleware, such as a Db2 or IMS, are classified as
Provisioning workflows. Provisioning workflows are used with IBM Cloud Provisioning and Management
for z/OS. For a provisioning workflow (the workflow category is Provisioning ), you can use the Category
Specific tab on the Properties for Workflow page to view additional properties of the workflow.
For a description of the items displayed on the Category Specific tab, see Table 12 on page 24.
```
```
Table 12. Fields on the Properties page for a provisioning workflow
```
```
Field Description
```
```
Product name Name of the product or component that is being provisioned through the workflow.
z/OSMF obtains this value from the workflow definition file when the workflow is
created.
```
```
Product version Version of the product or component that is being provisioned through the
workflow. z/OSMF obtains this value from the workflow definition file when the
workflow is created.
```
```
Product ID Identifier of the product or component that is being provisioned through the
workflow, such as the product identifier (PID) or function modification identifier
(FMID). z/OSMF obtains this value from the workflow definition file when the
workflow is created.
```
```
Software Type Indicates the type of software to be provisioned.
```
```
Related reference
General properties of workflows
You can use the General tab on the Properties for Workflow page to view the general properties for the
workflow. The general properties include the workflow name and description, the vendor that supplied
```
**24**   Workflows task


```
the workflow, the workflow version, ID, and category, the workflow owner, the system on which the
workflow is being performed, and the percentage and number of steps that are complete.
```
#### Generate Feedback Summary page.....................................................................................................

```
For a workflow that includes feedback questions, the workflow owner is responsible for collecting the
feedback. When the step owners have provided the required feedback, the workflow owner can save the
accumulated feedback into a feedback file, which can be sent to the workflow vender for evaluation.
```
#### Notify Step Owners page......................................................................................................................

```
On the Notify Step Owners page, the workflow owner can see which steps have incomplete feedback.
From this page, you can send a reminder notification to step owners to complete the feedback. Users who
own more than one step will receive only one notification.
```
#### Generate Feedback Summary page

```
For a workflow that includes feedback questions, the workflow owner is responsible for collecting the
feedback. When the step owners have provided the required feedback, the workflow owner can save the
accumulated feedback into a feedback file, which can be sent to the workflow vender for evaluation.
On the Generate Feedback Summary page:
```
- Use the **Export** function to save the feedback file or download it to a workstation. The workflow owner
    provides the feedback file to the workflow vendor for evaluation.
- If workflow feedback is incomplete, the option **Notify Step Owners** is enabled. Click this option to
    open a page to display the step owners with incomplete feedback. If the feedback for the workflow is
    completed, this option is disabled.
**Related reference**
General properties of workflows
You can use the **General** tab on the **Properties for Workflow** page to view the general properties for the
workflow. The general properties include the workflow name and description, the vendor that supplied
the workflow, the workflow version, ID, and category, the workflow owner, the system on which the
workflow is being performed, and the percentage and number of steps that are complete.
Category specific properties of workflows
For a workflow with a descriptive category, such as _Configuration_ or _Provisioning_ , you can use the
**Category Specific** tab on the Properties for Workflow page to view additional properties of the workflow.
For a general workflow, this tab is disabled.
Notify Step Owners page
On the **Notify Step Owners** page, the workflow owner can see which steps have incomplete feedback.
From this page, you can send a reminder notification to step owners to complete the feedback. Users who
own more than one step will receive only one notification.

#### Notify Step Owners page

```
On the Notify Step Owners page, the workflow owner can see which steps have incomplete feedback.
From this page, you can send a reminder notification to step owners to complete the feedback. Users who
own more than one step will receive only one notification.
In the table Select Users to Notify , the step owners with incomplete feedback are listed.
For steps that have no owners, a window is displayed to list the steps. These steps must be assigned to
step owners before feedback can be completed for them.
Related reference
General properties of workflows
You can use the General tab on the Properties for Workflow page to view the general properties for the
workflow. The general properties include the workflow name and description, the vendor that supplied
the workflow, the workflow version, ID, and category, the workflow owner, the system on which the
workflow is being performed, and the percentage and number of steps that are complete.
Category specific properties of workflows
```
```
Workflows task   25
```

```
For a workflow with a descriptive category, such as Configuration or Provisioning , you can use the
Category Specific tab on the Properties for Workflow page to view additional properties of the workflow.
For a general workflow, this tab is disabled.
Generate Feedback Summary page
For a workflow that includes feedback questions, the workflow owner is responsible for collecting the
feedback. When the step owners have provided the required feedback, the workflow owner can save the
accumulated feedback into a feedback file, which can be sent to the workflow vender for evaluation.
```
### Modifying the information for a workflow.................................................................................................

```
To modify the information for a workflow, such as the workflow name or owner user ID, use the Modify
action that is provided in the Workflows table. This action is available only to the workflow owner.
```
**Procedure**

1. In the Workflows table, select the workflow to be modified. You can select only one workflow.
2. From the **Actions** menu or context menu, select **Modify**. The **Modify Workflow** page is displayed.
3. Modify the workflow, as needed.
    a) In the **Workflow name** field, enter a descriptive name for the workflow.
       The workflow name:
       - Must be unique in the Workflows task
       - Can contain up to 100 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @)
       - Must not contain the characters for ampersand ('&'), forward slash ('/'), greater than ('>'), or less
          than ('<').
       The workflow name is not case-sensitive; for example: MyWorkflow and MYWORKFLOW are the
       same workflow.
b) In the **Owner user ID** field, specify the user ID of the workflow owner. Select a user ID from the list,
which contains up to 10 previously specified user IDs. Otherwise, type the user ID as it is defined to
your installation's z/OS security management product, such as RACF. A valid user ID consists of one
to eight alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
The ability to change the workflow owner user ID is limited to the current workflow owner and
members of the z/OSMF workflow administrators group. In z/OSMF, the following resource name is
used to manage administrative access to workflows:

```
<saf-prefix> .ZOSMF.WORKFLOW.ADMIN
```
```
Information about creating authorizations for z/OSMF is provided in IBM z/OS Management Facility
Configuration Guide.
c) In the Archive SAF ID field, you can specify the SAF ID of the user or group who will own the
archived workflow after a workflow is archived to a user specified directory.
The specified SAF ID can be the workflow owner user ID or the group ID with which the workflow
owner user ID belongs to. This field defaults to the workflow owner user ID.
d) In the Comments field, you can enter any information that you want to associate with this action
(up to 500 characters). Your comment is added to the existing comments in the workflow history.
The workflow history includes comments for all of the actions that were performed in the workflow,
recorded at the time each action was taken.
You might use this field to enter a meaningful comment to document this modification, for example:
Changed the workflow name, as per the new process.
e) Optionally, specify an Access type for the workflow. This value indicates what the user is permitted
to see and modify in the various sections of the workflow. For more information, see “Workflow
access type” on page 32.
```
**26**   Workflows task


```
f) If the Save jobs output option is enabled, the workflow automatically saves any job output files
that it creates to a user-specified location (the jobs output directory).
Use this option if you want to retain the output files, perhaps as a record of the work that is done
by the workflow. If this field is preset to a location, you can overwrite the value with a different
location, as needed. The specified location must be a valid UNIX file path and directory, beginning
with a single forward slash ('/'). For example: /u/IBMUSER/jobFiles.
Ensure that:
```
- File path and directory exist on the system on which the workflow steps are to be performed.
- Workflow owner user ID has write access to the directory.
- For the steps that create job output, ensure that the step owner user IDs have write access to the
    UNIX directory. Otherwise, the steps cannot be performed.
If the **Save jobs output** option is not enabled, you cannot specify a jobs output directory.
You cannot change the system name on this page. To change the system name for a workflow, you
must create a new workflow from the same workflow definition file and select a different system
name.
4. Click **OK** to save your changes.

### Creating a workflow...................................................................................................................................

```
To create a workflow, use the Create Workflow action that is provided in the Workflows table.
```
```
Before you begin
Obtain the fully qualified file name for the workflow definition file to be used for creating the workflow.
Also, if a workflow variable input file was supplied by the workflow provider, obtain the fully qualified
name of the file.
If these files were used previously by you or another z/OSMF user, you might find the file names to be
listed in the dialog menu. Otherwise, you must enter these values as input to the dialog, as described in
the procedure that follows.
Your user ID requires at least READ authority to the workflow definition file and the workflow variable
input file.
```
**Procedure**

1. From the **Actions** menu, select **Create Workflow**. The **Create Workflow** dialog is displayed.
    a) In the **Location (system)** field, select the system on which the workflow definition file and any
       related files reside. The Workflows task obtains the workflow files from this system.
       This field is a pull-down list of the z/OS systems that run z/OSMF. The list can include systems from
       the local sysplex and from remote sysplexes. If the pull-down list includes remote systems, the
       word _-Local_ is appended to the name of the local system on which z/OSMF is running. Otherwise, if
       the list contains no remote systems, the word _-Local_ is omitted from the name of the local system.
       For the local sysplex, only the currently logged-in system is included in the list. For a remote
       sysplex, all host systems that are defined to the Systems table are included in the list. You can view
       the Systems table in the Systems task.
       You cannot type over the system names. This field defaults to the local z/OS system on which
       z/OSMF is running.
b) Select a workflow definition file from the list, or type the name of a workflow definition file that
resides on the z/OS system on which z/OSMF is running.
Observe the following considerations:
- If the workflow definition file resides in a data set member, enter or select the fully qualified data
set name, including the member name. Ensure that this data set is cataloged. It is not necessary

```
Workflows task   27
```

```
to enclose the data set name in single quotation marks; z/OSMF ignores the quotation marks if
you include them.
```
- If the workflow definition file resides in a z/OS UNIX file, enter or select the fully qualified
    path name of the file, beginning with the forward slash (/) and including the file name. For
    example: /usr/lpp/zosmf/samples/workflow_sample_basic.xml.
If the workflow definition file resides on the local system, you can locate it with a type-ahead
search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for
a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
attempts to find a matching data set name.
When you select an object from the type-ahead list, the object populates the workflow definition
file input-box.
The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
pattern, a record at the end of the list indicates that some records are not displayed. To display all
objects in the results area, click **Display All**.
A step element contains a stepSignature element, which is not supported in a definition file from
the remote system.
c) If a workflow variable input file is available for the workflow, select the workflow variable input file
from the list, or type the name of the file as it resides on the z/OSMF host system. If no workflow
variable input file is available, leave this field blank.
Observe the following considerations:
- Usually, a workflow variable input file is provided by the workflow provider, or is produced as
output from another step in the workflow, or from another workflow. To obtain the name of
the workflow variable input file, refer to the workflow documentation or contact the workflow
provider.
- If the workflow variable input file resides in a data set member, enter or select the fully qualified
data set name, including the member name. Ensure that this data set is cataloged.
- If the workflow variable input file resides in a z/OS UNIX file, enter or select the fully qualified file
path, beginning with the forward slash (/) and including the file name. For example: /usr/lpp/
zosmf/samples/workflow_sample_automation_property.txt.
If the workflow variable input file resides on the local system, you can locate it with a type-ahead
search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for
a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
attempts to find a matching data set name.
When you select an object from the type-ahead list, the object populates the workflow variable
input file input-box.
The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
pattern, a record at the end of the list indicates that some records are not displayed. To display all
objects in the results area, click **Display All**.
d) To continue, click **Next**.
If you selected a system in a remote sysplex, z/OSMF checks your access to the remote system.
If the remote system is not enabled for single sign-on (SSO), the **Remote Server Authentication**
window is displayed for you to authenticate to the remote system. If so, enter a valid user ID
and password or passphrase for the remote system. You can avoid the authentication window by
ensuring that the remote system is enabled for single sign-on (SSO) in the z/OSMF Systems task.
For more information, see Defining your systems to z/OSMF.
If z/OSMF detects a conflict in the inputs variables file, a dialog is shown to prompt for a user
selection. For more information, see “Resolving a conflict in variable definitions” on page 31.
e) Complete the following steps:

**28**   Workflows task


```
i) In the Workflow name field, enter a descriptive name for the workflow. If the workflow
definition specifies a default name for the workflow, it is shown here. Otherwise, the Workflows
task initializes this field to a predetermined name for the workflow, based on the following
convention:
```
```
< workflow-description >–Workflow_< number >
```
```
Where:
```
- _workflow-description_ is the description from the workflow definition file.
- _number_ is the first available number, beginning at 0. If you later delete this workflow, its
    number can be reused by the Workflows task.
You can accept this name, or enter a name of your own choosing. The workflow name:
- Must be unique in the Workflows task.
- Can contain up to 100 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
- Must not contain the characters for ampersand ('&'), forward slash ('/'), greater than ('>'), or
    less than ('<').
The workflow name is not case-sensitive; for example: MyWorkflow and MYWORKFLOW are the
same workflow.
ii) In the **Owner user ID** field, specify the user ID of the person who holds the overall
responsibility for completing the workflow. Select a user ID from the list, which contains up
to 10 previously specified user IDs. Otherwise, type the user ID as it is defined to your z/OS
security management product, such as RACF. A valid user ID consists of 1 to 8 alphanumeric
characters (A-Z, a-z, 0-9, #, $, and @).
This field defaults to your user ID.

iii) In the **Archive SAF ID** field, you can specify the SAF ID who will own the archived workflow
after a workflow is archived to a user specified directory. Select a SAF ID from the list,
otherwise, type the SAF ID in the field. A valid ID consists of 1 to 8 alphanumeric characters
(A-Z, a-z, 0-9, #, $, and @). The specified SAF ID can be the workflow owner user ID or the
group ID with which the workflow owner user ID belongs to.
This field defaults to the workflow owner user ID.

iv) In the **System (where z/OSMF steps will be performed)** field, select a target system for
creating the workflow. The workflow steps are performed on this system. Any jobs or scripts
in the workflow are run on this system. Similarly, any work that you perform manually for the
workflow is done on this system.
This field is a pull-down list of systems that are defined in the z/OSMF Systems task. The list
can include systems in the local sysplex and remote sysplexes.
If you select a system in a remote sysplex:

- If the system is running z/OSMF, verify that the system is enabled for single sign-on (SSO).
    Otherwise, the **Remote Server Authentication** window is displayed for you to authenticate
    to the remote system when you perform the steps. You can avoid the authentication window
    by ensuring that the remote system is enabled for single sign-on (SSO) in the z/OSMF
    Systems task. For more information, see Defining your systems to z/OSMF.
- If the system is not running z/OSMF, it must be associated with the z/OSMF system for
    that sysplex. If so, set the z/OSMF system as the host system for the system on which
    the workflow is to be performed. Similarly, you must ensure that the z/OSMF system in the
    remote sysplex is enabled for single sign-on. Or, you must be ready to authenticate to the
    system with a valid user ID and password or passphrase.
For more information about defining z/OSMF systems and enabling them for single sign-on, see
Defining your systems to z/OSMF.

```
Workflows task   29
```

```
You cannot type over the system names. The field defaults to the z/OS system on which
z/OSMF is running.
v) In the Comments field, you can enter any information that you want to associate with this
action (up to 500 characters). Your comment is added to the existing comments in the
workflow history.
vi) Optionally, specify an Access type for the workflow. For more information about access type,
see “Workflow access type” on page 32.
vii) If the Save jobs output option is enabled, the workflow automatically saves any job output
files that it creates to a user-specified location (a UNIX directory on your system). Use this
option if you want to retain the output files, perhaps as a record of the work that is done by
the workflow. If this field is preset to a location, you can overwrite the value with a different
location, as needed. The specified location must be a valid UNIX file path and directory,
beginning with a single forward slash ('/'). For example: /u/IBMUSER/jobFiles.
Ensure that:
```
- File path and directory exist on the system on which the workflow steps are to be performed.
- Workflow owner user ID has write access to the directory.
- For the steps that create job output, ensure that the step owner user IDs have write access to
    the UNIX directory. Otherwise, the steps cannot be performed.
If the **Save jobs output** option is not enabled, the workflow does not save its job output files.
viii) Select **Open workflow on finish** if you want to go to the **Steps** page for the workflow on
completion of create workflow action. Otherwise, clear this option. By default, this option is
selected.
ix) Select **Assign all steps to owner user ID** if you want all of the steps to be assigned to
and accepted by you, the workflow owner, on creation of the workflow. Otherwise, leave this
checkbox cleared (the default).
x) Select **Delete workflow on completion** if you want the workflow to be automatically deleted
from the Workflows task when all of its steps are marked complete or skipped. When a
workflow is deleted, it no longer appears in the Workflows table. You might use this option to
avoid reaching the limit of 200 workflows per system.
If you want to retain the workflow after it is complete, leave this checkbox cleared (the
default). The workflow is retained until you explicitly delete it from the Workflow table.
**Note:** A called workflow cannot be deleted until all of its calling workflows are either deleted or
archived.
For your reference, this window includes the following details about the workflow to be created,
which z/OSMF obtains from the workflow definition file:
**Description**
Description of the function that the workflow provides.
**Vendor**
Name of the vendor that provided the workflow definition.
**Version**
Version of the workflow definition.
**Is Callable**
Indicates whether the workflow can be called by another workflow, and, if so, the callable range
for the workflow. One of the following values is displayed:
**In the same system**
When called by another workflow, one instance of this workflow is used in the local system.
If an existing instance of the called workflow is not already active, the Workflows task
creates a new instance of the called workflow for the system.

**30**   Workflows task


```
In the same sysplex
When called by another workflow, one instance of this workflow is used in the sysplex. If an
existing instance of the called workflow is not already active, the Workflows task creates a
new instance of the called workflow for the sysplex.
Cannot be called by another workflow
This workflow cannot be called by another workflow.
```
2. Click **Finish** to create the workflow.

```
Results
If you selected Open workflow on finish , the Steps page for the new workflow is displayed. Otherwise,
the workflow is displayed in the Workflows table on the Workflows page.
```
#### Resolving a conflict in variable definitions..........................................................................................

```
When you import a workflow variable input file, the Workflows task reads in the contents of the file and
saves its values for use with the created workflow. The Workflows task uses the variable input file in
addition to any global variables that are already defined to Workflows task.
If the Workflows task detects that an imported variable conflicts with an existing global variable, you are
prompted to choose the appropriate value. Your selection determines which version of the variable is to
be saved in the Workflows task global variable pool.
For any variable conflicts that are detected, the Workflows task displays the Global Variables table to
prompt for your selections. Table 13 on page 31 describes the columns in the Global Variables table.
```
```
Table 13. Columns in the Global Variables table
```
```
Column Description
```
```
Use Input File Value To use the input file value in place of the global variable, select the check box.
The Workflows task updates the global variable with the new value. Any other
workflows that refer to the variable use the updated value.
```
```
Variable Name The name of the variable in conflict. This name was found to be specified in
both the input file and the Workflows task global variable pool.
```
```
Variable Abstract The short description of the variable, as supplied in the workflow variable
input file.
```
```
Existing Value The value of the variable, as currently set by the global variable. For an array
variable, which can consist of many elements, only the first 20 characters of
the value are shown.
```
```
Input File Value The value of the variable, as supplied in the workflow variable input file.
For an array variable, which can consist of many elements, only the first 20
characters of the value are shown.
```
```
In the Global Variables table, select which input file variables are to be used in place of existing global
variables. To ignore an input file variable, and instead use the existing global variable, leave the check box
cleared. To preserve the existing global variable definitions, no check boxes are selected, by default.
Updating a global variable affects any other workflows that reference the same variable.
Related concepts
Workflow access type
```
```
Workflows task   31
```

```
This topic describes the workflow access type , which is used to control what the user is permitted to see
and modify in various sections of the workflow. The access type is specified at workflow creation time by
the workflow owner.
```
#### Workflow access type..........................................................................................................................

```
This topic describes the workflow access type , which is used to control what the user is permitted to see
and modify in various sections of the workflow. The access type is specified at workflow creation time by
the workflow owner.
When you create a workflow instance, you can optionally specify an access type for the workflow.
Generally, a workflow with a public access type is less restricted in the amount of data that is available to
the user. A workflow with a restricted or private access type is more secure, and requires the user to be a
workflow owner, step owner, or step assignee to access or modify particular areas in the workflow.
The effects of the valid access types can be summarized, as follows:
Public
Workflow information and step information can be viewed by all z/OSMF users.
Restricted
Workflow information and step information is restricted to a subset of users—the workflow owner,
step owners, and step assignees. Other users cannot access this information.
Private
Workflow information is restricted to a subset of users, and is further limited among these users.
Workflow information is accessible to the workflow owner. The steps information is accessible to the
step owner and step assignees for the particular step. Other users cannot access this information.
If you do not specify an access type, the default is public.
For details about the effects of each access type, see the following topics:
```
- “Controlling access to workflows and steps” on page 32
- “Controlling access to workflow notes and step notes” on page 34.

**Controlling access to workflows and steps**

```
In the Workflows table, the list of workflows is limited by the access type of the workflow. Workflows with
a public access type are visible to all z/OSMF users. To view a restricted or private access type workflow in
the Workflows task, however, the user must be a workflow owner, step owner, or step assignee.
Within a workflow, the access type determines the user’s ability to read or modify the following types of
information about the workflow:
```
- General workflow information. This data includes workflow title, name, owner, number of steps,
    assignees, status, skills, weight, auto enabled status, and whether the workflow calls another workflow
    for processing.
- General information about steps. This data includes the information that is provided in the tabs:
    "General," "Details," "Dependencies," and "Notes."
- Details about the steps. This data includes the information that is shown in the tabs "Perform," "Status"
    and "Input variables," and includes variables values, JCL, and so on.
The following tables summarize the effects of access type on the users of a workflow:
- Table 14 on page 33
- Table 15 on page 33
- Table 16 on page 33.
**Public access:** Table 14 on page 33 lists the information that is accessible to users of a public workflow.

**32**   Workflows task


```
Table 14. Information that is available to users of a public workflow
```
```
User Information that is accessible to the user
```
```
Workflow owner • General workflow information
```
- All of the steps information (common, general, and details).

```
Step owner or
assignee
```
- General workflow information
- For steps that are owned by, or assigned to the user, the user can access all of the
    steps information (common, general, and details).
- For other steps, the user can access the step common information and the
    general information. The user cannot access the details for other steps, however.

```
Others callers • General workflow information
```
- Step common information and the general restricted information. The user cannot
    access the details for other steps, however.

**Restricted access:** Table 15 on page 33 lists the information that is accessible to users of a restricted
workflow.

```
Table 15. Information that is available to users of a restricted workflow
```
```
User Information that is accessible to the user
```
```
Workflow owner • General workflow information
```
- All of the steps information (common, general, and details).

```
Step owner or
assignee
```
- General workflow information
- For steps that are owned by, or assigned to the user, the user can access all of the
    steps information (common, general, and details).
- For other steps, the user can access the step common information and the
    general information. The user cannot access the details for other steps, however.

```
Others callers • Cannot access the general workflow information
```
- Cannot access any of the step information.

**Private access:** Table 16 on page 33 lists the information that is accessible to users of a private
workflow.

```
Table 16. Information that is available to users of a private workflow
```
```
User Information that is accessible to the user
```
```
Workflow owner • General workflow information
```
- All of the steps information (common, general, and details).

```
Step owner or
assignee
```
- General workflow information
- For steps that are owned by, or assigned to the user, the user can access all of the
    steps information (common, general, and details).
- For other steps, the user can access the step common information. Cannot access
    other information for other steps.

```
Others callers • Cannot access the general workflow information
```
- Cannot access any of the step information.

```
Workflows task   33
```

```
Controlling access to workflow notes and step notes
When you specify an access type for a workflow, you control user access to workflow notes and step
notes. A workflow with a public access type imposes no restrictions on who can view the workflow notes
and step notes. A workflow with a restricted or private access type is more secure, and requires the user
to be a workflow owner, step owner, or step assignee to view or modify notes.
The effects of access type on user access to notes is described, as follows:
Public
The workflow notes and step notes can be viewed by all z/OSMF users. Only the workflow owner, step
owners and step assignees can modify the workflow notes.
Restricted
The workflow notes and step notes can be viewed only by the workflow owner, step owners, and step
assignees. Only the workflow owner can modify workflow notes. The workflow owner, step owner, or
step assignees can view all of the step notes.
Private
The workflow owner can view all workflow notes and step notes. Only the workflow owner can modify
workflow notes. The step notes can be viewed only by the step owner or step assignees for the
particular step.
Related information
Resolving a conflict in variable definitions
When you import a workflow variable input file, the Workflows task reads in the contents of the file and
saves its values for use with the created workflow. The Workflows task uses the variable input file in
addition to any global variables that are already defined to Workflows task.
```
### Upgrading a workflow................................................................................................................................

```
To upgrade an existing workflow to a new level of the workflow definition, use the action Create New
Based on Existing , which is provided in the Workflows table. When you upgrade a workflow, you create
a new instance of the workflow, while you retain your data from the existing workflow. This action is
available to the workflow owner only.
```
**Before you begin**

```
Obtain the fully qualified file name for the workflow definition file to be used for upgrading the workflow.
If this file was used previously, you might find that the file name is included in the dialog menu.
Otherwise, you must enter this value as input to the dialog, as described in the procedure that follows.
Your user ID requires at least READ authority to the workflow definition file.
```
```
About this task
Use this action to create a new instance of a workflow, based on an existing instance of the same
workflow. On completion of this action, the new workflow is available to be performed, and the old
workflow is saved in the Canceled state for your reference. You cannot use this action to create a new
workflow that is not based on an existing workflow.
Use this action for a workflow in the In Progress state or the Complete state. You cannot upgrade a
workflow that is in one of the following states:
```
- _Deleted_
- _Canceled_
- _Automation in Progress_
- _Locked_.
You cannot upgrade a workflow that is called for processing by another workflow. Also, if you upgrade
a workflow that calls another workflow, be aware that z/OSMF removes the calling relationship during

**34**   Workflows task


the upgrade process. You cannot reestablish the calling relationship by reactivating the prior (canceled)
workflow.

**Procedure**

1. In the **Workflows** table, select the workflow to be upgraded.
    You can select one workflow only.
2. From the **Actions** menu or context menu, select **Create New Based on Existing**.
    In this dialog, you specify the version of the workflow definition file to be used, and which data, if any,
    is to be passed to the upgraded workflow.
       a) In the **Location (system)** field, select the system on which the workflow definition file and any
          related files reside. The Workflows task will obtain the workflow files from this system.
          This field is a pull-down list of the z/OS systems that run z/OSMF. The list can include systems from
          the local sysplex and from remote sysplexes. If the pull-down list includes remote systems, the
          word _-Local_ is appended to the name of the local system on which z/OSMF is running. Otherwise, if
          the list contains no remote systems, the word _-Local_ is omitted from the name of the local system.
          For the local sysplex, only the currently logged-in system is included in the list. For a remote
          sysplex, all host systems that are defined to the Systems table are included in the list. You can view
          the Systems table in the Systems task.
          You cannot type over the system names. This field defaults to the local z/OS system on which
          z/OSMF is running.
b) Select a workflow definition file from the list, or type the name of a workflow definition file that
resides on the z/OS system on which z/OSMF is running.
Observe the following considerations:
- If the workflow definition file resides in a data set member, enter or select the fully qualified data
set name, including the member name. Ensure that this data set is cataloged. It is not necessary
to enclose the data set name in single quotation marks; z/OSMF ignores the quotation marks if
you include them.
- If the workflow definition file resides in a z/OS UNIX file, enter or select the fully qualified
path name of the file, beginning with the forward slash (/) and including the file name. For
example: /usr/lpp/zosmf/samples/workflow_sample_basic.xml.
If the workflow definition file resides on the local system, you can locate it with a type-ahead
search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for
a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
attempts to find a matching data set name.
When you select an object from the type-ahead list, the object populates the workflow definition
file input-box.
The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
pattern, a record at the end of the list indicates that some records are not displayed. To display all
objects in the results area, click **Display All**.
       c) To continue, click **Next**.
          If you selected a system in a remote sysplex, z/OSMF checks your access to the remote system.
          If the remote system is not enabled for single sign-on (SSO), the **Remote Server Authentication**
          window is displayed for you to authenticate to the remote system. If so, enter a valid user ID
          and password or passphrase for the remote system. You can avoid the authentication window by
          ensuring that the remote system is enabled for single sign-on (SSO) in the z/OSMF Systems task.
          For more information, see Defining your systems to z/OSMF.
d) In the **New workflow name** field, enter a descriptive name for the workflow.

```
Workflows task   35
```

```
If the workflow definition specifies a default name for the workflow, it is shown here. Otherwise,
the Workflows task initializes this field to a predetermined name for the workflow, based on the
following convention:
```
```
< workflow-description >–Workflow_< number >
```
```
Where:
```
- _workflow-description_ is the description from the workflow definition file
- _number_ is the first available number, beginning at 0. If you later delete this workflow, its number
    can be reused by the Workflows task.
You can accept this name, or enter a name of your own choosing. The workflow name:
- Must be unique in the Workflows task.
- Can contain up to 100 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
- Must not contain the characters for ampersand ('&'), forward slash ('/'), greater than ('>'), or less
    than ('<').
The workflow name is not case-sensitive; for example: MyWorkflow and MYWORKFLOW are the
same workflow.
e) In the **System (where workflow steps will be performed)** field, select a target system for creating
the workflow. The workflow steps are performed on this system. Any jobs or scripts in the workflow
are run on this system. Similarly, any work that you perform manually for the workflow is done on
this system.
This field is a pull-down list of systems that are defined in the z/OSMF Systems task. The list can
include systems in the local sysplex and remote sysplexes.
If you select a system in a remote sysplex:
- If the system is running z/OSMF, verify that the system is enabled for single sign-on (SSO).
Otherwise, the **Remote Server Authentication** window is displayed for you to authenticate to
the remote system when you perform the steps. You can avoid the authentication window by
ensuring that the remote system is enabled for single sign-on (SSO) in the z/OSMF Systems task.
For more information, see Defining your systems to z/OSMF.
- If the system is not running z/OSMF, it must be associated with the z/OSMF system for that
sysplex. If so, set the z/OSMF system as the host system for the system on which the workflow
is to be performed. Similarly, you must ensure that the z/OSMF system in the remote sysplex is
enabled for single sign-on. Or, you must be ready to authenticate to the system with a valid user
ID and password or passphrase.
For more information about defining z/OSMF systems and enabling them for single sign-on, see
Defining your systems to z/OSMF.
You cannot type over the system names. This field defaults to the z/OS system on which z/OSMF is
running.
f) Specify the upgrade options:
i) Select **Copy variable values based on upgrade definition** if you want to copy the variable
values from the current workflow. This option is selected by default; all variable values are
copied to the upgraded workflow.
ii) Select **Copy workflow notes** to retain any notes that might exist in the current workflow.
iii) Select **Copy workflow history** to retain the history records from the current workflow.
iv) Under **Step attributes** :
- Select **Copy step attributes based on upgrade definition** if you want to copy the step
attributes from the current workflow. If so, the current workflow step attributes are carried
over to the upgraded workflow, including the step assignees, step owners, step states, history,
notes, submitted job status, and the record of how variable conflicts, if any, were resolved.
This option is selected by default; all step attributes are copied to the upgraded workflow.

**36**   Workflows task


- Select **Assign all steps to owner user ID** if you want all of the steps to be assigned to
    and accepted by you, the workflow owner, on completion of the upgrade workflow action.
    Otherwise, leave this checkbox cleared (the default).
- Select **No copy and assign** if you do not want to copy the step attributes from the current
    workflow.
v) Select **Open workflow on finish** if you want to go to the **Steps** page for the workflow on
completion of the upgrade workflow action. Otherwise, clear this option. By default, this option
is selected.
vi) Select **Delete workflow on completion** if you want the workflow to be automatically deleted
from the Workflows task when all of its steps are marked complete or skipped. When a workflow
is deleted, it no longer appears in the Workflows table. You might use this option to avoid
reaching the limit of 200 workflows per system.
If you want to retain the workflow after it is complete, leave this checkbox cleared (the default).
The workflow is retained until you explicitly delete it from the Workflow table.
**Note:** A called workflow cannot be deleted until all of its calling workflows are either deleted or
archived.

For your reference, this window includes the following details about the workflow to be created,
which z/OSMF obtains from the workflow definition file:

**Upgrade notes**
Information about the new workflow definition file, such as usage notes.

**Workflow definition file**
File name of the workflow definition file.

**Version**
Version of the workflow definition that was used to create the current workflow.

**Upgrade version**
Version of the new workflow definition; this version is used to upgrade the current workflow.

**Description**
Description from the workflow definition file.

**Owner**
User ID of the workflow owner.

**Location (system)**
z/OS system that contains the workflow definition and related files.

**Percent complete**
Percentage of the workflow that is completed.z/OSMF calculates this value, which is based on
the number of steps in the workflow and the relative weighting value of each step.

**Archive SAF ID**
SAF ID of the user or group who will own the archived workflow after a workflow is archived to a
user specified directory.

**Steps complete**
Number of steps in the workflow that are complete of the total number of steps in the workflow.

**Status**
Indication of the current workflow status. One of the following values is displayed:

```
In Progress
One or more steps in the workflow are started.
```
```
Automation in Progress
Workflow contains an automated step that is running.
```
```
Complete
Workflow is complete; all steps are marked complete or skipped.
```
```
Workflows task   37
```

```
Locked
Workflow is locked for an update operation.
```
```
Canceled
Workflow is canceled and cannot be performed. However, you can view its properties or
delete it.
```
```
Archived
Workflow is archived and cannot be performed. The workflow owner can view its properties
or delete it.
Access
Access type of the workflow. This value indicates what the user is permitted to see and modify
in the various sections of the workflow.
One of the following values is displayed:
```
```
Public
The workflow notes, steps, and step notes can be viewed by all z/OSMF users.
```
```
Restricted
The workflow notes, steps, and step notes can be viewed only by the workflow owner, step
owners, and step assignees.
```
```
Private
The workflow notes can be viewed by the workflow owner. The steps and step notes can be
viewed only by the step owner or step assignees for the particular step.
Save jobs output
If this option is enabled, the workflow automatically saves any job output files that it creates
to a user-specified location (the jobs output directory). Use this option if you want to retain the
output files, perhaps as a record of the work that is done by the workflow. If this field is preset
to a location, you can overwrite the value with a different location, as needed. The specified
location must be a valid UNIX file path and directory, beginning with a single forward slash ('/').
For example: /u/IBMUSER/jobFiles.
Ensure that:
```
- File path and directory exist on the system on which the workflow steps are to be performed.
- Workflow owner user ID has write access to the directory.
- For the steps that create job output, ensure that the step owner user IDs have write access to
    the UNIX directory. Otherwise, the steps cannot be performed.
If the **Save jobs output** option is not enabled, you cannot specify a jobs output directory.
3. Click **Finish** to upgrade the workflow with the specified workflow definition file.

**Results**

```
A workflow is created with the new structure of specified workflow definition file. If you selected Open
workflow on finish , the Steps page for the upgraded workflow is displayed. Otherwise, the workflow is
displayed in the Workflows table on the Workflows page.
The previous workflow is shown in the Workflows table on the Workflows page with the Canceled status.
Note: Consider retaining the previous workflow in your system until you are certain that the upgraded
workflow is sufficient for your needs. If necessary, you can reactivate the canceled workflow as a
potential fall-back measure. If so, you are prompted to specify a new name for the reactivated workflow
to avoid a naming conflict with the current workflow.
```
**38**   Workflows task


### Reactivating a canceled workflow.............................................................................................................

```
You can reactivate a workflow that you canceled previously. To do so, use the Reactivate action that is
provided in the Workflows table. This action is available to the workflow owner only.
```
**Procedure**

1. In the **Workflows** table, select the canceled workflow that you want to reactivate.
2. From the **Actions** menu or context menu, select **Reactivate**. The Reactivate Workflow dialog is
    displayed.
3. In the _Workflow name_ field, specify a new name for the reactivated workflow. This step is necessary to
    avoid a naming conflict with the currently active workflow.
4. Click **OK** to reactivate the selected workflow.

**Results**

```
The reactivated workflow is displayed in the Workflows table on the Workflows page with the specified
name.
Note: If the workflow previously called other workflows, z/OSMF removed the calling relationship when
the workflow was canceled. You cannot reestablish the calling relationship by reactivating the canceled
workflow.
```
### Updating a workflow with custom steps...................................................................................................

```
You can add your own steps to a workflow. To do so, use the Update Workflow Steps action that is
provided in the Workflows table. You can use this dialog to tailor a workflow with steps that you design
specifically for your installation. If you later decide to modify or remove a previously added step, you can
do so by using this dialog. This action is available to the workflow owner only.
```
```
Before you begin
Before you follow this procedure, ensure that no other users require the workflow. During an update
operation, the workflow becomes locked from other users.
```
**Procedure**

1. In the **Workflows** table, select the workflow to be updated.
    You can select one workflow only.
2. From the **Actions** menu or context menu, select **Update Workflow Steps**. A warning message is
    displayed with the name of the workflow to by updated.
3. Click **OK** to continue.
    The **Workflow Steps** table is displayed.
4. In the **Workflows Steps** table, indicate where the new step is to be added by selecting an existing
    step that will either immediately precede or follow the new step.
5. From the **Actions** menu or context menu, select either **Insert Step Above** or **Insert Step Below** to
    indicate where the new step is to be placed in relation to the selected step.
    The Insert Step dialog is displayed.
6. Input the general information:
    a) In the **Step Title** field, specify a title for the step.
       This value is required.
       Up to 100 characters can be specified.
    b) In the **Step Description** field, describe the function of the step.
       This value is required.

```
Workflows task   39
```

```
Up to 300 characters can be specified.
c) In the Step Skill field, specify the skill that is needed to perform the step.
This value is optional.
For example: system programmer or security administrator
d) In the Step Weight field, specify the relative difficulty of the step (a positive integer value 1 -
1000).
This value is required.
The Workflows task uses this value in the calculation of the percentage-complete value that is
displayed as the workflow is performed. The scale is arbitrary; specify it at your discretion. Specify
a lesser value for a step in which the user performs a simple action. For a more complicated task,
specify a greater value.
```
7. To continue, click **Next**.
8. Specify the instructions:
    a) Specify the instructions for performing the step.
       This value is required.
       The instructions field is initialized with an example, which you can type over.
9. If the step does not run a program (it is a manual step), click **Finish** to add the step to the workflow.
    Otherwise, to define a program to be run by the step, click **Next** to continue.
10. Select the type of program to be run by the step.
The following choices are available:
**JCL**
A job is created to run JCL language statements.
**TSO_REXX_JCL**
A job is created to run a REXX exec program.
**SHELL_JCL**
A job is created to run a UNIX shell script.
11. To continue, click **Next**.
12. Enter the code for the program to be run.
Ensure that the code is syntactically correct.
13. Click **Finish** to update the workflow with the specified step.

```
Results
The Steps page for the updated workflow is displayed, showing the new step.
```
**What to do next**

```
If you later decide to modify or remove a previously added step, you can do so by using this dialog.
Choose either the Modify Step or Remove Steps action, as needed.
```
### Customizing the JOB statement for workflows on your system...............................................................

```
In the Select JOB Statement to Modify dialog, you can view the common JOB statement for workflows
on this system. You can use the dialog to modify the current JOB statement or select another JOB
statement to be used instead. Your changes are applicable to all workflows on the system.
```
**Procedure**

1. From the **Actions** menu, select **Customize JOB Statement**. The **Select JOB Statement to Modify**
    window is displayed.
       a) Select a JOB statement to modify.

**40**   Workflows task


```
The default JOB statement for the Workflows task is always displayed. If you previously customized
other JOB statements in the Workflows task, the customized JOB statements are listed in the
Selected JOB statement field. If so, you can select a customized JOB statement to modify and use
instead of the default JOB statement.
b) To remove a customized JOB statement from the list, select the statement and click Remove.
c) To save your selection and continue, click OK.
```
2. In the **Customize JOB statements** window, edit the contents of the selected JOB statement.
    The JOB statement is used for any jobs that are generated by workflows.
    z/OSMF performs only limited validation of the JOB statement. Therefore, you must ensure that the
    JOB statement contains valid values for your installation.
    For more information about specifying values for a JCL JOB statement, see z/OS MVS JCL Reference.
       a) To undo your changes and reset the JOB statement to the previously saved content, click **Undo**.
3. When you finish editing the JOB statement, determine the systems to which the changes apply. By
    default, your changes are applied to the z/OS system on which z/OSMF is running. To select other
    systems, click **Select** to display a list of systems that are defined to the Workflows task.
       a) Select the systems to which the JOB statement is to be applied.
b) To save your selection, click **OK**.
4. To save your changes to the JOB statement, click **OK**.

```
Results
The customized JOB statement is applied to any active workflows on the systems that you selected.
```
### Working with archived workflows..............................................................................................................

```
You can archive any workflows that you no longer need. Doing so removes the workflow from the
Workflows table and places it in an archive for your reference. An archived workflow is no longer active,
but its information can be viewed at any time. When you no longer want to retain an archived workflow,
you can delete it permanently from z/OSMF. You can archive an unlimited number of workflows.
The archive-related actions are available to the workflow owner only.
When a workflow is archived, z/OSMF sends a notification of the archive action to the users who are step
owners for the workflow.
The following topics describe the procedures to use:
```
- “Archiving an in-progress workflow” on page 41
- “Archived Workflows page” on page 42.

#### Archiving an in-progress workflow......................................................................................................

```
To archive a currently active workflow, use the Archive action that is provided in the Workflows table. This
action is available to the workflow owner only.
```
**About this task**

```
After you archive a workflow, you can view or delete it, or browse the workflow properties. You cannot
undo this action.
You can archive an unlimited number of workflows.
To be archived, a workflow must be in one of the following states:
```
- In-progress
- Complete
- Canceled.

```
Workflows task   41
```

```
It is not possible to archive a workflow while it is involved in a workflow activity. To do so, you must allow
the processing to complete first.
Specifically, you cannot archive a workflow when it:
```
- Is locked for an update operation
- Contains an automated step that is running.
- Is waiting for a called workflow to complete
- Is called for processing by another workflow.

**Procedure**

1. In the Workflows table, select the workflow to be archived. You can select more than one workflow at
    a time.
2. From the **Actions** menu, select **Archive**. The Archive Workflow dialog is displayed. Listed in the
    **Selected Workflow Names** field are the workflows that you are about to archive.
3. If you want to archive your workflows to a user specified directory, select the **Archive the workflows**
    **to a specified directory** check box.
    If you do so, the **Archive SAF ID** and **Archive Directory** fields are displayed. If you do not select the
    check box, the workflow is archived to the default directory.
    - For the archive SAF ID, specify the workflow owner user ID or the group ID of the workflow owner.
    - For the archive directory, specify an existing z/OS UNIX directory on your system, beginning with a
       single forward slash ('/'). Ensure that the z/OSMF server user ID (by default, IZUSVR) has read, write,
       and execute permission to the directory. Other users can have read and execution permission, but
       not write permission.
       Do not specify a directory that resides in the z/OSMF data directory (/global/zosmf/data) or
       configuration directory (/global/zosmf/configuration).
       Up to 5000 workflows can be archived to a specific directory. If you reach this limit, you can remove
       some workflows from the directory or select a new directory for archiving additional workflows.
4. Click **OK** to archive the selected workflows.

**Results**

```
The selected workflow is archived; the workflow is removed from the display of active workflows in the
Workflows table.
You can view the archived workflow in the workflow archive page, using the Workflows table action Open
Archived Workflows. An archived workflow is no longer active, but its information can be viewed by the
workflow owner.
Related reference
```
#### Archived Workflows page.....................................................................................................................

```
You can use the Archived Workflows page in the Workflows task to view the properties of archived
workflows, or delete the workflows permanently from z/OSMF. If you did not archive any workflows, the
Archived Workflows page displays an empty list.
```
#### Archived Workflows page

```
You can use the Archived Workflows page in the Workflows task to view the properties of archived
workflows, or delete the workflows permanently from z/OSMF. If you did not archive any workflows, the
Archived Workflows page displays an empty list.
Only the workflow owner can archive a workflow. However, the other possible actions for an archived
workflow depend on the workflow category, as follows:
```
- For a general workflow or configuration workflow, only the workflow owner can view the properties of
    the workflow, offload, or delete the workflow.

**42**   Workflows task


- For a provisioning workflow, only the domain administrator can view the properties of the workflow, or
    delete the workflow.
- When general workflows or configuration workflows are archived to a user specified directory, the
    workflow owner can view the properties of the workflow or delete the workflow. If the archived
    workflow owner is a group ID, all users in the group can view the properties of the workflow or delete
    the workflow.
The field that is labeled _Display archived workflows_ defaults to the value _Default Archive Directory_ ,
meaning that the **Archived Workflows** page shows the archive directory under a z/OSMF data directory
where the archived workflows are stored by default. User specified directories are also available in the
dropdown list.
For a description of the columns in the Archived Workflows table, see “Columns in the Archived
Workflows table” on page 43. For a description of the actions that you can take for workflows, see
“Actions for Archived Workflows” on page 43.

```
Columns in the Archived Workflows table
The rows in the table are sorted alphabetically in ascending order, which is based on the Workflow Name
column.
```
_Table 17. Columns in the Archived Workflows table_

**Column Description**

**Workflow Name** Descriptive name that identifies the workflow, as specified by the workflow owner.

**Description** Description of the workflow. z/OSMF obtains this value from the workflow
definition file when the workflow is created.

**Version** Version of the workflow definition. z/OSMF obtains this value from the workflow
definition file when the workflow is created.

**Vendor** Name of the vendor that provided the workflow definition. z/OSMF obtains this
value from the workflow definition file when the workflow is created.

**Owner** User ID of the workflow owner. This value can be modified by the workflow owner
only.

**System** z/OS system on which the workflow is to be used. This value is specified when the
workflow is created.

**Date Archived (GMT)** Date and time on the system when the workflow was archived. The date and time
is in Greenwich Mean Time (GMT). By default, this column is the sort column, and
the sort is descending. That is, the most recently archived workflow is displayed at
the top of the list.

**Actions for Archived Workflows**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.

_Table 18. Targeted actions for the Archived Workflows table_

**Action Description**

**View Properties** Display the **Workflow Properties** page so that you can view the properties for the
selected workflow. To enable this action, select one workflow only.

```
Workflows task   43
```

```
Table 18. Targeted actions for the Archived Workflows table (continued)
```
```
Action Description
```
```
Open Display the Steps page so that you can view the steps of the selected workflow. To
enable this action, select one workflow only.
```
```
Offload Display the Offload page to offload an archived workflow to a user specified
directory.
When you select the Offload action from the Actions menu, the Offload Workflow
dialog is displayed. Listed in the Selected Workflow Names field are the
workflows that you are about to offload. You can select multiple workflows. The
Offload action is only available for the archived workflows which are stored in the
default directory.
Select the Archive the workflows to a specified directory checkbox if you want
archive your workflows to a specific directory. If the checkbox is selected, the
Archive SAF ID and Archive Directory fields are displayed. In the Archive SAF ID
field, specify the SAF ID of the user or group who will own the archived workflow.
In the Archive Directory field, specify the directory where the workflow will be
archived.
```
```
Delete Display the Delete Workflow dialog so that you can permanently delete the
selected workflow from the archive. You can select multiple workflows.
For a general workflow or configuration workflow, only the workflow owner
can delete an archived workflow. For a provisioning workflow, only the domain
administrator can delete an archived workflow. For the workflows which were
archived to a user specified directory, the workflow owner can delete the archived
workflows.
This action deletes the selected workflow from z/OSMF, including any notes that
accompany the workflow and its steps, and the history log for the workflow.
You cannot undo this action.
```
```
Workflows View To display the active workflows on the system, select Active.
This action is also available through the Archived | Active button on the Archived
Workflows table.
```
```
Table 19. Table actions for the Archived Workflows table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**44**   Workflows task


```
Table 19. Table actions for the Archived Workflows table (continued)
```
```
Action Description
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
```
Related tasks
Archiving an in-progress workflow
To archive a currently active workflow, use the Archive action that is provided in the Workflows table. This
action is available to the workflow owner only.
```
### Canceling an in-progress workflow...........................................................................................................

```
You can cancel a workflow that you created previously, even if it is partially completed. To do so, use the
Cancel action that is provided in the Workflows table. This action is available to the workflow owner only.
```
**Procedure**

1. In the **Workflows** table, select the workflow to be canceled. You can select more than one workflow at
    a time.
2. From the **Actions** menu or context menu, select **Cancel**. The Cancel Workflow dialog is displayed.
    Listed in the _Selected Workflows_ field are the workflows that you are about to cancel.
3. Click **OK** to cancel the selected workflows.

### Managing the steps in a workflow.............................................................................................................

```
On the Steps page, you can manage the steps in a workflow. From this page, you can view the steps for a
workflow and select actions for the steps, such as assign steps, accept ownership of steps, and perform
steps. You can also use this page to view the history for a workflow and add notes to the workflow.
The Steps page contains a multiple select tree table, which is the list of steps for the selected workflow.
The available actions for a step depend on the current state of the step and the identity of the
authenticated user. Table 1 on page 8 shows the available actions from the Steps page, depending on the
current state of the step.
For a description of the columns in the Workflow Steps table, see Table 20 on page 46. For a description
of the actions that you can take for workflows, see “Actions for Steps” on page 47.
To navigate back to the Workflows page, click Return to Workflows.
```
```
Workflows task   45
```

**Columns in the Workflow Steps table**

```
Table 20. Columns in the Workflow Steps table
```
```
Column Description
```
```
State State of the step.
One of the following status indicators is displayed:
```
- **Unassigned.** The step is in the _Unassigned_ state; no users or groups are assigned
    to the step.
- **Assigned.** Users or groups are assigned to the step, but no users accepted
    ownership of the task.
- **Not Ready.** A user accepted ownership of the step, however, a prerequisite
    step must be completed or a conditional dependency must be satisfied before
    the step can be performed.
- **Ready.** The step is ready to be performed; all prerequisite steps and
    conditional dependencies are satisfied.
- **In Progress.** The step is in progress; that is, the step owner provided some
    input to the step. For a parent step, a state of _In Progress_ means that at least one
    of the child steps was started, but is not yet complete, overridden, or skipped.
    For a leaf step, a state of _In Progress_ means that the step was started, but is not
    yet complete, overridden, or skipped.
    This icon is also displayed for a step in the _Submitted_ state. That is, the step
included a job, which the step owner submitted.
- **Failed.** This icon is shown for a step that is:
    - _Failed_. The step included a job that was submitted by the step owner but failed
       to complete successfully, or manual tasks that cannot be completed.
- **Conflicts.** The step created an output file, for use by a subsequent step.
    However, values in that file conflict with existing instance or global variables.
    Resolve conflicts by using the **Resolve Conflicts** action.
- **Complete.** This icon is shown for a step that is:
    - _Complete_. The step was completed through the Workflows task. The step is
       included in the Percent Complete calculation for the workflow.
    - _Complete (Override)_. The step was completed, but this work was performed
       outside of the Workflows task. The step assignee marked the step as
       complete, which causes the step to be included in the Percent Complete
       calculation for the workflow.
    - _Skipped_. The step was bypassed by the step assignee. z/OSMF omits the step
       from the Percent Complete calculation for the workflow.
For a parent step, z/OSMF determines the state of the step, based on the states of
its descendant leaf steps. For more information, see “Parent steps and descendant
leaf steps” on page 9.

```
No. Number that indicates the step position in the sequence of steps that comprise
the workflow. A substep has the same numerical value as its parent, with '.x'
appended to this value. Up to five levels of nesting are possible.
```
**46**   Workflows task


_Table 20. Columns in the Workflow Steps table (continued)_

**Column Description**

**Title** Title of the step. z/OSMF obtains this value from the workflow definition file when
the workflow is created. If the step calls another workflow for execution, the step
title is preceded by the **Called Workflow** icon:

**Called Workflow** If the step calls another workflow for execution, this column displays the name of
the called workflow. This field is blank if the step does not use a called workflow.

**Automated** Indicates whether the step is enabled for automation (yes or no). If so, the
Workflows task can perform the step automatically (without user interaction) when
the step is in _Ready_ state. Otherwise, the step must be performed manually by the
step owner.

**Use RunAsUser ID** Indicates that the step is run under this specific user identity during automation.

**Owner** User ID of the step owner. This field is blank if no owner exists for the step.

**Skill Category** Skill category of the step, as specified in the workflow definition file. For example,
system programmer or security administrator. This information might
help you in determining the user or group to which the step should be assigned.

**Assignees** Users and groups who are assigned to the step.

**Feedback Status** Indicates whether feedback is submitted for a step (yes or no). If no feedback is
requested for a step, the column shows a dash ('-').

```
Actions for Steps
The actions are described in the following tables:
```
- Table 21 on page 47. Actions that apply to the selected steps in the Workflow Steps table. To use a
    targeted action, you must select one or more steps. Which actions can be taken on a step depend on
    the current state of the step and the identity of the currently authenticated user. For information, see
    “Available actions for a step” on page 7.
- Table 22 on page 49. Actions that apply to the entire table. No selection is required.

_Table 21. Targeted actions for the Workflow Steps table_

**Action Description**

**Properties** Display the **Step Properties** page so that you can view the properties for the
selected step. To enable this action, select one step only.
For a parent step, selecting the Properties action displays the properties for the
parent step, rather than those of the descendant steps.
This action is applicable to all step states.
This action is available to all users.

**Accept** Display the **Accept** dialog so that you can accept ownership of the selected steps.

```
Workflows task   47
```

```
Table 21. Targeted actions for the Workflow Steps table (continued)
```
```
Action Description
```
```
Perform Display the Perform tab of the Step Properties page so that you can perform the
selected step. To enable this action, select one step only.
This action is applicable when the state is:
```
- _Not Ready_ state
- _Ready_ state
- _In Progress_ state
- _Submitted_ state
- _Failed_ state
- _Complete_ state
- _Override Completed_ state
- _Skipped_ state.
This action is available to the step owner.

```
Skip Display the Skip dialog so that you can bypass the performing of the selected
steps.
This action is applicable to all step states.
This action is available to the workflow owner and the step owner.
```
```
Status Display the Status tab of the Step Properties page so that you can view the job
completion status of the last job to be submitted when the step was performed. To
enable this action, select one step only.
This action is applicable when the state is:
```
- _Submitted_ state
- _Failed_ state
- _Complete_ state
- _Override Completed_ state.
This action is available to the workflow owner, the step owner and the step
assignees.

```
Override Complete Display the Override Complete page so that you can mark the selected steps as
complete to indicate that the work was performed outside of the Workflows task.
This action is applicable to all step states, including Conflicts. However, when the
state is Conflicts , the recommended action is Resolve Conflicts.
This action is available to the workflow owner and the step owner.
```
```
Resolve Conflicts Display the Input Variables tab of the Step properties page so that you can
resolve conflicts between variables in the output file and existing variables for the
Workflows task.
This action is applicable when the state is Conflicts.
```
```
Change Called Workflow This action is available to the workflow owner and the step owner.
```
**48**   Workflows task


_Table 21. Targeted actions for the Workflow Steps table (continued)_

**Action Description**

**Assignment and
Ownership**

```
Select one of the following actions:
```
- **Add Assignees.** Display the **Add Assignees** page so that you can assign one or
    more users or groups to the selected steps.
- **Remove Assignees.** Display the **Remove Assignees** page so that you can remove
    one or more assignees from the selected steps. This action is available only when
    the selected steps have assignees.
- **Take Ownership.** Display the **Take Ownership** dialog so that you can assume
    ownership of the selected step from the current step owner.
- **Return.** Display the **Return** dialog so that you can cancel your acceptance of the
    selected steps, thus making the steps available for another assignee to accept.
- **Request Assignment.** Display the **Request Assignment** dialog so that you can
    request to be assigned the selected steps.
For more information about each action, see help topic “Managing assignees and
ownership for a step” on page 67.

**Feedback** Display the **Step Feedback** page so that you can answer questions about the step,
for use by the workflow vendor. Only the step owner can display the feedback
page for a step. This action is unavailable for steps that do not contain feedback
questions and for users other than the step owner.
To receive feedback, a step must be in one of the following states:

- _Not Ready_ state
- _Ready_ state
- _In Progress_ state
- _Submitted_ state
- _Failed_ state
- _Complete_ state
- _Override Completed_ state
- _Skipped_ state.
For a workflow that is canceled or locked or archived, the feedback pages are
read-only. No changes can be made.

**Expand** For a parent step, expand the step so that its substeps are visible.

```
This action is available to all users.
```
**Collapse** For a parent step, collapse the step so that its substeps are hidden.

```
This action is available to all users.
```
_Table 22. Table actions for the Workflow Steps table_

**Action Description**

**Export Workflow as
Printable Format**

```
Export the workflow steps in a printable format. You can use various filters to limit
the content to only the steps that interest you.
```
```
Workflows task   49
```

```
Table 22. Table actions for the Workflow Steps table (continued)
```
```
Action Description
```
```
Select All Steps Assigned
to Me
```
```
Selects all of the rows in the table for which you are the step owner, or are eligible
to own, based on your user ID or inclusion in a group of step assignees.
You can use this action to quickly assume ownership of all of the steps that you are
eligible to own.
```
```
Start Parallel Automation Start parallel automation for any automated steps that can be run concurrently.
This action is available only for a parallel-steps workflow. A parallel-steps
workflow is indicated in the Workflows page with Yes in the column Contains
Parallel Steps.
This action displays the Start Parallel Automation window to confirm your
selection. On this window, you can indicate how potential variable conflicts are
to be resolved during automation processing.
When you start automation for a parallel-steps workflow by using the Start
Parallel Automation table action, the Workflows task locates the automated steps
with one of the following statuses: ready, in-progress, or failed. These steps are
considered to be automation ready. The Workflows task attempts to run these
steps concurrently. For a failed step, the Workflows task performs the step again.
If a step is found in the conflicts state, the Workflows task resolves the conflicts
based on your selection in the Start Parallel Automation dialog. If you select to
resolve conflicts manually, the step remains in conflicts state until you resolve the
conflicts.
The failure of an automated step does not stop automation processing for the other
automated steps. Processing continues until all of the automated steps that are
owned by you are completed or failed, or a condition occurs that stops automation
processing, such as you stopping automation through the Stop Automation action.
This action is available to the workflow owner and the owner of at least one of the
automated steps.
```
```
Stop Automation For a workflow with automated steps, stop the processing of the workflow.
Any in-progress steps are allowed to complete before the workflow is stopped.
Subsequently, any automated steps in a ready state are not started; these steps
must be performed manually by the step owner.
This action is available only for automated steps.
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are to be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Search Clear the search.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible.
```
**50**   Workflows task


```
Table 22. Table actions for the Workflow Steps table (continued)
```
```
Action Description
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden.
```
```
Notes link
The Notes link is displayed in the Steps page. When you click the link, the Notes window is displayed. You
can use this window to view the notes for the workflow, and add your own.
```
```
If notes exist for the workflow, the Notes icon ( ) is displayed by the link. If no notes exist for the
workflow, a Disabled Notes icon ( ) is displayed by the link.
For more information, see help topic “Adding notes to workflows” on page 109.
```
**History link**

```
As a user progresses through a workflow, z/OSMF maintains a history or log of the user’s activities. For
example, z/OSMF captures information about the creation and modification of the workflow and the state
transitions of the steps. This information might be useful to your installation for auditing purposes.
To view this information, click the History link, which is displayed in the Steps page. For more
information, see “Workflow history” on page 109.
```
#### Viewing the properties of a step..........................................................................................................

```
You can use the Properties for Step page in the Workflows task to view the properties of a step, including
its general information, details, dependencies, notes, and status. From this page, you can select the
Perform tab to perform the step.
The content of this page is organized in tabs, as follows:
```
- “General tab” on page 51
- “Details tab” on page 53
- “Dependencies tab” on page 56
- “Notes tab” on page 58
- “Perform tab” on page 59
- “Status tab for template steps” on page 60
- “Status tab for REST steps” on page 61
- “Input Variables tab” on page 64
- “Feedback tab” on page 66

```
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Table 23 on page 51 lists and describes the fields displayed in the General tab.
```
```
Table 23. Fields in the General tab
```
```
Column Description
```
```
Title Title of the step. z/OSMF obtains this value from the workflow definition file when
the workflow is created.
```
```
Workflows task   51
```

```
Table 23. Fields in the General tab (continued)
```
```
Column Description
```
```
Description Description of the step. z/OSMF obtains this value from the workflow definition file
when the workflow is created.
```
```
If the step consists of substeps, the Substeps table is included with additional details about the substeps.
Table 24 on page 52 describes the columns in the Substeps table.
```
```
Table 24. Columns in the Substeps table
```
```
Column Description
```
```
State State of the step.
One of the following status indicators is displayed:
```
- **Unassigned.** The step is in the _Unassigned_ state; no users or groups are assigned
    to the step.
- **Assigned.** Users or groups are assigned to the step, but no users accepted
    ownership of the task.
- **Not Ready.** A user accepted ownership of the step, however, a prerequisite
    step must be completed or a conditional dependency must be satisfied before the
    step can be performed.
- **Ready.** The step is ready to be performed; all prerequisite steps and
    conditional dependencies are satisfied.
- **In Progress.** The step is in progress; that is, the step owner provided some
    input to the step. For a parent step, a state of _In Progress_ means that at least one
    of the child steps was started, but is not yet complete, overridden, or skipped. For
    a leaf step, a state of _In Progress_ means that the step was started, but is not yet
    complete, overridden, or skipped.
    This icon is also displayed for a step in the _Submitted_ state. That is, the step
    included a job, which the step owner submitted.
- **Failed.** This icon is shown for a step that is:
    - _Failed_. The step included a job that was submitted by the step owner but failed
       to complete successfully, or manual tasks that cannot be completed.
- **Conflicts.** The step created an output file, for use by a subsequent step.
    However, values in that file conflict with existing instance or global variables.
    Resolve conflicts by using the **Resolve Conflicts** action.
- **Complete.** This icon is shown for a step that is:
    - _Complete_. The step was completed through the Workflows task. The step is
       included in the Percent Complete calculation for the workflow.
    - _Complete (Override)_. The step was completed, but this work was performed
       outside of the Workflows task. The step assignee marked the step as complete,
       which causes the step to be included in the Percent Complete calculation for
       the workflow.
    - _Skipped_. The step was bypassed by the step assignee. z/OSMF omits the step
       from the Percent Complete calculation for the workflow.
For a parent step, z/OSMF determines the state of the step, based on the states of
its descendent leaf steps. For more information, see “Parent steps and descendant
leaf steps” on page 9.

**52**   Workflows task


_Table 24. Columns in the Substeps table (continued)_

**Column Description**

**No.** Number that indicates the step position in the sequence of steps that comprise
the workflow. A substep has the same numerical value as its parent, with '.x'
appended to this value. Up to 5 levels of nesting are possible.

**Title** Title of the step. z/OSMF obtains this value from the workflow definition file when
the workflow is created.

**Owner** User ID of the step owner. This field is blank if no owner exists for the step.

**Skill Category** Skill category of the step, as specified in the workflow definition file. For example,
system programmer or security administrator. This information might
help you in determining the user or group to which the step should be assigned.

**Assignees** Users and groups who are assigned to the step.

```
Related reference
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Notes tab
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Feedback tab
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Table 25 on page 54 describes the fields that are displayed on the Details tab.
```
```
Workflows task   53
```

```
Table 25. Fields on the Details tab
```
```
Column Description
```
```
State State of the step.
One of the following status indicators is displayed:
```
- **Unassigned.** The step is in the _Unassigned_ state; no users or groups are assigned
    to the step.
- **Assigned.** Users or groups are assigned to the step, but no users accepted
    ownership of the task.
- **Not Ready.** A user accepted ownership of the step, however, a prerequisite
    step must be completed or a conditional dependency must be satisfied before
    the step can be performed.
- **Ready.** The step is ready to be performed; all prerequisite steps and
    conditional dependencies are satisfied.
- **In Progress.** The step is in progress; that is, the step owner provided some
    input to the step. For a parent step, a state of _In Progress_ means that at least one
    of the child steps was started, but is not yet complete, overridden, or skipped.
    For a leaf step, a state of _In Progress_ means that the step was started, but is not
    yet complete, overridden, or skipped.
    This icon is also displayed for a step in the _Submitted_ state. That is, the step
included a job, which the step owner submitted.
- **Failed.** This icon is shown for a step that is:
    - _Failed_. The step included a job that was submitted by the step owner but failed
       to complete successfully, or manual tasks that cannot be completed.
- **Conflicts.** The step created an output file, for use by a subsequent step.
    However, values in that file conflict with existing instance or global variables.
    Resolve conflicts by using the **Resolve Conflicts** action.
- **Complete.** This icon is shown for a step that is:
    - _Complete_. The step was completed through the Workflows task. The step is
       included in the Percent Complete calculation for the workflow.
    - _Complete (Override)_. The step was completed, but this work was performed
       outside of the Workflows task. The step assignee marked the step as
       complete, which causes the step to be included in the Percent Complete
       calculation for the workflow.
    - _Skipped_. The step was bypassed by the step assignee. z/OSMF omits the step
       from the Percent Complete calculation for the workflow.
For a parent step, z/OSMF determines the state of the step, based on the states of
its descendant leaf steps. For more information, see “Parent steps and descendant
leaf steps” on page 9.

```
Skill Category Skill category of the step, as specified in the workflow definition file. For example,
system programmer or security administrator. This information might
help you in determining the user or group to which the step should be assigned.
```
```
Owner User ID of the step owner. This field is blank if no owner exists for the step.
```
```
Assignees Users and groups who are assigned to the step.
```
**54**   Workflows task


_Table 25. Fields on the Details tab (continued)_

**Column Description**

**Automated** Indicates whether the step is enabled for automation. One of the following values
is displayed:
**Yes**
The Workflows task can perform the step automatically (without user
interaction) when the step is in Ready state.
**No**
The step must be performed manually by the step owner.
**" " (empty)**
The step is a parent step; it cannot be set for automated processing.
**Yes, with suspend information**
A suspend element was included for this step in the workflow definition XML.
As a result, automation stops at this step. Here, the step is considered to be
_suspended_. The step requires a manual action to be performed before the step
can be marked complete.
When automation processing reaches a suspended step, z/OSMF can send a
notification to a user to prompt for action. In z/OSMF, users access notifications
through the Notifications task.
For a suspended step, the _Step Properties_ page includes a tabbed area called
**Suspend Information**. This area displays the following email settings, which are
used for creating the notification:
**Recipients**
Specifies the email addresses for the users to be notified of the suspended
step. Multiple recipients are separated by commas or spaces.
**Subject**
Brief, meaningful subject for the notification email. If omitted, this field shows
no subject by default.
**Content**
Text of the message to be sent to the recipient. If omitted, this field shows no
content by default.
In addition to any users that you specify for **Recipients** , note that:

- For a configuration or general workflow, z/OSMF always sends a notification to
    the workflow owner.
- For a provisioning workflow, z/OSMF sends a notification to the domain
    administrator, if this user identity is defined. Otherwise, z/OSMF notifies the
    workflow owner.

```
Related reference
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Notes tab
```
```
Workflows task   55
```

```
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Feedback tab
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
If the step has dependencies on other steps, more information is provided in the Step Dependencies
section. Expand the section for details, as follows:
Description
Is the text description of the step dependency, from the workflow definition.
Satisfied
Indicates whether the step dependency is satisfied. If the value is No, the step cannot be performed.
Use the information in the fields that follow to understand what needs to be done to satisfy the
dependency.
When step dependencies exist, more information is provided in the Step Dependencies table. Table 26 on
page 56 describes the contents of the Step Dependencies table.
```
```
Table 26. Columns in the Step Dependencies table
```
```
Column Description
```
```
State State of the step.
```
```
No. Number that indicates the step position in the sequence of steps that comprise the
workflow.
```
```
Title Title of the step. z/OSMF obtains this value from the workflow definition file when
the workflow is created.
```
```
Step Dependencies Identifies by number the dependent steps for the current step. Both explicit and
implicit dependent steps are displayed; the Workflows task might treat a step as a
dependent step even if the step is not specified as such in the workflow definition.
```
```
Owner User ID of the step owner. This field is blank if no owner exists for the step.
```
```
Assignees Users and groups who are assigned to the step.
```
**56**   Workflows task


If the step has conditional dependencies, more information is provided in the **Conditional Dependencies**
section. Expand the section for details, as follows:

**Description**
Is the text description of the conditional dependency, from the workflow definition.

**Satisfied**

```
Indicates whether the condition is satisfied. If the value is No ( ), the step cannot be performed. Use
the information in the fields that follow to understand what needs to be done to satisfy the condition.
```
**Expression**
Is the expression for the condition, from the workflow definition.
The table Expression Variable Values describes the variables that are used in the expression.
**Note:** The Current Value column shows the current value of each variable, with the exception of array
variables. For an array variable, the size of the variable (number of elements) is provided.

**Step Attribute Values Table**
Shows the current values for the variables in the conditional expression.

The **Resulting State** section indicates the state that the step assumes when the prerequisites and
dependencies are satisfied.

After you make changes to satisfy the step dependencies and conditional dependencies, you can update
the values on this tab by clicking **Refresh**.

**Related reference**

General tab
You can use the **General** tab on the _Step Properties_ page to view the step title and description, and display
a list of substeps, if any.

Details tab
You can use the **Details** tab on the _Step Properties_ page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.

Notes tab
You can use the **Notes** tab on the _Step Properties_ page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.

Perform tab
You can use the **Perform** tab on the **Step Properties** page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.

Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
_template step_. You can use the **Status** tab on the _Step Properties_ page to check the results of a template
step.

Status tab for REST steps
A step that issues a REST API request is called a _REST step_. You can use the **Status** tab on the _Step
Properties_ page to check the results of a REST step.

Input Variables tab
You can use the **Input Variables** tab on the _Step Properties_ page to resolve conflicts between values that
this step saved in a file and existing values for global variables.

Feedback tab

```
Workflows task   57
```

```
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Notes tab
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Table 27 on page 58 lists and describes the fields included on the Notes tab.
```
```
Table 27. Fields on the Notes tab
```
```
Field Description
```
```
Step notes Enter the notes to associate with the selected step. You can enter up to 2048
characters of text.
This field is blank if no notes are specified for the step. Otherwise, the notes
currently associated with the step are displayed. You can modify the existing notes
or add a new note.
If the selected step currently has notes associated with it, when you click OK ,
those notes are replaced with the information you entered in this window.
For a workflow with automated steps, it is not possible to add a note while an
automated step is running. Thus, the Step notes field is disabled for a workflow
with the status Automation in Progress.
```
```
Related reference
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Feedback tab
```
**58**   Workflows task


The **Feedback** tab on the _Step Properties_ page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.

**Perform tab**

You can use the **Perform** tab on the **Step Properties** page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.

When you click the Perform tab, the Workflows task displays a wizard or dialog to guide you in the
completion of the step. Depending on whether the step is automated or manual, or calls another
workflow, the Workflows task responds, as follows:

- For a manual step, the Workflows task displays a wizard, called the _Step Perform Wizard_ , to guide you
    in the completion of the step. The wizard contains instructions for you to follow, which are detailed
    directions for what you must do to perform the step to completion. Depending on the requirements of
    the step, the Workflows task might first prompt you for installation-specific values and then use these
    values to provide you with tailored instructions.
- For an automated step, the Workflows task displays a dialog, called the Perform Automated Step dialog,
    to confirm your selection for the step and subsequent automated steps, if any.
- For a called workflow, the Workflows task checks to determine whether an instance of the called
    workflow is already active on the system. If so, the Workflows task redirects focus to the called
    workflow, so that the step owner can complete it. If the called workflow is already completed, the
    Workflows task displays the Workflows Steps table, showing the step that invoked the called workflow
    as marked complete.
    Otherwise, if the called workflow is not already created, the Workflows task displays a dialog, called
    _Perform Step — Create Called Workflow_ , to prompt you for information about creating the workflow.

**Note:** For a workflow with automated steps, it is not possible to manually perform a step while an
automated step is running. Thus, the **Save** and **Finish** actions are disabled for a workflow with the status
Automation in Progress.

For more information, see one of the following topics.

- For information about the Step Perform wizard, see “Using the Step Perform wizard” on page 81
- For information about the Perform Automated Step dialog, see “Using the Perform Automated Step
    dialog” on page 74
- For information about the Create Called Workflow dialog, see “Performing a step that calls another
    workflow” on page 75.

**Related reference**

General tab
You can use the **General** tab on the _Step Properties_ page to view the step title and description, and display
a list of substeps, if any.

Details tab
You can use the **Details** tab on the _Step Properties_ page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.

Dependencies tab
You can use the **Dependencies** tab on the _Step Properties_ page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking **Refresh**.

Notes tab
You can use the **Notes** tab on the _Step Properties_ page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.

Status tab for template steps

```
Workflows task   59
```

```
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Feedback tab
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Table 28 on page 60 describes the fields displayed on the Status tab.
```
```
Table 28. Fields on the Status tab
```
```
Column Description
```
```
Name Name of the job. If this value is a link, clicking the link opens a window to display
the job status.
```
```
ID Identifier of the job.
```
```
Class Class of the job.
```
```
Type Type of the job.
```
```
Status Status of the job. Valid values are:
```
```
INPUT
The job was received, but not run yet.
ACTIVE
The job is running.
OUTPUT
The job has finished and has output to be printed or retrieved.
" "
The job status is unknown.
```
```
Return code Maximum return code from the job. This value is displayed when processing ends.
```
```
For a job, this value is the maximum return code received from the system that
processed the job. For a REXX exec program or a UNIX shell script, this value is the
exit code of the program or script.
```
```
Included in this page is a set of tabs that describe the output DD statements for the job, one tab per DD
statement. Each tab shows the data returned for the DD statement in the following set of fields:
DD name
Name of the DD card
Step name
Name of the step
```
**60**   Workflows task


**Procedure step name**
Name of the procedure

**Dataset ID**
Identifier of the data set

**Class**
Job class

**Record count**
Record count.

Following these properties is the output data received from the DD statement, contained in a field called
_Output (xxxKB of yyyKB shown)_ , where:

- _xxx_ is the amount of data in kilobytes displayed in the text box
- _yyy_ is the total amount of data contained in the DD statement.

If the total amount of data from the DD statement exceeds 250 KB, the Workflows task displays only the
first 250 KB of data, and a link that you can click to view the rest of the output.

**Related reference**

General tab
You can use the **General** tab on the _Step Properties_ page to view the step title and description, and display
a list of substeps, if any.

Details tab
You can use the **Details** tab on the _Step Properties_ page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.

Dependencies tab
You can use the **Dependencies** tab on the _Step Properties_ page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking **Refresh**.

Notes tab
You can use the **Notes** tab on the _Step Properties_ page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.

Perform tab
You can use the **Perform** tab on the **Step Properties** page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.

Status tab for REST steps
A step that issues a REST API request is called a _REST step_. You can use the **Status** tab on the _Step
Properties_ page to check the results of a REST step.

Input Variables tab
You can use the **Input Variables** tab on the _Step Properties_ page to resolve conflicts between values that
this step saved in a file and existing values for global variables.

Feedback tab
The **Feedback** tab on the _Step Properties_ page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.

**Status tab for REST steps**

A step that issues a REST API request is called a _REST step_. You can use the **Status** tab on the _Step
Properties_ page to check the results of a REST step.

Table 29 on page 62 describes the fields that are displayed on the **Status** tab.

```
Workflows task   61
```

```
Table 29. Fields on the Status tab
```
```
Field Description
```
```
State State of the step, such as Complete or Failed.
```
```
Expected status code The expected HTTP status code from the REST API request, as defined in the
workflow definition. For example, the status code 200 is often used to indicate a
successful operation.
```
```
Actual status code If the step was performed, this field includes the actual HTTP status code of the
step. If this value does not match the expected status code value, the Workflows
task marks the step as Failed.
```
```
Included in this page is a set of tabs that describe the REST request, as follows:
```
- “Request tab” on page 62
- “Response tab” on page 63
- “Message tab” on page 64

```
Request tab
“Request tab” on page 62 describes the fields that are displayed on the Request tab.
```
```
Table 30. Fields on the Request tab
```
```
Field Description
```
```
HTTP method Indicates the HTTP method that was used for issuing the REST request. The
following values are valid:
```
- GET
- PUT
- POST
- DELETE.

```
Request Shows the actual REST request after any variable substitution is performed.
Included is the Universal Resource Identifier (URI) path and, where appropriate,
any query parameters that further qualify the request.
```
```
Certificates Certificates for the REST request, if any are specified. Otherwise, this field is
omitted.
Certificate locations are shown as a JSON array, as follows:
```
- Square brackets '[ ]' enclose the array
- For each certificate, a fully qualified (absolute) path is provided
- For multiple certificates, commas are used to separate the locations.
For example:

```
[
"/tmp/SampleCertificate.cer",
"/tmp/AnotherCertificate.cer"
]
```
**62**   Workflows task


_Table 30. Fields on the Request tab (continued)_

**Field Description**

**Request headers** Shows the request header properties, if the request includes any. Otherwise, this
field is omitted.
The request header is shown as a JSON object:

- Braces '{ }' enclose the JSON content
- Each header property is a name-value pair, with the property and its value
    delineated with a colon (:)
For example:

```
{
"Content-Type" : "application/JSON",
"Accept" : "*/*"
}
```
```
If no header properties are specified, z/OSMF uses the following defaults for a PUT
or POST request:
Content-Type
application/JSON
Contents-Length
Length of the request body
Charset
UTF-8
Any properties that are specified in the request header will override the z/OSMF
defaults.
```
**Request body** Shows the request body, if the request includes one. Otherwise, the field is
omitted.
Typically, a **POST** or **PUT** request includes a request body. A **GET** or **DELETE** request
does not.

**Response tab**

```
If the requested REST service returns a response body, the contents of the response body are included in
the Response tab. Otherwise, this tab is disabled.
For most 4 nn and 5 nn HTTP error status codes, additional diagnostic information beyond the HTTP status
code is provided in the response body for the request. Table 31 on page 63 describes the response body
elements that are included in the Response field for a failed REST step.
```
```
Table 31. Error response body elements for a REST step
```
```
Field Type Description
```
```
additionalInfo String Additional information that describes the error.
```
```
debug String Debug information about the error.
```
```
httpStatus Integer HTTP status code.
```
```
messageID String Message identifier for the error.
```
```
messageText String Message text that describes the error.
```
```
Workflows task   63
```

```
Table 31. Error response body elements for a REST step (continued)
```
```
Field Type Description
```
```
requestMethod String Indicates the HTTP method that was used for issuing the REST
request. The following values are valid:
```
- GET
- PUT
- POST
- DELETE.

```
requestUri String URI path that was used for the REST request.
```
```
Message tab
If the requested REST service encountered an error, the Message tab contains the message text that
describes the error. Otherwise, this tab is disabled.
Related reference
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Notes tab
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Feedback tab
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
Table 32 on page 65 describes the fields displayed on the Input Variables tab.
```
**64**   Workflows task


_Table 32. Fields on the Input Variables tab_

**Column Description**

**Variable Name** Name of the variable.

**Variable Type** Variable type: Global or Local.

**Default Value** Default value for the variable, if any.

**Existing Value** The value of the global variable.

**Input File Value** The value of the variable that was saved in the file by this step.

**New Value** The value to be used. Select a value from the list to resolve the conflict.

**Load or Conflict Status** Indicates if the variable was found to be in conflict, or where the value was loaded
from. These values indicate a conflict:
**User Modified Conflicts**
The value of a local variable is different from the value in the file, and the user
has modified the value one or more times.
**Global Conflict**
The value of a global variable is different from the value in the file.
You must resolve all conflicts.

**Step Last Modified** The last step to modify the variable.

**Description** Description of the variable.

```
Related reference
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Notes tab
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Feedback tab
```
```
Workflows task   65
```

```
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
```
```
Feedback tab
The Feedback tab on the Step Properties page contains the questions that are used to gather your
feedback about the step. You can update this tab at any time during your work with the step, regardless of
whether the step is marked complete.
Required feedback questions are indicated with a red asterisk. Required questions must be answered;
optional questions can be skipped.
You can save your responses at any time, and return later to change your answers. After you submit your
feedback, you can no longer change your answers.
All required feedback questions must be answered before you can submit feedback for a step. When the
required questions are answered, the Submit option is enabled.
Related reference
General tab
You can use the General tab on the Step Properties page to view the step title and description, and display
a list of substeps, if any.
Details tab
You can use the Details tab on the Step Properties page to view detailed information about the step
and its prerequisite steps, if any. This information includes the state of the step, the skill needed for
performing the step, and the owner and assignees for the step.
Dependencies tab
You can use the Dependencies tab on the Step Properties page to view information about the step
dependencies and conditional dependencies. After you make changes to satisfy the step dependencies
and conditional dependencies, you can update the values on this tab by clicking Refresh.
Notes tab
You can use the Notes tab on the Step Properties page to specify additional information about a given
step. For example, you can use this tab to specify any installation-specific information about the step.
Perform tab
You can use the Perform tab on the Step Properties page to perform the current step. Doing so displays a
wizard or dialog in the Workflows task, which you can use to perform the step.
Status tab for template steps
A step that runs an executable program, such as a JCL job, a REXX exec, or a UNIX shell script, is called a
template step. You can use the Status tab on the Step Properties page to check the results of a template
step.
Status tab for REST steps
A step that issues a REST API request is called a REST step. You can use the Status tab on the Step
Properties page to check the results of a REST step.
Input Variables tab
You can use the Input Variables tab on the Step Properties page to resolve conflicts between values that
this step saved in a file and existing values for global variables.
```
#### Using the Export Workflow as a Printable Format dialog....................................................................

```
For your convenience, you can print a hardcopy of this workflow. To do so, use the Export Workflow as
a Printable Format action in the Workflow Steps table to view options for formatting the workflow as a
printable document.
From the Export Workflow in a Printable Format dialog, you can specify:
```
**66**   Workflows task


- Which steps are to be included in the printable output. By default, _All steps_ are selected. You can limit
    the output file to just a subset of steps. To do so, set the filter rules in the Workflow Steps table, and
    then select _As filtered_ in the **Export Workflow in a Printable Format** dialog.
- Whether to include the following additional information about steps:
    - For inline template steps, include the contents of the template
- For REST steps, include the HTTP request URI, parameters, and request body, if applicable.
- Whether to include a document style _Table of Contents_ with the output file. Be aware that the page
    numbers in the table of contents might not correspond to the workflow step numbers.
- Whether to include other document style elements in the output file, such as a cover, front matter,
    back matter, and back cover. To be included in the output file, these elements must be defined in the
    workflow definition file.
    If you select to include document style elements, the Workflow task displays extra fields for optionally
    including a bar code and logo. Typically, these are image files, which are supplied by the workflow
    provider. Specify the path and file name for each file. The Workflows task will search for them on the
    system on which the workflow definition file resides. This system name is displayed above the fields for
    logo and bar code.
    The logo and bar code are image files that:
    - Reside in an accessible file path on your system
    - Have a valid image format: png, jpeg, jpg, gif, or bmp
    - Do not exceed 1 MB.
Click **OK** to create the printable output (an HTML file). The output file opens in a new web browser
window. To print the file, select the print function for the web browser.
The amount of data that can be exported depends on the workflow _access type_ , as follows:
**Public**
    All information about the workflow, including the steps and notes, can be exported by all users.
**Restricted**
    Information about steps, variables, and notes, is restricted to a subset of users: Workflow owner, step
    owners, and step assignees. Other users cannot export this information.
**Private**
    Information is restricted to a subset of users, and is further limited among these users. Step owners
    and assignees can export information about the steps for which they are assigned or own, and limited
    information about other steps. Other users cannot access this information.
The export-to-print function is available for active workflows only. You cannot print an archived workflow.

#### Managing assignees and ownership for a step....................................................................................

```
You can manage the list of assignees for a step through the Assignment and ownership set of actions. You
can create step assignments based on SAF user ID or SAF group.
To perform a step, the assignee requires the same security authorizations as if the person were to perform
this work through a TSO/E session on the system. For example, submitting a job through the Workflows
task requires that the assignee user ID is authorized to run jobs on the system and is able to access any
protected resources that the job might require.
The following topics describe the procedures to use:
```
- “Adding assignees to a step” on page 68
- “Removing assignees from a step” on page 69
To help step owners manage the ownership of steps, the Workflows task provides the following actions:
- “Using the Take Ownership action” on page 71
- “Returning ownership of a step” on page 72.

```
Workflows task   67
```

```
In some cases, a new user might want to be added as the assignee to a step. If so, the user can request
assignment, as described in “Requesting assignment to a step” on page 70.
```
```
Adding assignees to a step
To add assignees to a step, use the Add Assignees action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the Add action to add a SAF user ID or SAF group, as
needed.
```
**Before you begin**

```
Ensure that any user IDs and groups to be assigned to the step have access to z/OSMF and the
Workflows task. Also, verify that your installation's security management product (for example, RACF)
permits these users and groups to access the system resources that are needed to perform the particular
step. If necessary, contact your installation's security administrator to authorize users and groups to the
appropriate system resources.
```
**Procedure**

1. In the **Workflow Steps** table, select the steps for which assignees are to be added.
    You can select multiple steps.
2. From the **Actions** menu, select **Assignment and Ownership** > **Add Assignees**. The **Add Assignees**
    page is displayed.
3. In the **Selected Steps** table, review the selected steps to ensure that the table includes only the steps
    that you want to assign.
4. In the **Available assignees** table, verify that the user IDs and groups to be assigned are included. To
    add user IDs and groups to the table, complete the following steps:
       a) In the **Available assignees** table, click **Add**. The **Add SAF user ID or SAF group** window opens.
b) Select either **SAF user ID** or **SAF group** , as needed.
The choice SAF user ID is selected by default.
       c) Specify the user ID or group name.
d) Click **OK** to add your selection to the **Available assignees** table.
e) Repeat Steps 3a - 3d to add more users and groups to the **Available assignees** table.
When the **Available assignees** table contains all of the users and groups that you want to assign to
the selected steps, proceed to the next step.
5. On the **Add Assignees** page, complete the following steps:
    a) In the **Available assignees** table, indicate which users are to be assigned to the step by selecting
       the appropriate user IDs and groups.
b) Click **Add** or **Add All** to transfer your selections to the **Assignees to be added** field.
c) To undo any selections, select the applicable user IDs and groups in the **Assignees to be added**
field and click **Remove** or **Remove All**.
6. Optionally, enter a comment in the **Comments** field to document this action.
    You can specify up to 500 characters.
7. Select whether to send z/OSMF notifications to the assignees.
    This check box is selected by default.
    If a user was previously assigned a particular step and was sent a notification, selecting this option
    sends a new notification to the user when the step is assigned.
8. Click **OK** to complete the assignment.

**68**   Workflows task


**Results**

The **Steps** page is displayed, showing that the specified users and groups are assigned to the selected
steps. For each step, if the state of the step was _Unassigned_ before this action, the state is changed to
_Assigned_. Otherwise, the state of the step is unchanged.

**Related tasks**

Removing assignees from a step
To remove assignees from a step, use the **Remove Assignees** action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.

Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the **Request Assignment** action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.

Using the Take Ownership action
To assume ownership of a step from the current step owner, use the **Take Ownership** action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.

Returning ownership of a step
If you do not want to own a workflow step, use the **Return** action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.

Accepting ownership of a step
To accept ownership of a step, use the **Accept** action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.

**Removing assignees from a step**

To remove assignees from a step, use the **Remove Assignees** action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.

**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps to be unassigned.
    You can select only one workflow.
3. From the **Actions** menu or context menu, select **Open**. The **Steps** page is displayed.
4. In the Workflow Steps table, select the step for which assignees are to be removed.
    You can select multiple steps.
5. From the **Actions** menu, select **Assignment and Ownership** > **Remove Assignees**. The **Remove**
    **Assignees** page is displayed.
    This page includes the following tables:
    - Selected Steps table. You can expand this section to review the steps for which this action applies.
    - Assignees table. This table shows which users and groups are currently assigned to the step.
6. In the Assignees table, select which users and groups are to be removed as assignees for the selected
    steps.
7. Optionally, enter a comment in the **Comments** field to document this action.

```
Workflows task   69
```

```
You can specify up to 500 characters.
```
8. Click **OK** to remove the selected users and groups as assignees for the selected steps.

```
Results
The Steps page is displayed, showing that the specified users and groups are no longer assigned to
the selected steps. If this action removes all assignees from a step, the state of the step is changed to
Unassigned. Otherwise, the state of the step is not changed.
This action does not send new notifications for the removed users. Nor does this action delete the
notifications, if any, that were previously sent to the assignees.
Related tasks
Adding assignees to a step
To add assignees to a step, use the Add Assignees action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the Add action to add a SAF user ID or SAF group, as
needed.
Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the Request Assignment action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.
Using the Take Ownership action
To assume ownership of a step from the current step owner, use the Take Ownership action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.
Returning ownership of a step
If you do not want to own a workflow step, use the Return action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.
Accepting ownership of a step
To accept ownership of a step, use the Accept action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.
```
```
Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the Request Assignment action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.
```
**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar. The **Workflows** page opens.
2. Select the workflow with the step to which you want to be assigned.
3. From the **Actions** menu or context menu, select **Open**.
    The **Steps** page is displayed.
4. In the Workflow Steps table, select the step to which you want to be assigned. You can select multiple
    steps.
5. From the **Actions** menu, select **Assignment and Ownership** > **Request Assignment**. The **Request**
    **Assignment** window is displayed.
6. Click **OK** to request assignment to the selected steps.

**70**   Workflows task


**Results**

The **Steps** page is displayed. z/OSMF sends a notification to the workflow owner with details about the
request for assignment.

**Related tasks**

Adding assignees to a step
To add assignees to a step, use the **Add Assignees** action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the **Add** action to add a SAF user ID or SAF group, as
needed.

Removing assignees from a step
To remove assignees from a step, use the **Remove Assignees** action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.

Using the Take Ownership action
To assume ownership of a step from the current step owner, use the **Take Ownership** action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.

Returning ownership of a step
If you do not want to own a workflow step, use the **Return** action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.

Accepting ownership of a step
To accept ownership of a step, use the **Accept** action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.

**Using the Take Ownership action**

To assume ownership of a step from the current step owner, use the **Take Ownership** action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.

**Before you begin**

A step must be assigned to you before you can take ownership of it. A step assignment can be
communicated to you through the Notifications task. For status of the step, see the **Steps** page.

**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps that you want to own.
    You can select only one workflow.
3. From the **Actions** menu or context menu, select **Open**. The **Steps** page is displayed.
4. In the Workflow Steps table, select the step to be owned by you. You can select multiple steps.
    This action is disabled if the step is not assigned to you.
5. From the **Actions** menu or context menu, select **Assignment and Ownership** > **Take Ownership**. The
    **Take Ownership** window is displayed.
    This page includes the Selected Steps table. You can expand this section to review the steps for which
    this action applies.
6. Optionally, enter a comment in the **Comments** field to document this action.

```
Workflows task   71
```

7. Click **OK** to complete the transfer of step ownership to yourself.

```
Results
The Steps page is displayed, showing that the selected steps are owned by you.
Related tasks
Adding assignees to a step
To add assignees to a step, use the Add Assignees action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the Add action to add a SAF user ID or SAF group, as
needed.
Removing assignees from a step
To remove assignees from a step, use the Remove Assignees action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.
Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the Request Assignment action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.
Returning ownership of a step
If you do not want to own a workflow step, use the Return action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.
Accepting ownership of a step
To accept ownership of a step, use the Accept action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.
```
```
Returning ownership of a step
If you do not want to own a workflow step, use the Return action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.
```
**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps to be returned.
3. From the **Actions** menu or context menu, select **Open**.
    The **Steps** page is displayed.
4. In the Workflow Steps table, select the steps to be returned. You can return only steps that you
    currently own. You can select multiple steps.
5. From the **Actions** menu, select **Assignment and Ownership** > **Return**. The **Return** window is
    displayed.
    This page includes the Selected Steps table. You can expand this section to review the steps for which
    this action applies.
6. Optionally, enter a comment in the **Comments** field to document this action.
7. Click **OK** to return the selected steps.

**72**   Workflows task


**Results**

The **Steps** page is displayed, showing that the selected steps are returned to the _Assigned_ state.

**Related tasks**

Adding assignees to a step
To add assignees to a step, use the **Add Assignees** action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the **Add** action to add a SAF user ID or SAF group, as
needed.

Removing assignees from a step
To remove assignees from a step, use the **Remove Assignees** action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.

Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the **Request Assignment** action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.

Using the Take Ownership action
To assume ownership of a step from the current step owner, use the **Take Ownership** action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.

Accepting ownership of a step
To accept ownership of a step, use the **Accept** action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.

**Accepting ownership of a step**

To accept ownership of a step, use the **Accept** action that is provided in the Workflow Steps table. Doing
so makes the step ready to perform when its prerequisites, if any, are satisfied. You can accept steps
individually, or you can select all of the steps that are assigned to you.

**Before you begin**

A step must be assigned to you before you can accept it. A step assignment can be communicated to you
through the Notifications task. For status of the step, see the **Steps** page.

**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps to be accepted.
    You can select only one workflow.
3. From the **Actions** menu or context menu, select **Open**. The **Steps** page is displayed.
4. In the Workflow Steps table, select the step to be accepted. You can select multiple steps.
    This action is disabled if the step is not assigned to you.
5. From the **Actions** menu or context menu, select **Assignment and Ownership** > **Accept**. The **Accept**
    **Step** window is displayed.
    This page includes the Selected Steps table. You can expand this section to review the steps for which
    this action applies.
6. Optionally, enter a comment in the **Comments** field to document this action.

```
Workflows task   73
```

7. Click **OK** to accept ownership of the steps.

```
Results
The Steps page is displayed, showing that the selected steps are owned by you. For each step, the state is
changed to
```
- _Ready_ , if the step is ready to be performed
- _Not Ready_ , if the step has prerequisites that must be satisfied before the step can be performed.
**Related tasks**
Adding assignees to a step
To add assignees to a step, use the **Add Assignees** action that is provided in Workflow Steps table. You
can create step assignments based on SAF user ID or SAF group. When you create the assignments, you
can select from a list of assignees or you can use the **Add** action to add a SAF user ID or SAF group, as
needed.
Removing assignees from a step
To remove assignees from a step, use the **Remove Assignees** action that is provided in the Workflow
Steps table. Doing so removes the specified users and groups as assignees for the step. This action does
not remove users and groups from your security management product.
Requesting assignment to a step
If you want to be assigned to a step, so that you are eligible to own the step and perform it, use
the **Request Assignment** action in the Workflow Steps table. You can use this action to request step
assignment from the workflow owner. After you are assigned to a step, you can take ownership of the step
from the current step owner and perform the step.
Using the Take Ownership action
To assume ownership of a step from the current step owner, use the **Take Ownership** action that is
provided in the Workflow Steps table. Doing so transfers step ownership to you, and removes it from the
current step owner.
Returning ownership of a step
If you do not want to own a workflow step, use the **Return** action that is provided in the Workflow Steps
table. Doing so cancels the step ownership. After you return a step, the step must be accepted again by
you or another user before it can be performed.

#### Using the Perform Automated Step dialog..........................................................................................

```
To perform an automated step, use the Perform action that is provided in the Workflow Steps table.
Doing so displays the Perform Automated Step dialog in the Workflows task. You can use the Perform
Automated Step dialog to confirm that the step is to be performed automatically by the Workflows task.
This section describes the options available in the dialog.
Before the step can be performed automatically, you must confirm your selection for the step, as follows:
```
- The step and any subsequent automated steps are to be performed now.
- Only the selected step is to be performed now.
- Do not perform the step automatically. Select this option if you plan to perform the step manually.
When steps are to be performed automatically, you must also confirm your selection for what to do when
input file variable conflicts occur.

#### Using the Start Parallel Automation dialog..........................................................................................

```
To run automated steps in parallel (concurrently), use the Start Parallel Automation action that is
provided in the Workflow Steps table. Doing so displays the Start Parallel Automation dialog in the
Workflows task. You can use the Start Parallel Automation dialog to confirm that automation-ready
steps are to be performed automatically by the Workflows task.
This action is available to anyone who owns at least one of the automation-ready steps.
```
**74**   Workflows task


```
When steps are to be performed automatically, you must also confirm your selection for what to do when
input file variable conflicts occur. Your selection determines which version of the variable is used:
```
- Variable in the input file
- Existing variable for the Workflows task.
- Allow the user to choose which version of the variable to use. The step remains in _conflicts_ state until
    the user resolves the conflicts.

#### Performing a step that calls another workflow...................................................................................

```
A step can be designed to call another workflow. If so, when you use the Perform action to perform the
step, z/OSMF attempts to pass control to the called workflow. If an instance of the called workflow is not
already created, you must create one. The Workflows task displays the Create Called Workflow dialog to
help you do so.
```
**Before you begin**

```
The current step might specify a default workflow definition file to be used for creating the called
workflow. If so, the Create Called Workflow dialog displays the workflow definition file name in the file
name input field. Otherwise, you must obtain the fully qualified file name for the workflow definition file.
If this file was used previously by you or another z/OSMF user, you might find the file name to be listed in
the dialog menu.
Your user ID requires at least READ authority to the workflow definition file.
```
**Procedure**

1. From the **Actions** menu, select **Perform**.
    The **Create Called Workflow** dialog is displayed.
2. Complete the following steps:
    a) In the **Location (system)** field, select the system on which the workflow definition file and any
       related files reside. The Workflows task obtains the workflow files from this system.
       This field is a pull-down list of the z/OS systems that run z/OSMF. The list can include systems from
       the local sysplex and from remote sysplexes. If the pull-down list includes remote systems, the
       word _-Local_ is appended to the name of the local system on which z/OSMF is running. Otherwise, if
       the list contains no remote systems, the word _-Local_ is omitted from the name of the local system.
       For the local sysplex, only the currently logged-in system is included in the list. For a remote
       sysplex, all host systems that are defined to the Systems table are included in the list. You can view
       the Systems table in the Systems task.
       You cannot type over the system names. This field defaults to the local z/OS system on which
       z/OSMF is running.
b) In the **Workflow definition file** field, select a workflow definition file from the list, or type the name
of a workflow definition file.
Observe the following considerations:
- If the workflow definition file resides in a data set member, enter or select the fully qualified data
set name, including the member name. Ensure that this data set is cataloged. It is not necessary
to enclose the data set name in single quotation marks; z/OSMF ignores the quotation marks if
you include them.
- If the workflow definition file resides in a z/OS UNIX file, enter or select the fully qualified
path name of the file, beginning with the forward slash (/) and including the file name. For
example: /usr/lpp/zosmf/samples/workflow_sample_basic.xml
If the workflow definition file resides on the local system, you can locate it with a type-ahead
search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for

```
Workflows task   75
```

```
a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
attempts to find a matching data set name.
When you select an object from the type-ahead list, the object populates the workflow definition
file input-box.
The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
pattern, a record at the end of the list indicates that some records are not displayed. To display all
objects in the results area, click Display All.
c) In the Workflow variable input file field, you can optionally specify the name of a workflow
variable input file, if one is available for the workflow. Select the workflow variable input file from
the list, or type the name of the file as it resides on the z/OS system on which z/OSMF is running. If
no workflow variable input file is available, leave this field blank.
Observe the following considerations:
```
- Usually, a workflow variable input file is provided by the workflow provider, or is produced as
    output from another step in the workflow, or from another workflow. To obtain the name of
    the workflow variable input file, refer to the workflow documentation or contact the workflow
    provider.
- If the workflow variable input file resides in a data set member, enter or select the fully qualified
    data set name, including the member name. Ensure that this data set is cataloged.
- If the workflow variable input file resides in a z/OS UNIX file, enter or select the fully qualified file
    path, beginning with the forward slash (/) and including the file name. For example: /usr/lpp/
    zosmf/samples/workflow_sample_automation_property.txt.
If the workflow variable input file resides on the local system, you can locate it with a type-ahead
search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for
a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
attempts to find a matching data set name.
When you select an object from the type-ahead list, the object populates the workflow variable
input file input-box.
The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
pattern, a record at the end of the list indicates that some records are not displayed. To display all
objects in the results area, click **Display All**.
For your reference, this window includes the following detail about the called workflow, which z/OSMF
obtains from the workflow definition file:
**Called workflow description**
Description of the function that is provided by the called workflow. This information can include
other details, such as the name and location of the workflow definition file that is used to create
the called workflow.
3. To continue, click **Next**.
If you selected a system in a remote sysplex, z/OSMF checks your access to the remote system. If
the remote system is not enabled for single sign-on (SSO), the **Remote Server Authentication** window
is displayed for you to authenticate to the remote system. If so, enter a valid user ID and password
or passphrase for the remote system. You can avoid the authentication window by ensuring that the
remote system is enabled for single sign-on (SSO) in the z/OSMF Systems task. For more information,
see Defining your systems to z/OSMF.
4. Complete the following steps:
a) In the **Workflow name** field, enter a descriptive name for the workflow.
If the workflow definition specifies a default name for the workflow, it is shown here. Otherwise,
the Workflows task initializes this field to a predetermined name for the workflow, based on the
following convention:

```
< workflow-description >–Workflow_< number >
```
**76**   Workflows task


```
where:
```
- _workflow-description_ is the description from the workflow definition file.
- _number_ is the first available number, beginning at 0. If you later delete this workflow, its number
    can be reused by the Workflows task.
You can accept this name, or enter a name of your own choosing. The workflow name:
- Must be unique in the Workflows task.
- Can contain up to 100 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
- Must not contain the characters for ampersand ('&'), forward slash ('/'), greater than ('>'), or less
    than ('<').
The workflow name is not case-sensitive; for example: MyWorkflow and MYWORKFLOW are the
same workflow.

b) In the **Owner user ID** field, specify the user ID of the person who holds the overall responsibility for
completing the workflow.
Select a user ID from the list, which contains up to 10 previously specified user IDs. Otherwise,
type the user ID as it is defined to your z/OS security management product, such as RACF. A valid
user ID consists of 1 to 8 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
This field defaults to your z/OS user ID.
c) In the **Archive SAF ID** field, you can specify the SAF ID of the user or group who will own the
archived workflow after a workflow is archived to a user specified directory.
Select a SAF ID from the list, otherwise, type the SAF ID in the field. A valid ID consists of 1 to 8
alphanumeric characters (A-Z, a-z, 0-9, #, $, and @). The specified SAF ID can be the workflow
owner user ID or the group ID with which the workflow owner user ID belongs to.
This field defaults to the workflow owner user ID.

d) In the **System (where z/OSMF steps will be performed)** field, select the name of the target
system to which this workflow applies.
The workflow steps are performed on this system. Any jobs or scripts in the workflow are run on
this system. Similarly, any work that you perform manually for the workflow is done on this system.
This field is a pull-down list of systems that are defined in the z/OSMF Systems task. The list can
include systems in the local sysplex and remote sysplexes.
If you select a system in a remote sysplex:

- If the system is running z/OSMF, verify that the system is enabled for single sign-on (SSO).
    Otherwise, the **Remote Server Authentication** window is displayed for you to authenticate to
    the remote system when you perform the steps. You can avoid the authentication window by
    ensuring that the remote system is enabled for single sign-on (SSO) in the z/OSMF Systems task.
    For more information, see Defining your systems to z/OSMF.
- If the system is not running z/OSMF, it must be associated with the z/OSMF system for that
    sysplex. If so, set the z/OSMF system as the host system for the system on which the workflow
    is to be performed. Similarly, you must ensure that the z/OSMF system in the remote sysplex is
    enabled for single sign-on. Or, you must be ready to authenticate to the system with a valid user
    ID and password or passphrase.
For more information about defining z/OSMF systems and enabling them for single sign-on, see
Defining your systems to z/OSMF.
You cannot type over the system names. This field defaults to the z/OS system on which z/OSMF is
running.
e) In the **Comments** field, you can enter any information that you want to associate with this action
(up to 500 characters).
Your comment is added to the existing comments in the workflow history.

```
Workflows task   77
```

```
f) If the Save jobs output option is enabled, the workflow automatically saves any job output files
that it creates to a user-specified location (the jobs output directory).
Use this option if you want to retain the output files, perhaps as a record of the work that is done
by the workflow. If this field is preset to a location, you can overwrite the value with a different
location, as needed. The specified location must be a valid UNIX file path and directory, beginning
with a single forward slash ('/'). For example: /u/IBMUSER/jobFiles.
Ensure that:
```
- File path and directory exist on the system on which the workflow steps are to be performed.
- Workflow owner user ID has write access to the directory.
- For the steps that create job output, ensure that the step owner user IDs have write access to the
    UNIX directory. Otherwise, the steps cannot be performed.
If the **Save jobs output** option is not enabled, you cannot specify a jobs output directory.
g) If the **Delete workflow on completion** option is enabled, the workflow is automatically deleted
from the Workflows task when all of its steps are marked complete or skipped.
When a workflow is deleted, it no longer appears in the Workflows table. If you want to retain the
workflow after it is complete, clear this checkbox, if it is selected. The workflow is retained until you
explicitly delete it from the Workflow table.
A called workflow cannot be deleted until all of its calling workflows are either deleted or archived.
For your reference, this window includes the following details about the called workflow to be created,
which z/OSMF obtains from the workflow definition file:
**Workflow definition file**
Location of the workflow definition file.
**Description**
Description of the function that the called workflow provides.
**Vendor**
Name of the vendor that provided the workflow definition.
**Version**
Version of the workflow definition.
**Is Callable**
Indicates whether the workflow can be called by another workflow, and, if so, the callable range
for the workflow. One of the following values is displayed:
**In the same system**
When called by another workflow, one instance of this workflow is used in the local system. If
an existing instance of the called workflow is not already active, the Workflows task creates a
new instance of the called workflow for the system.
**In the same sysplex**
When called by another workflow, one instance of this workflow is used in the sysplex. If an
existing instance of the called workflow is not already active, the Workflows task creates a new
instance of the called workflow for the sysplex.
**Cannot be called by another workflow**
This workflow cannot be called by another workflow.
The following options are not available for a called workflow:
- **Access**
- **Open workflow on finish**.
- **Assign all steps to owner user ID**.
5. Click **Finish** to create the called workflow.

**78**   Workflows task


```
Results
The Steps page for the new workflow is displayed.
```
#### Changing the selected called workflow...............................................................................................

```
To modify the current selection of a called workflow, use the Change Called Workflow action that is
provided in the Workflow Steps table. Doing so displays the Change Called Workflow dialog, which you
can use to select another called workflow to replace the current one.
```
```
Before you begin
The current step might specify a default workflow definition file to be used for creating the called
workflow. If so, the Change Called Workflow dialog displays the workflow definition file name in the file
name input field. Otherwise, you must obtain the fully qualified file name for the workflow definition file.
If this file was used previously by you or another z/OSMF user, you might find the file name to be listed in
the dialog menu.
Your user ID requires at least READ authority to the workflow definition file.
```
**Procedure**

1. From the Workflow Steps table, select the action **Change Called Workflow** for the step.
    The Change Called Workflow dialog is displayed.
2. Complete the following steps:
    a) In the **Workflow definition file** field, select a workflow definition file from the list, or type the name
       of a workflow definition file.
       Observe the following considerations:
       - If the workflow definition file resides in a data set member, enter or select the fully qualified data
          set name, including the member name. Ensure that this data set is cataloged. It is not necessary
          to enclose the data set name in single quotation marks; z/OSMF ignores the quotation marks if
          you include them.
       - If the workflow definition file resides in a z/OS UNIX file, enter or select the fully qualified
          path name of the file, beginning with the forward slash (/) and including the file name. For
          example: /usr/lpp/zosmf/samples/workflow_sample_basic.xml.
       If the workflow definition file resides on the local system, you can locate it with a type-ahead
       search. Begin by clicking the search icon for the input-box. In the path selector window, enter a
       pattern that is a partial or complete name of a data set, member, or a UNIX file path. To search for
       a UNIX file, you must enter the path name, beginning with the forward slash (/). Otherwise, the tool
       attempts to find a matching data set name.
       When you select an object from the type-ahead list, the object populates the workflow definition
       file input-box.
       The type-ahead list displays a maximum of 100 objects. If more than 100 objects match the
       pattern, a record at the end of the list indicates that some records are not displayed. To display all
       objects in the results area, click **Display All**.
b) In the **System** field, select the name of the system to which this workflow applies. Any jobs or
scripts in the workflow are run on this system. Similarly, any work that you perform manually for the
workflow is done on this system. This field is a pull-down selection of the systems that are defined
to z/OSMF. You cannot type over the system names. This field defaults to the z/OS system on which
z/OSMF is running.

```
For your reference, this window includes the following detail about the called workflow, which z/OSMF
obtains from the workflow definition file:
```
```
Workflows task   79
```

```
Called workflow description
Description of the function that is provided by the called workflow. This information can include
other details, such as the name and location of the workflow definition file that is used to create
the called workflow.
```
3. To continue, click **Next**.
4. Complete the following steps:
    a) In the **Workflow name** field, enter a descriptive name for the workflow.
       If the workflow definition specifies a default name for the workflow, it is shown here. The
       Workflows task initializes this field to a predetermined name for the workflow, based on the
       following convention:

```
< workflow-description >–Workflow_< number >
```
```
where:
```
- _workflow-description_ is the description from the workflow definition file
- _number_ is the first available number, beginning at 0. If you later delete this workflow, its number
    can be reused by the Workflows task.
You can accept this name, or enter a name of your own choosing. The workflow name:
- Must be unique in the Workflows task.
- Can contain up to 100 alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
- Must not contain the characters for ampersand ('&'), forward slash ('/'), greater than ('>'), or less
    than ('<').
The workflow name is not case-sensitive; for example: MyWorkflow and MYWORKFLOW are the
same workflow.
b) In the **Owner user ID** field, specify the user ID of the person who holds the overall responsibility for
completing the workflow.
Select a user ID from the list, which contains up to 10 previously specified user IDs. Otherwise,
type the user ID as it is defined to your z/OS security management product, such as RACF. A valid
user ID consists of one to eight alphanumeric characters (A-Z, a-z, 0-9, #, $, and @).
This field defaults to your z/OS user ID.
c) In the **Comments** field, you can enter any information that you want to associate with this action
(up to 500 characters).
Your comment is added to the existing comments in the workflow history.
d) If the **Save jobs output** option is enabled, the workflow automatically saves any job output files
that it creates to a user-specified location (the jobs output directory).
Use this option if you want to retain the output files, perhaps as a record of the work that is done
by the workflow. If this field is preset to a location, you can overwrite the value with a different
location, as needed. The specified location must be a valid UNIX file path and directory, beginning
with a single forward slash ('/'). For example: /u/IBMUSER/jobFiles.
Ensure that:
- File path and directory exist on the system on which the workflow steps are to be performed.
- Workflow owner user ID has write access to the directory.
- For the steps that create job output, ensure that the step owner user IDs have write access to the
UNIX directory. Otherwise, the steps cannot be performed.
If the **Save jobs output** option is not enabled, you cannot specify a jobs output directory.
e) If the **Delete workflow on completion** option is enabled, the workflow is automatically deleted
from the Workflows task when all of its steps are marked complete or skipped.

**80**   Workflows task


```
When a workflow is deleted, it no longer appears in the Workflows table. If you want to retain the
workflow after it is complete, clear this checkbox, if it is selected. The workflow is retained until you
explicitly delete it from the Workflow table.
A called workflow cannot be deleted until all of its calling workflows are either deleted or archived.
For your reference, this window includes the following details about the called workflow to be created,
which z/OSMF obtains from the workflow definition file:
Workflow definition file
Location of the workflow definition file.
Description
Description of the function that the called workflow provides.
Vendor
Name of the vendor that provided the workflow definition.
Version
Version of the workflow definition.
Is Callable
Indicates whether the workflow can be called by another workflow, and, if so, the callable range
for the workflow. One of the following values is displayed:
In the same system
When called by another workflow, one instance of this workflow is used in the local system. If
an existing instance of the called workflow is not already active, the Workflows task creates a
new instance of the called workflow for the system.
In the same sysplex
When called by another workflow, one instance of this workflow is used in the sysplex. If an
existing instance of the called workflow is not already active, the Workflows task creates a new
instance of the called workflow for the sysplex.
Cannot be called by another workflow
This workflow cannot be called by another workflow.
The following options are disabled for a called workflow:
```
- **Access**
- **Open workflow on finish**
- **Assign all steps to owner user ID**.
5. Click **Finish** to modify the current selection of a called workflow.

```
Results
The Steps page for the called workflow is displayed.
```
#### Using the Step Perform wizard............................................................................................................

```
To perform a manual step, use the Perform action provided in the Workflow Steps table. Doing so
displays the Step Perform wizard in the Workflows task. You can use the Step Perform wizard to view the
instructions for performing the step and possibly receive guided assistance in completing the work. This
section describes the pages included in the wizard.
The process of performing a step manually usually includes reviewing its instructions and possibly doing
one or more of the following actions:
```
- Entering input values to be used in the wizard
- Modifying input parameters to be used by an executable program
- Creating a file or job
- Modifying an executable program before it is run by the wizard
- Defining the JOB statement for z/OSMF to use for creating a job

```
Workflows task   81
```

- Reviewing the contents of an executable program or batch job and submitting it for execution.
For a description of the wizard layout, see help topic z/OSMF wizard layout.
For a called workflow, the Step Perform wizard provides only a link to the workflow. On clicking the link,
the Workflows task checks to determine whether an instance of the called workflow is already active on
the system. If so, the Workflows task redirects focus to the called workflow, so that you can complete
it. If the called workflow is already completed, the Workflows task displays the Workflows Steps table,
showing the step that invoked the called workflow as marked complete.

```
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
In the Confirm Parameters page:
```
- If the executable program resides in an external file, the location of the file is shown in the field Script
    file. Otherwise, if the executable program is inline (coded within the step), the field Script file is not
    displayed.
- The parameters are listed in the field Script parameters.

```
The Information icon ( ) is displayed for parameters that have more information available, such as a
description or guidance information. To learn more about the parameter, hover your cursor over the icon.
To restore the parameters to the values that are specified for the step in the workflow definition file, click
Restore Default Parameters. If no parameters are provided for the step in the workflow definition, this
option is disabled.
Related tasks
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Saving the file
You can save the file using the Specify File Location page on the Step Perform wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
Related reference
Review Script page
On the Review Script page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the Confirm Parameters page of the Step Perform wizard.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
```
**82**   Workflows task


If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review JCL page
On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Review File Contents page
On the _Review File Contents_ page in the _Step Perform_ wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page
On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**Review Script page**

On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

On the **Review Script** page:

- If the executable program resides in an external file, the location of the file is shown in the field Script
    file. Otherwise, if the executable program is inline (coded within the step), the field Script file is not
    displayed.
- The contents of the executable program are displayed in read-only mode.

The program will run in a TSO/E address space. You can specify the region size for the address space, or
accept the default value, if one is provided. The valid range of values is 50000 to 2096128 (kilobytes). If
no region size is specified, the region size is 50000 kilobytes, by default. To display a description of region

size, hover your cursor over the **Information** icon ( ).

To make changes to the program contents, click **Edit script**. Doing so displays the **Edit Script** page for you
to make changes to the program. Otherwise, click **Next** to a page that allows you to run the program or
save it for running at a later time.
**Related tasks**

Submitting or saving your JCL

```
Workflows task   83
```

```
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Saving the file
You can save the file using the Specify File Location page on the Step Perform wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
Related reference
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
```
**84**   Workflows task


On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**Edit Script page**

If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

In the **Edit Script** page:

- If the executable program resides in an external file, the location of the file is shown in the field Script
    file. Otherwise, if the executable program is inline (coded within the step), the field Script file is not
    displayed.
- The contents of the executable program are displayed in edit mode.

In the work area, edit the program contents. To undo your changes and reset the program to the original
contents, click **Undo All Changes**.

The program will run in a TSO/E address space. You can specify the region size for the address space, or
accept the default value, if one is provided. The valid range of values is 50000 to 2096128 (kilobytes). If
no region size is specified, the region size is 50000 kilobytes, by default. To display a description of region

size, hover your cursor over the **Information** icon ( ).

To save the contents of the program, click **Save**. Your changes are written to an in-storage copy of the
program; the actual program is not changed. On a subsequent page, you can run the program with your
changes. Or, you can save a permanent copy of the modified program in a data set or UNIX file.

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page

```
Workflows task   85
```

```
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
In the Run and Save Script page:
```
- To run the program on the selected system, click **Run script on system** **_sys-name_**. Then, click **Finish** to
    run the program. For the results of the program execution, see the **Script Status** page. Alternatively, you
    can run the program manually from the specified location.
    If you selected to run the program on a system in a remote sysplex, z/OSMF checks your access to the
    remote system.
    - If the system is running z/OSMF, verify that the system is enabled for single sign-on (SSO). Otherwise,
       the **Remote Server Authentication** window is displayed for you to authenticate to the remote
       system. If so, enter a valid user ID and password or passphrase for the remote system. You can
       avoid the authentication window by ensuring that the remote system is enabled for single sign-on
       (SSO) in the z/OSMF Systems task. For more information, see Defining your systems to z/OSMF.
    - If the system is not running z/OSMF, it must be associated with the z/OSMF system for that sysplex.
       If so, set the z/OSMF system as the host system for the system on which the workflow is to be
       performed. Similarly, you must ensure that the z/OSMF system in the remote sysplex is enabled for
       single sign-on. Or, you must be ready to authenticate to the system with a valid user ID and password
       or passphrase.
- To save the program to another location, click **Save script**. If a default location is provided for the
    program, the location is shown. You can save to this location, or specify another location by specifying
    the following details:
    - To save the program in a UNIX file, click **z/OS UNIX file**. Specify the full file path, including the file
       name. The file is created if it does not exist already.

**86**   Workflows task


- To save the program to a data set, click **z/OS data set**. Specify an existing data set. Include the
    following details about the data set, if applicable:
    - For a partitioned data set, include the member name. A new member is created if one does not
       exist already.
    - If the data set is not cataloged, specify the volume serial (volser).

If a file or member already exists by the same name, the request is failed with an error message. You can,
however, choose to allow the new file or member to overlay the existing structure. To do so, select the
option **Overwrite the file or member if it exists already**.

If a default location was provided, you can restore the location to the default value by clicking **Restore
Default Location**. Otherwise, this option is disabled.

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page

```
Workflows task   87
```

```
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Table 33 on page 88 describes the fields displayed on the Status tab.
```
```
Table 33. Fields on the Status tab
```
```
Field Description
```
```
Script file For a program or script that resides in a separate file, this field shows the location
of the file (the fully-qualified file path). If the program or script is inline (contained
with the step definition), this field is blank.
```
```
Target system Name of the system on which the program or script ran.
```
```
Status Status of the script. Valid values are:
```
```
Success
Success message, as defined in the step
Failed
Failure message, as defined in the step
Timeout
The program failed to completed within the defined time limit
Canceled
The script did not complete because it was canceled by the step owner or
workflow owner.
```
```
Return Variables If the program created output variables for use elsewhere in the workflow, the
variables and their associated values are listed in a tabular format. The variables
are saved in the Workflows task variables pool for use with other workflows.
Note: Array variables, which are used to map multiple values, are not shown in this
table.
```
```
Messages The messages that were issued during program execution are displayed in the field
Messages in read-only mode. This field includes messages from the TSO/E service
and any messages for the program in the workflow definition file.
```
**88**   Workflows task


**Canceling an in-progress program or script**

You can cancel a program or script while it is running. To do so, click **Cancel Script**. This action is available
only while the program or script is running. This option is disabled after the program or script completes,
or if the step is being performed through automation processing.

**Refreshing this page**

You can refresh the status of a program or script while it is running. To do so, click **Refresh**.

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be

```
Workflows task   89
```

```
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
The Input Variables page is displayed when the Step Perform wizard requires information from you
before you continue. The wizard presents the variables in groups according to type (variable category),
with a separate page for each category. Depending on the amount and type of information that is required,
the wizard might display multiple input pages for you to complete. The number of Input Variables pages
in the wizard is specified in the workflow definition file.
```
```
The Information icon ( ) is displayed for variables that have more information available, such as
guidance information or syntax rules. To learn more about the variable, click the icon.
If the variable is used by other steps in the workflow, clicking the icon also displays the Variable
References table. This table shows the other steps in the workflow that use the same variable.
Note: Array variables, which are used to map multiple values, are not shown in this page.
Table 34 on page 90 shows the format of the Variable References table.
```
```
Table 34. Columns in the Variable References table
```
```
Column Description
```
```
State State of the step.
```
```
No. Number that indicates the step position in the sequence of steps that comprise the
workflow.
```
```
Title Title of the step. z/OSMF obtains this value from the workflow definition file when
the workflow is created.
```
```
Owner User ID of the step owner. This field is blank if no owner exists for the step.
```
```
You cannot sort, filter, or refresh the data in the Variable References table.
If no other steps use the variable, the Variable References table is not displayed.
In some cases, if a value was previously provided in another step, the wizard shows the variable as
locked. That is, the variable is disabled and its input field is read-only.
To edit a locked variable, select the option Make value editable. When you select to make the variable
editable (by checking the box and pressing OK ), you can edit the variable setting on the input variable
page within the wizard. Here, it is recommended that you review the other steps that use the variable to
determine whether the steps are to be repeated with the new variable setting. Some variables are global
in scope and might be applicable to other workflows at your installation.
```
**90**   Workflows task


**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review JCL page
On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Review File Contents page
On the _Review File Contents_ page in the _Step Perform_ wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page

```
Workflows task   91
```

```
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
If you supplied input previously in the Input Variables page of the Step Perform wizard, the Review
Instructions page might include customized instructions for your use.
For a step that contains a JCL job, REXX exec program, or shell script, you can subsequently proceed
with the step, that is, generate, submit, and save the generated program. For a step that contains a file
template, you can continue on to generate and save the file. Alternatively, you can choose to not continue,
even when these options are available. If so, you are responsible for ensuring that the step is performed
manually (outside of the wizard), using the instructions provided on this page. If it is included on the page,
select an option to describe whether you were able to complete the step manually.
Related tasks
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Saving the file
You can save the file using the Specify File Location page on the Step Perform wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
Related reference
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Review Script page
On the Review Script page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the Confirm Parameters page of the Step Perform wizard.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Edit Sysout DD Name page
```
**92**   Workflows task


The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review JCL page
On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Review File Contents page
On the _Review File Contents_ page in the _Step Perform_ wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page
On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**Edit Output File Path page**

The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

On this page, you can review the path for the output file. If necessary, you can modify the file path as
appropriate for your environment.

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts

```
Workflows task   93
```

```
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
The sysout DD name uses the following syntax:
```
```
[step.]ddname
```
```
Where:
```
- _step_ is the name of the job step that creates the spool file. This value is optional. You can accept the
    default name, leave it blank, or enter a name of your own choosing.
    The step name must:
    - Contain 1 - 8 alphanumeric (A-Z, a-z, 0-9) or special ($, #, @) characters.
    - Begin with an alphabetic (A-Z, a-z) or special ($, #, @) character.
    - Be followed by a period.
    If this value is omitted, z/OSMF checks the results of the executed job to find a job step with a DD
    name that matches the _ddname_ in the field **Sysout DD Name**. Therefore, to avoid ambiguity, it is
    recommended that the step name is always specified.
- _ddname_ is the DD name that identifies the spool file. This value is required.
    You can accept this name, or enter a name of your own choosing.

**94**   Workflows task


```
The DD name must:
```
- Contain 1 - 8 alphanumeric (A-Z, a-z, 0-9) or special ($, #, @) characters.
- Begin with an alphabetic (A-Z, a-z) or special ($, #, @) character.

If both the step name and DD name are specified, these values must be joined by a period.

Example:

```
stepname.ddname
```
Avoid using DD names that have special meaning for JES2 or JES3, such as the following names:

- JOBAT
- JOBLIB
- STDIN
- STDOUT
- STEPCAT
- STEPLIB
- SYSABEND
- SYSOUT
- SYSPRINT
- SYSMDUMP
- SYSUDUMP

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts

```
Workflows task   95
```

```
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
On the first access of this page, the JOB statement is initialized with IBM-supplied values. Thereafter, the
JOB statement is populated with the values you used previously in the Workflows task.
Edit the JOB statement as needed. For example, you can modify the account number and job class. When
you finish, select whether the JOB statement is to be applied to the job in the current step, or to all steps
in the current workflow for which you are the step owner.
z/OSMF performs only limited validation of the JOB statement. Therefore, you must ensure that the JOB
statement contains valid values for your installation.
For more information about specifying values for a JCL JOB statement, see z/OS MVS JCL Reference.
```
**Variables in the JOB statement**

```
The JOB statement might include variables for installation-specific values on your system. If so, the
variables are enclosed in braces ('{ }'). To view the actual values for the variables, click View
Substitutions. You can modify instance variables, but not global variables.
```
**96**   Workflows task


For example, in the following JOB statement, the user ID for receiving job notifications is represented by
the instance variable named st_user.

```
//IZUWFJB JOB (ACCTINFO),CLASS=STEP,MSGCLASS=STEP,
// MSGLEVEL=(1,1),REGION=0M,NOTIFY=${st_user}
```
On clicking **View Substitutions** , the variable is resolved to the user ID IBMUSER.

```
//IZUWFJB JOB (ACCTINFO),CLASS=STEP,MSGCLASS=STEP,
// MSGLEVEL=(1,1),REGION=0M,NOTIFY=IBMUSER
```
You can overwrite this value to specify another user ID for receiving job notifications.

**Related tasks**

Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page

```
Workflows task   97
```

```
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
The generated JCL contains:
```
- JOB statement that you specified on the _Create JOB Statement_ page
- Job control statement, if the job is to be run on a system other than the system on which z/OSMF is
    running. If applicable, this part is automatically created by the Workflows task, based on the target
    system you specified when creating the workflow.
- Job logic, as provided by the workflow provider, including customizations or substitutions for the
    relevant user-supplied variable inputs.
The field **Maximum record length** indicates the maximum record length, in bytes, for the input data for
the job, as defined by the workflow definition. The default value is 1024.
To make changes to the input variables, click **Back** to return to the appropriate _Input Variables_ page of the
Step Perform wizard. To edit the JCL directly, click **Edit JCL**. When you are ready to submit the job, click
**Finish** to save the job.
When you are satisfied with the generated job, press **Next** to continue to the next page. You can then
submit the job, save the job, or both.
**Related tasks**
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the **Submit and Save JCL** page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the **Step Properties** page.
Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
**Related reference**
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before

**98**   Workflows task


you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review File Contents page
On the _Review File Contents_ page in the _Step Perform_ wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page
On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**_Edit JCL page_**
You can use the **Edit JCL** page in the Step Perform wizard to edit the JCL for the step. To modify the JCL,
you can edit it directly from this page, or you can close this page and use the **Back** button to navigate to
the appropriate **Input Variables** page of the Step Perform wizard. In most cases, it is recommended that
you move back to the previous pages to make corrections. Use the **Edit** function on this page only when
the inputs on the previous pages do not provide the JCL changes that you require.

When you click **Save** , z/OSMF performs limited syntax checking, such as checking line lengths. If z/OSMF
detects syntax violations, they are identified in the Messages table. The following columns are displayed
in the table:

**Line**
Line number for the JCL statement that contains the error. Click the line number link to scroll to and
highlight the line where the error occurred.

```
Workflows task   99
```

```
Message ID
Identifier for the message. To display the help for the message, you can click the Status icon or
message ID link.
Message Text
Text of the message.
The Messages table is displayed only if there are unresolved errors. Otherwise, it is not visible on the
page.
z/OSMF does not perform any other syntax validation; therefore, if the JCL contains errors, the job might
fail when you submit it.
```
```
Saving your changes
To save the changes you made to the JCL, click Save. The changes are used only for the current step.
z/OSMF discards the changes when you click Next to continue with the job submission, or click Cancel to
close the wizard and discard any input that you provided since the previous save.
```
**Undoing your changes**

```
To undo the changes you made to the JCL, click Undo All Changes. When you do so, the changes you
made since the last save are discarded. If no save was done previously, the job reverts to the originally
generated JCL.
To close the wizard and return to the Steps page, click Cancel. If any unsaved changes remain, you are
prompted to save or discard the changes.
```
```
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
```
**Procedure**

1. Select whether to submit the job by selecting the **Submit JCL** option.
2. To save the JCL on the local system, select **Save JCL** and specify a location for the saved JCL. Choose
    either an existing z/OS data set or a UNIX file.
3. To allow the new file to override an earlier copy, select **Overwrite the file or member if it exists**
    **already**.
4. If it is included on the page, select on option that indicates whether you were able to complete the
    step manually.
5. Click **Finish** to process the JCL as specified (submit, save, or submit and save).
    If you selected to run the job on a system in a remote sysplex, z/OSMF checks your access to the
    remote system.
    - If the system is running z/OSMF, verify that the system is enabled for single sign-on (SSO).
       Otherwise, the **Remote Server Authentication** window is displayed for you to authenticate to the
       remote system. If so, enter a valid user ID and password or passphrase for the remote system.
       You can avoid the authentication window by ensuring that the remote system is enabled for single
       sign-on (SSO) in the z/OSMF Systems task. For more information, see Defining your systems to
       z/OSMF.
    - If the system is not running z/OSMF, it must be associated with the z/OSMF system for that sysplex.
       If so, set the z/OSMF system as the host system for the system on which the workflow is to be
       performed. Similarly, you must ensure that the z/OSMF system in the remote sysplex is enabled
       for single sign-on. Or, you must be ready to authenticate to the system with a valid user ID and
       password or passphrase.

**100**   Workflows task


**Results**

On the **Steps** page, the selected step is displayed as Complete.

**Related tasks**

Saving the file
You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Related reference**

Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the **Confirm Parameters** page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.

Review Script page
On the **Review Script** page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the _Confirm Parameters_ page of the Step Perform wizard.

Edit Script page
If you select to edit an executable program, the **Edit Script** page is displayed. Here, you can make
changes to the program contents.

Run and Save Script page
When you finish editing the executable program, the **Run and Save Script** page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.

Status tab for programs and scripts
You can use the **Status** tab on the _Step Properties_ page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.

Input Variables page
If the Step Perform wizard displays one or more **Input Variables** pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.

Review Instructions page
On the _Review Instructions_ page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.

Edit Output File Path page
The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review JCL page
On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Review File Contents page

```
Workflows task   101
```

```
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
Call REST API page
On the Call REST API page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.
```
```
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
To make changes to the input variables, click Back to return to the appropriate Input Variables page of the
Step Perform wizard. To edit the file contents directly, click Edit Contents. When you are done, click Save
to save the file.
Related tasks
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Saving the file
You can save the file using the Specify File Location page on the Step Perform wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
Related reference
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Review Script page
On the Review Script page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the Confirm Parameters page of the Step Perform wizard.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
```
**102**   Workflows task


The _Edit Output File Path_ page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.

Edit Sysout DD Name page
The _Edit Sysout DD Name_ page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field **Sysout DD Name**.

Create JOB Statement page
On the **Create JOB Statement** page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.

Review JCL page
On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page
On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**_Edit File page_**
You can use the _Edit File_ page in the _Step Perform_ wizard to edit the generated file for the step.

To modify the file contents, you can edit the file directly or you can close this view and use the **Back**
button to navigate to the appropriate page in the wizard. If you edit the file directly, the **Back** button in
the wizard is disabled because revisiting the wizard pages might result in regenerating the file, which will
cause all of your changes to be discarded. If you want to make changes using the wizard pages, complete
those changes before editing the file.

**Saving your changes**

To save the changes you made to the file, click **Save**. The changed file is used only for the current step.

z/OSMF discards the changes when you click **Finish** to submit the job or click **Cancel** to cancel the
changes.

**Undoing your changes**

To undo the changes you made to the file, click **Undo All Changes** or **Cancel**. When you click **Undo All
Changes** , all of the changes you made since the last save are discarded.

When you click **Cancel** , z/OSMF discards all changes you made to the file. That is, the job is reverted to
the originally generated file.

**Saving the file**

You can save the file using the _Specify File Location_ page on the _Step Perform_ wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.

**Procedure**

1. Select whether to save the file as a UNIX file or z/OS data set.
    - To save the file as a UNIX file, specify the full path, including the file name.
    - To save the file as a data set, specify an existing data set, including the member name, if applicable.
2. To allow the new file to override an earlier copy, select _Overwrite the file or member if it exists already_.
    To restore the original file name or data set name, click **Restore Default Locations**. This option is
    disabled if no default location is available.

```
Workflows task   103
```

3. Click **Finish** to save the file to the specified location.

```
Results
The Steps page is displayed, showing that the selected step is Complete.
Related tasks
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Related reference
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Review Script page
On the Review Script page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the Confirm Parameters page of the Step Perform wizard.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
```
**104**   Workflows task


On the _Review JCL_ page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
_Input Variables_ page of the Step Perform wizard.

Review File Contents page
On the _Review File Contents_ page in the _Step Perform_ wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
_Input Variables_ page of the Step Perform wizard.

Call REST API page
On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

**Call REST API page**

On the **Call REST API** page in the Step Perform wizard, you can review the REST request and verify that it
is correct. The page displays the actual request after any variable substitution is performed.

On the **Call REST API** page:

**HTTP Method**
Shows the request method, which is one of the following values:

- GET
- PUT
- POST
- DELETE

**Request**
Shows the request, including the Universal Resource Identifier (URI) path and, where appropriate, any
query parameters that further qualify the request.

**Request headers**
Shows the request header properties, if the request includes any. Otherwise, this field is omitted.
The request header is shown as a JSON object:

- Braces '{ }' enclose the JSON content
- Each header property is a name-value pair, with the property and its value delineated with a colon (:)
For example:

```
{
"Content-Type" : "application/JSON",
"Accept" : "*/*"
}
```
```
If no header properties are specified, z/OSMF uses the following defaults for a PUT or POST request:
Content-Type
application/JSON
Contents-Length
Length of the request body
Charset
UTF-8
Any properties that are specified in the request header will override the z/OSMF defaults.
```
**Request body**
Shows the request body, if the request includes one. Otherwise, this field is blank. Typically, a **POST** or
**PUT** request includes a request body. A **GET** or **DELETE** request does not.

**Certificates**
If the current step specifies a secure connection for a remote endpoint, this field shows the location of
one or more certificates (the fully qualified paths and file names).

```
Workflows task   105
```

```
Certificate locations are shown as a JSON array, as follows:
```
- Square brackets '[ ]' enclose the array
- For each certificate, a fully qualified (absolute) path is provided
- For multiple certificates, commas are used to separate the locations.
For example:

```
[
"/tmp/SampleCertificate.cer",
"/tmp/AnotherCertificate.cer"
]
```
```
You cannot edit the REST request on this page. To edit the request, you must edit the workflow definition
file that you used to create the workflow, and create the workflow again.
If you supplied input variables for the step, you might determine that you need to modify the variable
values. If so, click Back to return to the appropriate Input Variables page of the Step Perform wizard.
Next and Save are unavailable.
When you are satisfied with the REST request, click Finish to submit the request for processing.
Otherwise, click Cancel to close this page.
Related tasks
Submitting or saving your JCL
You can submit the JCL, save it for future use, or both, using the Submit and Save JCL page on the Step
Perform wizard. If you submit the JCL, the job runs on the target system that was specified when the
workflow was created. The results of the job are shown in the Status tab of the Step Properties page.
Saving the file
You can save the file using the Specify File Location page on the Step Perform wizard. In this page, you
indicate the save location and the file type: UNIX file or z/OS data set.
Related reference
Confirm Parameters page
For a step that runs an executable program, if the step requires input parameters, the Step Perform
wizard displays the Confirm Parameters page. This page describes the parameters that must be supplied
to the executable program. On this page, you can accept the parameter values as they are displayed, or
you can modify the parameters by typing over the current values.
Review Script page
On the Review Script page in the Step Perform wizard, you can review the contents of the executable
program, perhaps to determine whether the program requires modifications for your environment before
you run it. This page shows the program code that is supplied by the workflow provider, plus any
parameter values you entered in the Confirm Parameters page of the Step Perform wizard.
Edit Script page
If you select to edit an executable program, the Edit Script page is displayed. Here, you can make
changes to the program contents.
Run and Save Script page
When you finish editing the executable program, the Run and Save Script page is displayed. Here, you
can run the program on the selected system or save it to another location for running at a later time.
Status tab for programs and scripts
You can use the Status tab on the Step Properties page to check the results of a REXX exec program or a
UNIX shell script that is run by a step.
Input Variables page
If the Step Perform wizard displays one or more Input Variables pages, you must specify the required
values. The Step Perform wizard uses your input to create customized content for your installation. Such
content might include user instructions for you to follow or JCL for you to submit through the wizard later.
Review Instructions page
```
**106**   Workflows task


```
On the Review Instructions page in the Step Perform wizard, review the instructions for performing the
step. This page is included for all steps.
Edit Output File Path page
The Edit Output File Path page is included for a step that generates an output file. The default name of the
output file is specified in the workflow definition, as part of the definition of the step.
Edit Sysout DD Name page
The Edit Sysout DD Name page is included for a step that creates a properties file as a JES spool file. On
this page, you can review the file name and, if necessary, modify it. The default name of the properties file
is extracted from the workflow definition, and is displayed in the field Sysout DD Name.
Create JOB Statement page
On the Create JOB Statement page in the Step Perform wizard, you can accept the default JOB
statement, modify the default JOB statement, or create a new JOB statement. The JOB statement can be
applied to the job in the current step, or to all steps in the current workflow for which you are the step
owner.
Review JCL page
On the Review JCL page in the Step Perform wizard, verify that the generated job is correct. The job
includes the JCL statements supplied by the workflow provider, plus any information you entered in the
Input Variables page of the Step Perform wizard.
Review File Contents page
On the Review File Contents page in the Step Perform wizard, verify that the generated file is correct. The
file includes the content supplied by the workflow provider and the information you entered earlier in the
Input Variables page of the Step Perform wizard.
```
#### Resolving a conflict in variable definitions in an output file..............................................................

```
When a workflow step saves variables in an output file, the Workflows task reads in the contents of the file
and saves its values for use with other steps in the workflow. If the Workflows task detects that a variable
in the output file conflicts with an existing variable, it prompts you to choose the appropriate value. Your
selection determines which version of the variable is to be used.
```
**About this task**

```
If the Workflows task detects that a variable in the output file conflicts with an existing variable, the step
is assigned a state of Conflicts, indicated by the Conflicts icon in the Conflict Status column. You must
resolve the conflicts.
```
**Procedure**

1. From the Workflow Steps table, select the **Resolve Conflicts** action for the step. The Input Variables
    tab of the **Step Properties** page is displayed.
2. For each variable in conflict, select the version of the variable that is to be saved in the Workflows task
    global variable pool, by using the list in the New Value column.
3. Click **Apply New Value Selections**.

**Results**

```
After you resolve all conflicts, the error message is removed, and the Conflicts icon is no longer
displayed for any of the steps in the Workflow Steps table.
```
#### Skipping a step in the workflow.........................................................................................................

```
To skip one or more steps in a workflow, use the Skip action that is provided in the Workflow Steps table.
Doing so allows you to bypass the steps. You might use this action for any steps that are not applicable
to your environment. Some steps in a workflow might be labeled as optional; here, the workflow provider
determined that the steps can be considered for use by your installation or skipped.
```
```
Workflows task   107
```

```
Before you begin
Verify that the step to be skipped is not needed in your environment.
```
**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps to be skipped.
3. From the **Actions** menu or context menu, select **Open**.
    The **Steps** page is displayed.
4. In the Workflow Steps table, select the step to be skipped. You can select multiple steps.
    This action is disabled if you are not the workflow owner or the step owner.
5. From the **Actions** menu or context menu, select **Skip**. The **Skip Step** window is displayed.
    This page includes the Selected Steps table. You can expand this section to review the steps for which
    this action applies.
6. Optionally, enter a comment in the **Comments** field to document this action.
    For example, you can indicate the reason for skipping the step.
7. Click **OK** to skip the selected steps.

**Results**

```
The Steps page is displayed, showing that the selected steps are changed to Skipped state.
```
#### Using the Override Complete action..................................................................................................

```
If a step describes work that was performed outside of the Workflows task, it is still important to indicate
that this work is done. Here, you can mark the step as complete through the Override Complete action
that is provided in the Workflow Steps table.
```
```
Before you begin
Verify that the step to be overridden was performed outside of the Workflows task.
```
**Procedure**

1. Select and double-click the **Workflows** task from the z/OSMF desktop. If the **Workflows** task is not
    displayed in the desktop, select it from the App Center in the taskbar.
    The **Workflows** page opens.
2. Select the workflow with steps to be overridden.
3. From the **Actions** menu or context menu, select **Open**.
    The **Steps** page is displayed.
4. In the Workflow Steps table, select the step to be overridden. You can select multiple steps.
    This action is disabled if you are not the workflow owner or the step owner.
5. From the **Actions** menu or context menu, select **Override Complete**. The **Override Complete** window
    is displayed.
    This page includes the Selected Steps table. You can expand this section to review the steps for which
    this action applies.
6. Optionally, enter a comment in the **Comments** field to document this action.
7. Click **OK** to override the selected steps.

**108**   Workflows task


```
Results
The Steps page is displayed, showing that the selected steps are marked Complete (Override).
```
#### Adding notes to workflows................................................................................................................

```
You can record useful information about a workflow by adding your own notes to it. You might add notes,
for example, to explain the purpose of the workflow, or specify the date by when the workflow should be
completed.
To create a note, click the Notes link that is provided on the Steps page. Doing so displays the Notes
window for you to view the notes for the workflow, and add your own. Enter the notes to associate with
the selected workflow. This field can contain up to 2048 characters. When you click OK , the notes are
updated with the information you entered.
Up to 500 notes can be recorded for a workflow. This number includes both workflow notes and step
notes.
By default, the workflow notes and step notes can be viewed by all users of the Workflows task. It is
possible to restrict access to notes by specifying an access type for the workflow—at workflow creation
time or later. The access type determines which users can view the workflow steps and edit the step
notes.
The valid values for the accessType property are summarized, as follows:
Public
Information about the workflow, including the steps, variables, and notes, can be viewed by all users.
Restricted
Information about steps, variables, and notes, is restricted to a subset of users—the workflow owner,
step owners, and step assignees. Other users cannot access this information.
Private
Information is restricted to a subset of users, and is further limited among these users. The workflow
owner can access information about steps, variables, and notes. Step owners and assignees can
retrieve information about the steps for which they are assigned or own, and the associated variables
for those steps. Other users cannot access this information.
By default, workflows are public. When you add notes to a public workflow, the notes are viewable and
editable by the other users of the Workflows task.
It is not possible to add or modify notes for a workflow with the status Automation in Progress. To do so,
you must either allow the automation processing to complete, or you can stop the processing through the
Stop Automation action on the Workflows page.
```
#### Workflow history................................................................................................................................

```
As users progress through a workflow, z/OSMF maintains a history or log of the workflow activities. For
example, z/OSMF captures information about the creation and modification of the workflow and the state
changes of the steps. This information might be useful to your installation later, perhaps for auditing
purposes. If you are the originator of a history comment, you can later modify your comment, as needed.
For a description of the columns in the Workflow history table, see Table 35 on page 110. For a
description of the actions that you can take for workflows, see “Actions for the workflow history” on
page 111.
```
```
Workflows task   109
```

**Columns in the Workflow History table**

```
Table 35. Columns in the Workflow History table
```
```
Column Description
```
```
Date and Time (GMT) Date and time on the system when the action was performed. The date and time is
in Greenwich Mean Time (GMT).
By default, items in the history table are sorted in ascending order, based on date
and time. You can modify the default sort and filter, but clearing them restores the
defaults. If you hide this column, the default sort and filter are still applied to the
table.
```
```
Action Action that was taken. One of the following values is displayed:
```
- Workflow Created
- Workflow Modified
- Workflow Canceled
- Workflow Upgraded
- Workflow Completed
- Step Assigned
- Step Unassigned
- Step Accepted
- Step Returned
- Step Skipped
- Step Completed
- Step Completed (Overridden)
- Submitted
- Failed
- Take Ownership
- Perform Step
- File Saved
- Automation Started
- Automation Stopped
- Automatic Step Complete
- Automatic Step Failed
- Automatic Step Skipped
- Output File Failed
- Conflicts Detected
- Conflict Resolved
- Condition Changed
- Refresh Step State^1
- Parallel Automation Started
- Parallel Step Complete
- Parallel Step Failed
- Parallel Step Skipped

**110**   Workflows task


_Table 35. Columns in the Workflow History table (continued)_

**Column Description**

Messages One or more messages that describe the action. For a description of each message,
click the message ID link.
More and Less links are provided so that you can control how much message text is
displayed.

User ID User ID of the user who performed the action.

Comments Comments, if any, that were provided at the time a particular action was taken. A

```
comment can be modified by the originator of the comment.
More and Less links are provided so that you can control how much message text is
displayed.
```
IP Address IP address of the system on which the user performed the action. By default, this
column is not displayed, but you can select to display it through the Configure
Columns action on the table.

(^1) The action Refresh Step State is used when a step changes state and other steps have dependency on
this step. Here, the Workflows task checks the conditions of the dependent steps and revises their states,
accordingly.
**Actions for the workflow history**
The actions are described in the following tables:

- Table 36 on page 111. Actions that apply to the selected comment. To use a targeted action, select one
    comment only.
- Table 37 on page 111. Actions that apply to the entire table. No selection is required.

_Table 36. Targeted actions for the Workflow History table_

**Action Description**

**Modify Comments** Display the **Modify Comments** dialog so that you can modify your comments for
the selected history record. You can modify only the comments that you created.
This action is disabled for a workflow with the status _Automation in Progress_. That
is, it is not possible to modify your comments while an automated step is running.
You must either allow the processing to complete, or you can stop the processing
through the Stop Automation action on the **Workflows** page.

_Table 37. Table actions for the Workflow History table_

**Action Description**

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.

**Show Filter Row** Display the filter row. This action is listed only when the filter row is not displayed
in the table.

**Clear Sorts** Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.

```
Workflows task   111
```

```
Table 37. Table actions for the Workflow History table (continued)
```
```
Action Description
```
```
Clear Search Clear the search.
```
**112**   Workflows task


## Index................................................................................................................

**A**

adding assignees to a step 68
adding notes to workflow steps 58
adding notes to workflows 109
adding users to the Workflows task 68
Archive Automation Settings 19
archived workflow 41
assignees 68

**C**

customizing the JOB statement 40

**E**

editing file 103
editing JCL 99
editing script 85

**G**

General Settings 18

**I**

instance variable 96
Internal Job Statement Settings 20

**J**

JCL 98, 99
job control language 98, 99
JOB statement 96

**P**

performing a parallel step automatically 74
performing a step 59, 85, 99, 100, 103
performing a step automatically 74
performing a step manually 81
printing the contents of a workflow 66
Properties for workflow page 20

**R**

removing assignees 69
returning a step 70, 72
reviewing the file contents 102
reviewing the JCL 98
reviewing the script 83
REXX exec program 83, 85

```
S
script 85
step assignees 68
```
```
U
UNIX shell script 83
```
**V**

```
viewing file contents 102
viewing JCL 98
viewing script code 83
```
```
W
workflow 1
workflow access type 32
workflow history 109
Workflow Settings 18
Workflows task 1, 10, 42
```
```
Index   113
```

IBM®


## Workflow Editor task

# IBM


## Contents

```
Workflow Editor task............................................................................................. 1
Workflow Editor task overview.................................................................................................................... 1
Terms you should know..........................................................................................................................2
Understanding the Workflow Editor layout............................................................................................4
How a workflow definition file is processed.......................................................................................... 6
Concurrency considerations...................................................................................................................8
Edit Workflow Definition dialog................................................................................................................... 8
Workflow Text Editor window....................................................................................................................11
Workflow Editor task main page................................................................................................................12
Metadata tab..............................................................................................................................................14
Steps tab.................................................................................................................................................... 17
Create a New Step................................................................................................................................20
Copy Step..............................................................................................................................................23
Moving a step within a workflow..........................................................................................................24
Overview tab.........................................................................................................................................24
Prerequisites tab.................................................................................................................................. 25
Instructions tab.................................................................................................................................... 27
Type tab................................................................................................................................................ 27
Shared step library............................................................................................................................... 48
Conditions tab...................................................................................................................................... 52
Security tab...........................................................................................................................................54
Step Variables tab................................................................................................................................ 57
Step Feedback tab................................................................................................................................59
Advanced tab........................................................................................................................................59
Variables tab.............................................................................................................................................. 61
Create a new variable...........................................................................................................................62
Create multiple variables..................................................................................................................... 64
Copy a variable..................................................................................................................................... 66
Workflow Variables tab........................................................................................................................ 67
Workflow feedback tab..............................................................................................................................73
Creating feedback questions for your workflow..................................................................................75
Input Properties tab...................................................................................................................................76
```
**Index.................................................................................................................. 78**

**ii**


**Workflow Editor task**

```
You can use the z/OSMF Workflow Editor task to view and modify a workflow definition.
With the Workflow Editor task, you can:
```
- Edit a workflow definition by using a graphical user interface (GUI). You can add, delete, and modify the
    steps and variables in a workflow definition without having to know or understand XML. As you work,
    the editor checks your changes for correct syntax.
- Tailor an existing workflow with steps and variables that you add specifically for your installation.
- Edit the workflow variable input file, if one is available for use with the workflow definition.
- Create a workflow by using a series of dialogs and prompts. On completion, your workflow is ready for
    use in the Workflows task.

**Key features**

```
The Workflow Editor task:
```
- Presents the details of a workflow definition in a graphical user interface (GUI).
- Provides easy-to-use options for viewing and modifying a workflow definition.
To get started with the Workflow Editor task, in the navigation area, select **Workflow Editor**.

### Workflow Editor task overview

```
With the z/OSMF Workflow Editor task, you can view and edit the XML elements that comprise a workflow
definition.
Using the Workflow Editor task, you can:
```
- Select an existing workflow definition file for editing. Or, have the Workflow Editor create a starter
    workflow with which you can begin working.
- View details about the different sections of a workflow definition—the metadata, steps, and variables.
- Modify the workflow information, steps, and variables sections of the definition, including adding and
    deleting steps and variable definitions.
- Edit the workflow variable input file, if one is available for use with the workflow definition.
- Overwrite the workflow definition with your changes.
To use the Workflow Editor, it is not necessary that you understand XML. However, it is important that
you understand the basic concepts of a workflow and how to access the elements of a workflow in the
Workflow Editor.
More information is provided in the following topics:
- The key terms are described in “Terms you should know” on page 2.
- The Workflow Editor interface is described in “Understanding the Workflow Editor layout” on page 4.
- Processing details for the Workflow Editor are provided in “How a workflow definition file is processed”
    on page 6.
- Further usage considerations for the Workflow Editor are described in “Concurrency considerations” on
    page 8.
For more information about creating workflows, see the topic _Creating workflow definitions for z/OS_ in IBM
z/OS Management Facility Programming Guide.
The following references provide more detailed information about the XML specification and coding
practices:

```
Workflow Editor task   1
```

- The World Wide Web Consortium (W3C) XML Technology page: [http://www.w3.org/standards/xml/](http://www.w3.org/standards/xml/)
- XML Core Working Group Public Page: [http://www.w3.org/XML/.](http://www.w3.org/XML/.)

#### Terms you should know

```
Workflow authors and users should be familiar with the following terms.
Automated step
A step can be designed to run automatically (without user interaction) when it is in Ready state. A
workflow that is comprised entirely of automated steps can run with little or no user intervention.
Called workflow
A workflow that is started by another workflow.
Calling step
A step that calls another workflow instance for processing.
Conditional step
A step with a state that is impacted by conditions on the z/OS® system or in the Workflows task.
Conditions can be used to mark steps ready, not ready, skipped, or complete. For example, a
conditional step might become eligible to be performed if a job that is run by another step ends
with a particular return code. Such a conditional step remains ineligible to be performed while the
condition is not satisfied.
File template step
A step that refers to another file for the code to be run. The external file that the step references
contains a JCL template, which is used to submit a job, a REXX exec program, or a UNIX shell script.
Contrast with inline template step.
Inline template step
A step that contains the code to be run. The step contains a JCL template, which is used to submit a
job, a REXX exec program, or a UNIX shell script. Contrast with file template step.
Instance variable
A variable definition that is available only to instances of a particular workflow.
Instructions step
A step that contains text instructions for the user to follow, but no executable code to run.
Output file
Another name for an output properties file. For more information, see Output properties file.
Output properties file
A file that contains the output from a JCL job step that determines new values for defined workflow
instance variables. The file’s format is similar to a properties file in that it lists one or more variables
that are defined in the workflow definition file and new values for those variables. In a step that
defines an output file, after the JCL job runs, the output file's contents are used to set or change
the included variable values in the workflow instance. In practice, a step might submit a batch job to
obtain some z/OS related parameters. Those parameters are then used by a subsequent step, thus
saving the Workflows task user from having to enter the parameter values manually. If an output
properties file is specified but not found, the step fails even if the job completed successfully.
Parallel-steps workflow
A workflow with automated steps that can be run in parallel (concurrently). When a parallel-steps
workflow is started, the Workflows task locates all of the automated steps with Ready status, and
attempts to run these steps concurrently. The failure of an automated step does not stop automation
processing for the other automated steps. Processing continues until all of the automated steps are
completed or failed, or the user stops automation processing by using the Stop Automation action on
the Workflows page.
Predefined variable
A variable that is treated as a string substitution for the current step only.
Properties file
Another name for a workflow variable input file. For more information, see Workflow variable input file.
```
**2**   Workflow Editor task


**REST step**
A step that issues a Representational State Transfer (REST) request, such as a GET or PUT request.

**Step**
A single, logical unit of work in a workflow. Consider each step to describe a specific activity to be
performed on the system. The workflow owner can assign all steps to themselves or assign individual
steps to different users. After a user has ownership of a step, they can perform it after all conditions
and prerequisites are met.

**Step owner**
The user who accepts ownership of a step and who is therefore responsible for performing the step.

**Workflow**

1. The sequence of actions that comprise an activity on the z/OS system, such as configuring a
    component or product or managing the z/OS system. A workflow consists of one or more units of
    work, or steps, to be performed on the z/OS system, as described by the workflow definition.
2. A shortened, catch-all name for a _workflow instance_ , _workflow definition_ , or _workflow definition file_.
    For more information, see Workflow instance, Workflow definition, or Workflow definition file.

**Workflow author**
The person, typically an application programmer, who creates the workflow definition.

**Workflow category**
A classification of the activities to be performed in the workflow. In z/OSMF, workflows that are used
to configure system software are classified as _Configuration workflows_. Workflows that are used to
provision system software are classified as _Provisioning workflows_. All other workflows are classified
as _General workflows_.

**Workflow definition**

1. The logical structure of a workflow that is represented as a series of one or more steps. The
    workflow definition identifies the various system objects and actions that constitute activities
    on z/OS and the logic for performing those activities. The workflow definition includes all the
    information that is specified in, or referenced by, the primary XML file (the _workflow definition file_ )
    and possibly other files that the workflow definition file includes. This content typically includes
    information about the workflow (such as name and version), step definitions, variable definitions,
    file templates, and bundle files. To build a workflow definition, either use the z/OSMF Workflow
    Editor task or write it in the text editor of your choice and save it as a workflow definition file.
2. A shortened name for a _workflow definition file_. For more information, see Workflow definition file.

**Workflow definition file**
The primary XML file for a workflow definition from which workflow instances are created. To create a
workflow instance, the workflow definition file must reside on a z/OS system in either a z/OS data set
or a UNIX System Services file system. A workflow instance is stored in a z/OSMF file system when its
workflow definition file and any other optional files are imported into the z/OSMF Workflows task. Use
the z/OSMF Workflow Editor task to create and modify workflow definition files.

**Workflow Editor task**
A z/OSMF plug-in that simplifies creation and editing of a workflow by providing an intuitive user
interface with online help. The z/OSMF Workflow Editor task hides all XML definitions and generates
syntactically valid XML when workflow definitions are saved.

**Workflow instance**
The executable instantiation of a workflow in z/OSMF, based on a workflow definition. A workflow
instance is created when the z/OSMF Workflows task or REST API is used to create an instance of a
workflow from a supplied workflow definition. After a workflow instance is created, any changes to the
source workflow definition are not reflected in the created instance. Use the z/OSMF Workflows task
to manage workflow instances.

**Workflow metadata**
In a workflow definition, identifies and provides details about the workflow. The metadata includes
the workflow identifier, description, category, version, vendor, and other details.

```
Workflow Editor task   3
```

```
Workflow owner
The user who is given ownership of the workflow through the Workflows task or the user who creates
the workflow instance by using a REST API. The workflow owner is responsible for running the steps
in the workflow or for delegating the steps in the workflow to other users to perform (the step
assignees).
Workflow provider
```
1. The source of the workflow definition file, typically IBM® or a software vendor.
2. Another name for a _workflow author_. For more information, see Workflow author.
**Workflow variable input file**
An optional file that supplies default values for one or more of the input variables that are defined in
the workflow definition file. If a workflow variable input file exists, it is specified with the workflow
definition file during the **Create workflow** action in the Workflows task or in the Create Workflow
REST API. Typically, a workflow provider supplies a workflow variable input file to save users from
having to manually enter inputs when they perform a workflow. By limiting user interaction, a
workflow variable input file can help to simplify the user experience of performing a workflow and
reduce the opportunities for user error.
**Workflow XML**
Another name for a _workflow definition file_. For more information, see Workflow definition file.
**Workflows task**
A z/OSMF plug-in that provides a framework for managing workflow instances in a z/OS environment.
**Related reference**
Understanding the Workflow Editor layout
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the _accordion_ , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.
How a workflow definition file is processed
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
Concurrency considerations
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.

#### Understanding the Workflow Editor layout

```
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the accordion , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.
Figure 1 on page 5 depicts the layout of the Workflow Editor interface.
```
**4**   Workflow Editor task


_Figure 1. Workflow Editor interface layout_

The following areas of the Workflow Editor are highlighted in Figure 1 on page 5:

1. Name of the selected workflow definition (the source file to be edited). As you edit the workflow, save
    your changes frequently to have them written to the source file at this location.
2. The major elements in a workflow are organized into the primary tabs: **Metadata** , **Steps** , **Variables** ,
    **Feedback** , and **Input Properties**. Select the tab for the type of element that you want to view or
    modify.
3. In the **Steps** and **Variables** tabs, a tabular view of the selectable elements is displayed. Select the step
    or variable that you want to view or modify. When you do so, the Workflow Editor opens the accordion
    area with more details about the step or variable to the right of the table.
4. When an element is selected from the table, a Details view (the accordion area) is enabled with
    information about the element that is extracted from the workflow definition.
5. An accordion separator is provided so that you can change the size of the Details view. Click and drag
    the separator to increase or decrease the size of the Details view. To hide the Details view, click the
    arrow icon in the separator or select the separator and press **Enter**. Hiding the view causes the open
    views to be expanded to fit the browser. To restore the Details view, click the arrow icon again or select
    the separator and press **Enter**. On the initial start-up of the editor, nothing is selected; the accordion is
    collapsed by default.
6. The Workflow Editor organizes the element information in a set of tabbed areas, from which you can
    edit the schema properties for the selected element. To view or modify the properties, select the
    appropriate tab, as follows:
    - In the **Step Details** view, you can view or modify the properties for the selected step. Select among
       the tabs for Overview, Prerequisites, Instructions, Type, Conditions, Security, Variables, Feedback,
       and Advanced.
    - In the **Variable Details** view, you can view or modify the properties for the workflow variables.
7. Help button that you can click to display help for the tab that currently has focus.

```
Workflow Editor task   5
```

8. Page-level help menu: Click **Help** to display information about the Workflow Editor or to open the
    z/OSMF integrated help system.
**Related concepts**
Terms you should know
Workflow authors and users should be familiar with the following terms.
**Related reference**
How a workflow definition file is processed
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
Concurrency considerations
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.

#### How a workflow definition file is processed

```
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
The Workflow Editor uses a process that is called unmarshalling to extract the contents of these files
into its cache. Later, when you save the edited file, the Workflow Editor uses a process that is called
marshalling to create a single, consolidated workflow definition file that represents all of the requisite
files. The resulting object is functionally equivalent to the original workflow structure, and the references
to external files are removed.
```
**What a workflow definition is**

```
A workflow definition might consist of just a single XML file, or it might consist of a primary XML file that
refers to one or more subordinate XML files and XML fragments. You might, for example, use a modular
approach and create a separate XML file to contain the variable definitions for a workflow. Further, a
workflow definition might include other types of external files, such as executable code, translated text
files, and velocity template files.
Collectively, this set of files comprises a workflow definition.
```
```
More about unmarshalling and marshalling
When you open a workflow definition file for editing, the Workflow Editor imports the file and its
constituent parts (the external files it references) into an internal cache. The Workflow Editor validates
the XML files for compliance with the schema that is supplied with the Workflows task. The schema
defines the required and optional properties (XML elements and attributes) of a workflow and imposes
constraints on the order in which the elements are specified, and on the values that can be specified for
each element and attribute.
The Workflow Editor then performs a number of actions to ensure that you always edit the complete set of
files as a single workflow definition file. Internally, the Workflow Editor creates copies of the primary XML
file and all of the external referenced XML files and merges the copies into a consolidated XML object.
This process, which is referred to as unmarshalling , removes the file references from the primary XML file.
This action logically "breaks" the connection between the workflow definition and the external referenced
XML files.
The unmarshalling process creates a single workflow definition file as output. Thereafter, whenever the
user saves changes in the editing session, the changes are applied to the cached version of the workflow
definition file. The original XML files are not changed by your actions in the Workflow Editor.
Later, when you save the edited file, the Workflow Editor uses a process that is called marshalling to
create a single, consolidated workflow definition file that represents all of the requisite files.
```
**6**   Workflow Editor task


For example, if the workflow definition file includes a reference to a variables XML file, the Workflow
Editor automatically locates and imports the file into the cache. The Workflow Editor extracts the variable
values from the XML file and merges the values with the workflow definition. These values are applied
to your editing session, and are reflected in the Variables tab of the Workflow Editor. Any subsequent
changes that you make to the variable values are not written back to the original variable XML file.

Note that any comments in the existing workflow definition are not preserved when you open a workflow
definition in the Workflow Editor.

Figure 2 on page 7 depicts the flow of events that occur when you open a workflow definition for
editing in the Workflow Editor interface.

_Figure 2. The Workflow Editor process flow for unmarshalling and marshalling the workflow definition files._

**Related concepts**

Terms you should know
Workflow authors and users should be familiar with the following terms.

**Related reference**

Understanding the Workflow Editor layout
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the _accordion_ , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.

Concurrency considerations

```
Workflow Editor task   7
```

```
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.
```
#### Concurrency considerations

```
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.
When you open a workflow definition for editing, the Workflow Editor creates an in-storage copy of the
file. Each time you save your changes to the workflow definition, the Workflow Editor updates its cached
version of the file. The Workflow Editor manages the cached version of the file until you end the editing
session. In this way, the Workflow Editor maintains concurrency between your editing session and its
cached copy of the workflow definition.
The Workflow Editor maintains no more than one cached copy of a workflow definition per user. Thus,
each user is limited to one editing session at a time.
If you were to start an another Workflow Editor session in a new browser window, you break this
synchronization. The Workflow Editor detects a mismatch between its copy of the workflow definition file
and the file that you are attempting to open for editing. Here, the Workflow Editor displays a warning
message: You are prompted to decide how to proceed, either by discarding the changes and starting a
new editing session, or by canceling out of the new session and returning to work on the open file.
If you decide to proceed with the new editing session, you must close the old session to avoid errors. The
file that you are editing no longer matches the file that is stored in the Workflow Editor cache; thus, the
Workflow Editor has no copy to which it can apply your edits.
Therefore, be careful to limit your use of the Workflow Editor to one session at a time. When your changes
are complete, save the file and close the Workflow Editor. To create a new session, close and reopen the
Workflow Editor.
Related concepts
Terms you should know
Workflow authors and users should be familiar with the following terms.
Related reference
Understanding the Workflow Editor layout
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the accordion , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.
How a workflow definition file is processed
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
```
### Edit Workflow Definition dialog

```
When you select the Workflow Editor task from the z/OSMF navigation area, the Edit Workflow Definition
dialog is displayed for you to begin an editing session.
```
```
Create a new workflow definition
Select this option to have the Workflow Editor create a new workflow definition for you. Here, the
Workflow Editor creates a "starter" workflow definition, with a minimal subset of XML elements and
properties, and one step already defined. This workflow is valid XML; it can provide you with the starting
point for creating a complete workflow definition to meet your needs.
```
**8**   Workflow Editor task


**Open an existing workflow definition**

Select this option to open an existing workflow definition for editing. The workflow definition file must be
valid XML, otherwise an error message is displayed.

When you open a workflow definition file, the Workflow Editor imports the file and its constituent parts
(the external files, if any) into an internal cache. For details, see “How a workflow definition file is
processed” on page 6.

Notice the option **Edit raw text of the workflow definition**. If you select this option, the Workflow
Editor opens the workflow definition in a simple text editor. The text editor provides editing access to
the specified file, but without the usual tabbed interface and multi-paned layout of the Workflow Editor.
Consider using the text editor when you need to correct a syntax error that prevents the file from opening
in the Workflow Editor UI. In the text editor, you can run XML validation checking of the file, which can be
helpful for locating the source of a tagging error.

For an existing workflow definition, complete the following fields.

**Workflow definition file**
Specify the location of the workflow definition. This value is required. The location is a sequential data
set, a member of a partitioned data set (PDS), or a z/OS UNIX path and file name.
If you edited the workflow definition previously, you might find that the location is saved in the
pull-down menu for this dialog. Otherwise, you must enter this value manually.
If the location is a z/OS UNIX file path, observe the following conventions:

- Enter either a relative path or the full path name, beginning with the forward
    slash (/) and including the file name. For example: /usr/lpp/zosmf/samples/
    workflow_sample_file_template0.xml.
- Ensure that the file permissions are set properly the user (the file owner). Specifically, the file
    permissions must be set, as follows:
    - To allow read and write access for the user, the workflow definition file requires file permissions
       of at least 600.
    - Any external files that are referenced by the workflow definition require file permissions of at
       least 600.
    - The directory location for these files requires file permissions of at least 505.
If the location is a data set, observe the following naming conventions:
- Enter the fully qualified data set name, including the member name if you are using a PDS.
- Do not enclose the data set name in quotation marks.
For example:

```
SYS1.PRODUCTX.TESTFLOW
SYS1.PRODUCTX(TESTFLOW)
```
```
The data set must exist and be cataloged. The Workflow Editor assumes that the data set resides on
the default volume for your z/OS user ID. You cannot specify a different volume for the data set.
Your user ID requires write access to the data set.
If the workflow definition file resides on the local system, you can locate it with a type-ahead search.
Click the search icon for the input field to open the path selector window. Then, enter a pattern that is
a partial or complete name of a data set, member, or a UNIX file path. A history list and a type-ahead
list assist your pattern entry task. Pattern matching for UNIX file paths is case-sensitive. When you
select an object from the type-ahead list, the object name populates the Workflow definition file
input field.
```
1. A workflow definition might be just one XML file, or it might consist of a primary XML file that refers
    to one or more subordinate XML files and fragments. To edit a workflow definition that consists of
    multiple files, ensure that the files reside in a common location. That is, the files must be members

```
Workflow Editor task   9
```

```
of the same PDS or reside in the same UNIX directory. You cannot use a sequential data set to
contain a workflow that consists of multiple files.
```
2. If you plan to store a workflow definition in a data set, be sure to remove the line numbers
    (sequence numbers) from your XML files before you save them. Otherwise, the line numbers can
    cause XML validation errors to occur when you attempt to open the file later.
    To avoid this problem, specify that the file is unnumbered when you save it. For example, on the
    TSO/E **EDIT** command, include the **UNNUM** operand to remove the line numbers from the file.
    In a z/OS data set, a numbered file appears as follows:

```
0010 AAAA...
0020 BBBB...
0030 CCCC...
```
```
After the line numbers are removed, the file appears as follows:
```
```
AAAA...
BBBB...
CCCC...
```
```
Workflow variable input file
Specify the location of the workflow variable input file for the workflow. This value is optional. The
location is a sequential data set, a member of a partitioned data set (PDS), or a z/OS UNIX path and
file name.
If no workflow variable input file is available, leave this field blank.
If you edited the workflow variable input file previously, you might find that the file location is saved in
the pull-down menu for this dialog. Otherwise, you must enter this value manually.
Usually, a workflow variable input file is provided by the workflow provider, or is produced as output
from another step in the workflow, or from another workflow. To obtain the name of the workflow
variable input file, refer to the workflow documentation or contact the workflow provider.
If you select a workflow variable input file for inclusion in your editing session, the Workflow Editor
maintains the file as separate from the workflow definition file. The updates that you make in the
Input Properties tab are written to the workflow variable input file when you save your changes.
If the location is a z/OS UNIX file path, observe the following conventions:
```
- Enter either a relative path or the full path name, beginning with the forward
    slash (/) and including the file name. For example: /usr/lpp/zosmf/samples/
    workflow_sample_property_file.txt.
- Ensure that the file permissions are set properly. A workflow variable input file requires read and
    write access for the "user" bit (file permissions of at least 600).
If the location is a data set, observe the following naming conventions:
- Enter the fully qualified data set name, including the member name if you are using a PDS.
- Do not enclose the data set name in quotation marks.
- Ensure that the file is unnumbered (contains no line sequence numbers).
If the workflow variable input file resides on the local system, you can locate it with a type-ahead
search. Click the search icon for the input field to open the path selector window. Then, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. A history
list and a type-ahead list assist your pattern entry task. Pattern matching for UNIX file paths is
case-sensitive. When you select an object from the type-ahead list, the object name populates the
**Workflow variable input file** input field.
If you select the option **Edit raw text of the workflow definition** , the field _Workflow variable input file_
is disabled. You cannot edit a workflow variable input file in the text editor.

**10**   Workflow Editor task


```
Click Finish to select the specified files. On finding the workflow definition file, z/OSMF validates the
definition for correct syntax.z/OSMF performs no validity checking for the workflow variable input file, if
one is specified.
On completion, the Workflow Editor task main page is displayed, with information about the workflow
definition, which is extracted from the workflow definition file.
Otherwise, if a problem is detected with the specified values or the workflow definition, an error message
is displayed. Correct the error or cancel the editing session. To exit the Workflow Editor, close the
Workflow Editor tab in the z/OSMF work area.
Related concepts
Workflow Editor task
You can use the z/OSMF Workflow Editor task to view and modify a workflow definition.
Workflow Editor task overview
With the z/OSMF Workflow Editor task, you can view and edit the XML elements that comprise a workflow
definition.
Terms you should know
Workflow authors and users should be familiar with the following terms.
Related reference
Understanding the Workflow Editor layout
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the accordion , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.
How a workflow definition file is processed
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
Concurrency considerations
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.
```
### Workflow Text Editor window

```
When you select the option Edit raw text of the workflow definition from the Edit Workflow Definition
dialog and click OK , a window is opened for you to begin an editing session. The field Workflow definition
file displays the file to be edited.
```
```
Using the text editor
The location of the source file is displayed above the text window. When you begin to edit the source file,
a small asterisk is displayed by the source file name to indicate that you have unsaved changes.
The file to be edited:
```
- Can reside in a z/OS UNIX file or z/OS data set.
- Have file permissions that are set properly so that you can write to the file.
    Specifically, the file permissions must be set, as follows:
    - To allow read and write access for the user, the workflow definition file requires file permissions of at
       least 600.
    - External files that are referenced by the workflow definition require file permissions of at least 600.
    - Workflow variable input file requires file permissions of at least 600.
    - The directory location for these files requires file permissions of at least 505.

```
Workflow Editor task   11
```

```
The text editor does not attempt to resolve references to external files, though you can use the editor to
modify such references or any other content in the file.
Your user ID requires write access to the file.
```
### Workflow Editor task main page

```
From the Workflow Editor task main page, you can view the different sections of the selected workflow
definition.
The Workflow Editor task main page displays:
```
- Location of the selected workflow definition.
- Tabbed sections for editing the workflow metadata, steps, variables, feedback questions, and input
    properties in the workflow definition.
- Task-level actions for the Workflow Editor: **Save** , **Save As** , **Test** , and **Cancel**.

```
Tabbed sections for editing
You can work with different parts of the workflow by selecting the appropriate tab. The Workflow Editor
Metadata tab is selected by default.
The major work areas of the Workflow Editor are described in the following topics:
```
- “Metadata tab” on page 14
- “Steps tab” on page 17
- “Variables tab” on page 61
- “Workflow feedback tab” on page 73
- “Input Properties tab” on page 76.

**Task-level actions for the Workflow Editor task**

```
Each of the major work areas includes the task-level actions Save , Save As , Test , and Cancel. These
actions apply to the current state of the entire workflow definition, including the input properties.
Table 1 on page 12 describes the task-level actions for the Workflow Editor task.
```
```
Table 1. Task-level actions for the Workflow Editor task
```
```
Action Description
```
```
Save Save the current state of the workflow definition. This action saves all outstanding
changes from any open tabs in the Workflow Editor, including your changes to
metadata, steps, variables, and the input properties.
```
**12**   Workflow Editor task


_Table 1. Task-level actions for the Workflow Editor task (continued)_

**Action Description**

**Save As** Save the current state of the workflow definition to a new file. You are prompted
to specify the location for the workflow definition file and variable input file. The
location can be a sequential data set, partitioned data set (PDS), or z/OS UNIX path
and file name. This action saves all outstanding changes from any open tabs in
the Workflow Editor, including your changes to metadata, steps, variables, and the
input properties.
Observe the following considerations when you save a workflow definition:

- If you are saving to a data set, the data set must exist. Otherwise, the save
    request fails with an error message.
- If you are saving to an existing PDS, and the member does not exist, the
    Workflow Editor attempts to create the member in the PDS.
- If you are saving to a UNIX file path, and the path does not exist, the Workflow
    Editor attempts to create it.
If you are saving to a data set, ensure that the data set logical record length
(LRECL) is large enough to contain the XML file. Otherwise, the save request fails
with an error message. For most workflow definition files, an LRECL of 1024 is
sufficient.
It is possible to save the workflow definition in a different file format, or in a
different location. If you attempt to do so, the Workflow Editor scans the workflow
definition for any relative references to file templates, including references that
are represented by substitution variables. For such references, the Workflow Editor
converts each reference to an absolute path (for a UNIX file) or a fully qualified
data set name. This change ensures that the file templates can be found after the
workflow definition is saved in the new format or location. After the conversion
is done, the change cannot be undone, except by manually editing the workflow
definition and changing the file template references. The Workflow Editor issues a
message to prompt you to confirm your decision.

**Test** Perform a test run of the workflow definition. This action attempts to open the
workflow definition in the Workflows task. You can test the workflow by trying to
create a workflow instance on your z/OS system.

**Cancel** Cancel your changes since the time of the last save. This action discards all
outstanding changes from any open tabs in the Workflow Editor. You are prompted
to confirm your cancel request.

```
Related concepts
Workflow Editor task overview
With the z/OSMF Workflow Editor task, you can view and edit the XML elements that comprise a workflow
definition.
Terms you should know
Workflow authors and users should be familiar with the following terms.
Related reference
Understanding the Workflow Editor layout
The Workflow Editor provides a visual framework for working with the elements of a workflow definition,
such as the steps, variables, and workflow metadata. The editor layout consists of tabbed sections and
a dynamic work area that is called the accordion , which can be expanded or compressed, as needed.
This framework provides a development environment for creating and modifying the files that comprise a
workflow definition.
How a workflow definition file is processed
```
```
Workflow Editor task   13
```

```
When you open a workflow definition file for editing, the Workflow Editor locates the file and reads it
into storage. The Workflow Editor also identifies any associated files that are referenced in the workflow
definition and reads them into storage.
Concurrency considerations
The Workflow Editor supports only one editing session, per user, at a time. You cannot edit more than one
workflow definition file at a time.
```
### Metadata tab

```
The Workflow Editor task opens with the Metadata tab in focus. On this tab, you can view and edit the
workflow metadata.
In a workflow definition, the metadata contains information that identifies the workflow and provides
details about the workflow behavior and usage. The metadata includes the workflow identifier,
description, category, version, and vendor, and other details, as described in this topic. The Workflow
Editor obtains the metadata from the selected workflow definition.
The Metadata tab shows the name of the selected workflow definition. You specified this name when you
opened the Workflow Editor task to edit the file.
The Workflow Editor obtains metadata from the selected workflow definition. Workflow metadata
includes the workflow identifier, description, category, version, and vendor, and possibly other details,
as follows:
Workflow ID
A short, arbitrary value that identifies the workflow.
Scope
Indicates the singleton scope for the workflow, as follows:
System
A maximum of one instance of this workflow can exist on any one system in the sysplex.
Sysplex
A maximum of one instance of this workflow can exist in the sysplex.
None
An existing instance cannot be used. A new instance of this workflow is always created.
Callable Workflow
Indicates whether the workflow can be called by another workflow. If selected, a range must be
specified. Otherwise, the workflow is not callable for processing by other workflows.
Job Output Location
Indicates a location to be used for automatically storing saved job output files from the workflow. Use
this option if you want to retain job output files, perhaps as a record of the work that is done by the
workflow. Specify a valid UNIX file path and directory on the user's system, beginning with a single
forward slash ('/'). For example: /u/IBMUSER/jobFiles. In the Workflows task user interface (UI),
the workflow owner can overwrite this value with a different location, as needed.
If this option is enabled, a value must be specified. The value must be an existing directory on
the user's system. Otherwise, the Workflows task cannot create the workflow; an error message is
displayed in the Workflows task UI.
The job output files are saved in the IBM-1047 encoding format. This format is viewable in a z/OS
Console by using the cat command. As an alternative, the user can use an FTP tool to view or
download the files with the transfer type ASCII.
Observe the following authorization requirements:
```
- Workflow owner user ID requires write access to the directory.
- For the steps that create job output, the step owner user IDs require write access to the directory.
    Otherwise, the steps cannot be performed.
If the Job Output Location option is not enabled, the workflow does not save its job output files.

**14**   Workflow Editor task


**Range**
For a callable workflow, this value indicates the callable range for the workflow, as follows:
**System**
When called by another workflow, one instance of this workflow is used in the local system.
**Sysplex**
When called by another workflow, one instance of this workflow is used in the sysplex.

**Default Name**
If the workflow definition specifies a default name for the workflow, it is shown here. Otherwise, this
field is blank.

**Description**
A short description of the workflow (up to 100 characters).

**Version**
Version of the workflow definition.

**Vendor**
Name of the vendor that provided the workflow definition.

**Category**
A classification of the activities to be performed in the workflow. The following values are valid:
**General**
All other workflows.
**Configuration**
Workflows that are used to configure system software, such as a product or component.
**Provisioning**
Workflows that are used to provision system software.

**Product ID**
Identifier of the product or component that is being configured through the workflow, such as
the product identifier (PID) or function modification identifier (FMID). This value is shown for
_Configuration_ and _Provisioning_ category workflows.

**Product Name**
Name of the product or component that is being configured through the workflow. This value is shown
for _Configuration_ and _Provisioning_ category workflows.

**Product Version**
Version and release of the product or component that is configured through the workflow. This value is
shown for _Configuration_ and _Provisioning_ category workflows.

**Software Type**
For a provisioning workflow, this value indicates the type of software to be provisioned. Otherwise,
this field is not displayed.

**Omit the prefix from instance variable references.**
Indicates whether the prefix instance- is omitted from references to instance variables in the
workflow. This option is provided as a convenience; it can save you time if your workflow includes
many references to instance variables. If you select this option, the workflow must use this shortened
naming convention for all references to instance variables.
For example, assume that you define an instance variable st_user for your workflow. If you select
to omit the prefix, your workflow must refer to this variable as ${st_user} or $st_user. If you
do not select this option, your workflow must refer to this variable as ${instance-st_user} or
$instance-st_user.
By default, this option is not selected.

- As shown in the preceding example, the use of braces around variable references is optional, but
    recommended as a good programming practice. The braces help to ensure that variables are clearly
    identified in the workflow, such as in conditional expressions, and jobs and scripts.

```
Workflow Editor task   15
```

- References that use incorrect syntax are not detected and might result in workflow failure or other
    incorrect processing.
**Users can take ownership of steps automatically.**
Indicates whether user requests for step assignment are granted automatically. If so, a requesting
user is added to the list of assignees for the step, without requiring the workflow owner to grant the
request. No notification is returned to the requester. The workflow owner receives a notification of the
request, but is not expected to act.
By default, this option is not selected, meaning that the workflow owner is responsible for handling
step assignment requests.
When a user becomes an assignee for a step, the user can either:
- Accept ownership of the step, by using the **Accept** action in the Workflow Steps table, if the step is
not currently assigned.
- Take ownership of the step from the current user, by using the **Take Ownership** action in the
Workflow Steps table.
**Contains parallel steps.**
Use parallel processing for any automated steps that can be run in parallel (concurrently). When
this option is selected, step automation can potentially complete more quickly than for sequentially
processed steps. However, the steps might complete in an unexpected sequence.
In z/OSMF, a workflow with steps that are eligible for parallel processing is known as a _parallel-steps
workflow_. When a parallel-steps workflow is started, the Workflows task locates all of the automated
steps with _Ready_ status, and attempts to run these steps concurrently. The failure of an automated
step does not stop automation processing for the other automated steps. Processing continues until
all of the automated steps are completed or failed, or the user stops automation processing by using
the **Stop Automation** action on the **Workflows** page.
To be eligible for parallel processing, a step must be:
- Enabled for automation. In the Workflow Editor **Overview** tab, the **Auto-Enable** option is selected
for the step.
- In _Ready_ state. All of the prerequisite steps are completed, and no user inputs are required.
By default, this option is no selected, meaning that automated steps are run one-by-one in the
sequence in which they appear in the workflow definition.
**Note:** The ability to suspend step processing is mutually exclusive with the ability to run steps in
parallel. Therefore, if you select the **Contains parallel steps** option, you cannot also specify the
**Suspend** option in the Advanced tab for any of the steps in the workflow.
**Maintain fragments.**
By default, when changes are saved all fragment content is merged into a single file single XML
file that no longer contains references to the fragment files. When this option is selected, fragment
references in the workflow definitions are instead preserved, and any updates are applied to all
fragment files when changes are saved.
_Fragments_ are valid XML files that can contain any combination of elements that follow the workflow
schema. Fragments are defined by external entity references at the beginning of the definition file.
The following conditions must be followed for this service to be supported:
- XML definition files must be pre-parsed or follow parsing standards. Each element must be logically
separated by new lines.
- Comments nested in XML elements are not maintained.
- Fragment references through variable entities or parameter entities are not supported.
- Nested fragments are not supported.
- The workflow cannot be a data set.
- The same fragment cannot be used twice in the same workflow definition.

**16**   Workflow Editor task


- The **Save as** action in Workflow Editor cannot be used while this function is enabled.
If these standards are not followed, or if the workflow does not contain fragment references, the field
is disabled.
By default, this option is not selected.
**Related concepts**
Workflow Editor task overview
With the z/OSMF Workflow Editor task, you can view and edit the XML elements that comprise a workflow
definition.
Terms you should know
Workflow authors and users should be familiar with the following terms.
**Related reference**
Advanced tab
z/OSMF includes advanced settings that can affect the behavior of a workflow.

### Steps tab

```
From the Steps tab, you can modify the steps in the selected workflow definition.
In the Steps tab, the Steps table displays the steps in the selected workflow definition. To view or edit the
properties of a step, select the step in the table. You can select one step only. The format and content of
the Steps table is described in “Steps table” on page 17.
When you select a step, the Workflow Editor opens an accordion area that is called Step Details to the
right of the table. The Step Details area is organized in tabs. Select the appropriate tab to view more
details about the step, as follows:
```
- “Overview tab” on page 24
- “Prerequisites tab” on page 25
- “Instructions tab” on page 27
- “Type tab” on page 27
- “Conditions tab” on page 52
- “Security tab” on page 54
- “Step Variables tab” on page 57
- “Step Feedback tab” on page 59
- “Advanced tab” on page 59.
The **Step Details** area overlays another area that is called **Variable Details**. This area is active when the
Workflow Editor is used to edit a variable. Otherwise, its fields are blank.

```
Steps table
For a description of the columns in the Workflow Editor Steps table, see Table 2 on page 18. For a
description of the actions that you can take for steps, see Table 3 on page 19 and Table 4 on page 20.
```
```
Workflow Editor task   17
```

```
Table 2. Columns in the Workflow Editor Steps table.
```
```
Column Description
```
```
Step No. The step number. Steps are numbered to indicate the sequence in which steps are
to be performed. For example, the first step in a workflow is 1.
A step can contain substeps, which can also contain substeps. Up to five levels
of nesting are possible. A workflow can contain up to 500 steps and substeps (a
combined total). Substeps are shown with indented titles.
A substep shares the numerical value with its parent, but with '.x' appended to
its step number, where 'x' is a numerical value that starts with 1. For a substep
nested five levels deep, for example, the step number is indicated in the form
'x.x.x.x.x'.
```
```
Name Name of the step. The step name must be unique across the entire workflow. It is
used within the workflow to reference prerequisite steps.
```
```
Title Title of the step. Substeps are shown with indented titles.
```
```
Signature Status The signature status of a runAsUser step.
For a parent step, the signature status is empty. For a leaf step, there are three
signature statuses for a runAsUser step.
Completed
The step has signers, all of the signers have signed, and all of the signatures
are valid.
Incomplete
The step has signers and only some of the signers have signed, some of the
signatures are invalid, or all of the signers have not yet signed.
N/A
Other leaf steps.
```
```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.
- Create Step action. Displays the **Create a New Step** window so that you can add a step to the workflow.
    For more information, see “Create a New Step” on page 20.

**18**   Workflow Editor task


_Table 3. Targeted actions for the Workflow Editor Steps table._

**Action Description**

**Create Step** Create a step and add it to the workflow. This action is enabled only when a parent
step is selected.
Select one of the following options to place the new step in the workflow:

- **Create a step above...** to insert the new step before the selected step. To enable
    this action, select one step only.
- **Create a step below...** to insert the new step after the selected step. To enable
    this action, select one step only.
- **Create a New Substep...** to create the new step as a nested step of an existing
    step.
The Workflow Editor task then displays the **Create a New Step** window so that you
can enter information about the new step. For more information, see “Create a New
Step” on page 20.

**Copy Step** Create a copy of the selected step and add it to the workflow. This action is enabled
only when a leaf (child) step is selected.
To enable this action, select one step only.
The Workflow Editor task displays the **Copy Step** window so that you can enter a
unique name for the new step. For more information, see “Copy Step” on page 23.

**Move Step** Move the selected step to a different position in the workflow. When you change
the position of step, the step number is updated in the Steps table.
Select one of the following actions to position the step in the workflow:

- **Move Up**. Move the step above its current position by one row.
- **Move Down**. Move the step below its current position by one row.
- **Move In**. Move the step into the parent step that precedes it in the Steps
    table. When you move a step into another step, you create a parent-child step
    relationship between the steps. That is, the selected step is nested within the
    target step.
    This action is available when at least one parent step exists in the steps that
    precede the selected step.
- **Move Out**. Move the step out of its current position by one nesting level. When
    you move a step out of its parent step, you remove the parent-child step
    relationship between the steps. The selected step becomes a peer of the parent
    step.
    This action is available for a step that is nested within a parent step.
- **Move To Target**. Display the **Move To Target** window so that you can reposition
    the step within the workflow. This action is available for leaf steps only; it is not
    available for parent steps.
    For more information about this action, see help topic “Moving a step within a
    workflow” on page 24.

```
Workflow Editor task   19
```

```
Table 3. Targeted actions for the Workflow Editor Steps table. (continued)
```
```
Action Description
```
```
Delete Delete the selected step from the workflow definition. For a parent step, this action
deletes the parent step and all of its leaf (child) steps. This action also deletes
references to the step, if the step is listed as a prerequisite for other steps in the
workflow. The references are removed for all of the steps deleted (parent and leaf).
This change is permanent; you are prompted to confirm this action before it is
taken.
To enable this action, select one step only.
The Delete action is disabled for a workflow that contains only one step.
```
```
Export to Step Library Export the selected step to the shared step library in the z/OSMF repository. The
step name must be unique in the shared step library.
By adding a step to the library, you make it available for use with other workflow
definitions and by other workflow authors. A shared step cannot be modified; it
can, however, be deleted by the step creator.
```
```
Import from Step Library Import a step from the shared step library in the z/OSMF repository. When you
import a step, you can rename it. The step name must be unique in the workflow
definition.
```
```
Expand Expand the selected step to display its substeps.
To enable this action, select one step only.
```
```
Collapse Collapse the display of substeps to show the parent step only.
To enable this action, select one step only.
```
```
Table 4. Table actions for the Workflow Editor Steps table.
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Clear Search Clear the search.
```
```
Expand All Expand the steps in the workflow to display all of the substeps.
```
```
Collapse All Collapse the display of the workflow steps to display the parent steps only.
```
```
Related information
For more information about creating steps, see the topic Creating workflow definitions for z/OS in IBM
z/OS Management Facility Programming Guide.
```
#### Create a New Step

```
You can add your own steps to a workflow. To do so, use the Create Step action that is provided in the
Steps table. Doing so opens a window that you can use to create the new step.
```
**Procedure**

1. Select **Leaf Step** or **Parent Step**.
    Your selection depends on the following design consideration:

**20**   Workflow Editor task


- If the step describes an action to be performed by a step owner, choose **Leaf Step**. Such steps might
    involve running an executable program or performing a manual action on the system.
- If the step includes one or more leaf steps, choose **Parent Step**. A parent step is considered
    complete when all of its leaf steps are complete.
Notice that if you select **Leaf Step** , the window displays a number of additional options for you to
specify for the leaf step.
2. Enter the following information:

```
a) In the Name field, specify a name for the step.
This value is required and must be unique within the workflow.
b) In the Title field, specify a title for the step.
This value is required.
Up to 100 characters can be specified.
c) In the Description field, describe the function of the step.
This value is required.
Up to 500 characters can be specified. Input that exceeds 500 characters is truncated to the first
500 characters when you save the step.
d) In the Weight (1-1000) field, specify the relative difficulty of the step (a positive integer value 1 -
1000).
This value is required.
The Workflows task uses this value in the calculation of the percentage-complete value that is
displayed as the workflow is performed. The scale is arbitrary; specify it at your discretion. As a
guide, specify a lesser value for a step in which the user action is simple. For a more complicated
task, specify a greater value.
e) In the Skills field, specify the skill that is needed to perform the step.
This value is optional.
For example: system programmer or security administrator
f) In the Step Type field, specify one of the following step types:
Instructions step
Step that contains text instructions for performing the step (sometimes called a manual step ).
File Template step
Step that refers to an external file for running executable code. The file can contain a JCL job, a
REXX exec program, or a UNIX shell script.
Inline Template step
Step that runs inline executable code. The code is a JCL job, a REXX exec program, or a UNIX
shell script.
REST step
Step that issues a Representational State Transfer (REST) request, such as a GET, PUT, POST, or
DELETE request.
Calling step
Step that calls another workflow for processing.
Your selection of Step Type determines which of the related options are displayed for the step, as
follows:
```
- For a file template step, you must specify:
    - **Location of the file template**. In this field, specify the location of the file that contains the
       executable code for performing the step, such as a JCL job, a REXX exec program, or a UNIX
       shell script. The location can be a sequential data set, a member of a partitioned data set
       (PDS), or z/OS UNIX path and file name. You can use variable substitution for this field.
       To search for a file template on your system, click the search icon for the input field. In the
       path selector window, enter a pattern that is a partial or complete name of a data set, member,

```
Workflow Editor task   21
```

```
or a UNIX file path. A history list and a type-ahead list assist your pattern entry task. Pattern
matching for UNIX file paths is case-sensitive. When you select an object from the type-ahead
list, the object name populates the Location of file template input field.
```
- **Submit Template As**. From this menu, select the type of program to be run and how it is to be
    processed on z/OS, as follows:
    **JCL**
       File contains a JCL job. The file is run as a JCL job by the Workflows task, which creates the
       necessary JCL and JOB statement, and displays the job output.
    **TSO-REXX-JCL**
       File contains a REXX program. The file is run as a JCL job by the Workflows task, which
       creates the necessary JCL and JOB statement, and displays the job output.
    **shell-JCL**
       File contains a UNIX shell script. The file is run as a JCL job by the Workflows task, which
       creates the necessary JCL and JOB statement, and displays the job output.
    **TSO-REXX**
       File contains a REXX program. The file is run as a REXX program in real time.
    **TSO-UNIX-REXX**
       File contains a REXX program for the UNIX environment. The program is run as a REXX
       program in real time.
    **TSO-UNIX-shell**
       File contains a UNIX shell script. The file is run as a UNIX shell script in real time.
    The size of any program to be run (JCL, REXX, or shell script) is limited to 10000 lines of code.
- For an inline template step, the inline code can be a JCL job, a REXX exec program, or a UNIX
shell script. In the **Submit Template As** menu, select one of the following options:
**JCL**
Step contains a JCL job. The code is run as a JCL job by the Workflows task, which creates the
necessary JCL and JOB statement, and displays the job output.
**TSO-REXX-JCL**
Step contains a REXX program. The code is run as a JCL job by the Workflows task, which
creates the necessary JCL and JOB statement, and displays the job output.
**shell-JCL**
Step contains a UNIX shell script. The code is run as a JCL job by the Workflows task, which
creates the necessary JCL and JOB statement, and displays the job output.
**TSO-REXX**
Step contains a REXX program. The code is run as a REXX program in real time.
**TSO-UNIX-REXX**
Step contains a REXX program for the UNIX environment. The code is run as a REXX program
in real time.
**TSO-UNIX-shell**
Step contains a UNIX shell script. The code is run as a UNIX shell script in real time.
The size of any program to be run (JCL, REXX, or shell script) is limited to 10000 lines of code.
- For a REST step, you must describe the REST request that is to be issued by the step, as follows:
- HTTP method to be used for issuing the REST request (GET, PUT, POST, or DELETE).
- Universal Resource Identifier (URI) path and, where appropriate, any query parameters that
further qualify the REST request. You can use variable substitution for this field.
- Expected HTTP status code from the REST API request, as defined in the workflow definition.
For example, the status code 200 is often used to indicate a successful operation.
- For a calling step, you must identify which workflow is to be called, as follows:

**22**   Workflow Editor task


- Specify the **workflow ID** of the called workflow, and, optionally, the **version** of the workflow
    definition file. Or, specify the called workflow **MD5** value, which is a 128-bit hash value that is
    used to identify the workflow. You can specify the MD5 value instead of the workflow ID and
    version.
- **Called workflow description** , which is a description of the function that is provided by the
    called workflow. This information can include other details, such as the name and location of
    the workflow definition file that is used to create the called workflow.
3. If the step is optional, select **Optional Step**.
4. To have the step run automatically, select **Auto-Enable**.
Doing so indicates that the step is to be performed automatically when all prerequisite steps are
completed, and no user inputs are required.
5. To allow the step to be marked as _Failed_ manually by the step owner, select **Allow manual marking of
step failure**.
6. Click **OK** to add the step to the workflow.

```
Results
On creation of a new leaf step, the Steps table is displayed, showing the new step. The Step Details
accordion is expanded so that you can specify more information about the leaf step.
On creation of a new parent step, you are prompted to create a child step. The Create a New Step
window is displayed for you to enter information about the child step.
```
#### Copy Step

```
To copy a step, use the Copy Step action that is provided in the Steps table. Doing so opens a window that
you can use to create a copy of the selected step.
```
```
About this task
If an existing step is similar to one that you want to create, use the Copy Step action to create a new step
based on the existing one. When you copy a step, you create a new step with all of the properties of the
copied step, except for the step name, which must be unique. If the original step identifies prerequisites
steps, the copy inherits the same prerequisite steps. If the original step is a REST step, the copy inherits
any variable mappings that might exist, such as an actual status code mapping or a property mapping.
The Copy Step action is enabled for leaf (child) steps only. This action is not available for parent steps.
```
**Procedure**

1. In the Steps table, select the step that you want to copy.
    Select one step only.
2. In the Steps table actions, click **Copy Step**.
3. In the **Step Name** field, specify a unique name for the step.
    This value is required and must be unique within the workflow.
4. Click **OK** to add the step to the workflow.

```
Results
On creation of the new step, the Steps table is displayed, showing the new step, which is placed directly
below the step that was copied. You can use the Workflow Editor Step Details area to customize the
properties of the new step, as needed.
```
```
Workflow Editor task   23
```

#### Moving a step within a workflow

```
To reposition a step within a workflow, you can use the Move to Target action that is provided in the Steps
table. Doing so opens a window that you can use to move the step to the desired location.
```
**About this task**

```
The Move to Target action is enabled for leaf (child) steps only. This action is not available for parent
steps.
```
**Procedure**

1. In the Steps table, select the step that you want to move.
    You can select one step only.
2. In the Steps table actions, click **Move Step** > **Move To Target**.
3. In the **Move To Target** window:
    a) From the **Target Step** menu, select the step to be used as the target for the move action.
       Notice that the name of each target step includes the step number in parentheses ‘()’.
b) From the **Step Placement** menu, select one of the available options for positioning the step in
relation to the target step.
The following placement options exist for all target steps:
- **Above**. This option places the step immediately above the target step.
- **Below**. This option places the step immediately below the target step.
If the target step is a parent step, an additional placement option is available:
- **In**. This option places the step within the target step after any other leaf steps that might be
present in the target step.
4. Click **OK** to complete the move action.

**Results**

```
The Steps table is displayed, showing the updated sequence of steps.
```
#### Overview tab

```
You can use the Overview tab on the Step Details page to view and modify the step name, title,
description, and other information for the step.
Table 5 on page 24 lists and describes the fields that are displayed in the Overview tab.
```
```
Table 5. Fields in the Overview tab
```
```
Column Description
```
```
Name Name of the step.
If you change the step name, the Workflow Editor applies this change throughout
the workflow definition, wherever the step name is referenced. For example, the
Workflow Editor finds and updates:
```
- Prerequisites for any other steps that refer to the old step name
- Conditional expressions in the workflow that refer to the old step name.
If you select to change the step name, you are prompted to confirm your decision.

```
Title Step title.
```
```
Description Step description.
```
**24**   Workflow Editor task


```
Table 5. Fields in the Overview tab (continued)
```
```
Column Description
```
```
Weight (1 -1000) The relative difficulty of the step as compared to other steps within this workflow.
This value is represented by a positive integer value (1 – 1000). The Workflows
task uses the step weight in the calculation of the percentage-complete value that
is displayed for the workflow. The scale is arbitrary.
```
```
Skills Skills that are required to perform the step, such as "security administration" or
"network administration."
```
```
Type Indicates the step type, as follows:
Instructions
Step that contains text only; no executable code. The Step Type tab is disabled
for instructions steps.
File Template
Step that refers to an external file that contains executable code for performing
the step. The file can contain a JCL job, a REXX exec program, or a UNIX shell
script.
Inline Template
Step that contains inline executable code for performing the step. The inline
code is a JCL job, a REXX exec program, or a UNIX shell script.
REST
Step that issues a Representational State Transfer (REST) request, such as a
GET or PUT request.
Calling
A step that calls another workflow for processing.
The step type is an attribute of a leaf step. A parent step does not have a step type;
therefore, no step type value is displayed for a parent step.
```
```
The Overview tab includes the following indicators for the step:
Optional step
Indicates whether performing the step is optional for completing the workflow.
Auto-Enable
Indicates whether the step can be performed automatically when all prerequisite steps are
completed, and no user inputs are required.
Allow manual marking of step failure
Indicates whether the step can be marked as failed manually by the step owner.
```
#### Prerequisites tab

```
The Prerequisites tab on the Step Details page displays information about the prerequisite steps for the
current step.
A step might have one or more prerequisite steps , which are steps that must reach a particular target
state before the current step can be performed. You can use the Prerequisites tab to add or remove
prerequisite steps, or modify the required target state for a prerequisite step. Up to 499 prerequisite steps
can be defined for a step.
In the Prerequisites tab:
```
- Table _Existing Prerequisite Steps_ lists the prerequisite steps for the current step
- Table _Eligible Prerequisite Steps_ lists the workflow steps that can be defined as prerequisite steps for
    the current step. To be eligible, a step must precede the current step in the sequence of workflow steps.

```
Workflow Editor task   25
```

```
You manage the list of prerequisite steps for the current step by transferring items between these tables.
To do so, select one or more table items at a time and click the appropriate directional arrow to transfer
the selected items to the other table.
You can optionally add conditional logic to further qualify the target states for the prerequisite steps. By
default, a prerequisite step must be in the Ready state (eligible to be performed) before the current step
can be performed.
Define the condition for a prerequisite step by adding a Description and selecting one of the following
options:
None
No expression is provided for selecting the target state for this step. As a result, the target state is
Ready , which is the default value.
Target State
You can specify a desired target state for the step, which is the state to which the step is set when
the expression evaluates to true. The valid target states are Ready , Complete , and Skipped. The target
state is optional. Typically, the target state is Ready , which is the default value.
State Expression
As an alternative to setting the Target State to a fixed value, you can define a conditional expression
that determines the target state. When you select this option, the Workflow Editor displays the State
Expression table so that you can add, modify, or remove a state expression for the step.
Extended Expression
You can specify additional conditional expressions for the step. When you select this option, the
Workflow Editor displays the Extended Expression table , so that you can add, modify, or remove an
extended expression for the step.
```
```
Using conditional expressions
You can add or delete expressions for a conditional step, or modify the values of the expressions. Table
6 on page 26 describes the actions that are available for the State Expression table and the Extended
Expression table.
```
```
Table 6. Available actions for the State Expression table and the Extended Expression table.
```
```
Action Description
```
```
Modify To modify an expression, select only one item in the table, and select Modify from
the table actions menu. When you do so, a window is displayed for you to change
the expression, target state, or both.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Remove To remove one or more expressions from the table, select the items in the table
and select Remove from the table actions menu. You are prompted to confirm your
selection. To complete the change, click OK. Otherwise, click Cancel to discard
your changes.
```
```
Add To add an expression, select Add in the actions menu of the table. When you do so,
a window is displayed for you to enter the expression and its target state.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Select All Select all of the rows in the table. This action is applicable for removing all of the
existing expressions from the table.
```
```
Deselect All Remove the selection of all currently selected rows in the table.
```
**Types of conditional expressions**

```
The following types of conditional expressions are supported:
```
**26**   Workflow Editor task


- Expressions using logical operators AND (&) and OR (|). For example:

```
${step1.returnCode} == "0000" || (${step2.returnCode}
== "0000" && ${step2.stepOwner} == “IBMUSER”)
```
- Expressions based on ternary operators. For example:

```
condition? value_if_true : value_if_false
```
- Mathematical functions. For example:

```
Math.max(${step1.returnCode} , ${step2.returnCode} ) > 0
```
#### Instructions tab

```
The Instructions tab on the Step Details page displays the detailed instructions on what the user must
do to perform the step to completion.
The text field Step Instructions contains the instructions for performing the step. You can enter any
number of characters in this field.
In the Workflows schema, the instructions element ( <instructions> ) defines the content of the Review
Instructions tab of the Step Perform wizard in the Workflows task. The instructions can contain certain
HTML tags for formatting, and hyperlinks to refer to additional information. Though not all HTML tags
(and their attributes) are allowed, the tags for headings, tables, lists, hyperlinks, and text formatting are
supported. Specifically, the following HTML tags are supported: h1, h2, h3, h4, h5, h6, ol, ul,
dl, dt, dd, li, br, p, hr, table, th, td (with the frame, rules, and width attributes), tr,
caption, colgroup, col, thead, tbody, tfoot, i, b, u, em, strong, cite, code,
samp, kbd, pre, tt, sub, sup, big, small.
The text field Step Instructions must contain some content. Otherwise, the Perform tab is omitted for the
step and the step cannot be performed.
To specify a hyperlink, use the anchor (<a>) tag. When clicked, the hyperlink opens a new tab or window,
based on the user's browser settings. You can specify the href attribute only. To include an ampersand
character (&) in the URL, enclose the symbol in quotes: "&". Also, include the protocol with the URL. For
example, a value of "http://www.ibm.com" is correct, but "www.ibm.com" is not.
The instructions can also contain substituted values (variables). If you include variables in the text field,
ensure that the option Contains variable substitution is selected so that the variables are processed
correctly.
You cannot provide instructions or feedback for a parent step or a calling step. Thus, the Instructions and
Feedback tabs are disabled for these types of steps.
To expand the input area to full screen width, click Expand. When you work in the expanded text area:
```
- To save your changes, click **OK**.
- To discard your changes, click **Cancel**.

#### Type tab

```
The Type tab on the Step Details page displays the step type, which indicates the type of processing that
the step performs. On this tab, you can view or change the step type attributes for the step.
The different step types are described in the following sections:
```
- “Instructions steps” on page 28
- “Template steps” on page 28, with more details provided in the following sections:

```
Workflow Editor task   27
```

- “File template steps” on page 29
- “Inline template steps” on page 37
- “Calling steps” on page 42
- “REST steps” on page 45
- _Step type_ is an attribute of a leaf (child) step. A parent step does not have a step type. Therefore, no step
type value is displayed for a parent step.
- A calling step cannot contain instructions, input variables, or step feedback. Therefore, if you change
the step type to a calling step, the workflow editor removes these properties from the step, if they were
specified previously.
For more information about creating steps, see the topic _Creating workflow definitions for z/OS_ in IBM
z/OS Management Facility Programming Guide.

```
Instructions steps
A step might consist of textual instructions only, such as describing a system change that the user must
perform manually. A step that contains only text is referred to as an instructions step.
You can view and modify the instructions for an instructions step and other types of steps in the
Instructions tab of the Workflow Editor. For information, see “Instructions tab” on page 27.
Related reference
Template steps
A step that runs a program, such as a JCL job, a REXX exec, or a UNIX shell script, is referred to as a
template step. On step completion, the program results can be made available to other steps, in the form
of variables or an output property file. This topic describes how to create a template step so that you can
run programs and batch jobs in your workflow.
Calling steps
A step that calls another workflow for processing is referred to as a calling step.
REST steps
A step that issues a Representational State Transfer (REST) request, such as a GET or PUT request, is
referred to as a REST step.
```
```
Template steps
A step that runs a program, such as a JCL job, a REXX exec, or a UNIX shell script, is referred to as a
template step. On step completion, the program results can be made available to other steps, in the form
of variables or an output property file. This topic describes how to create a template step so that you can
run programs and batch jobs in your workflow.
For a template step, the Workflows task enables the Next button on the wizard instructions page. When
the user presses Next , the wizard guides the user through the activity, such as running a program or job,
or creating and saving an output file. The behavior of the wizard is further controlled through the options
that you define for the template step.
For the program that you want to run in the step, you must determine whether to include the program
code inline (that is, within the step itself), or in a separate, external file that is called from the step. You
indicate your choice in the Workflow Editor by selecting the appropriate Step Type , as follows:
Inline Template step
Program code is specified inline in the step XML.
File Template step
Program is contained in an external file. You must supply the location for the file, which is a sequential
data set, a member of a partitioned data set (PDS), or z/OS UNIX path and file name.
You must also decide on whether the program runs in real time or is submitted as a batch job. You can
choose to run the step as an immediate execution step , which runs a program in real time for immediate
results. The program can be a REXX exec or a UNIX shell script. Or, you can run the step as a batch
```
**28**   Workflow Editor task


_execution step_ , which runs a program as a batch job. The batch job contains JCL and might also embed an
executable program that runs under batch, such as a REXX exec or UNIX shell script.

For an immediate execution step, select one of the following attributes on the **Submit Template As**
selection menu:

**TSO-REXX**
Run a REXX exec program in real time.

**TSO-UNIX-REXX**
Run a REXX exec program for the UNIX environment in real time.

**TSO-UNIX-shell**
Run a UNIX shell script in real time.

For a batch execution step, select one of the following attributes on the **Submit Template As** selection
menu:

**JCL**
Submit a JCL job for batch processing on z/OS. The results are indicated in the job log.

**TSO-REXX-JCL**
Submit a JCL job that contains a REXX program. The program runs as a batch job on z/OS; the results
are indicated in the job log.

**shell-JCL**
Submit a JCL job that contains a UNIX shell script. The program runs as a batch job on z/OS; the
results are indicated in the job log.

For a template step, you must also decide on the following program characteristics:

- Whether the program uses variables. If so, select the **Contains variable substitution** option for the
    appropriate fields in the Workflow Editor.
- Whether the program output is saved.
- Whether the program execution results are saved.

These considerations are described in the following topics:

- “File template steps” on page 29
- “Inline template steps” on page 37.

**Related reference**

Instructions steps
A step might consist of textual instructions only, such as describing a system change that the user must
perform manually. A step that contains only text is referred to as an _instructions step_.

Calling steps
A step that calls another workflow for processing is referred to as a _calling step_.

REST steps
A step that issues a Representational State Transfer (REST) request, such as a GET or PUT request, is
referred to as a _REST step_.

**_File template steps_**
A _file template step_ is one that refers to an external file that contains executable code for performing the
step. The file can contain a JCL job, a REXX exec program, or a UNIX shell script.

In this tab, you can edit the contents of the file template that is used to submit a job or another type of
program for processing. As you work, your changes are written to a temporary file in z/OSMF controlled
storage. Your changes are not saved to the target file until you click **Save** to save your changes in the
editor. If you exit this tab or click **Cancel** , your changes from the current editor session are discarded.

You must decide on whether the program runs in real time or is submitted as a batch job. You can choose
to run the step as an _immediate execution step_ , which runs a program in real time for immediate results.
The program can be a REXX exec or a UNIX shell script. Or, you can run the step as a _batch execution step_ ,

```
Workflow Editor task   29
```

```
which runs a program as a batch job. The batch job contains JCL and might also embed an executable
program that runs under batch, such as a REXX exec or UNIX shell script.
For a batch execution step, select one of the following attributes on the Submit Template As selection
menu:
JCL
Submit a JCL job for batch processing on z/OS. The results are indicated in the job log.
TSO-REXX-JCL
Submit a JCL job that contains a REXX program. The program runs as a batch job on z/OS; the results
are indicated in the job log.
shell-JCL
Submit a JCL job that contains a UNIX shell script. The program runs as a batch job on z/OS; the
results are indicated in the job log.
For an immediate execution step, select one of the following attributes on the Submit Template As
selection menu:
TSO-REXX
Run a REXX exec program in real time.
TSO-UNIX-REXX
Run a REXX exec program for the UNIX environment in real time.
TSO-UNIX-shell
Run a UNIX shell script in real time.
For a file template step, the Step Type tab includes the following information about the step:
Submit Template As:
Indicate the type of program to be run and how it is to be processed on z/OS, as follows:
JCL
File contains a JCL job.
The program is run as a JCL job by the Workflows task, which creates the necessary JCL and JOB
statement, and displays the job output.
TSO-REXX-JCL
File contains a REXX program.
The program is run as a JCL job by the Workflows task, which creates the necessary JCL and JOB
statement, and displays the job output.
shell-JCL
File contains a UNIX shell script.
The program is run as a JCL job by the Workflows task, which creates the necessary JCL and JOB
statement, and displays the job output.
TSO-REXX
File contains a REXX program.
The program is run as a REXX program in real time.
TSO-UNIX-REXX
File contains a REXX program for the UNIX environment.
The program is run as a REXX program in real time.
TSO-UNIX-shell
File contains a UNIX shell script.
The program is run as a UNIX shell script in real time.
The size of any program to be run (JCL, REXX, or shell script) is limited to 10000 lines of code.
```
**30**   Workflow Editor task


Depending on whether you selected to run the step in batch or immediately, you can select from the
following options to further define the step:

- “File template steps — options for batch execution” on page 31
- “File template steps — options for immediate execution” on page 34

_File template steps — options for batch execution_
The following options are displayed for batch execution steps.

**Location of file template**
Specifies the location of an external file that contains executable code for performing the step, such
as a JCL job, a REXX exec program, or a UNIX shell script. Specify the location, which can be a
sequential data set, a member of a partitioned data set (PDS), or z/OS UNIX path and file name.
If you change the location of the file template, the Workflow Editor prompts you to select whether to
reload the template contents. If you do so, understand that any other changes you made to the step
on this tab are discarded.
If the file template resides in a z/OS UNIX file, observe the following naming conventions:

- Enter the full path and file name, beginning with the forward slash (/) and
    including the file name, or a relative path. For example: /usr/lpp/zosmf/samples/
    workflow_sample_file_template0.xml.
- Ensure that the file permissions are set properly. To allow read and write access for the user, the file
    template requires file permissions of at least 600.
If the file template resides in a data set, observe the following naming conventions:
- Do not enclose the data set name in quotation marks.
- For a sequential data set, enter the fully qualified data set name. For example: //
    SYS1.PRODUCTX.TESTFLOW
- For a member of a PDS, enter the fully qualified data set name, including the member name in
    parentheses. For example: //SYS1.PRODUCTX(TESTFLOW)
    If the file template resides in the same PDS as the workflow definition file, you can specify just the
    member name to save typing. For example: TESTFLOW
- The data set must exist and be cataloged. The Workflow Editor assumes that the data set resides on
    the default volume for your z/OS user ID. You cannot specify a different volume for the data set.
- Your user ID requires write access to the data set.
The option **Contains variable substitution** can be selected to indicate that variable substitution is
to be used for the file template location. If you plan to use a variable substitution for the location,
observe the following considerations:
- Use a variable format that is consistent with the setting for **Omit the prefix from instance variable**
    **references** in the Metadata tab. For example, assume that you define an instance variable _var_name_
    for the location. If you select to omit the prefix, you must refer to this variable as **${** **_var_name_** **}**. If
    you do not select this option, you must refer to this variable as **${instance-** **_var_name_** **}**.
- One or more variables can be used to represent the file template location. For example, the
    following specification, which uses a combination of two variables references, is allowed:

```
${instance- file_name }.${instance- file_type }
```
- The variable must already be defined in the workflow variable input file that is being used. If you
    have not yet created a workflow variable input file, create one that includes a variable definition for
    the file template location. As with other variables, the variable must be defined as a name-value
    pair. That is, the variable name and its associated value must be delineated with an equal sign (=),
    colon (:), or blank (' ').
- The variable name must start with an alphabetic character; the remaining characters can be
    alphabetic, numeric, hyphens ("-") or underscores ("_").

```
Workflow Editor task   31
```

```
If you specify a variable in the field Location of file template , the Workflow Editor attempts to resolve
the variable and open to the template at the resolved location.
To search for a file template on your system, click the search icon for the input field. In the path
selector window, enter a pattern that is a partial or complete name of a data set, member, or a UNIX
file path. A history list and a type-ahead list assist your pattern entry task. Pattern matching for UNIX
file paths is case-sensitive. When you select an object from the type-ahead list, the object name
populates the Location of file template input field.
If the file template does not exist at the specified location, the Workflow Editor attempts to create it.
Observe the following considerations:
```
- If you are saving to a data set, the data set must exist. Otherwise, the save request fails with an
    error message.
- If you are saving to an existing PDS, and the member does not exist, the Workflow Editor attempts
    to create the member in the PDS.
- If you are saving to a UNIX file path, and the path does not exist, the Workflow Editor attempts to
    create the path.
**Max RC**
Maximum return code value for the job to be considered successful. The value must be an integer in
the range 0 - 4095. If the return code is less than or equal to this value, the Workflows task marks the
step as complete. Otherwise, the Workflows task marks the step as failed.
**Max LRECL**
For a step that runs a JCL job, this field specifies the maximum record length (LRECL) in bytes for the
input data.
This value is an integer 80 - 2048. The default value is 1024. If the job runs the IEBUPDTE program,
ensure that this value is set to 80.
This field is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this field is disabled.
**Template contents**
This field contains the executable code that is run by the step.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
To expand the input area to full screen width, click **Expand**. When you work in the expanded text area:
- To save your changes, click **OK**.
- To discard your changes, click **Cancel**.
z/OSMF performs no validity checking of the template contents. You must ensure that the contents
are valid. For a UNIX file, ensure that the template contents use UTF-8 character encoding.
**Save as data set**
Specifies the name of the data set (fully qualified, no quotations) for saving the executable code after
the user edits it in the Workflows task. The presence of this element results in the **save as data set**
option being presented to the user, primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
**Save as UNIX file**
Specifies the path and file name for saving the UNIX file after the user edits it in the Workflows task.
Enter or select the full path for the file, beginning with the forward slash (/) and including the file
name. The presence of this element results in the **save as UNIX file** option being presented to the
user, primed with this value, if specified.

**32**   Workflow Editor task


```
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option Contains variable substitution. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
```
**Output properties location**
For a step that runs a JCL job, this field specifies the path and file name of the output property file that
is produced by the step (a data set or UNIX file). The output file can contain variables and values that
are used by subsequent steps.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
This field is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this field is disabled.

**Need to resolve conflicts**
If the output file contains variables that conflict with existing variables in the workflow, the conflicts
must be resolved before the step can be performed. You can choose to have the user resolve the
conflicts, or you can indicate that the output file variables should be automatically used in place of
the existing variables. To have the Workflows task prompt the user to resolve the conflicts, select
the option **Need to resolve conflicts**. Here, the Workflows task displays the Input Variables tab to
allow the user to resolve the variable conflicts. Otherwise, leave the **Need to resolve conflicts** option
unselected to use the output file variables in place of any existing values, without prompting the user.
This setting applies to instance variables only; global variables are not overridden.

**Specifies a sysout DD name**
This option is used with the **Output properties location** value. If the output properties are written to
a job spool file, select this option to indicate that the **Output properties location** value identifies a job
spool file, rather than a data set or UNIX file.
Based on the specified XML schema element and attribute, z/OSMF expects the following syntax for
the output properties location:

```
[ step .] ddname
```
```
Where:
```
- _step_ is the name of the job step that creates the output properties.
- _ddname_ is the destination of the output file (the sysout DD name).
If the step name is omitted, z/OSMF scans the supplied template for the DD name, reading from the
end of the file to the beginning until it finds a match.
This option is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this option is unavailable.

**Load array variables from output file**
An _array variable_ contains a list of individual values or name-value pairs. Array variables provide an
alternative to defining multiple variables to represent multiple values.
Unlike other types of variables, an array variable cannot be modified manually by the user from the
Workflows task user interface (UI). Instead, an array variable can be set by using an output file in a
workflow step (an inline template step or file template step).
If the output file contains an array variable that conflicts with an existing array variable in the
Workflows task, the conflicts are resolved automatically. By default, a workflow uses the array
variable values from the output file, rather than from the Workflows task. If you use the default
behavior, specify the location (path and file name) of the output file in the field _Output properties
location_.
To use array values from the Workflows task rather than from the output file, clear this option.

```
Workflow Editor task   33
```

```
Use predefined variables
A predefined variable is a variable definition that is used for string substitution in the current step only.
In the Workflows schema, you use the predefinedVariable ( <predefinedVariable> ) element to specify
one or more predefined variables for a step.
If predefined variables are defined for the step, the option Use Predefined Variables is enabled and
the variables are displayed in the Predefined Variables table. The table shows the variables and their
current values in the columns Name and Value.
To modify the predefined variables for the step, use the actions in the table. You can add or delete
predefined variables for a step, or modify the values of the variables. Table 7 on page 34 describes
the actions that are available for the Predefined Variables table.
```
```
Table 7. Available actions for the Predefined Variables table.
```
```
Action Description
```
```
Modify To modify a variable, select one only one variable in the table, and select Modify
from the table actions menu. When you do so, a window is displayed for you to
change the variable name, value, or both.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Remove To remove one or more variables from the table, select the variables in the table
and select Remove from the table actions menu. You are prompted to confirm your
selection. To complete the change, click OK. Otherwise, click Cancel to discard
your changes.
```
```
Add To add a variable, select Add in the actions menu of the table. When you do so, a
window is displayed for you to enter the variable name and its value.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Select All Select all of the rows in the table. This action is applicable for removing the existing
variables from the table.
```
```
Deselect All Remove the selection of all currently selected rows in the table.
```
```
File template steps — options for immediate execution
The following options are displayed for immediate execution steps.
Message for program success:
Specify one (and only one) message for a successful program completion. This value is required.
Message for program failure:
You can omit this option or specify up to 100 different failure messages for the step. Click Add to
specify more error messages.
Currently defined failure messages for the program:
You can use the Remove or Remove All button to remove error messages.
Prefix for variables that are written to an output file:
If the program creates output variables for use elsewhere in the workflow, specify a meaningful prefix
that identifies a string as a variable.
To allow the user to resolve variable name conflicts, select the option Prompt user to resolve
variable name conflicts.
Input parameter value:
If the program has input parameters that can be set by the step owner, use this field to list the input
parameters. You can specify up to 100 characters; spaces are truncated.
Input parameter description:
Text description of the parameter, such as its intended use or recommended value.
```
**34**   Workflow Editor task


```
This field is optional. It is disabled if no value is specified for Input parameter value.
```
**TSO/E logon procedure:**
TSO logon procedure to be used for the address space in which the job runs.

**Address space region size:**
Region size (in kilobytes) to be used for the address space in which the job runs. The valid range of
values is 50000 - 2096128 (KB).

**Program time out (in seconds):**
Specify a time limit for program processing. The valid range of values is 60 - 3600 (seconds).

**Location of file template**
Specifies the location of an external file that contains executable code for performing the step, such
as a JCL job, a REXX exec program, or a UNIX shell script. Specify the location, which can be a
sequential data set, a member of a partitioned data set (PDS), or z/OS UNIX path and file name.
If you change the location of the file template, the Workflow Editor prompts you to select whether to
reload the template contents. If you do so, understand that any other changes you made to the step
on this tab are discarded.
If the file template resides in a z/OS UNIX file, observe the following naming conventions:

- Enter the full path name, beginning with the forward slash (/) and including
    the file name, or a relative path. For example: /usr/lpp/zosmf/samples/
    workflow_sample_file_template0.xml.
- Ensure that the file permissions are set properly. To allow read and write access for the user, the file
    template requires file permissions of at least 600.
If the file template resides in a data set, observe the following naming conventions:
- Do not enclose the data set name in quotation marks.
- For a sequential data set, enter the fully qualified data set name. For example: //
    SYS1.PRODUCTX.TESTFLOW
- For a member of a PDS, enter the fully qualified data set name, including the member name in
    parentheses. For example: //SYS1.PRODUCTX(TESTFLOW)
    If the file template resides in the same PDS as the workflow definition file, you can specify just the
    member name to save typing. For example: TESTFLOW
- The data set must exist and be cataloged. The Workflow Editor assumes that the data set resides on
    the default volume for your z/OS user ID. You cannot specify a different volume for the data set.
- Your user ID requires write access to the data set.
The option **Contains variable substitution** can be selected to indicate that variable substitution is
to be used for the file template location. If you plan to use a variable substitution for the location,
observe the following considerations:
- Use a variable format that is consistent with the setting for **Omit the prefix from instance variable**
    **references** in the Metadata tab. For example, assume that you define an instance variable _var_name_
    for the location. If you select to omit the prefix, you must refer to this variable as **${** **_var_name_** **}**. If
    you do not select this option, you must refer to this variable as **${instance-** **_var_name_** **}**.
- One or more variables can be used to represent the file template location. For example, the
    following specification, which uses a combination of two variables references, is allowed:

```
${instance- file_name }.${instance- file_type }
```
- The variable must already be defined in the workflow variable input file that is being used. If you
    have not yet created a workflow variable input file, create one that includes a variable definition for
    the file template location. As with other variables, the variable must be defined as a name-value
    pair. That is, the variable name and its associated value must be delineated with an equal sign (=),
    colon (:), or blank (' ').

```
Workflow Editor task   35
```

- The variable name must start with an alphabetic character; the remaining characters can be
    alphabetic, numeric, hyphens ("-") or underscores ("_").
If you specify a variable in the field **Location of file template** , the Workflow Editor attempts to resolve
the variable and open to the template at the resolved location.
To search for a file template on your system, click the search icon for the input field. In the path
selector window, enter a pattern that is a partial or complete name of a data set, member, or a UNIX
file path. A history list and a type-ahead list assist your pattern entry task. Pattern matching for UNIX
file paths is case-sensitive. When you select an object from the type-ahead list, the object name
populates the **Location of file template** input field.
If the file template does not exist at the specified location, the Workflow Editor attempts to create it.
Observe the following considerations:
- If you are saving to a data set, the data set must exist. Otherwise, the save request fails with an
    error message.
- If you are saving to an existing PDS, and the member does not exist, the Workflow Editor attempts
    to create the member in the PDS.
- If you are saving to a UNIX file path, and the path does not exist, the Workflow Editor attempts to
    create the path.
**Max RC**
Maximum return code value for the job to be considered successful. The value must be an integer in
the range 0 - 4095. If the return code is less than or equal to this value, the Workflows task marks the
step as complete. Otherwise, the Workflows task marks the step as failed.
**Template contents**
This field contains the executable code that is run by the step.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
To expand the input area to full screen width, click **Expand**. When you work in the expanded text area:
- To save your changes, click **OK**.
- To discard your changes, click **Cancel**.
z/OSMF performs no validity checking of the template contents. You must ensure that the contents
are valid. For a UNIX file, ensure that the template contents use UTF-8 character encoding.
**Save as data set**
Specifies the name of the data set (fully qualified, no quotations) for saving the executable code after
the user edits it in the Workflows task. The presence of this element results in the _save as data set_
option being presented to the user, primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
**Save as UNIX file**
Specifies the path name for saving the UNIX file after the user edits it in the Workflows task. Enter or
select the full path name of the file, beginning with the forward slash (/) and including the file name.
The presence of this element results in the **Save as UNIX file** option being presented to the user,
primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
**Load array variables from output file**
An _array variable_ contains a list of individual values or name-value pairs. Array variables provide an
alternative to defining multiple variables to represent multiple values.

**36**   Workflow Editor task


```
Unlike other types of variables, an array variable cannot be modified manually by the user from the
Workflows task user interface (UI). Instead, an array variable can be set by using an output file in a
workflow step (an inline template step or file template step).
If the output file contains an array variable that conflicts with an existing array variable in the
Workflows task, the conflicts are resolved automatically. By default, a workflow uses the array
variable values from the output file, rather than from the Workflows task. If you use the default
behavior, specify a value for Prefix for variables that are written to an output file.
To use array values from the Workflows task rather than from the output file, clear this option.
Use predefined variables
A predefined variable is a variable definition that is used for string substitution in the current step only.
In the Workflows schema, you use the predefinedVariable ( <predefinedVariable> ) element to specify
one or more predefined variables for a step.
If predefined variables are defined for the step, the option Use Predefined Variables is enabled and
the variables are displayed in the Predefined Variables table. The table shows the variables and their
current values in the columns Name and Value.
To modify the predefined variables for the step, use the actions in the table. You can add or delete
predefined variables for a step, or modify the values of the variables. Table 8 on page 37 describes
the actions that are available for the Predefined Variables table.
```
_Table 8. Available actions for the Predefined Variables table._

**Action Description**

**Modify** To modify a variable, select one only one variable in the table, and select **Modify**
from the table actions menu. When you do so, a window is displayed for you to
change the variable name, value, or both.
To complete the change, click **OK**. Otherwise, click **Cancel** to discard your changes.

**Remove** To remove one or more variables from the table, select the variables in the table
and select **Remove** from the table actions menu. You are prompted to confirm your
selection. To complete the change, click **OK**. Otherwise, click **Cancel** to discard
your changes.

**Add** To add a variable, select **Add** in the actions menu of the table. When you do so, a
window is displayed for you to enter the variable name and its value.
To complete the change, click **OK**. Otherwise, click **Cancel** to discard your changes.

**Select All** Select all of the rows in the table. This action is applicable for removing the existing
variables from the table.

**Deselect All** Remove the selection of all currently selected rows in the table.

```
Inline template steps
A step that contains inline code for performing a function is called an inline template step. The inline code
can be a JCL job, a REXX exec program, or a UNIX shell script.
In this tab, you can edit the contents of the inline template that is used to run a job or another type of
program for processing. As you work, your changes are written to a temporary file in z/OSMF controlled
storage. Your changes are not saved to the step until you click Save to save your changes in the editor. If
you exit this tab or click Cancel , your changes from the current editor session are discarded.
You must decide on whether the program runs in real time or is submitted as a batch job. You can choose
to run the step as an immediate execution step , which runs a program in real time for immediate results.
The program can be a REXX exec or a UNIX shell script. Or, you can run the step as a batch execution step ,
which runs a program as a batch job. The batch job contains JCL and might also embed an executable
program that runs under batch, such as a REXX exec or UNIX shell script.
```
```
Workflow Editor task   37
```

```
The size of any program to be run (JCL, REXX, or shell script) is limited to 10000 lines of code.
For a batch execution step, select one of the following attributes on the Submit Template As selection
menu:
JCL
Submit a JCL job for batch processing on z/OS. The results are indicated in the job log.
TSO-REXX-JCL
Submit a JCL job that contains a REXX program. The program runs as a batch job on z/OS; the results
are indicated in the job log.
shell-JCL
Submit a JCL job that contains a UNIX shell script. The program runs as a batch job on z/OS; the
results are indicated in the job log.
For an immediate execution step, select one of the following attributes on the Submit Template As
selection menu:
TSO-REXX
Run a REXX exec program in real time.
TSO-UNIX-REXX
Run a REXX exec program for the UNIX environment in real time.
TSO-UNIX-shell
Run a UNIX shell script in real time.
Depending on whether you selected to run the step in batch or immediately, you can select from the
following options to further define the step:
```
- “Inline template steps - options for batch execution” on page 38
- “Inline template steps — options for immediate execution” on page 40.

```
Inline template steps - options for batch execution
The following options are displayed for batch execution steps.
Max RC
Specifies the maximum return code value for the job to be considered successful. The value must be
an integer in the range 0 - 4095. If the return code is less than or equal to this value, the Workflows
task marks the step as complete. Otherwise, the Workflows task marks the step as failed.
Max LRECL
For a step that runs a JCL job, this field specifies the maximum record length (LRECL) in bytes for the
input data.
This value is an integer 80 - 2048. The default value is 1024. If the job runs the IEBUPDTE program,
ensure that this value is set to 80.
This field is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this field is unavailable.
Template Contents
This field contains the executable code that is run by the step.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option Contains variable substitution. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
To expand the input area to full screen width, click Expand. When you work in the expanded text area:
```
- To save your changes, click **OK**.
- To discard your changes, click **Cancel**.
z/OSMF performs no validity checking of the template contents. You must ensure that the contents
are valid. For a UNIX file, ensure that the template contents use UTF-8 character encoding.

**38**   Workflow Editor task


**Save as Dataset**
Specifies the name of the data set (fully qualified, no quotations) for saving the executable code after
the user edits it in the Workflows task. The presence of this element results in the _save as data set_
option being presented to the user, primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.

**Save as UNIX file**
Specifies the path name for saving the UNIX file after the user edits it in the Workflows task. Enter
or select the full path name of the file, beginning with the forward slash (/) and including the file
name. The presence of this element results in the _save as UNIX file_ option being presented to the user,
primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.

**Output properties location**
For a step that runs a JCL job, this field specifies the path and file name of the output property file
that is produced by the step. The output property file can contain variables and values that are used
by subsequent steps.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
This field is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this field is unavailable.

**Need to resolve conflicts**
If the output file contains variables that conflict with existing variables in the workflow, the conflicts
must be resolved before the step can be performed. You can choose to have the user resolve the
conflicts, or you can indicate that the output file variables should be automatically used in place of
the existing variables. To have the Workflows task prompt the user to resolve the conflicts, select
the option **Need to resolve conflicts**. Here, the Workflows task displays the Input Variables tab to
allow the user to resolve the variable conflicts. Otherwise, leave the **Need to resolve conflicts** option
unselected to use the output file variables in place of any existing values, without prompting the user.
This setting applies to instance variables only; global variables are not overridden.

**Specifies a sysout DD name**
This option is used with the **Output properties location** value. If the output properties are written to
a job spool file, select this option to indicate that the value that is specified in the Output properties
location field identifies a job spool file, rather than a data set or UNIX file.
Based on the specified XML schema element and attribute, z/OSMF expects the following syntax for
the output properties location:

```
[ step .] ddname
```
```
where:
```
- _step_ is the name of the job step that creates the output properties
- _ddname_ is the destination of the output file (the sysout DD name).
If the step name is omitted, z/OSMF scans the supplied template for the DD name, reading from the
end of the file to the beginning until it finds a match.
This option is available for JCL jobs only. For other types of programs, such as REXX execs or shell
scripts, this option is unavailable.

```
Workflow Editor task   39
```

```
Load array variables from output file
An array variable contains a list of individual values or name-value pairs. Array variables provide an
alternative to defining multiple variables to represent multiple values.
Unlike other types of variables, an array variable cannot be modified manually by the user from the
Workflows task user interface (UI). Instead, an array variable can be set by using an output file in a
workflow step (an inline template step or file template step).
If the output file contains an array variable that conflicts with an existing array variable in the
Workflows task, the conflicts are resolved automatically. By default, a workflow uses the array
variable values from the output file, rather than from the Workflows task. If you use the default
behavior, specify the location (path and file name) of the output file in the field Output properties
location.
To use array values from the Workflows task rather than from the output file, clear this option.
Use Predefined Variables
A predefined variable is a variable definition that is used for string substitution in the current step only.
In the Workflows schema, you use the predefinedVariable ( <predefinedVariable> ) element to specify
one or more predefined variables for a step.
If predefined variables are defined for the step, the option Use predefined variables is enabled and
the variables are displayed in the Predefined Variables table. The table shows the variables and their
current values in the columns Name and Value.
To modify the predefined variables for the step, use the actions in the table. You can add or delete
predefined variables for a step, or modify the values of the variables. Table 9 on page 40 describes
the actions that are available for the Predefined Variables table.
```
```
Table 9. Available actions for the Predefined Variables table.
```
```
Action Description
```
```
Modify To modify a variable, select one only one variable in the table, and select Modify
from the table actions menu. When you do so, a window is displayed for you to
change the variable name, value, or both.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Remove To remove one or more variables from the table, select the variables in the table
and select Remove from the table actions menu. You are prompted to confirm your
selection. To complete the change, click OK. Otherwise, click Cancel to discard
your changes.
```
```
Add To add a variable, select Add in the actions menu of the table. When you do so, a
window is displayed for you to enter the variable name and its value.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Select All Select all of the rows in the table. This action is applicable for removing the existing
variables from the table.
```
```
Deselect All Remove the selection of all currently selected rows in the table.
```
```
Inline template steps — options for immediate execution
The following options are displayed for immediate execution steps.
Message for program success:
Specify one (and only one) message for a successful program completion. This value is required.
Message for program failure:
You can omit this option or specify up to 100 different failure messages for the step. Use the Add
button to specify more error messages.
```
**40**   Workflow Editor task


**Currently defined failure messages for the program:**

```
You can use the Remove or Remove All button to remove error messages.
```
**Prefix for variables that are written to an output file:**
If the program creates output variables for use elsewhere in the workflow, specify a meaningful prefix
that identifies a string as a variable.
To allow the user to resolve variable name conflicts, select the option **Prompt user to resolve
variable name conflicts**.

**Input parameter value:**
If the program has input parameters that can be set by the step owner, use this field to list the input
parameters. You can specify up to 100 characters; spaces are truncated.

**Input parameter description:**
Text description of the parameter, such as its intended use or recommended value.
This field is optional. It is disabled if no value is specified for **Input parameter value**.

**TSO/E logon procedure:**
TSO logon procedure to be used for the address space in which the job runs.

**Address space region size:**
Region size (in kilobytes) to be used for the address space in which the job runs. The valid range of
values is 50000 - 2096128 (KB).

**Program time out (in seconds):**
Specify a time limit for program processing. The valid range of values is 60 - 3600 (seconds).

**Max RC**
Maximum return code value for the job to be considered successful. The value must be an integer in
the range 0 - 4095. If the return code is less than or equal to this value, the Workflows task marks the
step as complete. Otherwise, the Workflows task marks the step as failed.

**Template Contents**
This field contains the executable code that is run by the step.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.
To expand the input area to full screen width, click **Expand**. When you work in the expanded text area:

- To save your changes, click **OK**.
- To discard your changes, click **Cancel**.
z/OSMF performs no validity checking of the template contents. You must ensure that the contents
are valid. For a UNIX file, ensure that the template contents use UTF-8 character encoding.

**Save as Dataset**
Specifies the name of the data set (fully qualified, no quotations) for saving the executable code after
the user edits it in the Workflows task. The presence of this element results in the _save as data set_
option being presented to the user, primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.

**Save as UNIX file**
Specifies the path name for saving the UNIX file after the user edits it in the Workflows task. Enter or
select the full path name of the file, beginning with the forward slash (/) and including the file name.
The presence of this element results in the **Save as UNIX file** option being presented to the user,
primed with this value, if specified.
It is possible to use variable substitution in this field. To do so, specify the substitution string in the
field and select the option **Contains variable substitution**. When the step is in the Ready state, the
system performs the variable substitution to derive the actual value for the variable.

```
Workflow Editor task   41
```

```
Load array variables from output file
An array variable contains a list of individual values or name-value pairs. Array variables provide an
alternative to defining multiple variables to represent multiple values.
Unlike other types of variables, an array variable cannot be modified manually by the user from the
Workflows task user interface (UI). Instead, an array variable can be set by using an output file in a
workflow step (an inline template step or file template step).
If the output file contains an array variable that conflicts with an existing array variable in the
Workflows task, the conflicts are resolved automatically. By default, a workflow uses the array
variable values from the output file, rather than from the Workflows task. If you use the default
behavior, specify a value for Prefix for variables that are written to an output file.
To use array values from the Workflows task rather than from the output file, clear this option.
Use Predefined Variables
A predefined variable is a variable definition that is used for string substitution in the current step only.
In the Workflows schema, you use the predefinedVariable ( <predefinedVariable> ) element to specify
one or more predefined variables for a step.
If predefined variables are defined for the step, the option Use Predefined Variables is enabled and
the variables are displayed in the Predefined Variables table. The table shows the variables and their
current values in the columns Name and Value.
To modify the predefined variables for the step, use the actions in the table. You can add or delete
predefined variables for a step, or modify the values of the variables. Table 10 on page 42 describes
the actions that are available for the Predefined Variables table.
```
```
Table 10. Available actions for the Predefined Variables table.
```
```
Action Description
```
```
Modify To modify a variable, select one only one variable in the table, and select Modify
from the table actions menu. When you do so, a window is displayed for you to
change the variable name, value, or both.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Remove To remove one or more variables from the table, select the variables in the table
and select Remove from the table actions menu. You are prompted to confirm your
selection. To complete the change, click OK. Otherwise, click Cancel to discard
your changes.
```
```
Add To add a variable, select Add in the actions menu of the table. When you do so, a
window is displayed for you to enter the variable name and its value.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Select All Select all of the rows in the table. This action is applicable for removing the existing
variables from the table.
```
```
Deselect All Remove the selection of all currently selected rows in the table.
```
```
Calling steps
A step that calls another workflow for processing is referred to as a calling step.
For a calling step, the Step Type tab includes the following information about the step:
Call Workflow By:
To run a called workflow, the calling step must identify which workflow is to be called. The Workflows
schema provides two methods for you to uniquely identify the called workflow:
```
**42**   Workflow Editor task


```
Name (ID/version)
Workflow ID of the called workflow and optionally the version of the workflow definition of the
called workflow.
MD5
Workflow MD5 element; a 128-bit hash value that can be used to identify the called workflow.
This value can be used in place of the workflow ID and version elements.
Use either of the following approaches:
```
- Specify the **Workflow ID** of the called workflow. This value is used to help locate an existing
    workflow instance when the step is performed.
    You can further qualify this specification by optionally including the **Workflow Version** of the
    workflow definition of the called workflow. The version is typically updated by the workflow author
    whenever any portion of the workflow definition file is changed. The Workflows task caches only
    the latest version of an imported workflow definition file. Therefore, to ensure that the most current
    version is used, you must update the version value whenever you modify the workflow definition.
- Specify the **Workflow MD5** of the called workflow, which is a 128-bit hash value that can be used
    to identify the called workflow. You can specify this element in place of the workflow ID and version
    values.
**Note:** No more than one level of nesting of called workflows is permitted in a workflow-to-workflow
relationship. Thus, the specified workflow definition cannot contain a step that calls another workflow.

**Workflow Definition File**
Name of the workflow definition file that is used to create a new workflow if an active instance is
not found when this step is performed. Specify the fully qualified path name of the file, beginning
with the forward slash (/) and including the file name. For example: /usr/lpp/zosmf/samples/
workflow_sample_basic.xml.
This field can contain substituted values (variables). If you include variables in this field, ensure
that the option _File path name contains substitution_ is selected so that the variables are processed
correctly.
If the workflow definition file resides on the local system, you can locate it with a type-ahead search.
Click the search icon for the input field to open the path selector window. Then, enter a pattern that is
a partial or complete name of a data set, member, or a UNIX file path. A history list and a type-ahead
list assist your pattern entry task. Pattern matching for UNIX file paths is case-sensitive. When you
select an object from the type-ahead list, the object name populates the **Workflow Definition File**
input field.

**Workflow Variable Input File**
Location of the workflow variable input file, which is an optional properties file that is used to specify
the values for one or more variables in the workflow definition file. Specify the fully qualified z/OS
UNIX path of the file, beginning with the forward slash (/) and including the file name. This value is
optional.
This field can contain substituted values (variables). If you include variables in this field, ensure
that the option _File path name contains substitution_ is selected so that the variables are processed
correctly.
If the workflow variable input file resides on the local system, you can locate it with a type-ahead
search. Click the search icon for the input field to open the path selector window. Then, enter a
pattern that is a partial or complete name of a data set, member, or a UNIX file path. A history
list and a type-ahead list assist your pattern entry task. Pattern matching for UNIX file paths is
case-sensitive. When you select an object from the type-ahead list, the object name populates the
**Workflow Variable Input File** input field.

**Workflow Description**
Description of the workflow to be called, from the point of view of the calling workflow.

```
Workflow Editor task   43
```

- To avoid duplication of some information, the Step Overview tab contains the calling step overview
    fields on that tab. Thus, properties such as the calling step weight are shown on the Step Overview tab,
    rather than repeated on this tab.
- You cannot provide instructions, feedback, or input variables for a calling step. Therefore, the
    **Instructions** and **Feedback** tabs are disabled for calling steps, and no input variables are shown on
    the Step Type tab.

```
Sharing variables between workflows
It is possible to share variables between the calling workflow and the called workflow. Any variables that
are defined to either workflow can be shared by selecting the following options:
```
- **Transfer variable values from this workflow to the called workflow**. Use this option to specify the
    variable values that are to be transferred from the calling workflow to the called workflow.
- **Transfer variable values from the called workflow to this workflow**. Use this option to specify the
    variable values that are to be transferred from the called workflow to the calling workflow.
By default, if variable conflicts exist, the calling workflow variables take precedence over the called
workflow variables. You can reverse this behavior by selecting the option **Override calling workflow
variables**. Doing so causes the called workflow variables to be used in place of any conflicting variables in
the calling workflow.
In the expanded work area for each option, you can optionally specify the following attributes for the
variables:
**Regular Expressions**
    One or more regular expressions. Use this field to filter on variable names with one or more wildcard
    characters. For example, to select all variables that are prefixed with "setting," you can specify:

```
^setting.*$
```
```
Variable Name
Name of the variable. Specify the variable that is to be shared with the target workflow.
To map this variable to a specific variable in the target workflow, set the Map To value for the variable
to the name to the target variable. The behavior of the Map To setting for the variable depends on
which workflow is the target for the variables, as follows:
```
- When specified on the option **Transfer variable values from this workflow to the called workflow** ,
    the variables are mapped to the target variables only when a new instance of the called workflow is
    created in response to the calling step.
- When specified on the option **Transfer variable values from the called workflow to this workflow** ,
    the variables are mapped to the target variables on completion of the called workflow.
**Related reference**
Instructions steps
A step might consist of textual instructions only, such as describing a system change that the user must
perform manually. A step that contains only text is referred to as an _instructions step_.
Template steps
A step that runs a program, such as a JCL job, a REXX exec, or a UNIX shell script, is referred to as a
_template step_. On step completion, the program results can be made available to other steps, in the form
of variables or an output property file. This topic describes how to create a template step so that you can
run programs and batch jobs in your workflow.
REST steps

**44**   Workflow Editor task


A step that issues a Representational State Transfer (REST) request, such as a GET or PUT request, is
referred to as a _REST step_.

**REST steps**

A step that issues a Representational State Transfer (REST) request, such as a GET or PUT request, is
referred to as a _REST step_.

For a REST step, the **Step Type** tab includes the following information about the step:

**HTTP Method**
Indicates the HTTP method that is used for issuing the REST request. The following values are valid:

- GET
- PUT
- POST
- DELETE.

**Scheme Name**
Specifies the hypertext transfer protocol (HTTP) header for the request: HTTP or HTTPS.
To connect to a system other than the local system, specify a scheme name, the host name for the
receiving system, and, optionally, a port number for the receiving system. Additionally, for a secured
connection (HTTPS), you must also specify the user name and password to be used for logging in to
the receiving system.
Scheme name and host name, and the optional port number, are used together. You must specify both
scheme name and host name, or neither of them. Otherwise, the workflow fails validation when the
user attempts to import the workflow definition into the Workflows task.
If you omit the scheme name, no host name is required. In this case, the REST request is sent to the
local z/OSMF server.

**Host Name**
Host name or IP address of the system to which the REST request is directed. For example:
[http://www.ibm.com.](http://www.ibm.com.)
If you specify a scheme name (HTTP or HTTPS), you must also specify a host name. You can
optionally specify a port number for the host name.
To omit the host name, leave this field blank. The default is the host name that was defined for the
local z/OSMF server, which is "*" by default.
The option **Check to use substitution** indicates whether variable substitution is used in this field.

**Port Number**
Port number for the REST request. This value is optional. If you omit it, the default is the port number
that was defined for z/OSMF, which is "80" for HTTP requests and "443" for HTTPS requests.
The option **Check to use substitution** indicates whether variable substitution is used in this field.

**User name**
z/OS user ID that allows the user to access the specified URI. This value is a user ID that is specified
in your installation's z/OS security management facility (for example, RACF).

- For an HTTPS request, the user name and password are required. These values are used to create a
    secure request to the specified URI.
- For an HTTP request, the user name and password are optional. These values are used for basic
    authentication only.
The option **Check to use substitution** indicates whether variable substitution is used in this field.

**Password**
Password or pass phrase that is associated with the user name. For an HTTPS request, the user name
and password are required.

```
Workflow Editor task   45
```

```
The Workflows task applies Base64 decoding to this value. Therefore:
```
- To specify a password value on this element, encode the value by using Base64 encoding and
    specify the result here. For example, the string password would be specified as cGFzc3dvcmQ==.
- To use variable substitution for the password, ensure that the password variable is included in the
    workflow input variable file for the workflow, and is specified in Base64 encoded form.
The option **Check to use substitution** indicates whether variable substitution is used in this field.
**URI Path**
URI path for the REST request. This value is required.
The option **Check to use substitution** indicates whether variable substitution is used in this field.
**Query Parameters**
For a GET or POST request, this field contains the query parameters. This value is optional; no default
is provided.
The option **Check to use substitution** indicates whether variable substitution is used in this field.
**Request Header**
Request header for the REST request. This value is optional; no default is provided.
Specify the contents of the request header as a JSON object, as follows:
- Use braces '{ }' to enclose the JSON content.
- Specify each header property as a name-value pair, with the property and its value delineated with a
colon (:).
- For multiple header properties, use commas to separate the properties.
For example:

```
{
"X-CSRF-ZOSMF-HEADER": "",
"Content-Type" : "application",
"Accept" : "*/*"
}
```
```
The option Check to use substitution indicates whether variable substitution is used in this field.
Request Body
For a PUT or POST request, this field contains the request body. This value is optional; no default is
provided.
The option Check to use substitution indicates whether variable substitution is used in this field.
Poll Attributes
You can optionally use polling to find out the status of an asynchronous request. In this field, specify
the attributes for polling as follows:
Poll Count Maximum
Specify the number of times to poll before the REST call receives the expected condition. The valid
range is 1 - 1000.
The option Check to use substitution indicates whether variable substitution is used in this field.
Wait Time
Specify the time (in seconds) to wait between each poll, up to a maximum of 3600 seconds (1
hour). If you specify this value, you must also specify the poll count maximum.
The option Check to use substitution indicates whether variable substitution is used in this field.
Exit Response Property
Specify the name of the response property, which is the condition to end the polling. A program
can check the value of this property to determine whether to exit polling. This property is required
if you specify a poll count maximum.
```
**46**   Workflow Editor task


```
Property Value
Specify the value that indicates that polling should end. For example: "Complete" or 0000.
If the returned value for the property matches this value, the poll exits and returns to the caller.
Otherwise, polling continues for the specified poll count maximum. If no match is found in the
returned response body within the specified polling limits, the REST step fails.
The exit response property and its value do not support substitution variables. These properties
must be set in the workflow definition file.
```
**Certificates**
Certificates for the REST request. This value is optional; no default is provided.
Specify the certificate locations as a JSON array, as follows:

- Use square brackets '[ ]' to enclose the array.
- For each certificate, provide a fully qualified (absolute) path.
- For multiple certificates, use commas to separate the locations.
For example:

```
[
"/tmp/SampleCertificate.cer",
"/tmp/AnotherCertificate.cer"
]
```
```
The option Check to use substitution indicates whether variable substitution is used in this field.
```
**Expected Status Code**
The expected HTTP status code from the REST request. If this value does not match the
actualStatusCode value, the workflow step fails. This value is required.

**Actual Status Code Mapping**
The actual HTTP status code that is received from the REST request. This value is optional; no default
is provided.

**Property Mappings**
Indicates how properties in the response body are to be mapped to variables in the workflow. This
value is optional; no default is provided.
The REST step is enhanced to return the entire response body. If empty square brackets are used for
the propertyMapping, the REST step will return the entire response body and map it to the workflow
variable specified by the _mapTo_ value. For example:

```
<propertyMapping mapTo="responseBody">[]</propertyMapping>
```
```
In order to map the entire response body, the response type may need to be updated. For example, if
the response is in plain text, the Accept header will need to be updated to "Accept": "text/plain". This
update can be done using the requestHeader field in the REST step. For example, assuming you want
to map a text response to workflow variable results:
```
```
<rest>
:
:
<propertyMapping mapTo=“results”>[]</propertyMapping>
:
<requestHeaders>
{
“Accept” : “text/plain”
}
</requestHeaders>
</rest>
```
```
In the Property Mappings table, you can launch actions to modify or remove the selected mappings, or
add mappings.
```
```
Workflow Editor task   47
```

```
Related reference
Instructions steps
A step might consist of textual instructions only, such as describing a system change that the user must
perform manually. A step that contains only text is referred to as an instructions step.
Template steps
A step that runs a program, such as a JCL job, a REXX exec, or a UNIX shell script, is referred to as a
template step. On step completion, the program results can be made available to other steps, in the form
of variables or an output property file. This topic describes how to create a template step so that you can
run programs and batch jobs in your workflow.
Calling steps
A step that calls another workflow for processing is referred to as a calling step.
```
#### Shared step library

```
The Workflow Editor includes a shared step library, which provides you with a place for saving steps within
the Workflow Editor. From the shared step library, you and other workflow authors at your company can
share the steps you create and use them in other workflow definitions, as needed.
A step must have a unique name to be saved in the shared step library. When stored in the shared step
library, a shared step cannot be modified. It can, however, be imported into a workflow definition and then
modified.
After a step is stored in the shared step library, only the step creator can delete it.
The following topics provide more information about using the shared step library:
```
- “Exporting a step to the shared step library” on page 48
- “Importing a step from the shared step library” on page 49
The shared step library includes a "toolbox" of IBM-supplied steps. For more information, see “Steps
supplied by IBM” on page 50.

```
Exporting a step to the shared step library
You can export a step to the shared step library. This action makes the step available for use later, by you
or another workflow author. To export a step, use the Export to Step Library action that is provided in the
Steps table.
```
**Before you begin**

```
This action adds the selected step to the shared step library, which is a repository in z/OSMF.
You can export parent steps or leaf steps. If you select a parent step for the export action, the step and its
child steps are exported in their entirety to the step library.
For an exported step, understand that not all of the step attributes are included in the exported step. The
Workflow Editor excludes from the exported step any attributes that might not be relevant or transferable
to another workflow definition file.
Specifically, the following step attributes are not included with the exported step:
Prerequisite steps
A step might have one or more prerequisite steps , which are steps that must reach a particular target
state before the current step can be performed.
Predefined variables
A variable definition that is used for string substitution in the current step only.
Conditions
Conditional logic that is used to determine the target state for the current step, such as when a
particular condition is satisfied on the z/OS system or in the Workflows task. Otherwise, the step
remains in the Not Ready state.
```
**48**   Workflow Editor task


**Variable references**
References to variables that were defined earlier in the workflow definition (instance variables and
global variables).

**Set instance variables on step completion**
Predetermined values to be used for instance variables, on completion of the step.

**Feedback references**
A step might have feedback questions for the step owner to complete.

**Signature**
The signature is generated automatically after the signer signs the step.

**Procedure**

1. In the **Steps** table, select the step to be exported. You can select only one step at a time.
    The step must be valid; otherwise, the step cannot be exported and the action **Export to Step Library**
    is disabled.
2. From the **Actions** menu or context menu, select **Export to Step Library**. The Export to Step Library
    dialog is displayed.
       a) In the _Name_ field, specify a meaningful name for the step. The step name must be unique in the
          shared step library; otherwise, you are prompted to select a different name for the step.
b) In the _Description_ field, describe the step. Provide enough information so that other users of the
shared step library can easily determine whether the step can be used for a particular purpose.
3. Click **OK** to export the selected step.

**Results**

The step is stored in the shared step library. The Workflow Editor makes the step available for use with
other workflow definitions and by other workflow authors.

A step in the shared step library cannot be modified. The step can be deleted by the step creator.

**Related tasks**

Importing a step from the shared step library
To import a step, use the **Import from Step Library** action that is provided in the Steps table. By default,
the shared step library includes a number of IBM-supplied steps in the shared step library for your use. To
delete a step from the shared step library, the step creator can use the **Import from Step Library** action
to access a **Delete** option for steps in the shared step library.

**Related reference**

Steps supplied by IBM
The shared step library includes a set of useful steps from IBM. The steps are designed for performing
common tasks on z/OS, such as creating a data set or submitting a REST request. This set of IBM-
supplied steps is known collectively as the _IBM step toolbox_.

**Importing a step from the shared step library**

To import a step, use the **Import from Step Library** action that is provided in the Steps table. By default,
the shared step library includes a number of IBM-supplied steps in the shared step library for your use. To
delete a step from the shared step library, the step creator can use the **Import from Step Library** action
to access a **Delete** option for steps in the shared step library.

**Before you begin**

By default, the Workflow Editor places the imported step immediately after the selected step. If no step is
selected, the Workflow Editor places the step at the end of the workflow. You can move the step by using
the various **Move** actions in the Steps table **Actions** menu.

```
Workflow Editor task   49
```

```
After you import a step, you can adjust its parent or leaf relationship to the other steps in the workflow.
To make a step a parent or leaf of another step, use the Move In and Move Out actions in the Steps table
Actions menu.
If you select a parent step from the step library, the Import from Step Library action obtains the step
and its child steps in their entirety. Likewise, the Delete action removes the parent step and its child steps
from the step library.
For a REST step, understand that the step might include an actual status code mapping or property
mappings for one or more variables. If so, you must ensure that the referenced variables are defined in
the workflow definition file before you import the step. Otherwise, an error results. In the Workflow Editor,
use the Variables tab to create the variables that are mapped in the REST step. Then, import the step.
```
**Procedure**

1. In the Steps table, optionally select a position in the workflow for placing the imported step. To do
    so, select the step that should precede the imported step. Otherwise, the Workflow Editor places the
    imported step at the end of the workflow, by default.
2. From the **Actions** menu or context menu, select **Import from Step Library**. A dialog is displayed,
    showing a list of the steps that are available for importing. If no steps are available, the shared step
    library is empty.
3. Review the list of steps and select one. You can select one step only.
    If you select a parent step, the step and its child steps are included in the operation.
    - **Import a step:** To continue with the Import operation, click **Next** to display a dialog for naming
       the step. Specify a step name that is unique in the workflow definition file. Then, click **Finish** to
       complete the import operation.
    - **Delete a step:** To delete a step from the shared step library, click **Manage** to display a list of the
       steps that are available for deletion. Select the step to be deleted. From the **Actions** menu or
       context menu, select **Delete**. Only the step creator can delete the step.

**Results**

```
Depending on the selected action, the step is either imported or deleted from the shared step library.
Related tasks
Exporting a step to the shared step library
You can export a step to the shared step library. This action makes the step available for use later, by you
or another workflow author. To export a step, use the Export to Step Library action that is provided in the
Steps table.
Related reference
Steps supplied by IBM
The shared step library includes a set of useful steps from IBM. The steps are designed for performing
common tasks on z/OS, such as creating a data set or submitting a REST request. This set of IBM-
supplied steps is known collectively as the IBM step toolbox.
```
```
Steps supplied by IBM
The shared step library includes a set of useful steps from IBM. The steps are designed for performing
common tasks on z/OS, such as creating a data set or submitting a REST request. This set of IBM-
supplied steps is known collectively as the IBM step toolbox.
Before you create a workflow definition, review the step toolbox to determine whether any of the steps
are applicable to your needs. If so, you can save time by importing an IBM-supplied step from the shared
step library and modifying it, rather than creating your own step.
If an IBM-supplied step includes variable definitions, they are included with the step when you import the
step.
```
**50**   Workflow Editor task


```
It is not possible to delete the IBM-supplied steps from the shared step library. These steps are
automatically filtered from view if the user selects the Delete action.
Nor, can you modify an IBM-supplied step in the shared step library. Instead, you can import the step into
your workflow definition and modify the step there.
```
```
Accessing the step toolbox
To access the IBM supplied steps (the step toolbox), select the Import action from the shared step
library. The IBM-supplied steps are included in the list of steps that is displayed. The IBM-supplied steps
are easy to identify; they are prefixed by IBM-Toolbox-.
```
_Table 11. IBM steps included in the shared steps library._

**Step Name Step type Description**

**IBM-Toolbox-
CreateDataset**

```
Inline template step A step that allocates (creates) a partitioned data set (PDS) by
submitting a batch job to run on z/OS. As input, the step uses the
variable IBM-Toolbox-CreateDataset-dsname. Set this variable to
a valid data set name.
```
**IBM-Toolbox-
CopyData**

```
Inline template step A step that copies data into a PDS member by using the
IEBGENER utility. As input, the step uses the following variables:
```
- _IBM-Toolbox-CopyData-dsname_. Set this variable to the name of
    the target data set.
- _IBM-Toolbox-CopyData-memberName_. Set this variable to the
    name of the target data set member.

**IBM-Toolbox-
CopyMember**

```
Inline template step A step that copies a member from one data set to another by
using the IEBCOPY utility. As input, the step uses the following
variables:
```
- _IBM-Toolbox-CopyMember-dsname1_. Set this variable to the
    name of the source data set.
- _IBM-Toolbox-CopyMember-memberName_. Set this variable to
    the name of the source data set member.
- _IBM-Toolbox-CopyMember-dsname2_. Set this variable to the
    name of the target data set.

**IBM-Toolbox-
ObtainZosReleasee**

```
REST step A step that obtains the z/OS release level for the local system
by submitting a REST request. Specifically, the step issues a GET
request for the z/OS version; the returned value is mapped to the
variable IBM-Toolbox-ObtainZOSRelease-zos_version.
```
**IBM-Toolbox-Shell** Inline template step An example of a shell script. When run, this script writes "Hello
World" to the user's display. This step uses no variables.

```
Related tasks
Exporting a step to the shared step library
You can export a step to the shared step library. This action makes the step available for use later, by you
or another workflow author. To export a step, use the Export to Step Library action that is provided in the
Steps table.
Importing a step from the shared step library
To import a step, use the Import from Step Library action that is provided in the Steps table. By default,
the shared step library includes a number of IBM-supplied steps in the shared step library for your use. To
delete a step from the shared step library, the step creator can use the Import from Step Library action
to access a Delete option for steps in the shared step library.
```
```
Workflow Editor task   51
```

#### Conditions tab

```
On the Conditions tab on the Step Details page, you can specify conditional logic, which is used by the
Workflows engine to determine the state of the step.
To make a step conditional, select the option Set this step as conditional , then provide an expression
to be evaluated in the Expression field. An expression is a mathematical or logical expression that the
Workflows engine can use to evaluate the state of the step. If the expression evaluates to true, the step is
set to the desired target state, such as Ready. Otherwise, the step remains in the Not Ready state.
In the following fields on the Conditions tab, specify the expression that is being tested and a text
description of the condition:
Expression
Specify an expression based on input variables and boolean logic. When the expression resolves to
true for the current workflow instance, the step is Ready (eligible to be performed).
For example, an expression like the following can be used to determine whether the job issued by
Step 1 completed successfully with return code zero:
```
```
${step1.returnCode} == "0000"
```
```
Examples of expressions include:
```
- String-to-string comparisons
- Boolean comparisons
- Mathematical comparisons, such as greater than (>), less than (<), or equal to (==).
See“Types of conditional expressions” on page 53.
It is assumed that you will use one or more variables in the expression, such as workflow input
variables. Doing so allows conditional steps to resolve to true or false, based on installation-specific
conditions.
**Description**
Describe the condition that must be satisfied before the step can be performed. For example:

```
Make this step ready if the job in the previous step ran successfully (return code 0).
```
```
The description is optional, but recommended.
Tip: The user of the z/OSMF Workflows task can view the conditional expression and its description in the
Dependencies tab on the Step Properties page for the step.
To disable all conditions from a step, thus making it non-conditional, deselect the option Set the step as
conditional. The step will assume the Ready state at workflow creation time.
```
**How z/OSMF evaluates step states**

```
Workflow input variables are set at workflow creation time, and are evaluated again each time a step in
the workflow is performed.
The Workflows engine evaluates any conditional expressions as either true or false, as follows:
```
- Steps with conditions that evaluate to true are set to the _Ready_ state or a different state, if you specify
    one. See the description of _target state_ , which follows.
- Steps that contain an unsatisfied condition are set to the _Not Ready_ state.
- Steps that have no conditions or prerequisite steps are set to the _Ready_ state.
Each time a step in the workflow is performed, all of the remaining _Ready_ and _Not Ready_ steps are
evaluated again, which means that their states can be revised. After a step is _Complete, Skipped_ , or _Failed_ ,
its conditional expression is no longer evaluated, and its state is not reset.

**52**   Workflow Editor task


```
Expression table actions
You can provide additional conditional logic for selecting the step state by specifying one of the following
options:
None
No additional logic is provided for selecting the step state. As a result, the step state is Not Ready until
the conditional expression in the Expression field is true.
Target State
This drop-down menu allows you to select a target state other than Ready when the expression
evaluates to true. The valid target states are Ready , Complete , and Skipped. The default target state is
Ready.
State Expression
As an alternative to setting Target State to a fixed value, you can define a conditional expression
that determines the target state. When you select this option, the Workflow Editor displays the State
Expression table so that you can add, modify, or remove a state expression for the step. You can add
up to 12 expressions for the step.
Extended Expression
Same as the State Expression option, except that you can specify a description for each conditional
expression. When you select this option, the Workflow Editor displays the Extended Expression table ,
so that you can add, modify, or remove an extended expression for the step. You can add up to 12
expressions for the step.
Table 12 on page 53 describes the actions that are available for the State Expression table and the
Extended Expression table.
```
_Table 12. Available actions for the State Expression table and the Extended Expression table._

**Action Description**

**Modify** To modify an expression, select one only one item in the table, and select **Modify**
from the table actions menu. When you do so, a window is displayed for you to
change the expression, target state, or both.
To complete the change, click **OK**. Otherwise, click **Cancel** to discard your changes.

**Remove** To remove one or more expressions from the table, select the items in the table
and select **Remove** from the table actions menu. You are prompted to confirm your
selection. To complete the change, click **OK**. Otherwise, click **Cancel** to discard
your changes.

**Add** To add an expression, select **Add** in the actions menu of the table. When you do so,
a window is displayed for you to enter the expression and its target state.
To complete the change, click **OK**. Otherwise, click **Cancel** to discard your changes.

**Select All** Select all of the rows in the table. This action is applicable for removing all of the
existing expressions from the table.

**Deselect All** Remove the selection of all currently selected rows in the table.

**Types of conditional expressions**

```
The following types of conditional expressions are supported:
```
- Expressions that use logical operators AND (&) and OR (|). For example:

```
${step1.returnCode} == "0000" || (${step2.returnCode}
== "0000" && ${step2.stepOwner} == “IBMUSER”)
```
- Expressions based on ternary operators. For example:

```
Workflow Editor task   53
```

```
condition? value_if_true : value_if_false
```
- Mathematical functions. For example:

```
Math.max(${step1.returnCode} , ${step2.returnCode} ) > 0
```
```
Example
Suppose that your workflow contains a step that depends on the successful completion of a job that was
by a previous step. For this workflow, you can do the following:
```
- Add a step ("Step1") that submits a job to run on z/OS. On job completion, the step uses the variable
    _step1.returnCode_ to store the job return code (a string value " _nnnn_ ").
- Add a step ("Step2") that contains a conditional expression that evaluates to true when
    _step1.returnCode_ equals string "0000".
Step2 remains in the _Not Ready_ state as long as variable _step1.returnCode_ equals something other than
"0000". Each time a step is performed in the workflow, z/OSMF reevaluates the conditions for the
remaining steps to determine whether any step target states have changed.
A design like this can be further expanded with additional conditions for selecting different target states
( _Ready_ , _Not Ready_ , _Skipped_ , _Failed_ , _Complete_ ) for other possible conditions.

**Design considerations for conditional steps**

```
Observe the following design considerations for conditional steps:
```
- A conditional step must be a leaf step (a step with no substeps). A parent step cannot be a conditional
    step.
- You can use the following step attributes in conditional expressions: <stepState> and
    <returnCode>.
- You can add up to 12 expressions for the step. The first condition that evaluates to true is used.
- Avoid specifying conflicting conditions.
For more step design considerations, see IBM z/OS Management Facility Programming Guide.

#### Security tab

```
The Security tab on the Step Details page displays information about the user identities, approvals, and
signatures that might be required for performing the step.
```
**Run this step as user ID**

```
If the step must be run under a specific user identity, the user ID is displayed in the field Run this step as
user ID. You can edit this field by replacing the current value, or entering a user ID, if the field is blank.
You are responsible for ensuring that the value you enter is a valid z/OS user ID. The Workflow Editor
checks the value for syntax, but it does not verify that the user ID is defined to the security management
product on your system.
For a workflow definition that originates from z/OS Management Services Catalog or IBM Cloud
Provisioning and Management for z/OS, the runAsUser steps support Variable substitution, and Approval
is required before a step can be performed.
If a workflow definition does not originate from z/OS Management Services Catalog or IBM Cloud
Provisioning and Management for z/OS includes runAsUser steps, a signature is required before a step
can be performed. For more information, see “Actions for the Signers table” on page 55. For more
```
**54**   Workflow Editor task


information about how to configure the workflow signing function, see the chapter Configuring the z/
OSMF workflow signing certificate of IBM z/OS Management Facility Configuration Guide.

**The Signers table and the Approvers table cannot be used together.**

**Variable substitution**

It is possible to use variable substitution for the user IDs on the **Security** tab. To do so, specify the
substitution string in the input field and select the option **User ID contains variable substitution**. When
the step is in the Ready state, the system performs the variable substitution to derive the actual user ID
for the step.

For example, to use variable substitution for a user ID, you might specify the following variable:

```
${instance-ADMIN-USERID}
```
A substitution variable follows this format:

- Dollar sign ($).
- Scope, which must be instance, not global.
- Hyphen (-).
- Variable name, for example, ADMIN-USERID.

In a workflow that is called by another workflow, the caller's instance variables can be shared with the
called workflow. Such variables are known as _caller scope variables_. Caller scope variables are eligible
for use with user ID substitution. For more information about caller scope variables, see IBM z/OS
Management Facility Programming Guide.

**Actions for the Signers table**

The Signers table only applies to a workflow definition that does not originate from z/OS Management
Services Catalog or IBM Cloud Provisioning and Management for z/OS.

Before a step can be performed, a signature may be required from another member of your I/T
organization. If signers are defined for a step, the signer user IDs are displayed in the Signers table
in the **Security** tab.

**The author of a workflow definition must ensure that general workflow information, step
information, and signer information are finalized before asking the signers to sign the steps.
Otherwise, the signatures may become invalid, and re-signing is required.**

In the Signers table, the signers user IDs are listed in the column Signer/Group ID. The column Signature
Status indicates the signature as _valid_ , _invalid_ or _no signature_.

If the signature is successful, the status shows “valid”.

The signature is invalid and “invalid” is displayed in the following cases:

1. The keylabel used for the signature cannot be found or has changed, meaning that the public and
    private keys are inconsistent with the signature, or the workflow signing certificate is expired.
2. General information for the workflow was modified.
3. Signature step data was modified, including the filetemplate content.
4. Properties of other steps (with the exception of signature properties) were modified, including the
    filetemplate content.

Using the Workflow Editor, you can add or delete signers for a step, or modify the list of signers. Table 13
on page 56 describes the actions that are available for the Signers table.

```
Workflow Editor task   55
```

```
Table 13. Available actions for the Signers table in the Security tab.
```
```
Action Description
```
```
Modify To modify a signer user ID, select one user ID in the table, and select Modify from
the table actions menu. When you do so, a window is displayed for you to change
the signer user ID.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Remove To remove a user ID from the table, select one or more user IDs in the table and
select Remove from the table actions menu. You are prompted to confirm your
selection. To complete the change, click OK. Otherwise, click Cancel to discard
your changes.
```
```
Unsign To remove a signature from the table, select one or more signers in the table and
select Unsign from the table actions menu.
```
```
Add To add signers, select Add in the actions menu of the table. When you do so, a
window is displayed for you to enter the user IDs of one or more signers. To enter
multiple user IDs, separate each entry with a blank.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
Note: There are a maximum of twelve signer records in Signers Table.
```
```
Sign Signing a step means that you agree to perform the step under the runAsUser
identity. To sign the step, select Sign from the table actions menu. Your signer
records can be signed at the same time.
If you click sign, the step is signed again, even if you have signed before.
```
```
Select All Select all of the rows in the table. This action is applicable for removing the existing
user IDs from the Signers table.
```
```
Deselect All Remove the selection of all currently selected rows in the Signers table.
```
```
Actions for the Approvers table
Before a step can be performed, approval might be required from another member of your I/T
organization. If approvals are defined for a step, the approver user IDs and group IDs are displayed
in the Approvers table in the Security tab.
User IDs must have a security profile with an OMVS segment and a UID assigned. Group IDs must have a
security profile with an OMVS segment and a GID assigned
In the Approvers table, the approver user IDs and group IDs are listed in the column User/Group ID. To
indicate whether substitution is used in the user ID, the column Substitution indicates true or false.
Using the Workflow Editor, you can add or delete approvers for a step, or modify the list of approvers.
Table 14 on page 56 describes the actions that are available for the Approvers table.
```
```
Table 14. Available actions for the Approvers table in the Security tab.
```
```
Action Description
```
```
Modify To modify an approver user ID or group ID, select one user ID or group ID in the
table, and select Modify from the table actions menu. When you do so, a window
is displayed for you to change the approver user ID or group ID. If appropriate,
indicate whether the user ID contains a substitution value.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
**56**   Workflow Editor task


```
Table 14. Available actions for the Approvers table in the Security tab. (continued)
```
```
Action Description
```
```
Remove To remove a user ID or group ID from the table, select one or more user IDs or
group IDs in the table and select Remove from the table actions menu. You are
prompted to confirm your selection. To complete the change, click OK. Otherwise,
click Cancel to discard your changes.
```
```
Add To add approvers, select Add in the actions menu of the table. When you do so,
a window is displayed for you to enter the user IDs or group IDs of one or more
approvers. To enter multiple user IDs or group IDs, separate each entry with a
blank. If any of the user IDs contain a substitution value, select the option User ID
contains variable substitution.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
```
```
Select All Select all of the rows in the table. This action is applicable for removing the existing
user IDs and group IDs from the Approvers table.
```
```
Deselect All Remove the selection of all currently selected rows in the Approvers table.
```
```
Add signer
You can add the user IDs for one or more signers on a workflow step. To add signers, select Add in the
actions menu of the table. When you do so, a window is displayed for you to enter the user IDs of one or
more signers.
Enter the user IDs for one or more signers. To enter multiple user IDs, separate each entry with a blank.
For multiple user IDs’ signer record, any user ID signature is acceptable for the step.
You are responsible for ensuring that the values you enter are valid z/OS user IDs or valid z/OS group IDs.
The Workflow Editor checks the value for syntax.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
Note: There is a maximum of twelve signer records in the Signer table.
```
```
Modify signer
You can modify the user IDs for one or more signers on a workflow step. To do so, select one user ID in
the table, and select Modify from the table actions menu. When you do so, a window is displayed for you
to change the signer user ID.
Modify the user IDs for one or more signers. To enter multiple user IDs, separate each entry with a blank.
For multiple user IDs’ signer record, any user ID signature is acceptable for the step.
You are responsible for ensuring that the values you enter are valid z/OS user IDs or valid z/OS group IDs.
The Workflow Editor checks the value for syntax.
To complete the change, click OK. Otherwise, click Cancel to discard your changes.
Note: There is a maximum of twelve signer records in the Signer table.
```
#### Step Variables tab

```
A step that submits a job can use one or more predefined variables, if any are set in the body of the job. If
so, the Step Variables tab lists the predefined variables.
In the Step Variables tab, the variables that are defined as references for the step are shown in the Input
Variables field. When you select a variable, the following fields are completed:
```
- Variable Name
- Scope

```
Workflow Editor task   57
```

- No prompt if Set
- Required.
If you want to modify the values for Variable Name and Scope, you can do so by using the **Variables** tab,
which is described in “Variables tab” on page 61.
You can select or deselect the options **No prompt If Set** and **Required**. If you select more than one
variable in the _Input Variables_ field, these options are disabled. To use these options, select one variable
only.
Table 15 on page 58 lists and describes the fields that are displayed in the **Step Variables** tab.

```
Table 15. Fields in the Step Variables tab
```
```
Column Description
```
```
Input Variables Displays the variables that are currently defined for the step.
```
```
Variable Name Name of the variable.
If you want to modify the variable name, you can do so by using the Variables tab,
which is described in “Variables tab” on page 61.
```
```
Scope Scope of the referenced variable; either instance or global.
If you want to modify the variable scope, you can do so by using the Variables tab,
which is described in “Variables tab” on page 61.
```
```
No Prompt if Set Indicates whether the variable is displayed in read-only mode, if the variable
already has a value. This field is an optional, Boolean value. If not specified, the
default is false , that is, always display the variable in read/write mode.
```
```
Required Indicates whether the variable must have a value for this step. The required
attribute is an optional, Boolean value. If not specified, the default is false. When
set to true , the Workflows task does not allow the user to complete the step
without providing a value (if a default is not defined in the XML).
```
```
To add or remove the step variables for the step, click Add/Remove. Doing so displays a window that you
can use to add step variables from the workflow definition file or a related XML file, if one is referenced in
the workflow definition file. You can move variables to the right to add them as step variable references
and move them to the left to remove them. With this action, you can also remove step variables from the
step.
When you click OK, the list of step variables on the tab is updated.
```
```
Set instance variables on step completion
It is possible to preset the values for the instance variables that are referenced in this step. If so, the
variables assume the values on completion of the step. Such variables are referred to as set variables.
The Set Variable table shows the variable references for the step. You can use this table to preset values
for the variables. You can also add more variable references to the step, and set values for them. However,
you cannot remove variable references from the step by using this table.
To add more variable references for the step, click the Add table action. Doing so displays a list of
instance variables that can be preset for the step. Ensure that any variables that you select are valid for
use in the step. The Workflow Editor performs no validity checking for the specified variable to verify that
it conforms to its defined constraints. For example, the Workflow Editor does check a string variable to
ensure that it does not exceed its maximum length.
It is possible to use variable substitution in the Set Variable field. To do so, specify the substitution string
in the Value field and select the option Value uses substitution.
Similarly, you can modify the variables in the Set Variable table by using the Modify table action.
```
**58**   Workflow Editor task


#### Step Feedback tab

```
The Feedback tab on the Step Details page displays the feedback questions for the step owner to
answer. On this tab, you can add or remove feedback questions for the step, based on the list of questions
that are defined for the workflow.
Including feedback questions is optional. Answering the questions can be optional or required, as
determined by you, the workflow author.
The Feedback tab is disabled for parent steps.
```
```
Adding or removing a feedback question
You can select questions for users to answer after they perform this step.
```
**Before you begin**

```
The Step Feedback table displays the currently defined feedback questions for the step. If no questions
are defined, the table is empty.
```
**Procedure**

1. From the **Actions** menu, select **Add**.
    The **Add Step Feedback** window is displayed.
    If you attempt to add a question when all of the currently defined feedback questions are added to this
    step, a message is displayed.
    Notice that you can remove a question by using the **Remove** action.
2. From the **Question name** menu, select a question to add.
3. To indicate that the user must supply an answer to the question, select **Required**.
    Notice that you can modify this option by using the **Modify** action.
4. Click **OK** to add the question to the Step Feedback table.
5. Continue adding or removing questions until you are done.
6. Click **Save** to save the contents of the Step Feedback table.

```
Results
The selected questions are available for use in the step.
In the Workflows task, the step owner selects a step and selects the table action Feedback. Only the
step owner can display the feedback page for a step. The feedback page is disabled for steps that do not
contain feedback questions and for users other than the step owner.
Related reference
Workflow feedback tab
On the workflow Feedback tab, you can create questions for step owners to answer. Such feedback might
be useful to you, for example, in determining the effectiveness of a workflow design, or for collecting user
requirements for future enhancements to a workflow.
```
#### Advanced tab

```
z/OSMF includes advanced settings that can affect the behavior of a workflow.
In most cases, you should not need to specify these settings. However, in some situations you might be
asked by the workflow provider to specify an advanced setting. To do so, use the Advanced Settings for
this Step tab on the Step Details page.
```
```
Workflow Editor task   59
```

```
Automation Settings
An automated workflow contains one or more steps that can be performed without the need for user
interaction, such as a job that can be submitted without user input. Typically, the Workflows task runs
these steps automatically, as soon as any prerequisite steps in the workflow are completed. As the
workflow author, you can force automation to stop before a particular step is run. You might do so, for
example, to allow the user to perform a particular action outside of the workflow before the user returns
to the workflow.
To force a stop in the sequence of automated steps, select the option Suspend automation processing
when this step is reached. As the result, the step is suspended ; it must be performed manually by the
step owner.
When processing reaches this step, which requires user interaction before the workflow can continue,
z/OSMF creates a notification for the step owner to prompt for action. In z/OSMF, users can access
notifications through the Notifications task.
If you select the option Suspend automation processing when this step is reached , the Advanced tab
expands to display the email settings that you can use to tailor the notification that is sent to the step
owner. Table 16 on page 60 describes these settings.
```
```
Table 16. Information to specify for notifying a user about a suspended step.
```
```
Field Description
```
```
Email recipients Enter the email address for the user to be notified of the suspended step. To
specify more than one recipient, enter each address, separated by commas or
spaces.
It is possible to use variable substitution in this field. To do so, specify the
substitution string in the field and select the option Email recipients contains
variable substitution.
```
```
Email subject Enter a brief, meaningful subject for the notification email. If you leave this field
empty, the email subject is set to no subject by default.
It is possible to use variable substitution in this field. To do so, specify the
substitution string in the field and select the option Email subject contains
variable substitution.
```
```
Email content Enter the text of the message that you want to send to the recipient. If you leave
this field empty, the email content is set to no content by default.
It is possible to use variable substitution in this field. To do so, specify the
substitution string in the field and select the option Email content contains
variable substitution.
```
```
Note: The ability to suspend step processing is mutually exclusive with the ability to run steps in parallel.
Therefore, if you select the Suspend option for any steps, you cannot also specify the Contains parallel
steps option in the Metadata tab.
Related reference
Metadata tab
```
**60**   Workflow Editor task


```
The Workflow Editor task opens with the Metadata tab in focus. On this tab, you can view and edit the
workflow metadata.
```
### Variables tab

```
In a workflow, a variable can be specified for any property that accepts variable substitution. From the
Variables tab, you can launch actions to view, create, and modify the variables in the selected workflow
definition.
In the Variables tab, the Variables table displays the variables in the selected workflow definition.
Variables are sorted alphabetically by name, with casing (upper and lower) used to further sort names.
Variable names with uppercase letters are displayed before variable names with lowercase letters.
To view or edit the properties of a variable, select the variable in the table. You can select one variable
only. The format and content of the Variables table is described in “Variables table” on page 61.
When you select a variable, notice that the Workflow Editor opens an accordion area that is called
Variable Details to the right of the table. You can use the Variable Details area to view and modify the
properties of a variable, including its name, scope, description, and other properties. This area contains
the properties that are described in “Workflow Variables tab” on page 67.
The Variable Details area overlays another area that is called Step Details. This area is active when the
Workflow Editor is used to edit a step. Otherwise, its fields are blank.
```
```
Variables table
For a description of the columns in the Workflow Editor Variables table, see Table 17 on page 61. For a
description of the actions that you can take for variables, see Table 18 on page 61 and Table 19 on page
62.
To sort the table based on the values in one or more columns, click the column header for the columns
you want to sort. If a sort is defined for a column, the ascending (▴) or descending (▾) sort icon is shown in
the column header. To remove all the sorting from the table, select Clear Sorts from the Actions menu.
```
```
Table 17. Columns in the Workflow Editor Variables table
```
```
Column Description
```
```
Variable Name Name of the variable. By default, this column is the sort column, and the sort is
ascending.
```
```
Scope Variable scope, which is either instance or global.
```
```
Category Name of the logical grouping to which this variable belongs. The default is General.
```
```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.

```
Table 18. Targeted actions for the Workflow Editor Variables table
```
```
Action Description
```
```
Create Variable Display the Create a New Variable window so that you can define a new variable
for the workflow. For more information, see “Create a new variable” on page 62.
```
```
Create Multiple Variables Display the Create Multiple Variables window so that you can define a number
of variables at one time. For more information, see “Create multiple variables” on
page 64.
```
```
Workflow Editor task   61
```

```
Table 18. Targeted actions for the Workflow Editor Variables table (continued)
```
```
Action Description
```
```
Copy Variable Display the Copy Variable window so that you can create a copy of the selected
variable. For more information, see “Copy a variable” on page 66.
```
```
Delete Delete the selected variable from the workflow definition. You are prompted
to confirm your decision. This action removes the variable from the workflow
permanently. You are responsible for manually removing any other references to
this variable where it used.
```
```
Table 19. Table actions for the Workflow Editor Variables table
```
```
Action Description
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
```
Related information
For more information about creating variables, see the topic Creating workflow definitions for z/OS in IBM
z/OS Management Facility Programming Guide.
```
#### Create a new variable

```
You can add your own variables to a workflow. To do so, use the Create Variable action that is provided
in the Variables table. You can use this window to enhance a workflow with variables that you design
specifically for your installation.
```
**Procedure**

1. In the **Variables** table, click **Create Variable**.
2. Enter the general information:
    a) In the **Variable Name** field, specify a name for the variable.
       The name is required, and must be a string of letters (uppercase or lowercase), numeric digits,
       the hyphen, and the underscore character. This value must begin with a letter. The combination of
       name and scope must be unique within the workflow.
b) In the **Scope** field, specify a scope for the variable.
The scope is required, and the value must be _instance_ or _global_. The default is _instance_. The
combination of name and scope must be unique within the workflow.
    c) In the **Label** field, provide a short label for the variable, as it should appear in the Workflows task.
       This value is required.
d) In the **Abstract** field, provide a brief description of the variable, as it should appear in the
Workflows task.
This value is required.
    e) In the **Description** field, provide a longer explanation of what the variable is used for, and perhaps
       what the syntactic requirements are.
       This value is required.
f) In the **Category** field, indicate the name of the logical grouping to which this variable belongs:
_general_ , _variables_ , or _REST_.
The default is _general_.

**62**   Workflow Editor task


```
General is always included as an option in the menu. However, you can enter a new category of your
choosing. Any previously created categories appear as options in the menu.
g) In the Visibility field, indicate whether the variable is displayed to the Workflows task user (either
public or private ).
This value is optional.
h) In the Type field, select the variable type.
This value is required.
The following variable types are supported:
```
- Array
- Boolean
- Date
- Decimal
- Integer
- Password
- String
- Time
3. To have the Workflows task prompt the user to set the variable during the create workflow process,
select **Prompt At Create**.
By default, this option is not selected.
4. To require that the variable is set during the workflow create process, select **Required At Create**.
By default, this option is not selected.
5. Click **Next** , if this option is enabled, to specify further values for the variable.
Depending on the variable type, the **Workflow Variables** tab displays more information about the
variable. The additional fields are described in the following topics:
- “Details about the array variable type” on page 70
- “Details about the Boolean variable type” on page 70
- “Details about the date variable type” on page 70
- “Details about the decimal variable type” on page 71
- “Details about the integer variable type” on page 71
- “Details about the password variable type” on page 71
- “Details about the string variable type” on page 72
- “Details about the time variable type” on page 73
6. Click **Finish** to add the variable definition to the workflow.

**Results**

The **Variables** table is displayed, showing the new variable. In the table, variables are sorted
alphabetically by name, with casing (upper and lower) used to further sort names. Variable names with
uppercase letters are displayed before variable names with lowercase letters.

**What to do next**

If you later decide to remove a previously added variable, you can do so by using the **Delete** action in the
Variables table.

```
Workflow Editor task   63
```

#### Create multiple variables

```
You can create a number of variables at one time. To do so, use the Create Multiple Variables action that
is provided in the Variables table.
```
**About this task**

```
In the Create Variables table, define one variable per row. Enter a value for each of the required
properties: Name , scope , label , abstract , description , category , and type. Add more rows, as needed.
You can define a maximum of 1500 variables for a workflow. When you are done, click Finish to save the
variables and make them available for use in the workflow steps.
For a description of the columns in the Create Variables table, see Table 20 on page 64. For a description
of the actions that you can take for variables, see Table 21 on page 64 and Table 22 on page 65.
To sort the table based on the values in one or more columns, click the column header for the columns
you want to sort. If a sort is defined for a column, the ascending (▴) or descending (▾) sort icon is shown in
the column header. To remove all the sorting from the table, select Clear Sorts from the Actions menu.
```
```
Table 20. Columns in the Create Variables table
```
```
Column Description
```
```
Name Name of the variable.
```
```
Scope Variable scope, which is either instance or global.
```
```
Label A short label for the variable.
```
```
Abstract A brief description of the variable.
```
```
Description A longer explanation of what the variable is used for. Also, the syntax
requirements, if any, for coding the variable.
```
```
Category Name of the logical grouping to which this variable belongs. The default is General.
```
```
Type Type of variable, which is one of the following values:
```
- Array
- Boolean
- Date
- Decimal
- Integer
- Password
- String
- Time

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.

```
Table 21. Targeted actions for the Create Variables table
```
```
Action Description
```
```
Remove Row Remove the selected row from the table. You can select multiple rows.
```
**64**   Workflow Editor task


_Table 21. Targeted actions for the Create Variables table (continued)_

**Action Description**

**Repeat Row** Repeat the selected row. This option is enabled when only one row is selected.

```
This action displays the Repeat Rows window, which you can use to replicate a
particular variable a number of times. You can define a maximum of 1500 variables
for a workflow.
A row can be repeated when valid values have been specified for all of the required
fields. Otherwise, the Workflow Editor displays an error message to prompt you for
the missing values. Note that each variable name must be unique.
When you are done, click Finish to save the variables and make them available for
use in the workflow steps.
```
**Add Row** Add one row to the end of the table.

_Table 22. Table actions for the Create Variables table_

**Action Description**

**Select All** Select all of the rows in the table. This action is applicable for removing all of the
existing expressions from the table.

**Deselect All** Remove the selection of all currently selected rows in the table.

**Clear Sorts** Clear the sort from all of the columns in the table.

**Procedure**

1. In the Variables table actions menu, click **Create Multiple Variable**.
    The **Create Multiple Variables** window is displayed.
2. In the Create Variables table, enter the general information:
    a) In the **Name** field, specify a name for the variable.
       The name is required, and must be a string that consists of letters (uppercase or lowercase),
       numeric digits, the hyphen, and the underscore character. This value must begin with a letter. The
       variable name must be unique within the workflow.
b) In the **Scope** field, specify a scope for the variable.
The scope is required, and the value must be _instance_ or _global_. The default is _instance_.
    c) In the **Label** field, provide a short label for the variable, as it should appear in the Workflows task.
       This value is required.
d) In the **Abstract** field, provide a brief description of the variable, as it should appear in the
Workflows task.
This value is required.
    e) In the **Description** field, provide a longer explanation of what the variable is used for, and perhaps
       what the syntactic requirements are.
       This value is required.
f) In the **Category** field, indicate the name of the logical grouping to which this variable belongs:
_General_ , _Variables_ , or _REST_.
The default is _General_.
General is always included as an option in the menu. However, you can enter a new category of your
choosing. Any previously created categories are displayed as options in the menu.
    g) In the **Type** field, select the variable type.
       This value is required.

```
Workflow Editor task   65
```

```
The following variable types are supported:
```
- Array
- Boolean
- Date
- Decimal
- Integer
- Password
- String
- Time
3. To add another variable definition, click the **Add Row** table action.
4. To remove a variable from the table, select the variable and click **Remove Row** table action.
5. When you are finished creating variable definitions, click **Finish** to add the variables to the workflow.

```
Results
The Variables table is displayed, showing the new variables.
```
**What to do next**

```
To further customize the variables, use the Variable Details area for each variable, where you can add
more properties or change these initial settings.
If you later decide to remove a previously added variable, you can do so by using the Delete action in the
Variables table.
```
#### Copy a variable

```
To copy a variable, use the Copy Variable action that is provided in the Variables table. Doing so opens a
window that you can use to create a copy of the selected variable.
```
**About this task**

```
If an existing variable is similar to one that you want to create, use the Copy Variable action to create a
new variable based on the existing one. When you copy a variable, you create a new variable with all of
the properties of the copied variable, except for the variable name and scope, which you must specify. The
combination of variable name and scope must be unique within the workflow.
```
**Procedure**

1. In the Variables table, select the variable that you want to copy.
    Select one variable only.
2. In the Variables table actions, click **Copy Variable**.
3. In the **Variable Name** field, specify a unique name for the variable.
    This value is required.
4. In the **Scope** menu, select a scope for the variable.
    The scope is required, and the value must be _instance_ or _global_. The default is _instance_.
5. Click **OK** to add the variable to the workflow.

**Results**

```
The Variables table is displayed, showing the new variable.
```
**66**   Workflow Editor task


```
What to do next
In the Variable Details area, you can view or modify the properties for the new variable.
If you later decide to remove a previously added variable, you can do so by using the Delete action in the
Variables table.
```
#### Workflow Variables tab

```
You can use the Workflow Variables tab on the Variables Details page to view and modify the variable
name, scope, description, and other properties of the selected variable.
Table 23 on page 68 lists and describes the fields that are displayed in the Workflow Variables tab.
```
```
Workflow Editor task   67
```

```
Table 23. Fields in the Workflow Variables tab
```
```
Column Description
```
```
Variable Name Name of the variable. This value is required.
If you change the variable name in this field, the Workflow Editor searches the
workflow definition for references to the old variable name. The Workflow Editor
applies the name change throughout the workflow definition, wherever variable
substitution is allowed.
Specifically, the Workflow Editor finds and updates the variable name in:
```
- Step variables.
- Conditional expressions.
- Instructions text.
- Inline template step properties that accept variable substitution:
    - Location for saving the template as a data set or UNIX file
    - Location for output properties
- Name of the TSO/E logon procedure
- Contents of the inline template.
- RunAsUser user IDs and approver user IDs.
- Set variables.
- Email properties (recipients, subject, and content).
- REST API properties that accept variable substitution:
    - Host name
    - Port number
    - User name
    - Password
    - URI path
    - Query parameters
    - Request header
    - Request body
    - Certificates.
- Calling steps (mapping variables).
- Feedback questions.
The Workflow Editor does not update a variable name when it is used:
- Outside of the workflow definition, such as in an external file that is referenced
    by a file template step.
- In the path name of a file template.
- As a filter in a regular expression.
You are responsible for finding and updating these references, if applicable.
If you select to change the name of a variable, you are prompted to confirm your
decision.

**68**   Workflow Editor task


_Table 23. Fields in the Workflow Variables tab (continued)_

**Column Description**

**Scope** Scope of the referenced variable; either _instance_ or _global_.

```
If you change the scope of a variable from instance to global, understand that in
some situations, a global variable cannot be used in place of an instance variable.
When the scope of a variable is changed from instance to global, the Workflow
Editor searches the workflow definition for steps that refer to the variable. In
places where a global variable cannot be used, the Workflow Editor removes the
variable reference from the step.
For example, a global variable cannot be used as follows:
```
- As a set variable
- In a REST step, to represent the actual status code or in a property mapping.
The Workflow Editor removes the variable references in these cases.
If you select to change the scope of a variable from instance to global, you are
prompted to confirm your decision.

**Label** A short label for the variable. This value is required.

**Abstract** A brief description of the variable. This value is required.

**Description** A longer explanation of what the variable is used for. Also, the syntax
requirements, if any, for coding the variable. This value is required.

**Category** The name of the logical grouping to which this variable belongs. The default is
_General_.
The following values are valid:

- General
- Times and dates
- Boolean variable
- Identity related
- Numeric variables
- Network
- Allowable characters
- String variables
- Data set related

**Expose To User** Indicates whether the variable is displayed to the user when the user is modifying
a JOB statement in the Workflows task.

**Read Only At** Indicates whether the variable is read-only ( _true_ or _false_ ).

```
The option Check to use substitution indicates whether variable substitution is
used in this field.
```
**Required At Create** To indicate that a value must be specified for the variable during the create
workflow process, select this option.

**Prompt At Create** To indicate that the user must be prompted to specify a value for the variable
during the create workflow process, select this option.

**Visibility** Indicates whether the variable is publicly accessible. The valid values are public or
private. The default is _private_.

```
Workflow Editor task   69
```

```
Table 23. Fields in the Workflow Variables tab (continued)
```
```
Column Description
```
```
Type Type of variable, which is one of the following values:
```
- Array
- Boolean
- Date
- Decimal
- Integer
- Password
- String
- Time
Depending on the variable type, the **Workflow Variables** tab displays more
information about the variable. The additional fields are described in the sections
that follow:
- “Details about the array variable type” on page 70
- “Details about the Boolean variable type” on page 70
- “Details about the date variable type” on page 70
- “Details about the decimal variable type” on page 71
- “Details about the integer variable type” on page 71
- “Details about the password variable type” on page 71
- “Details about the string variable type” on page 72
- “Details about the time variable type” on page 73

```
Default Value Default value of the variable.
This field is not displayed (or valid) for a password variable.
```
```
Details about the array variable type
When you need to map a set of multiple values, consider using an array variable.
When you specify the array variable type, the Workflow Editor creates the variable using the values that
you specify for variable name, scope, label, abstract, and description, plus the optional values. However,
you cannot use the Workflow Editor to set values for an array variable. Instead, use a workflow variable
input file, if you need to set the values for an array variable.
As with other types of variables, you can use variable substitution for the values in an array variable.
```
**Details about the Boolean variable type**

```
For a Boolean variable, the Workflow Variables tab indicates the current value of the variable, as true or
false.
```
**Details about the date variable type**

```
Depending on the variable type, the Workflow Variables tab displays more information about the
variable. For a date variable, the following fields are provided:
Minimum Value
Minimum value. This value is optional. If specified, its value must be a date in yyyy-mm-dd format. If
the maximum value is specified, the maximum value must be greater than the minimum value.
```
**70**   Workflow Editor task


**Maximum Value**
Maximum value. This value is optional. If specified, its value must be a date in _yyyy-mm-dd_ format. If
the minimum value is specified, the maximum value must be greater than the minimum value.

**Default Value**
Default value for the variable. This value is optional. If specified, the default value must be a date in
_yyyy-mm-dd_ format and must adhere to any minimum value and maximum value that is specified.

**Details about the decimal variable type**

Depending on the variable type, the **Workflow Variables** tab displays more information about the
variable. For a decimal variable, the following fields are provided:

**Minimum Value**
Minimum value. This value is optional. If specified, its value must be a decimal. If the maximum value
is specified, the maximum value must be greater than the minimum value.

**Maximum Value**
Maximum value. This value is optional. If specified, its value must be a decimal. If the minimum value
is specified, the maximum value must be greater than the minimum value.

**Default Value**
Default value for the variable. This value is optional. If specified, the default value must be a decimal
that adheres to any minimum value and maximum value that is specified. Decimal places are rounded
by the Workflows task, based on the number of decimal places setting.

**Number of Decimal Places**
Maximum number of decimal places that can be specified. The value can be an integer in the range of
1—6. The default is 1.

**Details about the integer variable type**

Depending on the variable type, the **Workflow Variables** tab displays more information about the
variable. For an integer variable, the following fields are provided:

**Minimum Value**
Minimum value. This value is optional. If specified, its value must be an integer. If the maximum value
is specified, the maximum value must be greater than the minimum value.

**Maximum Value**
Maximum value. This value is optional. If specified, its value must be an integer. If the minimum value
is specified, the maximum value must be greater than the minimum value.

**Default Value**
Default value for the variable. This value is optional. If specified, the default value must be an integer
that adheres to any minimum value and maximum value that is specified.

**Details about the password variable type**

By defining a password variable, you can add a password prompt to your workflow. If you do so, the user
is prompted to provide a password on the **Input Variables** tab of the Workflows task.

You must specify a type of validation checking for a password variable. The Workflows task can validate
the input value for compliance with either of the following rules:

- Minimum and maximum length
- Match with a regular expression.

The password variable type has no default value.

For a password variable, the following fields are provided:

**Minimum Value**
Minimum value. This value is optional. If specified, its value must be a non-negative integer. If the
maximum length is specified, the maximum length must be greater than the minimum length.

```
Workflow Editor task   71
```

```
The minimum length and maximum length combination mutually excludes the regular expression
setting.
Maximum Value
Maximum value. This value is optional. If specified, its value must be a non-negative integer. If the
minimum value is specified, the maximum value must be greater than the minimum value.
The minimum length and maximum length combination mutually excludes the regular expression
setting.
Regular Expression
Standard regular expression that constrains the variable value. This value is optional.
The regular expression value mutually excludes the minimum length and maximum length
combination.
Error Message
Error message to be displayed if the user enters an incorrect value for the password. This value is
optional.
```
```
Details about the string variable type
For a string variable, the Workflow Variables tab includes the fields and indicators that are described in
Table 24 on page 72.
```
```
Table 24. Fields and indicators in the Workflow Variables tab for string variables
```
```
Option Description
```
```
Check for Multi-line Indicates whether a multi-line text box is required for the variable. This option is
optional; if unspecified, its value is false by default.
```
```
Value Choices Specifies one or more possible choices for the variable value. You can enter up
to 1337 value choices. Each choice must adhere to the validation type, if one is
specified in the Validation Options field, and to any regular expression, minimum
length, and maximum length that is specified.
To add or remove user-selectable choices, click Add Choice or Remove Choice , as
needed. To set a particular choice as the default, select the choice and click Set
Default.
To restrict the user's selection to one of the provided choices, select the option
Value Must be a Choice. Otherwise, the user can enter any syntactically valid
string for the variable value, including a string that is not included in the Variable
Choices field. If the Value Choice field is empty (no choices are predefined), the
option Value Must be a Choice is disabled.
```
```
Validation Options Validation types. This value is optional. If specified, it must have one of the
following values: ALPHA, ALPHAB, ALPHANUM, BIT, DSMEMBERNAME, DSNAME,
DSQUAL, GROUP, HEX, IPADDR, IPADDR4, IPADDR6, TSOUSERID, UNIXID,
USERID, VOLSER.
The validation value mutually excludes the minimum length and maximum length
combination and the regular expression value.
The UNIXID validation type verifies that a z/OS UNIX UID or GID is in the range 0 –
```
2147483647. Here, a UID or GID is treated as a string, not an integer. If you have
code that treats a UID or GID as numeric, use an integer type to define the variable,
instead of a string validation type. You can enforce the minimum and maximum
values within the integer variable definition.

**72**   Workflow Editor task


```
Table 24. Fields and indicators in the Workflow Variables tab for string variables (continued)
```
```
Option Description
```
```
Regular Expression Standard regular expression that constrains the variable value. This value is
optional.
The regular expression value mutually excludes the minimum length and maximum
length combination and the validation setting.
```
```
Minimum Length Minimum string length. This value is optional. If specified, its value must be a
non-negative integer. If the maximum length is specified, the maximum length
must be greater than the minimum length.
The minimum length and maximum length combination mutually excludes the
validation and regular expression settings.
```
```
Maximum Length Maximum string length. This value is optional. If specified, its value must be a
non-negative integer. If the minimum length is specified, the maximum length
must be greater than the minimum length.
The minimum length and maximum length combination mutually excludes the
validation and regular expression settings.
```
```
Details about the time variable type
Depending on the variable type, the Workflow Variables tab displays more information about the
variable. For a time variable, the following fields are provided:
Minimum Value
Minimum value. This value is optional. If specified, its value must be a time in hh:mm:ss format.
If the maximum value is specified, the maximum value must be greater than the minimum value.
Maximum Value
Maximum value. This value is optional. If specified, its value must be a time in hh:mm:ss format. If the
minimum value is specified, the maximum value must be greater than the minimum value.
Default Value
Default value for the variable. This value is optional. If specified, the default value must be a time in
hh:mm:ss format. If the minimum value is specified, the maximum value must be greater than the
minimum value.
```
### Workflow feedback tab

```
On the workflow Feedback tab, you can create questions for step owners to answer. Such feedback might
be useful to you, for example, in determining the effectiveness of a workflow design, or for collecting user
requirements for future enhancements to a workflow.
You might notice that the Workflow Editor user interface includes a Feedback tab at both the workflow
level and the step level. You use both tabs in conjunction. Use this tab—the workflow Feedback tab—to
define a set of questions that can be included for the steps in your workflow. Then, as you define steps
elsewhere in the Workflow Editor, you can select to include one or more of the questions in the step
Feedback tab.
```
**Feedback Questions table**

```
The Feedback Questions table displays the currently defined feedback questions for the workflow. If no
questions are defined, the table is empty.
For a description of the columns in the Feedback Questions table, see Table 25 on page 74. For a
description of the actions that you can take for feedback questions, see Table 26 on page 74 and Table
27 on page 74.
```
```
Workflow Editor task   73
```

```
Table 25. Columns in the Feedback Questions table.
```
```
Column Description
```
```
Question Name Name of the question. The question name must be unique across the entire
workflow. It is used by steps in the workflow to refer to the question.
```
```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Table actions. Actions that apply to the entire table. No selection of table items is required.
- Add Question action. Displays the **Add Question** window so that you can define a new feedback
    question for the workflow. For information, see “Adding or removing a feedback question” on page 59.

```
Table 26. Targeted actions for the Feedback Questions table.
```
```
Action Description
```
```
Remove Remove the selected question from the Feedback Questions table. This action
also removes the question from any steps in the workflow that might refer to the
question.
You can select one question only.
This change is permanent; you are prompted to confirm this action before it is
taken.
```
```
Add Display the Add Question window so that you can define a new feedback question
for the workflow. For information, see “Adding or removing a feedback question” on
page 59.
```
```
Table 27. Table actions for the Feedback Questions table.
```
```
Action Description
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
```
Sample questions and answer types
Some examples of feedback questions and answer types follow.
```
```
Table 28. Sample feedback questions that you might use.
```
```
Question Answer type Possible Answers
```
```
How difficult was this step? Choose
one of the following:
```
```
Single select. Very difficult, Difficult, Moderate, Easy, Very
easy.
```
```
What did you like about this step?
Choose all that apply:
```
```
Multiple select. Ease of use, Instructions were helpful,
Performed a useful function, Ran quickly.
```
```
How would you describe your
experience with this step? Enter a text
response of 1 to 500 characters.
```
```
Text Write-in response from the user.
```
**74**   Workflow Editor task


```
How feedback is collected from workflow users
At the completion of the workflow, the workflow owner is responsible for collecting the feedback on
the Generate Feedback Summary page of the Workflows task. When the step owners have provided
the required feedback, the workflow owner can save the accumulated feedback into a feedback file and
download it to a workstation for further evaluation.
For a workflow that includes feedback questions, the workflow owner is responsible for collecting the
feedback. In the Workflows task, the workflow owner can select Feedback to launch actions that
are related to feedback. The workflow owner can display pages to see which steps require feedback,
which steps have incomplete feedback, and options for notifying the step owners who need to complete
feedback.
To answer feedback for a step, the step owner selects a step and selects the table action Feedback. Only
the step owner can display the feedback page for a step. The Feedback action is disabled for steps that do
not contain feedback questions and for users other than the step owner.
When all of the required feedback is provided by step owners, the workflow owner can save the
accumulated feedback into a feedback file. In the Workflows task, on the Generate Feedback Summary
page, the workflow owner can create a report of the feedback and download it to a workstation for review.
Related tasks
Adding or removing a feedback question
You can select questions for users to answer after they perform this step.
```
#### Creating feedback questions for your workflow

```
You can create questions for users to answer as they perform the steps in your workflow.
```
```
Before you begin
The Feedback Questions table displays the currently defined feedback questions for the workflow. If no
questions are defined, the table is empty.
```
**Procedure**

1. From the **Actions** menu, select **Add**.
    The **Add Question** window is displayed.
    Notice that you can remove a question by using the **Remove** action.
2. In the field _Question name_ , enter a unique name for the question.
    This value is required.
    For example: Question1
3. In the field _Question_ , enter a question for the user to answer.
    This value is required.
    Examples:

```
How difficult was this step?
What did you like about this step?
How would you describe your experience with this step?
```
4. You can include a substituted value (a variable) in the question. If you do so, select the option
    **Question contains variable substitution** so that the variables are processed correctly.
    This selection is optional.
5. Click **OK** to add the question to the Feedback Questions table.
    Notice that an area to the right of the Feedback Questions table is displayed to show the information
    that you entered. Also displayed is the **Answer type** menu.
6. In the **Answer type** menu, select the expected format of the user's answer, as follows:

```
Workflow Editor task   75
```

- To require a write-in response, select _Text_ , which is the default. The user can enter a text response
    (up to 500 characters).
- To limit the answer to one choice, select _Single select_. If so, the user must select one (and only one)
    answer from the available choices.
- To allow more than one answer to be selected from the available choices, select _Multiple select_. If
    so, the user can select more than one of the available choices.
7. For a single select or multiple select answer, include the following information, which is needed to
define the set of valid answers:
a) To allow the user to choose "Other" as a response when none of the available choices is correct,
select the option **User can choose other as a valid response to the question**.
b) In the Possible Answers table, from the **Actions** menu, select **Add**.
The **Add Answer** window is displayed.
Notice that you can modify or remove a question by using the **Modify** or **Remove** actions.
c) In the field _Answer text_ , enter the text of a possible answer.
For example, if your question asks the user to indicate the difficulty of performing the step, a
possible answer might be a descriptive term, such as _easy_ , _moderate_ , or _difficult_.
d) In the field _Value Associated with the Answer_ , assign a meaningful value to the answer.
This value is required.
The value is used for collecting the user feedback for the workflow. Consider assigning it a
numerical value that corresponds to the answer.
For example, if your question asks the user to indicate the relative difficulty of performing the step,
you might use this field to assign a numerical value to the answer, such as 1 for an easy step to
10 for a difficult step. Later, when feedback is collected for the workflow, answers like this can be
averaged together by the workflow owner to produce a rating.
e) Continue defining answers until you are done.
The answers are added to the Possible Answers table.
Notice that you can modify an answer by using the **Modify** action.
8. Continue defining questions until you are done.
9. Click **Save** to save the contents of the Feedback Questions table.

```
Results
The questions that you define in the Feedback Questions table are available for use in the workflow. You
can select to include one or more of these questions in the Step Feedback tab for the individual steps in
your workflow.
Similarly, if you remove a feedback question from the Feedback Questions table, the question is removed
from all of the workflow steps that might reference the question. That is, the removed feedback question
is no longer included in the Step Feedback tab for the individual steps in your workflow.
```
### Input Properties tab

```
On the Workflow Editor task main page, you can select the Input Properties tab to display the contents
of the workflow variable input file, if you specified one on the Edit Workflow Definition dialog. From
the Input Properties tab, you can edit the input properties to add, delete, or modify the variable input
properties for the workflow.
The workflow variable input file is used to supply default values for one or more of the input variables that
are defined in the workflow definition file. By including an input file with the workflow definition file, the
workflow author saves users from having to manually enter values for some or all of the variables in the
workflow and reduces the opportunities for user error.
The contents of the workflow variable input file consists of one or more name-value pairs, each of which
defines an input property for the workflow. You can add or modify properties, or delete them. When
```
**76**   Workflow Editor task


saved, your changes are available for use with the selected workflow and the other workflows at your
installation.

**Actions for the Input Properties tab**

The **Input Properties** tab shows the name of the selected workflow variable input file. You specified this
value when you opened the Workflow Editor task, and optionally specified the workflow variable input file
for editing.

The contents of the workflow variable input file are shown in the field called _File Content_. The values
are displayed in edit mode so that you can modify them. Type your changes into the input area. Specify
the properties (the variables and their respective values) as one or more key-value pairs. Valid separator
characters are equal signs (=), colons (:) or blanks.

```
Workflow Editor task   77
```

## Index

**B**

banner area 4

**E**

editor 1
editor layout 4, 8

**H**

hiding the navigation area 4, 8

**I**

Input Properties tab 76

**L**

login section 4, 8

**M**

metadata 14

**N**

navigation area 4, 8

**S**

Steps tab 17

**T**

task section 4, 8
taskbar 4, 8
terms 2

**V**

Variables tab 61

**W**

work area 4, 8
workflow 1
workflow editor 1
Workflow Editor task 1, 12
workflow metadata 14

**78**   Workflow Editor task



IBM®


**Cloud Provisioning**

```
This section, when the appropriate plug-ins are installed, describes the z/OSMF tasks that you can use
to perform software provisioning for IBM Cloud Provisioning and Management for z/OS. This includes
creating instances of z/OS or IBM® middleware, such as IBM CICS® (CICS), IBM Db2®, IBM Information
Management System (IMS), IBM MQ, z/OS Connect, and IBM WebSphere® Application Server, and creating
middleware resources, such as MQ queues, CICS regions, and Db2 databases.
Cloud provisioning makes it possible for consumers to quickly provision and deprovision an environment
as needed.
```
**Getting started**

```
To provide access to the Cloud Provisioning function, a security administrator defines the IDs and
roles that are required, such as the domain administrator (typically a middleware system programmer),
network administrator, approvers, and consumers.
The steps for setting up cloud provisioning are illustrated in Figure 1 on page 1. More detail about the
steps and the roles follows the figure.
```
```
Figure 1. Steps for cloud provisioning
```
**1. Define access and roles (Security administrator)**
A security administrator is responsible for the security of the cloud configuration, including the
various roles that are required, such as the provisioning administrator, domain administrator, network
administrator, approvers, and consumers. For more information about setting up security for cloud
provisioning, see Configure the Cloud Provisioning services in _IBM z/OS Management Facility Configuration
Guide_.
**2. Process a request for a development environment (Domain administrator)**

```
The domain administrator, typically a middleware system programmer, processes a request for a new
environment, which might come from an application development team. This request starts the efforts to
use cloud provisioning to make the environment available.
```
```
Cloud Provisioning   1
```

```
The domain administrator can take advantage of cloud provisioning to make environments available
to a development team when they are needed, while the z/OS system programmer (the provisioning
administrator, described in the next step) retains control over what is provisioned and how many
instances are provisioned.
```
**3. Define a domain (Provisioning administrator)**
Software services templates are associated with a domain, which defines a system or set of systems. A
domain can include systems from more than one sysplex.
A provisioning administrator, typically a z/OS system programmer, decides which system or systems
(LPARs) are used for provisioning and creates a domain. If the domain extends beyond one sysplex,
the provisioning administrator configures a primary z/OSMF system for communicating with secondary
z/OSMF systems.
The provisioning administrator identifies the domain administrator. The domain administrator is typically a
middleware system programmer for the middleware that is to be provisioned. For more information about
defining the provisioning administrator and domain administrator, see Configure the Cloud Provisioning
services in _IBM z/OS Management Facility Configuration Guide_.
Tenants that are associated with a domain define users or classes of users of the domain.
To help you get started quickly, a default domain is provided. The default domain is fully operational
without any further configuration, and is accessible to any z/OSMF administrator. A default tenant is
associated with the default domain.
The systems in the domain must be included in the group of systems that are named IYUCLOUD in the
**Systems** task of the **z/OSMF Settings** category. So, you might begin by verifying that the IYUCLOUD group
contains the systems that you need.
When a domain includes more than one system, the domain administrator can specify:
- The systems that are to be used as potential targets for provisioning
- How the target system should be selected when the software service is provisioned: either
    automatically, by z/OSMF, or manually, by the consumer
- That the instance can be relocated to a system in the domain other than the system it was originally
    provisioned on. The instance can run on only one system at a time.
In a multiple-sysplex domain, creating and modifying objects is controlled from the primary z/OSMF
system. From this system, the domain administrator can provision templates on other, secondary z/OSMF
systems. For more information, see “Rules for a multiple sysplex environment” on page 4.
**4. Create a software services template and define the tenant for the line of business
(Domain administrator)**

```
To make an environment available to consumers as a software service, a domain administrator creates
and configures a software services template. The template describes what is provisioned. For example, a
template might request that a Db2 subsystem be deployed onto a z/OS® system with three databases, or
might create a set of CICS regions.
To provision the software, templates start and run z/OSMF workflows. A template includes a workflow
definition file, along with other files, including a file that defines input variables for the workflow, and a file
that defines actions that can be used against the provisioned software.
The domain administrator also defines a tenant for the development team, so that they can control how
many instances of the software can be provisioned by that team, and the networking resources that they
can use.
```
**2** Cloud Provisioning


**5. Customize the template and connect the template to resources (Domain**

**administrator)**

The template might need to be customized for the installation – for example, to conform with naming
standards in your company. You might modify variables that are input to the workflow, or use a properties
file that is provided with the template to configure the provisioned software. For information about
customization, you typically refer to documentation that is included with the template by the software
provider. In addition, the domain administrator:

- Adds the software services template to a tenant.
- Connects the template to network, storage, and WLM resource pools. Resource pools are sets of z/OS
    resources that are required by the z/OS software service, for example, ports, IP addresses, or APPLIDs.
**6. Create the pools of resources for the network and WLM (Network and WLM**

**resource pool administrators)**

When a template requires resource pools, for example, when you want to dynamically allocate ports
to provisioned software instances, the network and WLM resource pool administrators (typically z/OS
system programmers) use the appropriate z/OSMF tasks to complete the resource pools.

**7. Approve the template**

Offering self-service provisioning to a development team might require that some steps in the template,
or certain actions, run under automation IDs. Any use of these user IDs in a template must be approved.
Approval records are created for a template when a workflow or action definition file contains an element
that identifies a user ID under which a workflow step or action is to be performed. (The workflow element
is runAsUser ID, and the ID is sometimes referred to as a runAsUser ID). Approval records can also
be defined for the template in general, and for a domain. Approval records must be approved by the
approvers (typically identified by user ID) before the template can be tested or published.

**8. Test and publish the software services template (Domain administrator)**

The domain administrator tests the template to ensure that it successfully provisions the software,
that is, creates the environment. Software that is provisioned from a template is known as a software
services instance. (Note that this is different than a software instance that you manage with the Software
Management task. A _software instance_ is a collection of data sets containing installed software, and other
data sets that may be associated with that installed software.) You manage a software services instance
by using actions such as **Remove** and **deprovision**.

Publishing the template makes it available to consumers in the tenant – the application developers who
require the new environment.

**Use a marketplace to make software services available to consumers**

The Cloud Provisioning tasks include a sample marketplace of software services and a sample function for
administering the marketplace. From the marketplace, consumers such as application developers can use
the software services to quickly create a software environment. You might use the samples as inspiration
to build your own software services marketplace.

**Tailored Fit Pricing for IBM Z**

You can define a tenant as a container for Tailored Fit Pricing for IBM Z by specifying a solution ID for
the tenant. Then, any software that you provision for that tenant is treated as part of the solution. This
approach simplifies the setup that is required for Tailored Fit Pricing for IBM Z, because the Resource
Management task does the z/OSMF Workload Management work for you, including creating the tenant
resource group, tenant report class, and classifications.

```
Cloud Provisioning   3
```

```
Rules for a multiple sysplex environment
Observe the following rules for a multiple sysplex environment:
```
- Multiple sysplex domains, tenants, templates, and resource pools can be created and modified only
    from the primary sysplex. These objects should be removed from a secondary sysplex only in the event
    of an error, if they cannot be removed from the primary sysplex. Only the domain administrator can
    perform these actions.
- The primary sysplex and the secondary sysplexes must use the same cloud security mode: automatic
    or manual. A mix of automatic and manual cloud security modes between the primary and secondary
    sysplex is not supported.
- User IDs and group IDs that are used within the domain must exist in both the primary and the
    secondary sysplex. If the sysplexes have separate security databases, the user and group IDs must be
    defined in each security database. For example, consider consumer user IDs.
- Each sysplex has its own default domain. A primary sysplex cannot manage the default domain in a
    secondary sysplex.
- Lower-level network resources to be used in the secondary sysplex must be configured by using the
    z/OSMF Network Configuration Assistant task in the secondary sysplex, not the primary sysplex.
- A multiple sysplex domain in a secondary sysplex includes only the z/OS systems in its local sysplex.
- The z/OSMF system settings in the primary sysplex must contain system definitions for all of the
    systems in the multiple sysplex domain. The z/OSMF system settings in the secondary sysplex must
    contain the system definitions for the systems in the secondary sysplex. The system definition for a
    system in the z/OSMF system settings in the secondary sysplex must match the system definition for a
    system in the z/OSMF system settings in the primary sysplex. That is, the system nicknames, systems,
    and sysplex names must be identical in the primary sysplex and the secondary sysplex.
- No more than one primary sysplex can be used to manage other secondary sysplexes.

```
Summary of terms
The following are the key terms that you should be familiar with to exploit the Cloud Provisioning tasks.
```
**Resources**

```
The following are the key resources in the Cloud Provisioning tasks.
```
```
Table 1. Resources for Cloud Provisioning
```
```
Resource Description
```
```
Domain Defines the management scope for tenants, services, and resource pools.
A domain consists of one or more z/OS systems. A domain can include z/OS
systems from more than one sysplex.
A z/OS system can be in a single domain or in multiple domains that are managed
by a single instance of z/OSMF. A cloud domain is defined by a z/OS system
programmer who acts as the provisioning administrator. Each cloud domain is
assigned one or more middleware system programmers who act as domain
administrators.
A base z/OSMF configuration includes one domain by default — the default domain.
```
```
Resource pool Identifies the z/OS resources that are required by a z/OS software service. In
a cloud domain with multiple tenants, the resource pool defines the scope of
resource sharing and resource isolation. For example, a resource pool can define a
range of dedicated IP addresses or ports for each tenant.
A base z/OSMF configuration includes one resource pool by default — the default
domain shared resource pool.
```
**4** Cloud Provisioning


```
Table 1. Resources for Cloud Provisioning (continued)
```
```
Resource Description
```
```
Tenant Defines the group of users who have the authority to provision software instances.
A tenant consists of a user or group of users that have contracted for the use of
specified services and pooled z/OS resources that are associated with the services
in a domain.
A base z/OSMF configuration includes one tenant by default — the default tenant.
```
```
User roles
The following are the key roles in the Cloud Provisioning tasks.
```
_Table 2. User roles for Cloud Provisioning_

**Role Performer Description**

_Provisioning
administrator_

```
z/OS system
programmer
```
```
Defines the cloud domains and the associated system resources for the
cloud. The provisioning administrator also designates one or more users
as domain administrators.
```
_Domain
administrator_

```
Middleware
system
programmer
```
```
Manages a domain. The domain administrator is responsible for defining
services, tenants, and resource pools for the domain, and managing the
relationship across tenants, services, and resource pools.
```
_Resource pool
networking
administrator_

```
Network
administrator
```
```
Manages the resource pool for the networking resources in the cloud,
such as network configuration policies.
```
_Resource pool
WLM
administrator_

```
Performance
administrator
```
```
Manages the resource pool for the WLM resources in the cloud, such as
WLM policies.
```
_Security
administrator_

```
Security
administrator
```
```
Maintains the installation's security manager, such as RACF.
```
_Template
approver_

```
System
programmer or
security
administrator
```
```
Responsible for approving the pending approval records that are
associated with the template.
```
_Consumer_ Application
programmer

```
Has access to the software services and resource pools for a tenant.
This user can provision a software services instance by using a software
services template, and can manage the lifecycle of a software services
instance.
```
**Objects**

```
The following are some basic objects that you work with in the Cloud Provisioning tasks.
```
```
Table 3. Objects for Cloud Provisioning
```
```
Object Description
```
```
Instance, or software services
instance
```
```
Represents software that is provisioned by using templates.
```
```
Cloud Provisioning   5
```

```
Table 3. Objects for Cloud Provisioning (continued)
```
```
Object Description
```
```
Template, or software services
template
```
```
Represents z/OS or z/OS middleware, or a z/OS middleware resource
service. A template consists of workflows and input variables that
can be used to provision z/OS software, actions that can be used
with the provisioned software (the instance), and documentation.
```
### What's new in Cloud Provisioning

```
This topic identifies the enhancements that are described in the help for the Cloud Provisioning tasks in
z/OS Version 2 Release 4. It was previously part of the "What's New" topic for z/OSMF as a whole.
The enhancements are described in the following sections:
```
- “June 2022 enhancements” on page 6
- “March 2021 enhancements” on page 7
- “z/OS V2R5 enhancements” on page 7
- “December 2020 enhancements” on page 8
- “May 2020 enhancements” on page 9
- “December 2019 enhancements” on page 9
- “May 2019 enhancements” on page 10
- “March 2019 enhancements” on page 10
- “December 2018 enhancements” on page 10
- “May 2018 enhancements” on page 11
- “March 2018 enhancements” on page 12
- “December 2017 enhancements” on page 12
- “April 2017 enhancements” on page 13
- “December 2016 enhancements” on page 13.

```
June 2022 enhancements
The z/OS Provisioning tasks are enhanced in the following ways:
```
- You can provision a z/OS instance with a new RACF database with the base RACF definitions that are
    required for IPL and z/OSMF. Creating the new RACF database adds about 5 minutes to the provisioning
    time.
- You can configure Network job entry (NJE) with Transmission Control Protocol/Internet Protocol
    (TCP/IP) support to allow transmitting commands, messages, and jobs between the provisioned target
    LPAR and NJE configured nodes. The LPAR information that is used for the NJE definitions is retrieved
    from the properties file and from the LPAR pool. JES2 initialization is updated to configure NJE with
    TCP/IP support.
- Storage Management Subsystem (SMS) support now provides a basic configuration for the target LPAR.
    SMS changes the storage management approach from user-managed volumes to SMS-managed data
    sets in SMS-managed storage groups. The configuration defines the SMS automatic class selection
    (ACS) routines, which automatically assign the SMS classes and storage groups to data sets. It also
    provides the required storage classes and groups for configuration. You can allocate the source and
    active control data sets on the different volumes, and an alternative volume to allocate these data sets
    is provided.
- You can provision z/OS with z/OS Integrated Cryptographic Service Facility (ICSF) support. Basic
    configuration includes PARMLIB and PROCLIB setup and empty CKDS and PKDS data sets. More actions
    are required to prime the data sets.

**6** Cloud Provisioning


- IBM Health Checker is enabled on the provisioned z/OS instance to help detect issues with
    configuration. You can use the checked information to correct and optimize all issues that Health
       Checker compares the system environment to established settings to uncover potential problems.
- You can provision z/OS with Policy Agent support. Configuring Policy Agent allows Secure Telnet and
    Secure FTP to be enabled on the provisioned system to provide secure access through either Secure
    FTP or TN3270 with TLS enabled.

The Cloud Provisioning and Management tasks are enhanced in the following ways:

- LPAR pools can now be created and maintained in both domain and tenant-shared resource pools, and
    LPAR pool entries can be obtained and released from a shared resource pool.
- You can archive history entries for domains, tenants, resource pools, and templates by offloading them
    to an external file in a user-specified directory. If the archive directory path is specified, entries are
    removed from the history based on the maximum number of history entries and then archived. If no
    archive directory path is specified, then history entries are removed but not archived.
- The Software Services task is updated to support properly defined RACF group IDs as a RunAs step
    approver, as opposed to providing a list of individual users in a provisioning workflow definition.
- Administrators can view which tenants are associated with a particular template in the Resource
    Management and Software Services tasks. Administrators can also see the template that the resource
    pool is associated to and easily retrieve the information of either resource.
- The Software Services task also displays the version of the Software Services template that an instance
    was provisioned from. The template version property can be set and obtained from the instances API.
- The Resource Management task provides a list of provisioned instances that are using resources from a
    specific resource pool. This applies to dedicated and shared resource pools.
- You can begin provisioning with the new default shared resource pool in the default domain. The default
    pool is created upon the initialization of Cloud Provisioning and Management. This further expedites the
    setup process as you do not have to create a shared or dedicated pool to get started with provisioning.

**March 2021 enhancements**

The Cloud Provisioning tasks are enhanced in the following ways:

- History logging for a domain can be enabled or disabled, as needed. To do so, the domain administrator
    uses the option **Enable history logging** in the Resource Management task. History logging is enabled by
    default.
    A new option **Maximum number of history entries** allows the domain administrator to manage the size
    of the history log in the range of 10 - 200 entries. By default, the history log is limited to 50 entries.

**z/OS V2R5 enhancements**

The Cloud Provisioning tasks are enhanced in the following ways:

- You can provision an instance of the z/OS operating system. The steps for doing so are similar to the
    steps you would follow for provisioning other types of software instances. A key difference is that the
    z/OS image must be associated with a new type of dedicated resource pool that is called an _LPAR_
    _resource pool_. A maximum of one LPAR resource pool can exist per domain.
    Provisioning a z/OS instance requires some customization of the z/OS provisioning template properties
    file to use values that are suitable for your environment.
    The Resource Management task now includes actions for creating, viewing, and modifying an LPAR
    resource pool.

The Workflow Editor task includes the following enhancements:

- For a REST step, the **Step Type** tab now includes options for using polling to find out the status of an
    asynchronous request. You can, for example, specify the maximum number of times to poll before the
    REST call receives the expected condition and the desired wait time between polling attempts.

```
Cloud Provisioning   7
```

```
December 2020 enhancements
The Cloud Provisioning tasks are enhanced in the following ways:
```
- A resource pool defines the scope of shared z/OS resources within a cloud domain that has multiple
    tenants. In this release, the concept of a shared resource pool is expanded to include sharing resources
    across an entire domain. Here, the resource pool is referred to as a _domain-shared resource pool_.
    Previously, you were limited to sharing a resource pool within a single tenant. By allowing multiple
    tenants within a domain to share a resource pool, you simplify the management of resources in a
    cloud provisioning environment. Administrators need only create a domain shared resource pool once;
    thereafter resources from this pool are shared across multiple tenants when you provision middleware
    templates. In contrast, if resource isolation across tenants and templates is needed for your z/OS
    environments, it is recommended that you define a tenant-specific shared resource pool or a dedicated
    resource pool.
    The Resource Management task is updated with new functions to create, view, and modify domain-
    shared resource pools. The Software Services task is updated to allow a domain-shared resource pool
    to be associated with a template. The names of shared resource pools end with two wildcard qualifiers
    (*.*).
    When you define a domain-shared resource pool, you also select the templates to be associated with
    the resource pool. A template can be associated with a domain-shared resource pool for one or more
    tenants within the domain. However, within a tenant, a template can be associated with only one of the
    following types of resource pools:
    - Dedicated resource pool
    - Tenant shared resource pool
    - Domain-shared resource pool
- The default domain now supports manual security mode for creating templates and tenants. This option
    is intended for provisioning environments that cannot use automatic security mode. Previously, the
    default domain was required to run in automatic security mode. Now, when the default domain is
    created at z/OSMF startup time, it is placed in manual security mode if no security administrator is
    specified on the CLOUD_SEC_ADMIN statement in the IZUPRMxx parmlib member.
- If you have incorrectly configured the security mode for Cloud Provisioning and Management, it is now
    possible to change it. Doing so requires only that you edit the CLOUD_SEC_ADMIN statement in the
    IZUPRMxx parmlib member and restart the z/OSMF server. You can switch a domain from automatic
    security to manual security, and vice versa. Your changes to the CLOUD_SEC_ADMIN statement affect
    the security mode of all existing domains. The suggested practice is that you run Cloud Provisioning and
    Management in automatic security mode. 0
    Previously, when a domain's security mode was set, it could not be changed without deleting the
    domain and starting over. With this support, the security mode of any existing domain—even the default
    domain—can be switched quickly.
- It is possible to set a maximum time limit for a provisioned instance, such as 7 days, 30 days, or
    unlimited. This time limit can be set by the domain administrator for the associated resource pool.
    When a provisioned instance exceeds its time limit, it is marked as expired, and the instance remains in
    _provisioned_ state. The **Instances** tab of the Software Services task shows when an instance is expired
    in the "State" column as _"Provisioned - Expired"_. When an instance for which a time limit is set nears
    its time limit, z/OSMF notifies the consumer, who can then deprovision the instance. By default, no time
    limit is set; a provisioning instance is retained until it is deleted explicitly by the domain administrator.
- The domain administrator can modify a published template. With this support, the domain administrator
    can change following attributes of a published template without the need to create a new version of the
    template:
    - Description of the template
    - Workflow and job disposition
    - Disposition of deprovisioned instance.
- When creating a template, the domain administrator can now specify new options to do the following:

**8** Cloud Provisioning


- Delete instances automatically when they are deprovisioned. Previously, it was always necessary to
    delete a deprovisioned instance manually.
- Archive provisioning workflows automatically when they complete. This selection is made through
    the workflows disposition setting. Previously, the domain administrator was limited to selecting to
    either keep or delete a workflow. Archive is the new default value for the workflows disposition
    setting.
- It is possible to modify the software services instance name prefix. The domain administrator can
specify a different general name prefix, or switch to using the SNA application ID as the prefix. After the
prefix is in use by existing instances, it cannot be modified.
- In the Software Services task, it is now possible to provide an optional description for the provisioning
actions that you define.
- The domain administrator is automatically notified when a template is approved or rejected.
- History logging is added to the Resource Management task and Software Services task. This support
enables the domain administrator to retrieve a history of actions that were performed on various
objects, such as a template, domain, tenant, or resource pool.
- The actions editor is enhanced to work with variables of all types. Previously, the editor was limited to
working with string variables only.

The Workflow Editor task includes the following enhancements:

- It is now possible to delete multiple steps at once in the Workflow Editor shared step library. Previously,
    you were limited to deleting one step at a time.
- You can open the Workflows task directly from the Workflows Editor by using the new **Test** option. This
    option opens the Workflows task and initializes its input fields with values for your workflow files. It
    provides a way to quickly create a workflow instance with your workflow definition.
- A path selector option is added to some input fields to assist you with locating workflow files and
    templates on your system. In the path selector window, enter a pattern that is a partial or complete
    name of a data set, member, or a UNIX file path.

**May 2020 enhancements**

Additional support for multiple sysplex domains is provided, as follows:

- Creating and provisioning composite templates and clustered composite templates in a multiple sysplex
    environment is now supported.
- WLM resource pools in a multiple sysplex environment are now supported.
- The _Managed By_ column in selected tables is enhanced to show the URL of the primary z/OSMF system.
- With the installation of APAR PH24190, z/OSMF Workflow Editor is enhanced to use the VS code editor,
    already included in z/OSMF, when working with large amounts of text. The VS code editor provides a
    large area to do editing as well as standard editor support, such as find and replace string, line numbers,
    and the file overview.

The Workflow Editor task includes the following enhancements:

- You can import and export parent steps with the step library in the z/OSMF repository. If you select
    a parent step for the import or export action, the step and its child steps are copied in their entirety.
    Previously, it was possible only to import or export child steps or _leaf steps_.

**December 2019 enhancements**

The Cloud Provisioning tasks are enhanced in the following ways:

- You can define a multiple sysplex domain, which allows you to provision middleware across multiple
    sysplexes in your enterprise. In this configuration, creating and modifying objects is done from a
primary z/OSMF system, from which you can provision templates on other, secondary z/OSMF systems.
This enhancement allows your cloud provisioning environment to scale beyond the scope of a single
sysplex.

```
Cloud Provisioning   9
```

```
To use this capability, you must configure a primary z/OSMF system for communicating with secondary
z/OSMF systems. You can perform this setup by using the z/OSMF Systems task to define the z/OSMF
systems, then enable them for single sign-on.
```
- You can create storage resource pools and assign them to specific tenants and templates. When you
    add or modify a template and resource pool for tenants, you have the option to create a storage
    resource pool by using the Resource Pools tab. If so, you can use the data set attributes table to add,
    modify, or remove data set attributes that are associated with your storage resources.
    To use this capability, the provisioning templates must be updated to dynamically obtain data set
    attributes by using the Resource Management services REST API, which is described in the _IBM z/OS_
    _Management Facility Programming Guide_. Previously, it was not possible to isolate storage resources to
    particular tenants or templates, which might lead to contention for storage resources.
- You can specify SAF groups for the various administrator roles when you create, modify, or view
    domains. You can also specify a SAF group for template approvers when you create or modify a
    template. Previously, it was necessary to specify individual user IDs for these roles. You might find that
       using groups to represent users can help to simplify the management of Cloud Provisioning resources.
The Workflow Editor task includes the following enhancements:
- A raw text option is added to the Workflow Editor. If you select this option, the Workflow Editor opens
    the workflow definition in a simple text editor. The text editor provides editing access to the specified
    file, but without the usual tabbed interface and multi-paned layout of the Workflow Editor. Consider
    using the text editor when you need to quickly correct a syntax error that prevents the file from opening
    in the Workflow Editor UI.
- An **Expand** option is added to the **Instructions** tab on the **Step Details** page and the **Template**
    **contents field** for template steps. Use this option to expand the input area to full screen width for a
    larger text entry area.
- It is possible to create an input properties file in the Workflow Editor during an editing session.
    Previously, you had to supply an existing input properties file at the beginning of an editing session.
- As a convenience, the Edit Workflow Definition dialog now saves the location of the files that you edit.
    On subsequent uses, you can select the file location from the pull-down menu, rather than having to
    enter the full path and file name manually, as was done previously.

```
May 2019 enhancements
The name Container Pricing for IBM Z was changed to Tailored Fit Pricing for IBM Z. This name is found in
discussions of solution IDs.
```
**March 2019 enhancements**

```
Changes are made to support using an XML descriptor, rather than a REXX exec, to enable Automatic
security. These fields on the pages to create, modify, and view a domain are shown only when REXX is
used: Security workflow disposition, Security jobs disposition, and Specify customized security JCL JOB
statement.
```
**December 2018 enhancements**

- You can now set a cap for the memory that is consumed by software services instances that are
    provisioned in a tenant. You can also view a tenant's memory consumption.
- New clustered composite templates allow you to use sysplex capabilities to provision a continuously
    available middleware environment. With a single provisioning action, you can provision network-
    clustered instances of a specific middleware in a sysplex.
- The Resource Management task is reorganized for better usability. Properties of a domain, including the
    associated tenants and resource pools, are now displayed on tabs.
- The files for a template, such as the workflow and actions definition files, can now be in sequential or
    partitioned data sets. Previously, they were required to be in z/OS UNIX files.

**10** Cloud Provisioning


- Diagnostic information for provisioning an instance is enhanced. When you view an instance, you see
    new information for instances that are being provisioned or that failed provisioning, including the
    template owner, the number of steps and current step of the provisioning workflow, and the workflow
    message text. You can also display additional information by hovering the mouse pointer over the state
    of an instance on the Instances table.
- The Workflow Editor task is enhanced, as follows:
    - The Workflow Editor now includes a "toolbox" of IBM-supplied steps, which are designed for
       performing common tasks on z/OS, such as creating a data set or submitting a REST request.
       Whenever you create a workflow definition, check the step toolbox to see whether any of the steps
       would be applicable to your needs. If so, you can save time by importing an IBM-supplied step from
       the shared step library and modifying it, rather than creating your own step.
    - REST steps can now specify the HTTPS protocol for secure connections. Here, you must also specify
       the host name for the receiving system, and the user name and password that are to be used for
       logging in to the receiving system. Previously, REST steps were limited to using the HTTP protocol.
    - An array is a new type of variable that you can define for your workflow. Consider using an array
       variable when you need to map a list of values. As with other types of variables, you can use variable
       substitution for the values in an array variable, and preset the values by using a workflow variable
       input file.
    - The files for a workflow—the primary XML file, fragment files, and the variable input file—can now
       reside in sequential or partitioned data sets. Previously, they were required to reside in z/OS UNIX
       files.
    - For a file template step, you can use variable substitution for the file template location. For usage
       considerations, see the Workflow Editor online help.

**May 2018 enhancements**

- Security setup is simplified.
    - The default domain is now fully operational without any further configuration, and is accessible to
       any z/OSMF administrator. The default tenant that is associated with the default domain now grants
       access to all z/OSMF users as consumers of the templates that are associated with that default
       tenant. (z/OSMF users are members of the z/OSMF users group – the default is IZUUSER.)
    - A new option in parmlib, CLOUD_SEC_ADMIN, specifies the security administrator for Cloud
       Provisioning. You now specify the security administrator directly, when creating or modifying a
       domain, only when:
       - Creating a domain when CLOUD_SEC_ADMIN is not specified in parmlib.
       - Modifying a domain that has manual security.
       The user ID that you specify must be a valid Cloud Provisioning and Management security
       administrator ID, but it is used solely for notifications when security updates are required.
       Manual security is in effect when no value was specified for the parmlib option CLOUD_SEC_ADMIN.
       Manual and automatic security for Cloud Provisioning are no longer options that you select when
       creating a domain.
- You can use a new option to specify whether members of a tenant can view and perform actions against
    software services instances that are provisioned from an associated template. If this option is not
    selected, users must be owners of the template or domain administrators to have that authority.
- The Resource Management task saves a provisioning version with each domain, tenant, and resource
    pool object. For an action to be valid for a domain, the provisioning version of the domain object must
    not be higher than the provisioning version of the code for the Resource Management task.
    Similarly, the Software Services task saves a provisioning version with each template and instance
    object. For an action to be valid for a template or instance, the provisioning version of the object must
    not be higher than the provisioning version of the code for the Software Services task.

```
Cloud Provisioning   11
```

- When defining connector variables for a composite template by using the Software Services task, you
    can now select the source variable name from a list of public variables.
- External files that are referenced by a workflow or action definition file by using the fileTemplate
    element can now reside in sequential or partitioned data sets and in z/OS UNIX files. Previously, for
    Cloud Provisioning, those external files could reside only in z/OS UNIX files.
    The Workflow Editor and the Actions Editor are enhanced to work with external files in sequential or
    partitioned data sets. Previously, these editor programs were limited to working with z/OS UNIX files
    only.
- A new comprehensive collection of content about Cloud Provisioning is available in the IBM
    Documentation. It brings content from several sources together in one place. It is also available in
    PDF format.

```
March 2018 enhancements
Through parallel processing, a workflow can take less time to complete. A workflow with automated steps
that can be run in parallel is called a parallel-steps workflow. A parallel-steps workflow is indicated in the
Workflows page with Yes in the column Contains Parallel Steps. To start automation for a parallel-steps
workflow, use the Start Parallel Automation action in the Workflow Steps table.
The Workflow Editor task is updated to work with parallel-step workflows.
```
**December 2017 enhancements**

```
The Cloud Provisioning tasks include the following enhancements:
```
- Composite templates represent multiple services and can be provisioned with a single Run operation.
    They are made up of multiple published standard templates, each of which represents a single service.
- Shared resource pools let you use a single resource pool for multiple templates that are associated with
    a single tenant.
- Instances can be relocated to a system in the domain other than the system they were originally
    provisioned on. An instance can run on only one system in the sysplex at a time.
- Tenant-level metering and capping:
    - Metering provides tenant-level CPU consumption. New views show metered CPU use.
    - Capping provides the ability to cap CPU resource consumption by the tenant for all services that are
       deployed by the tenant.
- Tenant resource consumption can be associated with a specific solution ID, for Container Pricing for
    IBM Z.
- RunAsUser user IDs can be supplied dynamically by a workflow.
- RunAsUser elements with missing required approvers are now clearly identified, on the Approvers tab
    when you view the properties of a template.
- Notifications for approvers now link directly to the Approvals page in the Software Services task.
- You can use the actions editor to create an actions definition file. Click **Create New** for the Actions file
    field when adding a template.
- You can restart provisioning and actions workflows when they fail.
- The properties of templates and instances are now organized on tabs.
- You can now select the disposition (keep or delete) of workflows and jobs used for security, when
    you create or modify a domain. The default matches the behavior prior to this enhancement: keep
    workflows and delete jobs.
The Workflow Editor task includes the following enhancements:
- You can create multiple variables at one time. To do so, use the new action **Create Multiple Variables** ,
    which is provided in the Variables table.
- You can modify the variable type for a variable.

**12** Cloud Provisioning


- If you change a variable name on the **Workflow Variables** tab, the Workflow Editor applies this change
    throughout the workflow definition, wherever the variable is used in substitution.
- You can reposition a step within a workflow. To do so, use the new action **Move To Target** , which is
    provided in the Steps table.
- If you change a step name in the **Step Details** page, the Workflow Editor applies this change throughout
    the workflow definition, wherever the step name is referenced.

The Workload Management task in the Performance category adds support for Container Pricing for IBM
Z, which includes new tenant resource groups and tenant report classes.

**April 2017 enhancements**

- A domain that you define for cloud provisioning can now include multiple systems. You define a
    domain with the Resource Management task of the Cloud Provisioning category. You define the group of
    available systems with the Systems task of the **z/OSMF Settings** category.
- The Software Services task now includes an editor for action definitions. To use the editor, use the
    **Modify** action in the Templates table, then click **Edit** for the actions definition file on the **Modify**
    **Template** page.
- You can now opt to perform security setup for a domain manually, rather than having z/OSMF perform it
    for you, by selecting Manual for a new Security Definition field for the domain. You can display the SAF
    resources that are used for security when you view the properties of a domain or tenant. You define a
    domain with the Resource Management task of the Cloud Provisioning category.
- Enhancements are made to the Workflows XML schema that is supplied with z/OSMF. This file provides
    the XML syntax and rules for creating a workflow definition. The enhancements allow workflow authors
    to specify that workflow automation should be suspended with a specific step. You might suspend a
    workflow so that manual tasks can be performed outside of z/OSMF.
- The Software Services task reflects the suspended state of a workflow in the table of software
    instances. With a **Resume** action, you can resume a software instance that is in a suspended state.
- The Software Services task now lets you set the disposition of workflows that are used for provisioning
    and jobs that are dynamically submitted. By default, provisioning workflows are deleted when they
    complete successfully, and jobs are kept.
- When you add a template and resource pool to a tenant, which you do with the Resource Management
    task, you can now optionally choose to prevent modification of the account information for the template
    when the template is provisioned.

**December 2016 enhancements**

- A new category, Cloud Provisioning, with new tasks, Resource Management, Software Services,
    Marketplace, and Marketplace Administration. Use the new tasks to provision z/OS software and
    to manage the provisioned software, including deprovisioning. This includes creating instances of
    IBM middleware, such as CICS, DB2®, IMS, IBM MQ, or WebSphere Application Server, and creating
    middleware resources, such as Db2 databases.
- A new tab, Resource Pools, in the Workload Management task. Use this tab to manage workload
    management resource pools for cloud provisioning.
- A new Workflow Editor task. You can use the Workflow Editor task to view and modify a workflow
    definition.

```
Cloud Provisioning   13
```

## Index

**C**

cloud 1

**P**

provisioning 1

**14** Cloud Provisioning



IBM®


## Marketplace task

# IBM


## Contents

**Marketplace task...................................................................................................1**

**Index.................................................................................................................... 2**

**ii**


**Marketplace task**

```
The Marketplace task is a sample of a software services marketplace for consumers. You can use it, along
with the Marketplace Administration task, as a model for developing your own consumer marketplace for
software services.
The Marketplace task is available to consumers as well as to service providers.
To get started with the Marketplace task, expand the Cloud Provisioning category in the navigation area,
then select Marketplace.
Use links to view aspects of the marketplace.
All Services
View the software services that are available and subscribe to services.
My Subscriptions
View and manage your subscriptions. These are all of the services that you are either trying to
subscribe to or have subscribed to in the past. Select actions for a subscription from a menu. Expand
the row for a subscription to see its properties.
A subscription begins in the being-provisioned state. You may need to refresh the subscription
properties to see the state change to provisioned, which indicates that the subscription is available. To
```
```
refresh properties, click.
Once a service is no longer needed, disable it with the deprovision action. Then, remove it with the
Remove action.
```
```
Marketplace task   1
```

## Index

**M**

Marketplace task 1

**2**   Marketplace task



IBM®


## Resource Management task

# IBM


## Contents

```
Resource Management task................................................................................... 1
Default domain.............................................................................................................................................1
Resource Management................................................................................................................................ 1
How to manage resources for cloud provisioning................................................................................. 4
Defining a domain administrator............................................................................................................5
View a domain........................................................................................................................................ 6
Modify a domain................................................................................................................................... 14
Create a domain................................................................................................................................... 23
View a tenant........................................................................................................................................30
Modify a tenant.....................................................................................................................................35
Create a tenant.....................................................................................................................................39
Add a template and resource pool.......................................................................................................42
Modify template and resource pool.....................................................................................................46
View template and resource pool........................................................................................................ 50
Create a shared resource pool.............................................................................................................54
Modify a shared resource pool.............................................................................................................58
View a shared resource pool................................................................................................................62
Create storage resource pool...............................................................................................................65
Add LPAR pool entry.............................................................................................................................69
Quiesce a resource pool.......................................................................................................................77
Metering and capping...........................................................................................................................77
```
**Index.................................................................................................................. 81**

**ii**


**Resource Management task**

```
Use the Resource Management task to define a cloud domain and the administrators for the domain. You
also define the tenants (classes of users), and associate software services templates with tenants. When
associating a template with a tenant, you can request that resource pools be defined. Resource pools
identify z/OS® resources that are required by the software service.
A default domain is provided, which has a default tenant. This allows you to quickly get started with Cloud
Provisioning. However, you might want to create a domain and tenants with your own supplied values. For
more information, see “Default domain” on page 1.
To get started with the Resource Management task, select and double-click the Resource Management
task on the z/OSMF desktop.
```
### Default domain

```
A default domain, with a default tenant and default domain shared resource pool, is provided to help you
get started with Cloud Provisioning.
The default domain is fully operational without any configuration, and is accessible to any z/OSMF
administrator (that is, a user with a user ID that is connected to the security group IZUADMIN). A
default tenant, which includes all users in security group IZUUSER, is associated with the default domain.
Both the default domain and tenant are named default. For more information about the user groups
and other security setup, see Preparing to use cloud provisioning in IBM z/OS Management Facility
Configuration Guide.
```
### Resource Management

```
Use the Resource Management page to define the cloud domain, and the tenants (classes of users).
```
```
Domains
The properties of the domains are shown in a table.
For a description of the columns in the table, see Table 1 on page 1. For a description of the actions
that you can take for domains, refer to “Actions for domains” on page 3.
```
**Columns in the Domains table**

```
Table 1. Columns in the domains table
```
```
Column Description
```
```
Domain Name of the domain.
```
```
Resource Management task   1
```

```
Table 1. Columns in the domains table (continued)
```
```
Column Description
```
```
State State of the domain. For more information about an error state, hover the mouse
pointer over the text.
Network Update Failed indicates that an attempt to modify the network cloud
domain (managed with the Configuration Assistant task) that is associated with
the domain failed. The network cloud domain is modified when you modify
the domain's network administrators or the domain's systems. Review the
accompanying error message, make corrections as necessary, and use the Set
Security Complete action to retry the network cloud domain modification for the
domain.
Security Update Failed indicates that the security workflow that provides
automatic security failed. The accompanying error message indicates the workflow
name and workflow key. To understand why the security workflow failed, use the
Workflows task to review the failed workflow step status and the workflow history.
(To view the workflow steps, click the workflow name on the Workflows page. Then
click the History link to view the history.) Make corrections as necessary, then use
the Set Security Complete action for the domain.
Pending Security Update indicates the following:
```
- Manual security is required for the domain, and security setup is required.
    Manual security is required when no value for a cloud security administrator
    was specified in parmlib, with option CLOUD_SEC_ADMIN. To see the relevant
    SAF resources, use the **View** action for the domain. When the security setup is
    complete, use the **Set Security Complete** action for the domain.
- The Automatic Security workflow did not complete within 60 seconds. Use
    the Workflows task to see whether the workflow for the domain completed
    successfully, failed, or is still running. Make corrections as necessary, then use
    the **Set Security Complete** action for the domain.
Operational indicates that the domain is ready for use.

```
Domain Administrators User IDs of the administrators for the domain.
```
```
Approvers User IDs of the domain approvers who are responsible for approving templates
that are defined in the domain before it can be used to provision software services
instances.
```
```
Sysplex.System Names of the sysplexes and systems for the domain.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
**2**   Resource Management task


```
Actions for domains
The actions are described in the following tables:
```
- General actions. Actions that apply to domains. No selection is required. See Table 2 on page 3.
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 3 on page 3.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 4
    on page 4.
The Resource Management task saves a provisioning version with each domain object. For an action to be
valid for a domain, the provisioning version that is associated with the domain object must not be higher
than the provisioning version of the code for the Resource Management task.

_Table 2. General actions for the domains table_

**Action Description**

**Create Domain** Display the **Create Domain** window to create a new domain for cloud provisioning.
You must be authorized to create a domain.

_Table 3. Targeted actions for the domains table_

**Action Description**

**Create Tenant** Display the **Create Tenant** window so that you can create a new tenant for the
selected domain. You must be a domain administrator to create a tenant.
In a domain that spans multiple sysplexes, this action is available only on the
managing (or primary) z/OSMF system. This action is not available on the secondary
z/OSMF systems.

**View** Display the properties of the selected domain.

**Modify** Display the **Modify** window so that you can modify the properties of the selected
domain. You must be authorized to create a domain.
In a domain that spans multiple sysplexes, this action is available only on the
managing (or primary) z/OSMF system. This action is not available on the secondary
z/OSMF systems.

**Shared Resource Pool** Select **Add Template** , **Remove Template** , **Create Shared Pool** , **Delete Shared
Pool** , **View Shared Pool** , **Modify Shared Pool** , **Quiesce Shared Pool** or **Unquiesce
Shared Pool** for the selected domain.
To delete a shared resource pool, there must not be any currently provisioned
resources for the pool. You can use **Quiesce** to prevent new provisioning of the
template.

**Set Security Complete** Indicate that the security definition for the domain is complete and the domain
is ready for use. To see the relevant SAF resources, use the **View** action for the
domain.
In a domain that spans multiple sysplexes, this action is available only on the
managing (or primary) z/OSMF system. This action is not available on the secondary
z/OSMF systems.

**Delete** Delete the selected domains. You must be authorized to delete a domain. You
cannot delete the default domain.
In a domain that spans multiple sysplexes, this action is available only on the
managing (or primary) z/OSMF system. This action is not available on the secondary
z/OSMF systems.

```
Resource Management task   3
```

```
Table 4. Table actions for the domains table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### How to manage resources for cloud provisioning

```
Use the Resource Management task to define domains and tenants, as part of provisioning and
deprovisioning software.
```
```
Before you begin
To create a domain, you must be a provisioning administrator. To make multiple systems available
as targets for provisioning, ensure that those systems are included in the group of systems named
IYUCLOUD in the Systems task of the z/OSMF Settings category.
A domain can be defined to include systems from more than one sysplex. In this configuration, creating
and modifying templates and other objects is done from a sysplex that you designate as the primary
z/OSMF system. Objects that are created on the secondary systems are managed by the primary z/OSMF
system. Managed objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
Observe the following rules for a multiple sysplex environment:
```
- Multiple sysplex domains, tenants, templates, and resource pools can be created and modified only
    from the primary sysplex. These objects should be removed from a secondary sysplex only in the event
    of an error, if they cannot be removed from the primary sysplex. Only the domain administrator can
    perform these actions.
- The primary sysplex and the secondary sysplexes must use the same cloud security mode: automatic
    or manual. A mix of automatic and manual cloud security modes between the primary and secondary
    sysplex is not supported.
- User IDs and group IDs that are used within the domain must exist in both the primary and the
    secondary sysplex. If the sysplexes have separate security databases, the user and group IDs must be
    defined in each security database. For example, consider consumer user IDs.
- Each sysplex has its own default domain. A primary sysplex cannot manage the default domain in a
    secondary sysplex.
- Lower-level network resources to be used in the secondary sysplex must be configured by using the
    z/OSMF Network Configuration Assistant task in the secondary sysplex, not the primary sysplex.
- A multiple sysplex domain in a secondary sysplex includes only the z/OS systems in its local sysplex.

**4**   Resource Management task


- The z/OSMF system settings in the primary sysplex must contain system definitions for all of the
    systems in the multiple sysplex domain. The z/OSMF system settings in the secondary sysplex must
    contain the system definitions for the systems in the secondary sysplex. The system definition for a
    system in the z/OSMF system settings in the secondary sysplex must match the system definition for a
    system in the z/OSMF system settings in the primary sysplex. That is, the system nicknames, systems,
    and sysplex names must be identical in the primary sysplex and the secondary sysplex.
- No more than one primary sysplex can be used to manage other secondary sysplexes.
A default domain, with an associated default tenant and default domain shared resource pool, is provided
to simplify or even eliminate the need for defining domains and tenants. See “Default domain” on page 1.

```
About this task
The following procedure describes the basic steps for creating a domain. For more details, see the links
for related topics.
```
**Procedure**

1. In the z/OSMF desktop, select the Cloud Provisioning icon, then select Resource Management.
2. Choose or create a domain.
    - If you want to use the default domain, you can proceed to “3” on page 5. If you want to use the
       default tenant, you can proceed to using the Software Services task to work with templates.
    - To create a domain, in the domains table, click **Actions** , then select **Create Domain**. On the
       **Create Domain** window, supply the values, including the systems to included in the domain, and
       the user IDs or SAF groups for the domain administrator, the network administrator, the security
       administrator, and approvers. Then, click **OK**.
       **Note:** You must be a domain administrator to add a template with the Software Services task.
       Adding a template is the first step in provisioning middleware.
3. Modify or create a tenant.
    - To modify a tenant, select the domain that you want to use. Then, do the following:
       a. Click **Actions** , then select **Modify**.
b. Click the Tenants tab.
c. In the tenants table, select a tenant.
d. Click **Actions** , then select **Modify**.
    - To create a tenant, select the domain that you want to use, then click **Actions** , then select **Create**
       **Tenant**. On the **Create Tenant** window, supply the values. Then, click **OK**. For more information,
       see “Create a tenant” on page 39.
       The table of templates might be empty because you have not yet added a template using the
       Software Services task. After you add a template, return to the Resource Management task and add
       a template to the tenant. This is explained in detail in the help for the Software Services task.

**What to do next**

```
With the Software Services task, you can add a template for a domain, then run the template to create a
software instance, that is, a middleware instance or resource.
```
#### Defining a domain administrator

```
To add a template with the Software Services task, you must be a domain administrator.
```
```
About this task
An authorized user, often referred to as the provisioning administrator, can define the administrators for
a domain by using the following procedure. If you are not the provisioning administrator but need domain
```
```
Resource Management task   5
```

```
administrator authority, contact the provisioning administrator. For more information about security
setup, see Preparing to use cloud provisioning in IBM z/OS Management Facility Configuration Guide.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain, click **Actions** , then select **Modify**.
3. On the **Modify** window, supply your ID or SAF group in the Domain Administrator field, then click **Add**.
4. Click **OK** to save the change.

#### View a domain

```
You can view details about a domain that is shown in the Domains table.
```
**Procedure**

1. Select the Cloud Provisioning icon in the z/OSMF desktop, then select **Resource Management**.
2. In the Domains table, either:
    - Select the domain, then click **Actions** , then select **View**.
    - Click the domain name.

**Values on the View Domain window**

```
Domain Details
Domain name
Name of the domain.
Domain ID
An internal identifier that z/OSMF assigned to the domain.
Description
Description of the domain.
Enable history logging
Indication of whether history logging is enabled for the domain. If so, z/OSMF maintains a history log
of the actions that are performed on this domain.
Maximum number of history entries
If history logging is enabled for the domain, this field shows the maximum number of actions that can
be logged. When this number is reached, the oldest history log entries are overwritten by new entries.
History archive directory path
Specifies the directory path to store archived history entries. No default value is set.
If the archive directory path is specified, entries are removed from the history based on the maximum
number of history entries and then archived. If no archive directory path is specified, then history
entries are removed but not archived.
The user ID of the z/OSMF started task must have write permission to the archive directory path to
create files to store the archived history entries. The default user ID of the z/OSMF started task is
IZUSVR.
Managed by
Primary or managing system for this domain, in the format sysplex-name.system-name. If the domain
is not managed from another sysplex, this field is blank.
Managed by domain ID
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.
```
**6**   Resource Management task


```
Managed by z/OSMF URL
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.
Domain error details
Details about the error state of the domain. This field is displayed only if the domain is in an error
state.
```
```
Tenants
Tenants define the users who are able to run templates and create software services instances. The
properties of the tenants for the selected domain are shown in a table. You can associate templates and
resource pools to tenants. A resource pool is a high-level pool of shared z/OS resources within a cloud
domain.
For details, see “Tenants tab” on page 11.
```
```
Administrators and Approvers
Domain administrators
User IDs of the domain administrators for the domain.
Domain administrator groups
SAF groups for the domain administrators for the domain.
Network administrators
User IDs of the network administrators for the domain.
Network administrator groups
SAF groups for the network administrators for the domain.
Workload administrators
User IDs of the workload administrators for the domain.
Workload administrator groups
SAF groups for the workload administrators for the domain.
Approvers for templates
User IDs of the approvers for templates for the domain.
Approver groups
SAF groups for the template approvers for the domain.
```
**History**

```
The History tab shows a history of the actions that were performed on this domain.
If history logging is not enabled for the domain, the table indicates that no data is available to display.
```
_Table 5. Columns in the History table_

**Column Description**

**Type** Type of action that was taken on the domain, such as "modify.”

**Ran by User** User ID under which the action was performed.

**Ran at Time** Time at which the action occurred.

**Details** Description of the action.

```
Resource Management task   7
```

```
Systems
Systems
Systems in the domain, including the sysplex name and the system nicknames. LOCAL indicates the
system that you are logged on to.
In a domain that includes systems from other sysplexes (a multi-sysplex domain), this field includes
the names of the participating systems on the other sysplexes, in the form sysplex-name. system-
name.
```
**Shared Resource Pool**

```
From this tab, you can view the attributes of a domain-shared resource pool.
Templates associated with the Shared Resource Pool for Domain
A table shows the templates that are associated with the shared resource pool for this domain. See
Table 6 on page 8.
Table 6 on page 8 shows the columns in the table.
```
```
Table 6. Columns in the Templates associated with the Shared Resource Pool for Domain table.
```
```
Column Description
```
```
Resource Pool Name of the domain-shared resource pool. The resource pool name is in the form
domain-name .*.*, where asterisks (*.*) are used to indicate that the resource pool is
shared across the domain.
A quiesced resource pool is indicated by this image before the resource pool name:
.
```
```
Tenant.Template Names of the templates associated with the resource pool for the specified tenant.
```
```
Instances Limit Maximum number of software services instances that are allowed to be created
from the template.
```
```
Instances Actual Actual number of software services instances created from the template.
```
```
Sysplex.System Sysplex and system for provisioning.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
**Actions for the Shared Resource Pool tab**

```
Table 7. Targeted actions for the Templates associated with the Shared Resource Pool for Domain table.
```
```
Action Description
```
```
Add Template Display a window to add a template to the domain-shared resource pool. If this
action is not available, it might be because no shared pool is defined.
```
**8**   Resource Management task


_Table 7. Targeted actions for the Templates associated with the Shared Resource Pool for Domain table.
(continued)_

**Action Description**

**Remove Template** Display a window to remove a template from the domain-shared resource pool. If
this action is not available, it might be because no shared pool is defined.

_Table 8. General actions for the Templates associated with the Shared Resource Pool for Domain table._

**Action Description**

**Create Shared Pool** Display the **Shared Resource Pool** window to add a shared resource pool to the
domain.

**Delete Shared Pool** Display a window to delete the domain-shared resource pool. There must not be
any currently provisioned resources for the pool. You can use Quiesce to prevent
new provisioning of the template.

**View Shared Pool** View the properties of the domain-shared resource pool.

**Modify Shared Pool** Display a window to modify the domain-shared resource pool.

**Quiesce Shared Pool** Quiesce the domain-shared resource pool.

**Unquiesce Shared Pool** Unquiesce the domain-shared resource pool.

```
A quiesced resource pool is indicated by this image before the resource pool name:
.
```
_Table 9. Table actions for the Templates associated with the Shared Resource Pool for Domain table_

**Action Description**

**Select All** Select all of the items in the table.

**Deselect All** Clear all of the items in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Show Filter Row** Display the filter row.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Clear Sorts** Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.

**Clear Search** Clear the search.

```
Security
Security definition
Type of security definition:
Automatic
z/OSMF uses an XML descriptor file or a REXX exec to perform security setup dynamically.
```
```
Resource Management task   9
```

```
Manual
Security setup must be performed manually. This mode is used when no value for a cloud
security administrator is specified on the CLOUD_SEC_ADMIN statement in the IZUPRMxx parmlib
member.
To see the relevant SAF resources, use the View action for the domain.
For more information, see Preparing to use cloud provisioning in IBM z/OS Management Facility
Configuration Guide.
If you later decide to change the security mode for the domain, it is possible to do so, by editing the
CLOUD_SEC_ADMIN statement in IZUPRMxx and restarting the z/OSMF server. Edit the IZUPRMxx
parmlib member, as follows:
For automatic security...
On the CLOUD_SEC_ADMIN statement, specify the user ID of the security administrator who is to
be notified of required security updates.
For manual security...
Ensure that no user ID is specified on the CLOUD_SEC_ADMIN statement.
You can switch a domain from automatic security to manual security, and vice versa. Your changes
to the CLOUD_SEC_ADMIN statement affect the security mode of all existing domains. The suggested
practice is that you run domains in automatic security mode.
It is possible to change the security mode of a domain after it is created. You can switch a domain
from automatic security to manual security, and vice versa.
To make this change effective, the system programmer must restart the z/OSMF server. The new
security mode is applied to all domains in your cloud provisioning environment.
Security administrator
The user ID of the security administrator, specified in parmlib, with option CLOUD_SEC_ADMIN.
For manual security, supply the user ID of the security administrator who is to be notified of required
security updates. A group is not allowed.
The security administrator ID must be a member of the z/OSMF security administrator group
(IZUSECAD, by default).
Security workflow disposition
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select Delete successful workflows on completion to cause the workflow that is used for security to
be deleted automatically after it completes successfully. The default is to delete successful workflows
after they complete.
If you do not specify that the workflows should be deleted automatically, you can manually delete
workflows from the workflows table in the Workflows task.
Security jobs disposition
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select Delete jobs on completion to cause the jobs that are dynamically submitted for security to be
deleted automatically after they complete. The default is to keep jobs after they complete.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.
Specify customized security JCL JOB statement
Select this to supply JOB statement JCL for jobs that manage security definitions for cloud resources
such as domains and templates. These jobs are submitted dynamically when the cloud resources are
created, modified, or deleted.
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
```
**10**   Resource Management task


```
JOB statement JCL
Supply JOB statement JCL to be used in jobs that manage security definitions for cloud resources
such as domains and templates. z/OSMF creates and submits the jobs for you when cloud resources
are created, modified, or deleted.
Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Account information can be a maximum of 143 characters, including commas, quotation marks, and
parentheses. When a subparameter contains characters other than alphanumeric characters or #, $,
@, it must be enclosed in apostrophes.
Separate subparameters with commas and enclose them in parentheses, for example
(5438,GROUP6) or '5438,GROUOP6'. When enclosed in apostrophes, additional apostrophes must
be added in pairs, for example, 'DEPT''58'.
Click **Restore Default** to discard any changes you have made and restore the default JCL.
The **SAF Resources** tab shows the SAF resources that are used to protect the domain and associated
elements, such as resource pools and approvers. You can expand or collapse the sections for all
resources, or for a single resource, to show or hide details.
**User access**
Access level that is required for the resources.
**_resource-name_** **(** **_count_** **)**
Name of the SAF resource, followed by a count of the number of associated classes, if there is more
than 1. Expand the resource to see details:
**Class**
Class the resource belongs to.
**User IDs**
User IDs that require access to the resource.
**Roles**
Roles for the user IDs.
**RACF Commands**
Expand this field to display sample RACF commands that grant access to the resource.

```
Tenants tab
This topic describes the contents of the Tenants tab. For a description of the columns in the Tenants table,
see Table 10 on page 11. For a description of the actions that you can take for tenants, refer to Table 11
on page 13, Table 12 on page 13, and Table 13 on page 13.
```
_Table 10. Columns in the Tenants table_

**Column Description**

**Tenant Name** Name of the tenant.

```
Resource Management task   11
```

```
Table 10. Columns in the Tenants table (continued)
```
```
Column Description
```
```
State State of the tenant.
Security Update Failed indicates that the security workflow that provides
automatic security failed. The accompanying error message indicates the workflow
name and workflow key. To understand why the security workflow failed, use the
Workflows task to review the failed workflow step status and the workflow history.
(To view the workflow steps, click the workflow name on the Workflows page. Then
click the History link to view the history.) Make corrections as necessary, then use
the Set Security Complete action for the domain.
Pending Security Update indicates the following:
```
- The Automatic Security workflow did not complete within 60 seconds. Use
    the Workflows task to see whether the workflow for the domain completed
    successfully, failed, or is still running. Make corrections as necessary, then use
    the **Set Security Complete** action for the tenant.
WLM Update Failed indicates that an attempt to modify the Workload Management
(WLM) service definition that is associated with the tenant failed. The attempted
modification included one of these:
- Specifying a Solution ID, enabling metering, or enabling capping
- Modifying existing Workload Management resource pools.
Review the accompanying error messages, make corrections as necessary, and use
the **Set Security Complete** action to try the Workload Management modification
for the tenant and accompanying Workload Management resource pools again. Or,
reverse the modification (for example, disable metering) and, if necessary, use the
**Set Security Complete** action to return the state to Operational.
Operational indicates that the tenant is ready for use.

```
Groups List of groups in the tenant.
```
```
User IDs List of user IDs in the tenant.
```
```
CPU Capping Indicates whether the tenant is participating in CPU capping. Capping lets you limit
the use of resources by the tenant.
```
```
Memory Capping Indicates whether the tenant is participating in memory capping. Capping lets you
limit the use of resources by the tenant.
```
```
Metering Indicates whether the tenant is participating in metering. Metering helps you
manage the use of resources by the tenant.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
**12**   Resource Management task


```
The actions are described in the following tables:
```
- General actions. Actions that apply to tenants. No selection is required. See Table 11 on page 13.
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 12 on page 13.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 13
    on page 13.
The Resource Management task saves a provisioning version with each tenant object and resource pool
object. For an action to be valid for a tenant or resource pool, the provisioning version associated with the
object must not be higher than the provisioning version of the code for the Resource Management task.

_Table 11. General actions for the tenants table_

**Action Description**

**Create Tenant** Display the **Create Tenant** window to create a new tenant.

_Table 12. Targeted actions for the tenants table_

**Action Description**

**View** Display the properties of a selected tenant.

**Modify** Display the **Modify** window so that you can modify the properties of a selected
tenant. You must have selected a domain.

**Set Security Complete** Indicate that the security definition is complete and the tenant is ready for use. To
see the relevant SAF resources, use the **View** action for the tenant.

**Delete** Delete the selected tenants. You cannot delete the default tenant.

**Shared Resource Pool** Select **Create Shared Pool** , **Modify Shared Pool** , **Delete Shared Pool** , **View
Shared Pool** , **Quiesce Shared Pool** , or **Unquiesce Shared Pool** for selected
tenants.
To delete a shared resource pool, there must not be any currently provisioned
resources for the pool. You can use **Quiesce** to prevent new provisioning of the
template.

**Templates and Resource
Pools**

```
Select Add Template and Pool.
```
**Capping** Select **CPU** or **Memory** , then **Enable** or **Disable** , to control capping for the selected
tenant. **Enable** displays a window that lets you specify values. You can use capping
to limit the use of resources by the tenant. For more information, see “Restrictions
and other considerations for Solution ID, Metering, and Capping” on page 80.

**Metering** Select **Enable** or **Disable** to control metering for the selected tenant. You can
use metering to help manage the use of resources by the tenant. Select **View
Metered Usage** to display a graph of the metered usage. For more information, see
“Restrictions and other considerations for Solution ID, Metering, and Capping” on
page 80.

**View Metered Usage** Select **Memory Usage** or **CPU Usage** to display a graph of the appropriate metered
usage.

_Table 13. Table actions for the tenants table_

**Action Description**

**Select All** Select all of the items in the table.

```
Resource Management task   13
```

```
Table 13. Table actions for the tenants table (continued)
```
```
Action Description
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Modify a domain

```
To modify a domain, use the Modify action that is provided in the Domains table.
```
```
Before you begin
You must be a provisioning administrator to modify a domain.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed in the desktop, select it from the App Center in the taskbar.
2. In the Domains table, click **Actions** , then select **Modify**.
3. On the **Modify** window, supply values. Asterisks (*) preceding labels for tabs or fields are used to
    indicate fields that are required. See “Values on the Modify window ” on page 14.
4. Click **OK** to create the domain.

**Values on the Modify window**

```
Domain Details
Domain name
Name of the domain. It can be up to 32 characters, which can include alphanumeric characters and
these special characters:
@
$
_ (not valid for the first or last character)
```
- (not valid for the first or last character)
**Description**
Description of the domain.
**Enable history logging**
Indicates whether history logging is enabled for the domain (true or false). If so, z/OSMF maintains a
history log of the actions that are performed on this domain. History logging is enabled by default.

**14**   Resource Management task


```
If this option is deselected, z/OSMF retains the existing history log and adds an entry to indicate that
logging is disabled. No additional actions are logged until history logging is enabled.
```
**Maximum number of history entries**
If history logging is enabled, this field indicates the maximum number of history log entries to be
retained. Specify a value in the range of 10 - 200. By default, this value is set to 50.
If the maximum number is reached, z/OSMF trims the history log by 10 percent to allow for the
addition of new entries. Here, z/OSMF removes the oldest entries from the history log.
If the maximum number is reduced from a larger value, and more than the maximum number of
log entries exist, z/OSMF trims the history log down to the maximum value minus 10 percent. If the
reduction of the maximum number would result in the loss of existing entries, you are prompted to
confirm this change.

**History archive directory path**
Specifies the directory path to store archived history entries. No default value is set.
If the archive directory path is specified, entries are removed from the history based on the maximum
number of history entries and then archived. If no archive directory path is specified, then history
entries are removed but not archived.
The user ID of the z/OSMF started task must have write permission to the archive directory path to
create files to store the archived history entries. The default user ID of the z/OSMF started task is
IZUSVR.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Tenants**

Tenants define the users who are able to run templates and create software services instances. The
properties of the tenants for the selected domain are shown in a table. You can associate templates and
resource pools to tenants. A resource pool is a high-level pool of shared z/OS resources within a cloud
domain.

For details, see “Tenants tab” on page 21.

**Administrators and Approvers**

Administrators and approvers for the domain. These roles can be assigned to user IDs or SAF groups, or a
combination of both.

- To add a user ID or SAF group, type the value in the appropriate field, then click **Add**.
- To remove a user ID or SAF group, click the user ID or group name in the list, then click **Remove**.

Administrators are specified in the following fields:

**Domain administrators**
User IDs of the domain administrators for the domain.

**Domain administrator groups**
SAF group names of the domain administrators for the domain.

```
Resource Management task   15
```

```
Network administrators
User IDs of the network administrators for the domain. A network administrator must be specified if a
network resource pool is to be created.
Network administrator groups
SAF group names for network administrators for the domain. A network administrator must be
specified if a network resource pool is to be created.
Workload administrators
User IDs of the workload administrators for the domain. A workload administrator must be specified if
a WLM resource pool is to be created.
To enable metering and capping for a tenant, you must specify a workload administrator for the
associated domain.
Workload administrator groups
SAF group names for workload administrators for the domain. A workload administrator must be
specified if a WLM resource pool is to be created.
To enable metering and capping for a tenant, you must specify a workload administrator for the
associated domain.
Approvers are specified in the following fields:
Approvers for templates
User IDs of the approvers for templates for the domain. These approvers apply to all templates that
are associated with the domain while the template is in any of the draft states.
Approver groups
SAF group names for template approvers for the domain. These approvers apply to all templates that
are associated with the domain while the template is in any of the draft states.
```
```
History
The History tab shows a history of the actions that were performed on the domain.
If history logging is not enabled for the domain, the table indicates that no data is available to display.
```
```
Table 14. Columns in the History table
```
```
Column Description
```
```
Type Type of action that was taken on the domain, such as "modify.”
```
```
Ran by User User ID under which the action was performed.
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
```
Systems
Available Systems
Systems for this domain
Define the systems to include in the domain. The Available systems table shows the systems that are
available to be included, in the form sysplex-name. system-name. LOCAL indicates the system that you
are logged on to. The available systems are the group of systems named IYUCLOUD.
A domain can be defined to include systems from more than one sysplex. In this configuration,
creating and modifying templates and other objects is done from a sysplex that you designate as
the primary z/OSMF system. Objects that are created on the secondary systems are managed by the
primary z/OSMF system. Managed objects are viewable and usable on the sysplex where they reside,
but they can be modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the z/OSMF Systems
task, and be enabled for single sign-on. For more information, see Defining your systems to z/OSMF.
```
**16**   Resource Management task


```
If there are no systems to select, update the group of systems that are named IYUCLOUD with the
Systems task of the z/OSMF Settings category. Then, on the Create Domain page, click Refresh to
update the table of systems.
Use Add or Remove to build the set of systems for the domain.
```
```
Removing systems from a domain
Removing a system from a domain prevents that system from being assigned to new resource pools.
However, existing resource pools are not modified when the system is removed from the domain.
Therefore, it is still possible for templates for those resource pools to provision instances on the system
that was removed from the domain.
To prevent further provisioning of instances on the system that you remove from the domain, modify the
template and resource pools for the appropriate tenants to remove that system from the set of systems
for provisioning. The template must not have any existing instances that are already provisioned on the
system that you want to remove.
```
**Shared Resource Pool**

```
You can define a resource pool for the domain. If so, the resource pool is shared with the tenants in
the domain. Here, the resource pool is referred to as a domain-shared resource pool. When you define a
domain-shared resource pool, you can also select the templates to be associated with the resource pool.
From this tab, you can select actions to modify a domain-shared resource pool.
Templates associated with the Shared Resource Pool for Domain
A table shows the templates that are associated with the shared resource pool for this domain. See
Table 15 on page 17.
Table 15 on page 17 shows the columns in the table.
```
_Table 15. Columns in the Templates associated with the Shared Resource Pool for Domain table._

**Column Description**

**Resource Pool** Name of the domain-shared resource pool. The resource pool name is in the form
_domain-name_ .*.*, where asterisks (*.*) are used to indicate that the resource pool is
shared across the domain.
A quiesced resource pool is indicated by this image before the resource pool name:
.

**Tenant.Template** Names of the templates associated with the resource pool for the specified tenant.

**Instances Limit** Maximum number of software services instances that are allowed to be created
from the template.

**Instances Actual** Actual number of software services instances created from the template.

**Sysplex.System** Sysplex and system for provisioning.

```
Resource Management task   17
```

```
Table 15. Columns in the Templates associated with the Shared Resource Pool for Domain table. (continued)
```
```
Column Description
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
**Actions for the Shared Resource Pool tab**

```
Table 16. Targeted actions for the Templates associated with the Shared Resource Pool for Domain table.
```
```
Action Description
```
```
Add Template Display a window to add a template to the domain-shared resource pool. If this
action is not available, it might be because no shared pool is defined.
```
```
Remove Template Display a window to remove a template from the domain-shared resource pool. If
this action is not available, it might be because no shared pool is defined.
```
```
Table 17. General actions for the Templates associated with the Shared Resource Pool for Domain table.
```
```
Action Description
```
```
Create Shared Pool Display the Shared Resource Pool window to add a shared resource pool to the
domain.
```
```
Delete Shared Pool Display a window to delete the domain-shared resource pool. There must not be
any currently provisioned resources for the pool. You can use Quiesce to prevent
new provisioning of the template.
```
```
View Shared Pool View the properties of the domain-shared resource pool.
```
```
Modify Shared Pool Display a window to modify the domain-shared resource pool.
```
```
Quiesce Shared Pool Quiesce the domain-shared resource pool.
```
```
Unquiesce Shared Pool Unquiesce the domain-shared resource pool.
A quiesced resource pool is indicated by this image before the resource pool name:
.
```
```
Table 18. Table actions for the Templates associated with the Shared Resource Pool for Domain table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
**18**   Resource Management task


_Table 18. Table actions for the Templates associated with the Shared Resource Pool for Domain table (continued)_

**Action Description**

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Show Filter Row** Display the filter row.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Clear Sorts** Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.

**Clear Search** Clear the search.

```
Security
Security definition
Type of security definition:
Automatic
z/OSMF uses an XML descriptor file or a REXX exec to perform security setup dynamically.
Manual
Security setup must be performed manually. This mode is used when no value for a cloud
security administrator is specified on the CLOUD_SEC_ADMIN statement in the IZUPRMxx parmlib
member.
To see the relevant SAF resources, use the View action for the domain.
For more information, see Preparing to use cloud provisioning in IBM z/OS Management Facility
Configuration Guide.
If you later decide to change the security mode for the domain, it is possible to do so, by editing the
CLOUD_SEC_ADMIN statement in IZUPRMxx and restarting the z/OSMF server. Edit the IZUPRMxx
parmlib member, as follows:
For automatic security...
On the CLOUD_SEC_ADMIN statement, specify the user ID of the security administrator who is to
be notified of required security updates.
For manual security...
Ensure that no user ID is specified on the CLOUD_SEC_ADMIN statement.
You can switch a domain from automatic security to manual security, and vice versa. Your changes
to the CLOUD_SEC_ADMIN statement affect the security mode of all existing domains. The suggested
practice is that you run domains in automatic security mode.
It is possible to change the security mode of a domain after it is created. You can switch a domain
from automatic security to manual security, and vice versa.
To make this change effective, the system programmer must restart the z/OSMF server. The new
security mode is applied to all domains in your cloud provisioning environment.
Security administrator
The user ID of the security administrator, specified in parmlib, with option CLOUD_SEC_ADMIN.
For manual security, supply the user ID of the security administrator who is to be notified of required
security updates. A group is not allowed.
```
```
Resource Management task   19
```

```
The security administrator ID must be a member of the z/OSMF security administrator group
(IZUSECAD, by default).
Security workflow disposition
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select Delete successful workflows on completion to cause the workflow that is used for security to
be deleted automatically after it completes successfully. The default is to delete successful workflows
after they complete.
If you do not specify that the workflows should be deleted automatically, you can manually delete
workflows from the workflows table in the Workflows task.
Security jobs disposition
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select Delete jobs on completion to cause the jobs that are dynamically submitted for security to be
deleted automatically after they complete. The default is to keep jobs after they complete.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.
Specify customized security JCL JOB statement
Select this to supply JOB statement JCL for jobs that manage security definitions for cloud resources
such as domains and templates. These jobs are submitted dynamically when the cloud resources are
created, modified, or deleted.
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
JOB statement JCL
Supply JOB statement JCL to be used in jobs that manage security definitions for cloud resources
such as domains and templates. z/OSMF creates and submits the jobs for you when cloud resources
are created, modified, or deleted.
Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Account information can be a maximum of 143 characters, including commas, quotation marks, and
parentheses. When a subparameter contains characters other than alphanumeric characters or #, $,
@, it must be enclosed in apostrophes.
Separate subparameters with commas and enclose them in parentheses, for example
(5438,GROUP6) or '5438,GROUOP6'. When enclosed in apostrophes, additional apostrophes must
be added in pairs, for example, 'DEPT''58'.
Click **Restore Default** to discard any changes you have made and restore the default JCL.
The **SAF Resources** tab shows the SAF resources that are used to protect the domain and associated
elements, such as resource pools and approvers. You can expand or collapse the sections for all
resources, or for a single resource, to show or hide details.
**User access**
Access level that is required for the resources.

**20**   Resource Management task


```
resource-name ( count )
Name of the SAF resource, followed by a count of the number of associated classes, if there is more
than 1. Expand the resource to see details:
Class
Class the resource belongs to.
User IDs
User IDs that require access to the resource.
Roles
Roles for the user IDs.
RACF Commands
Expand this field to display sample RACF commands that grant access to the resource.
```
```
Tenants tab
This topic describes the contents of the Tenants tab.
```
_Table 19. Columns in the Tenants table_

**Column Description**

**Tenant Name** Name of the tenant.

**State** State of the tenant.

```
Security Update Failed indicates that the security workflow that provides
automatic security failed. The accompanying error message indicates the workflow
name and workflow key. To understand why the security workflow failed, use the
Workflows task to review the failed workflow step status and the workflow history.
(To view the workflow steps, click the workflow name on the Workflows page. Then
click the History link to view the history.) Make corrections as necessary, then use
the Set Security Complete action for the domain.
Pending Security Update indicates the following:
```
- The Automatic Security workflow did not complete within 60 seconds. Use
    the Workflows task to see whether the workflow for the domain completed
    successfully, failed, or is still running. Make corrections as necessary, then use
    the **Set Security Complete** action for the tenant.
WLM Update Failed indicates that an attempt to modify the Workload Management
(WLM) service definition that is associated with the tenant failed. The attempted
modification included one of these:
- Specifying a Solution ID, enabling metering, or enabling capping
- Modifying existing Workload Management resource pools.
Review the accompanying error messages, make corrections as necessary, and use
the **Set Security Complete** action to try the Workload Management modification
for the tenant and accompanying Workload Management resource pools again. Or,
reverse the modification (for example, disable metering) and, if necessary, use the
**Set Security Complete** action to return the state to Operational.
Operational indicates that the tenant is ready for use.

**Groups** List of groups in the tenant.

**User IDs** List of user IDs in the tenant.

**CPU Capping** Indicates whether the tenant is participating in CPU capping. Capping lets you limit
the use of resources by the tenant.

```
Resource Management task   21
```

```
Table 19. Columns in the Tenants table (continued)
```
```
Column Description
```
```
Memory Capping Indicates whether the tenant is participating in memory capping. Capping lets you
limit the use of resources by the tenant.
```
```
Metering Indicates whether the tenant is participating in metering. Metering helps you
manage the use of resources by the tenant.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
```
The actions are described in the following tables:
```
- General actions. Actions that apply to tenants. No selection is required. See Table 20 on page 22.
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 21 on page 22.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 22
    on page 23.

```
Table 20. General actions for the tenants table
```
```
Action Description
```
```
Create Tenant Display the Create Tenant window to create a new tenant.
```
```
Table 21. Targeted actions for the tenants table
```
```
Action Description
```
```
View Display the properties of a selected tenant.
```
```
Modify Display the Modify window so that you can modify the properties of a selected
tenant. You must have selected a domain.
```
```
Set Security Complete Indicate that the security definition is complete and the tenant is ready for use. To
see the relevant SAF resources, use the View action for the tenant.
```
```
Delete Delete the selected tenants. You cannot delete the default tenant.
```
```
Shared Resource Pool Select Create Shared Pool , Modify Shared Pool , Delete Shared Pool , View
Shared Pool , Quiesce Shared Pool , or Unquiesce Shared Pool for selected
tenants.
To delete a shared resource pool, there must not be any currently provisioned
resources for the pool. You can use Quiesce to prevent new provisioning of the
template.
```
```
Templates and Resource
Pools
```
```
Select Add Template and Pool.
```
**22**   Resource Management task


```
Table 21. Targeted actions for the tenants table (continued)
```
```
Action Description
```
```
Capping Select CPU or Memory , then Enable or Disable , to control capping for the selected
tenant. Enable displays a window that lets you specify values. You can use capping
to limit the use of resources by the tenant. For more information, see “Restrictions
and other considerations for Solution ID, Metering, and Capping” on page 80.
```
```
Metering Select Enable or Disable to control metering for the selected tenant. You can
use metering to help manage the use of resources by the tenant. Select View
Metered Usage to display a graph of the metered usage. For more information, see
“Restrictions and other considerations for Solution ID, Metering, and Capping” on
page 80.
```
```
View Metered Usage Select Memory Usage or CPU Usage to display a graph of the appropriate metered
usage.
```
```
Table 22. Table actions for the tenants table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Create a domain

```
To create a domain, use the Create Domain action provided in the Domains table.
```
```
Before you begin
You must be a provisioning administrator. To make multiple systems available as targets for provisioning,
ensure that those systems are included in the group of systems named IYUCLOUD in the Systems task of
the z/OSMF Settings category.
A domain can be defined to include systems from more than one sysplex. In this configuration, creating
and modifying templates and other objects is done from a sysplex that you designate as the primary
z/OSMF system. Objects that are created on the secondary systems are managed by the primary z/OSMF
system. Managed objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
Observe the following rules for a multiple sysplex environment:
```
```
Resource Management task   23
```

- Multiple sysplex domains, tenants, templates, and resource pools can be created and modified only
    from the primary sysplex. These objects should be removed from a secondary sysplex only in the event
    of an error, if they cannot be removed from the primary sysplex. Only the domain administrator can
    perform these actions.
- The primary sysplex and the secondary sysplexes must use the same cloud security mode: automatic
    or manual. A mix of automatic and manual cloud security modes between the primary and secondary
    sysplex is not supported.
- User IDs and group IDs that are used within the domain must exist in both the primary and the
    secondary sysplex. If the sysplexes have separate security databases, the user and group IDs must be
    defined in each security database. For example, consider consumer user IDs.
- Each sysplex has its own default domain. A primary sysplex cannot manage the default domain in a
    secondary sysplex.
- Lower-level network resources to be used in the secondary sysplex must be configured by using the
    z/OSMF Network Configuration Assistant task in the secondary sysplex, not the primary sysplex.
- A multiple sysplex domain in a secondary sysplex includes only the z/OS systems in its local sysplex.
- The z/OSMF system settings in the primary sysplex must contain system definitions for all of the
    systems in the multiple sysplex domain. The z/OSMF system settings in the secondary sysplex must
    contain the system definitions for the systems in the secondary sysplex. The system definition for a
    system in the z/OSMF system settings in the secondary sysplex must match the system definition for a
    system in the z/OSMF system settings in the primary sysplex. That is, the system nicknames, systems,
    and sysplex names must be identical in the primary sysplex and the secondary sysplex.
- No more than one primary sysplex can be used to manage other secondary sysplexes.

```
About this task
The provisioning administrator is a z/OS System Programmer who has z/OSMF administration access. A
domain defines a system or set of systems in the sysplex.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed in the desktop, select it from the App Center in the taskbar.
2. In the Domains table, click **Actions** , then select **Create Domain**.
3. On the **Create Domain** window, supply values. Asterisks (*) preceding labels for tabs or fields are used
    to indicate fields that are required. See “Values on the Create Domain window ” on page 24.
4. Click **OK** to create the domain.

**Values on the Create Domain window**

```
Domain Details
Domain name
Name of the domain. It can be up to 32 characters, which can include alphanumeric characters and
these special characters:
@
$
_ (not valid for the first or last character)
```
- (not valid for the first or last character)
**Description**
Description of the domain.
**Enable history logging**
Indicates whether history logging is enabled for the domain (true or false). If so, z/OSMF maintains a
history log of the actions that are performed on this domain. History logging is enabled by default.

**24**   Resource Management task


```
If this option is deselected, z/OSMF retains the existing history log and adds an entry to indicate that
logging is disabled. No additional actions are logged until history logging is enabled.
```
**Maximum number of history entries**
If history logging is enabled, this field indicates the maximum number of history log entries to be
retained. Specify a value in the range of 10 - 200. By default, this value is set to 50.
If the maximum number is reached, z/OSMF trims the history log by 10 percent to allow for the
addition of new entries. Here, z/OSMF removes the oldest entries from the history log.
If the maximum number is reduced from a larger value, and more than the maximum number of
log entries exist, z/OSMF trims the history log down to the maximum value minus 10 percent. If the
reduction of the maximum number would result in the loss of existing entries, you are prompted to
confirm this change.

**History archive directory path**
Specifies the directory path to store archived history entries. No default value is set.
If the archive directory path is specified, entries are removed from the history based on the maximum
number of history entries and then archived. If no archive directory path is specified, then history
entries are removed but not archived.
The user ID of the z/OSMF started task must have write permission to the archive directory path to
create files to store the archived history entries. The default user ID of the z/OSMF started task is
IZUSVR.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Administrators and Approvers**

Administrators and approvers for the domain. These roles can be assigned to user IDs or SAF groups, or a
combination of both.

- To add a user ID or SAF group, type the value in the appropriate field, then click **Add**.
- To remove a user ID or SAF group, click the user ID or group name in the list, then click **Remove**.

Administrators are specified in the following fields:

**Domain administrators**
User IDs of the domain administrators for the domain.

**Domain administrator groups**
SAF group names of the domain administrators for the domain.

**Network administrators**
User IDs of the network administrators for the domain. A network administrator must be specified if a
network resource pool is to be created.

**Network administrator groups**
SAF group names for network administrators for the domain. A network administrator must be
specified if a network resource pool is to be created.

**Workload administrators**
User IDs of the workload administrators for the domain. A workload administrator must be specified if
a WLM resource pool is to be created.

```
Resource Management task   25
```

```
To enable metering and capping for a tenant, you must specify a workload administrator for the
associated domain.
Workload administrator groups
SAF group names for workload administrators for the domain. A workload administrator must be
specified if a WLM resource pool is to be created.
To enable metering and capping for a tenant, you must specify a workload administrator for the
associated domain.
Approvers are specified in the following fields:
Approvers for templates
User IDs of the approvers for templates for the domain. These approvers apply to all templates that
are associated with the domain while the template is in any of the draft states.
Approver groups
SAF group names for template approvers for the domain. These approvers apply to all templates that
are associated with the domain while the template is in any of the draft states.
```
```
History
The History tab shows a history of the actions that were performed on the domain.
If history logging is not enabled for the domain, the table indicates that no data is available to display.
```
```
Table 23. Columns in the History table
```
```
Column Description
```
```
Type Type of action that was taken on the domain, such as "modify.”
```
```
Ran by User User ID under which the action was performed.
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
```
Systems
Available Systems
Systems for this domain
Define the systems to include in the domain. The Available systems table shows the systems that are
available to be included, in the form sysplex-name. system-name. LOCAL indicates the system that you
are logged on to. The available systems are the group of systems named IYUCLOUD.
A domain can be defined to include systems from more than one sysplex. In this configuration,
creating and modifying templates and other objects is done from a sysplex that you designate as
the primary z/OSMF system. Objects that are created on the secondary systems are managed by the
primary z/OSMF system. Managed objects are viewable and usable on the sysplex where they reside,
but they can be modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the z/OSMF Systems
task, and be enabled for single sign-on. For more information, see Defining your systems to z/OSMF.
If there are no systems to select, update the group of systems that are named IYUCLOUD with the
Systems task of the z/OSMF Settings category. Then, on the Create Domain page, click Refresh to
update the table of systems.
Use Add or Remove to build the set of systems for the domain.
```
**26**   Resource Management task


```
Shared Resource Pool
You can define a resource pool for the domain. If so, the resource pool is shared with the tenants in
the domain. Here, the resource pool is referred to as a domain-shared resource pool. When you define a
domain-shared resource pool, you can also select the templates to be associated with the resource pool.
From this tab, you can select actions to create and manage a domain-shared resource pool.
Templates associated with the Shared Resource Pool for Domain
A table shows the templates that are associated with the shared resource pool for this domain. See
Table 24 on page 27.
Table 24 on page 27 shows the columns in the table.
```
_Table 24. Columns in the Templates associated with the Shared Resource Pool for Domain table._

**Column Description**

**Resource Pool** Name of the domain-shared resource pool. The resource pool name is in the form
_domain-name_ .*.*, where asterisks (*.*) are used to indicate that the resource pool is
shared across the domain.
A quiesced resource pool is indicated by this image before the resource pool name:
.

**Tenant.Template** Names of the templates associated with the resource pool for the specified tenant.

**Instances Limit** Maximum number of software services instances that are allowed to be created
from the template.

**Instances Actual** Actual number of software services instances created from the template.

**Sysplex.System** Sysplex and system for provisioning.

**Managed By** For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the _primary z/OSMF system_. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.

**Actions for the Shared Resource Pool tab**

_Table 25. Targeted actions for the Templates associated with the Shared Resource Pool for Domain table._

**Action Description**

**Add Template** Display a window to add a template to the domain-shared resource pool. If this
action is not available, it might be because no shared pool is defined.

**Remove Template** Display a window to remove a template from the domain-shared resource pool. If
this action is not available, it might be because no shared pool is defined.

```
Resource Management task   27
```

```
Table 26. General actions for the Templates associated with the Shared Resource Pool for Domain table.
```
```
Action Description
```
```
Create Shared Pool Display the Shared Resource Pool window to add a shared resource pool to the
domain.
```
```
Delete Shared Pool Display a window to delete the domain-shared resource pool. There must not be
any currently provisioned resources for the pool. You can use Quiesce to prevent
new provisioning of the template.
```
```
View Shared Pool View the properties of the domain-shared resource pool.
```
```
Modify Shared Pool Display a window to modify the domain-shared resource pool.
```
```
Quiesce Shared Pool Quiesce the domain-shared resource pool.
```
```
Unquiesce Shared Pool Unquiesce the domain-shared resource pool.
A quiesced resource pool is indicated by this image before the resource pool name:
.
```
```
Table 27. Table actions for the Templates associated with the Shared Resource Pool for Domain table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
```
Security
Security definition
Type of security definition:
Automatic
z/OSMF uses an XML descriptor file or a REXX exec to perform security setup dynamically.
Manual
Security setup must be performed manually. This mode is used when no value for a cloud
security administrator is specified on the CLOUD_SEC_ADMIN statement in the IZUPRMxx parmlib
member.
To see the relevant SAF resources, use the View action for the domain.
For more information, see Preparing to use cloud provisioning in IBM z/OS Management Facility
Configuration Guide.
```
**28**   Resource Management task


```
If you later decide to change the security mode for the domain, it is possible to do so, by editing the
CLOUD_SEC_ADMIN statement in IZUPRMxx and restarting the z/OSMF server. Edit the IZUPRMxx
parmlib member, as follows:
For automatic security...
On the CLOUD_SEC_ADMIN statement, specify the user ID of the security administrator who is to
be notified of required security updates.
For manual security...
Ensure that no user ID is specified on the CLOUD_SEC_ADMIN statement.
You can switch a domain from automatic security to manual security, and vice versa. Your changes
to the CLOUD_SEC_ADMIN statement affect the security mode of all existing domains. The suggested
practice is that you run domains in automatic security mode.
It is possible to change the security mode of a domain after it is created. You can switch a domain
from automatic security to manual security, and vice versa.
To make this change effective, the system programmer must restart the z/OSMF server. The new
security mode is applied to all domains in your cloud provisioning environment.
```
**Security administrator**
The user ID of the security administrator, specified in parmlib, with option CLOUD_SEC_ADMIN.
For manual security, supply the user ID of the security administrator who is to be notified of required
security updates. A group is not allowed.
The security administrator ID must be a member of the z/OSMF security administrator group
(IZUSECAD, by default).

**Security workflow disposition**
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select **Delete successful workflows on completion** to cause the workflow that is used for security to
be deleted automatically after it completes successfully. The default is to delete successful workflows
after they complete.
If you do not specify that the workflows should be deleted automatically, you can manually delete
workflows from the workflows table in the Workflows task.

**Security jobs disposition**
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.
Select **Delete jobs on completion** to cause the jobs that are dynamically submitted for security to be
deleted automatically after they complete. The default is to keep jobs after they complete.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.

**Specify customized security JCL JOB statement**
Select this to supply JOB statement JCL for jobs that manage security definitions for cloud resources
such as domains and templates. These jobs are submitted dynamically when the cloud resources are
created, modified, or deleted.
Shown only for Automatic security when the security REXX exec is being used to enable automatic
security management.

**JOB statement JCL**
Supply JOB statement JCL to be used in jobs that manage security definitions for cloud resources
such as domains and templates. z/OSMF creates and submits the jobs for you when cloud resources
are created, modified, or deleted.
Job names:

- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @

```
Resource Management task   29
```

- Can use workflow variables, which you specify as follows:
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Account information can be a maximum of 143 characters, including commas, quotation marks, and
parentheses. When a subparameter contains characters other than alphanumeric characters or #, $,
@, it must be enclosed in apostrophes.
Separate subparameters with commas and enclose them in parentheses, for example
(5438,GROUP6) or '5438,GROUOP6'. When enclosed in apostrophes, additional apostrophes must
be added in pairs, for example, 'DEPT''58'.
Click **Restore Default** to discard any changes you have made and restore the default JCL.
The **SAF Resources** tab shows the SAF resources that are used to protect the domain and associated
elements, such as resource pools and approvers. You can expand or collapse the sections for all
resources, or for a single resource, to show or hide details.
**User access**
Access level that is required for the resources.
**_resource-name_** **(** **_count_** **)**
Name of the SAF resource, followed by a count of the number of associated classes, if there is more
than 1. Expand the resource to see details:
**Class**
Class the resource belongs to.
**User IDs**
User IDs that require access to the resource.
**Roles**
Roles for the user IDs.
**RACF Commands**
Expand this field to display sample RACF commands that grant access to the resource.

#### View a tenant

```
View a tenant to see details of its properties.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, click the name of a domain.
3. Click the Tenants tab.
4. In the Tenants table, click the name of a tenant.

**Values on the View Tenant window**

```
Tenant Details
Tenant name
Name of the tenant.
Tenant ID
An internal identifier that z/OSMF assigned to the tenant.
Description
Description of the tenant.
```
**30**   Resource Management task


**Solution ID**
The solution ID associated with the tenant. This corresponds to your Tailored Fit Pricing for IBM Z
solution as defined in the License Management Support (LMS) web portal.

**Tenant resource group name**
Name of the tenant resource group for the tenant.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Consumers**

**Groups**
Groups that are included in the tenant.

**User IDs**
Users IDs that are included in the tenant.

**Metering and Capping**

**Metering**
Indicates if the tenant is participating in metering. Metering helps you manage the use of resources by
the tenant.

**CPU**
Indicates if the tenant is participating in CPU capping. Capping lets you limit the use of resources by
the tenant.

**CPU capping type and CPU capping limit**
Capping type and capping limit.

```
Table 28. CPU capping types and values
```
```
CPU Capping Type Description Values for
Capping Limit
```
```
LPAR share percentage The capacity is specified as a percentage of the LPAR
share in the general-purpose processor pool.
```
##### 0.01-999.99

```
Service unit The capacity is specified in unweighted CPU service
units per second.
```
##### 1-99,999,999

```
CP A number of general-purpose processors (CPs),
including numbers with up to two decimal places.
```
```
0.01 to 9,999.99
```
```
MSU The capacity is specified as millions of service units
per hour.
```
##### 1-999,999

**Memory**
Indicates if the tenant is participating in memory capping. Capping lets you limit the use of resources
by the tenant.

**Memory capping limit**
Indicates the limit for memory capping.

```
Resource Management task   31
```

```
History
The History tab shows a history of the actions that were performed on the tenant.
```
```
Table 29. Columns in the History table
```
```
Column Description
```
```
Type Type of action that was taken on the tenant, such as "modify.”
```
```
Ran by User User ID under which the action was performed.
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
```
Shared Resource Pool
Templates associated with the Shared Resource Pool for the tenant
A table shows shared resource pools for the tenant, along with templates that are associated with the
resource pools.See Table 30 on page 32.
```
```
Table 30. Columns in the Templates and Resource Pools for Tenant table on the View Tenants window
```
```
Column Description
```
```
Resource Pool Name of the resource pool. The resource pool name is in the form domain-
name. tenant-name. template-name , where template-name is an asterisk (*) for a
shared resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
```
Templates Names of the templates associated with the resource pool.
```
```
Instances Limit Maximum number of software services instances that are allowed to be created
from the template.
```
```
Instances Actual Actual number of software services instances created from the template.
```
```
Sysplex.System Sysplex and system for provisioning.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
**Actions for the Shared Resource Pool tab**

```
Table 31. Targeted actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Add Template Display a window to add a template to the to the shared resource pool. If this
action is not available, it might be because there is no shared pool.
```
**32**   Resource Management task


_Table 31. Targeted actions for the Templates and Resource Pools for Tenant table (continued)_

**Action Description**

**Remove Template** Display a window to remove a template from the shared resource pool. If this
action is not available, it might be because there is no shared pool.

_Table 32. General actions for the Templates and Resource Pools for Tenant table_

**Action Description**

**Create Shared Pool** Display a window to create a shared resource pool.

**Delete Shared Pool** Display a window to delete the shared resource pool. There must not be any
currently provisioned resources for the pool. You can use Quiesce to prevent new
provisioning of the template.

**View Shared Pool** View the properties of the shared resource pool.

**Modify Shared Pool** Display a window to modify the shared resource pool.

**Quiesce Shared Pool** Quiesce the shared resource pool.

**Unquiesce Shared Pool** Unquiesce the shared resource pool.

```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
_Table 33. Table actions for the Templates and Resource Pools for Tenant table_

**Action Description**

**Select All** Select all of the items in the table.

**Deselect All** Clear all of the items in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Show Filter Row** Display the filter row.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Clear Sorts** Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.

**Clear Search** Clear the search.

```
Dedicated Resource Pools
The contents of this tab are the same as the contents of the Shared Resource Pool tab, except that they
are for dedicated resource pools.
```
```
Resource Management task   33
```

```
Table 34. Targeted actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Add Template and Pool Display a window to add templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
Remove Template and
Pool
```
```
Display a window to add templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
View Template and Pool View the properties of templates and resource pools. If this action is not available,
it might be because no templates have been added.
```
```
Modify Template and
Pool
```
```
Display a window to modify templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
Quiesce Dedicated Pool Quiesce the resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
```
Unquiesce Dedicated
Pool
```
```
Unquiesce the resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
```
Table 35. Table actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
**SAF Resources**

```
This tab shows the SAF resources that are used to protect the tenant and associated elements, such as
resource pools. You can expand or collapse the sections for all resources, or for a single resource, to show
or hide details.
User access
Access level that is required for the resources.
resource-name ( count )
Name of the SAF resource, followed by a count of the number of associated classes, if there is more
than 1. Expand the resource to see details:
```
**34**   Resource Management task


```
Class
Class the resource belongs to.
User IDs
User IDs that require access to the resource.
Roles
Roles for the user IDs.
RACF Commands
Expand this field to display sample RACF commands that grant access to the resource.
```
#### Modify a tenant

```
To modify a tenant, use the Modify action that is provided in the Tenants table.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. Click the Tenants tab.
5. In the Tenants table, select a tenant.
6. Click **Actions** , then select **Modify**.
7. On the **Modify** window, supply values. Asterisks (*) preceding labels for tabs or fields are used to
    indicate fields that are required. See “Values on the Modify window ” on page 35.
8. Click **OK** to modify the tenant.

**Values on the Modify window**

```
Tenant Details
Tenant name
Name of the tenant. It can be up to 32 characters, which can include alphanumeric characters and
these special characters:
@
$
_ (not valid for the first or last character)
```
- (not valid for the first or last character)
**Description**
Description of the tenant.
**Solution ID**
Supply the solution ID that corresponds to your Tailored Fit Pricing for IBM Z solution as defined
in the License Management Support (LMS) web portal. To ensure that the value is correct, copy the
value from LMS and then paste it into this field. For more information, see “Restrictions and other
considerations for Solution ID, Metering, and Capping” on page 80.
**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.
**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

```
Resource Management task   35
```

```
Managed by z/OSMF URL
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.
```
```
Consumers
Groups
Define the groups to include in the tenant. To add a group, type or select a group in the Groups field,
then click Add. To remove a group, select it in the list of groups, then click Remove.
User IDs
Define the users to include in the tenant. To add a user ID, type or select a user ID in the User IDs
field, then click Add. To remove a user ID, select it in the list of user IDs, then click Remove.
```
```
Metering and Capping
Enable metering
Select this option to enable metering for the tenant, which can help you manage the use of resources
by the tenant. A workload administrator must have been specified for the domain. If you cannot select
this option, verify that a workload administrator was specified for the domain.
Enable CPU capping
Select this option to enable CPU capping for the tenant, which you can use to limit the use of
resources by the tenant. After selecting this option, specify values for CPU capping type and CPU
capping limit. A workload administrator must have been specified for the domain. If you cannot select
this option, verify that a workload administrator was specified for the domain.
CPU capping type and CPU capping limit
Select a capping type and then specify the value for the capping limit. These fields are available
only when Enable CPU capping has been selected.
```
```
Table 36. CPU capping types and values
```
```
CPU Capping Type Description Values for
Capping Limit
```
```
LPAR share percentage The capacity is specified as a percentage of the
LPAR share in the general-purpose processor pool.
```
##### 0.01-999.99

```
Service unit The capacity is specified in unweighted CPU service
units per second.
```
##### 1-99,999,999

```
CP A number of general-purpose processors (CPs),
including numbers with up to two decimal places.
```
```
0.01 to 9,999.99
```
```
MSU The capacity is specified as millions of service units
per hour.
```
##### 1-999,999

```
For more information, see “Restrictions and other considerations for Solution ID, Metering, and Capping”
on page 80.
Enable memory capping
Select this option to enable memory capping for the tenant, which you can use to limit the use of
resources by the tenant. After selecting this option, specify a value for the memory capping limit.
A workload administrator must have been specified for the domain. If you cannot select this option,
verify that a workload administrator was specified for the domain.
```
**36**   Resource Management task


```
Shared Resource Pool
Templates associated with the Shared Resource Pool for the tenant
A table shows shared resource pools for the tenant, along with templates that are associated with the
resource pools.See Table 30 on page 32.
```
_Table 37. Columns in the Templates and Resource Pools for Tenant table on the View Tenants window_

**Column Description**

**Resource Pool** Name of the resource pool. The resource pool name is in the form _domain-
name_. _tenant-name_. _template-name_ , where _template-name_ is an asterisk (*) for a
shared resource pool.

```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
**Templates** Names of the templates associated with the resource pool.

**Instances Limit** Maximum number of software services instances that are allowed to be created
from the template.

**Instances Actual** Actual number of software services instances created from the template.

**Sysplex.System** Sysplex and system for provisioning.

**Managed By** For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the _primary z/OSMF system_. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.

**Actions for the Shared Resource Pool tab**

_Table 38. Targeted actions for the Templates and Resource Pools for Tenant table_

**Action Description**

**Add Template** Display a window to add a template to the to the shared resource pool. If this
action is not available, it might be because there is no shared pool.

**Remove Template** Display a window to remove a template from the shared resource pool. If this
action is not available, it might be because there is no shared pool.

_Table 39. General actions for the Templates and Resource Pools for Tenant table_

**Action Description**

**Create Shared Pool** Display a window to create a shared resource pool.

**Delete Shared Pool** Display a window to delete the shared resource pool. There must not be any
currently provisioned resources for the pool. You can use Quiesce to prevent new
provisioning of the template.

**View Shared Pool** View the properties of the shared resource pool.

```
Resource Management task   37
```

```
Table 39. General actions for the Templates and Resource Pools for Tenant table (continued)
```
```
Action Description
```
```
Modify Shared Pool Display a window to modify the shared resource pool.
```
```
Quiesce Shared Pool Quiesce the shared resource pool.
```
```
Unquiesce Shared Pool Unquiesce the shared resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
```
Table 40. Table actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
**Dedicated Resource Pools**

```
Table 41. Targeted actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Add Template and Pool Display a window to add templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
Remove Template and
Pool
```
```
Display a window to add templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
View Template and Pool View the properties of templates and resource pools. If this action is not available,
it might be because no templates have been added.
```
```
Modify Template and
Pool
```
```
Display a window to modify templates and resource pools. If this action is not
available, it might be because no templates have been added.
```
```
Quiesce Dedicated Pool Quiesce the resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
```
Unquiesce Dedicated
Pool
```
```
Unquiesce the resource pool.
```
```
A quiesced resource pool is indicated by this prior to the resource pool name:.
```
**38**   Resource Management task


```
Table 42. Table actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Create a tenant

```
To create a tenant, use the Create Tenant action that is provided in the Domains table or the Tenants
table.
```
```
Before you begin
You must be a domain administrator to create a tenant. If you would like to complete these steps using a
video see How to create a tenant and resource pool using IBM Cloud Provisioning and Management for
z/OS (mediacenter.ibm.com/media/
How+to+create+a+tenant+and+resource+pool+using+IBM+Cloud+Provisioning+and+Management+for+
z+OS/0_tarv9ew3/101043781).
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Create Tenant**.
4. On the resulting window, supply values. Asterisks (*) preceding labels for tabs or fields are used to
    indicate fields that are required. See “Values on the Create Tenant window ” on page 39.
5. Click **OK** to create the tenant.

**Values on the Create Tenant window**

```
Tenant Details
Tenant name
Name of the tenant. It can be up to 32 characters, which can include alphanumeric characters and
these special characters:
@
$
_ (not valid for the first or last character)
```
```
Resource Management task   39
```

- (not valid for the first or last character)
**Description**
Description of the tenant.
**Solution ID**
Supply the solution ID that corresponds to your Tailored Fit Pricing for IBM Z solution as defined
in the License Management Support (LMS) web portal. To ensure that the value is correct, copy the
value from LMS and then paste it into this field. For more information, see “Restrictions and other
considerations for Solution ID, Metering, and Capping” on page 80.
**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.
**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.
**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

```
Consumers
Groups
Define the groups to include in the tenant. To add a group, type or select a group in the Groups field,
then click Add. To remove a group, select it in the list of groups, then click Remove.
User IDs
Define the users to include in the tenant. To add a user ID, type or select a user ID in the User IDs
field, then click Add. To remove a user ID, select it in the list of user IDs, then click Remove.
```
```
Metering and Capping
Enable metering
Select this option to enable metering for the tenant, which can help you manage the use of resources
by the tenant. A workload administrator must have been specified for the domain. If you cannot select
this option, verify that a workload administrator was specified for the domain.
Enable CPU capping
Select this option to enable CPU capping for the tenant, which you can use to limit the use of
resources by the tenant. After selecting this option, specify values for CPU capping type and CPU
capping limit. A workload administrator must have been specified for the domain. If you cannot select
this option, verify that a workload administrator was specified for the domain.
CPU capping type and CPU capping limit
Select a capping type and then specify the value for the capping limit. These fields are available
only when Enable CPU capping has been selected.
```
```
Table 43. CPU capping types and values
```
```
CPU Capping Type Description Values for
Capping Limit
```
```
LPAR share percentage The capacity is specified as a percentage of the
LPAR share in the general-purpose processor pool.
```
##### 0.01-999.99

```
Service unit The capacity is specified in unweighted CPU service
units per second.
```
##### 1-99,999,999

```
CP A number of general-purpose processors (CPs),
including numbers with up to two decimal places.
```
```
0.01 to 9,999.99
```
**40**   Resource Management task


```
Table 43. CPU capping types and values (continued)
```
```
CPU Capping Type Description Values for
Capping Limit
```
```
MSU The capacity is specified as millions of service units
per hour.
```
##### 1-999,999

```
For more information, see “Restrictions and other considerations for Solution ID, Metering, and Capping”
on page 80.
Enable memory capping
Select this option to enable memory capping for the tenant, which you can use to limit the use of
resources by the tenant. After selecting this option, specify a value for the memory capping limit.
A workload administrator must have been specified for the domain. If you cannot select this option,
verify that a workload administrator was specified for the domain.
```
```
Dedicated Resource Pools
Templates that are associated with the Dedicated Resource Pool for the tenant
A table shows shared resource pools for the tenant, along with templates that are associated with the
resource pools. See Table 44 on page 41.
Table 44 on page 41 shows the columns in the table.
```
_Table 44. Columns in the Templates and Resource Pools for Tenant table on the Create Tenants window_

**Column Description**

**Resource Pool** Name of the resource pool. The resource pool name is in the form _domain-
name_. _tenant-name_. _template-name_ , where _template-name_ is an asterisk (*) for a
shared resource pool.
A quiesced resource pool is indicated by this image before the resource pool name:
.

**Templates** Names of the templates associated with the resource pool.

**Instances Limit** Maximum number of software services instances that are allowed to be created
from the template.

**Instances Actual** Actual number of software services instances created from the template.

**Sysplex.System** Sysplex and system for provisioning.

**Managed By** For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the _primary z/OSMF system_. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.

```
The actions are described in the following tables:
```
- General actions. Actions that apply to templates. No selection is required. See Table 45 on page 42.

```
Resource Management task   41
```

- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 46 on page 42.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 47
    on page 42.

```
Table 45. General actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Add Template and
Resource Pool
```
```
Display the Add Template and Resource Pool window to add a template and
resource pool to the tenant. If this action is not available, it might be because no
templates have been added.
```
```
Table 46. Targeted actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Remove Template and
Pool
```
```
Display the Remove Resource Pool window so that you can remove the selected
resource pool.
```
```
View Template and Pool Display the properties of the selected template and resource pool.
```
```
Modify Template and
Pool
```
```
Display the Modify Resource Pool window so that you can modify the properties of
the selected resource pool.
```
```
Quiesce Dedicated Pool Quiesce the resource pool.
```
```
Quiesce Dedicated Pool Unquiesce the resource pool.
```
```
Table 47. Table actions for the Templates and Resource Pools for Tenant table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Add a template and resource pool

```
To add a template and resource pool to a tenant, use the Template and Resource Pool action of the
Tenants table.
```
**Procedure**

1. From the z/OSMF Desktop, select **Resource Management**.

**42**   Resource Management task


2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. Click the Tenants tab.
5. In the Tenants table, select a tenant.
6. Click **Actions** , select **Templates and Resource Pools** , then select **Add Template and Pool**.
    - If a shared resource pool exists, a dialog is displayed. There, you select the template and an option
       for the resource pool:
       **Create a dedicated resource pool**
          Select this option to create a resource pool that is dedicated to the template. Clicking **OK**
          displays the **Add Template and Resource Pool** window.
       **Use an existing shared resource pool**
          Select this option to use a shared resource pool that has already been created and can be
          shared among templates. Clicking **OK** closes the dialog and returns you to the tenants table.
7. On the **Add Template and Resource Pool** window, supply values, then click **OK**. See “Values on the
    Add Template and Resource Pool window ” on page 43.
    You can also add a template and dedicated resource pool to a tenant when you create the tenant,
    using the **Add Template and Resource Pool** action in the table on the Tenants tab.

**Values on the Add Template and Resource Pool window**

**Template Details**

**Select template**
Select a template from the list, if you have not already selected a template while navigating to this
page. If the template you want to add to the tenant is not in the list, use the Software Services task to
add a template.

**Template type**
Type of template to add to the tenant. The type affects the fields that are displayed on the rest of the
page.

**Instance Details**

**Software services instance name prefix**
Character string to use as the beginning of the names of instances when they are created from
templates. The requirements and the fields that are displayed for the prefix vary with the software
type and vendor. For a shared resource pool, all three fields are required because the shared resource
pool might be used when you provision any software type, for example, CICS, Db2, or WebSphere
Application Server Liberty.
Descriptions of each of the possible fields follow. For help on specifying the prefix, you can also hover
the mouse pointer on for the field.
**Use SNA APPLID (standard templates only)**
Derive the character string from the SNA application ID. This option requires a network pool to be
created, and is displayed only if a network administrator was specified for the domain. Used if the
software type is CICS and the SNA APPLID is available from the shared resource pool.
**Specify general name prefix**
Specify a character string that is up to six alphanumeric characters. The first character must be
alphabetic. You can specify a wildcard character (*) as the last character.
**Specify subsystem name prefix (standard templates only)**
Specify a character string that is up to 2 characters.

```
Resource Management task   43
```

```
Maximum number of software services instances
Maximum number of software services instances that are allowed: Up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.
Maximum number of software services instances for a user
Maximum number of software services instances that are allowed for a single user. If you do not
specify a value, the only limit for a standard template is the one that is specified for Maximum number
of software services instances. For a composite template, if a child template set a maximum other
than 1, the valid maximum is shown in parentheses.
Maximum days to keep provisioned software services instances
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in provisioned-expired state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this time limit. Doing so changes the time limit for provisioned
instances that are created after the modification. Existing instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.
Allow members of the tenant to access and run actions for software services instances
Allow members of the tenant to view and perform actions against software services instances that are
provisioned from the template. If you do not select this option, users must be owners of the template
or domain administrators to have that authority.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Specifies whether the account information can be modified when a template is provisioned, with a
Test Run or Run action. For a composite template, this option is selected if it is selected for any of the
child templates.
```
```
Job Statement JCL
Specify customized JOB statement JCL (standard templates only)
Select this to supply JOB statement JCL that will be used in all provisioning jobs. Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-softwareServiceInstanceName}**
       Software service instance name
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Click **Restore Default** to discard any changes you have made and restore the default JCL.

```
Resource Pools
Create network resource pool
Select this option to cause a resource pool for the template to be created with network resources. A
network resource pool defines shared network resources within the domain.
```
**44**   Resource Management task


```
This option is enabled only if a network administrator is defined for the domain and the template is a
standard template or a composite cluster template.
The network administrator must complete the network resource pool definition by using the Network
Configuration Assistant task, in the Configuration category.
See the documentation from the software provider for information about whether the template
requires a network pool. This documentation can include:
```
- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.

**Create workload management pool (standard templates only)**
Select this option to cause a workload management resource pool to be created. The resource pool is
created with the name _domain_. _tenant_. _template-type_.
This option is enabled only if a workload management administrator is defined for the domain.
The workload management administrator must complete the workload management pool definition
by using the Workload Management task, in the Performance category.
See the documentation from the software provider for information about whether the template
requires a workload management pool. This documentation can include:

- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.
**Service Level Agreement (standard templates only)** Select a value to specify the level of
performance that the software services instance requires.
**PLATINUM**
    Highest
**GOLD**
    High
**SILVER**
    Intermediate
**BRONZE**
    Low
The WLM administrator must associate the service level agreement that is specified in the WLM
resource pool for the tenant with a service class that provides the appropriate level of performance.
This option is available only if a workload administrator was specified for the domain.

**Create storage resource pool**
Check this box to create a storage resource pool to manage your storage resources. This option
creates a table that allows you to add, modify, or remove data set attributes for your storage
resources. After the storage resource pool is defined with the appropriate data set attributes as
described by the template, at provisioning time the template can dynamically obtain data set
attributes by using the Resource Management services _Get data set attributes_ REST API. See _IBM z/OS
Management Facility Programming Guide_ for information about the REST API. See “Create storage
resource pool” on page 65 for details about the data set attributes table.S

**Create LPAR resource pool**
Select this option to cause a logical partition (LPAR) resource pool for the template to be created. An
LPAR pool defines LPAR resources within the domain. This option creates a table that allows you to
add, modify, or remove volumes and other resources for the LPAR pool.
The LPAR pool can only be used by z/OS provisioning templates.

```
Resource Management task   45
```

```
Systems
System selection for provisioning
Select an option for selecting the system on which the software service is provisioned.
Use a specific system
Select a system on which the template is to be provisioned, in the System field.
Assign system automatically
Select a system from a list of available systems.
Systems for domain: domain-name
The available systems are shown in the form sysplex-name. system-name. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use Add or Remove to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
Systems for automatic assignment
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
Prompt user for system
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the Run or Test Run action for a template.
Systems for domain: domain-name
The Systems for domain table shows the full set of systems for the domain, in the form
sysplex-name. system-name. LOCAL indicates the system that you are logged on to.
Use Add or Remove to build the list of systems that will be included in the user prompt. The
user can select from that list.
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
Allow resources to be relocated to other systems
Select this to specify that the template's instances can be relocated to another system in the sysplex,
meaning that the template's instances can each run on a system in the sysplex other than the system
that it was provisioned on. The candidate systems are managed in the resource pool for the tenant
in which the template is created. You cannot select this option for a standard template if there are
provisioned instances for the template.
```
#### Modify template and resource pool

```
To modify a template and resource pool, use the Template and Resource Pool action of the Tenants
table.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. Click the Tenants tab.
5. In the Tenants table, select a tenant.

**46**   Resource Management task


6. Click **Actions** , then select **Modify**.
7. Click the tab for a shared or dedicated resource pool.
8. Select a row in the table.
9. Click **Actions** , then select the appropriate Modify action.
10. Supply values on the **Modify Template and Resource Pool** window. See “Values on the Modify
Template and Resource Pool window ” on page 47.

**What to do next**

Removing a system from the set of systems for provisioning prevents further provisioning of instances
on that system. The template must not have any existing instances that are already provisioned on the
system that you want to remove. For more information, see “Removing systems from a domain” on page
17.

**Values on the Modify Template and Resource Pool window**

**Template Details**

**Select template**
Select a template from the list, if you have not already selected a template while navigating to this
page. If the template you want to add to the tenant is not in the list, use the Software Services task to
add a template.

**Template type**
Type of template to add to the tenant. The type affects the fields that are displayed on the rest of the
page.

**Instance Details**

**Software services instance name prefix**
Character string to use as the beginning of the names of instances when they are created from
templates. The requirements and the fields that are displayed for the prefix vary with the software
type and vendor. For a shared resource pool, all three fields are required because the shared resource
pool might be used when you provision any software type, for example, CICS, Db2, or WebSphere
Application Server Liberty.
Notice that you can modify the software services instance name prefix. You can specify a different
general name prefix, or switch to using the SNA application ID as the prefix. After the prefix is in use
by existing instances, you can no longer modify it.
Descriptions for each of the possible fields follow. For help on specifying the prefix, you can also hover
the mouse pointer on for the field.
**Use SNA APPLID (standard templates only)**
Derive the character string from the SNA application ID. This option requires a network pool to be
created, and is displayed only if a network administrator was specified for the domain. Used if the
software type is CICS and the SNA APPLID is available from the shared resource pool.
**Specify general name prefix**
Specify a character string that is up to six alphanumeric characters. The first character must be
alphabetic. You can specify a wildcard character (*) as the last character.
**Specify subsystem name prefix (standard templates only)**
Specify a character string that is up to 2 characters.

**Maximum number of software services instances**
Maximum number of software services instances that are allowed: Up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.

```
Resource Management task   47
```

```
Maximum number of software services instances for a user
Maximum number of software services instances that are allowed for a single user. If you do not
specify a value, the only limit for a standard template is the one that is specified for Maximum number
of software services instances. For a composite template, if a child template set a maximum other
than 1, the valid maximum is shown in parentheses.
Maximum days to keep provisioned software services instances
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in provisioned-expired state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this value, to extend or reduce the time limit as needed. Doing
so changes the time limit for provisioned instances that are created after the modification. Existing
instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.
Allow members of the tenant to access and run actions for software services instances
Allow members of the tenant to view and perform actions against software services instances that are
provisioned from the template. If you do not select this option, users must be owners of the template
or domain administrators to have that authority.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Specifies whether the account information can be modified when a template is provisioned, with a
Test Run or Run action. For a composite template, this option is selected if it is selected for any of the
child templates.
```
```
Job Statement JCL
Specify customized JOB statement JCL (standard templates only)
Select this to supply JOB statement JCL that will be used in all provisioning jobs. Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-softwareServiceInstanceName}**
       Software service instance name
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Click **Restore Default** to discard any changes you have made and restore the default JCL.

```
Resource Pools
Create network resource pool
Select this option to cause a resource pool for the template to be created with network resources. A
network resource pool defines shared network resources within the domain.
This option is enabled only if a network administrator is defined for the domain and the template is a
standard template or a composite cluster template.
```
**48**   Resource Management task


```
The network administrator must complete the network resource pool definition by using the Network
Configuration Assistant task, in the Configuration category.
See the documentation from the software provider for information about whether the template
requires a network pool. This documentation can include:
```
- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.

**Create workload management pool (standard templates only)**
Select this option to cause a workload management resource pool to be created. The resource pool is
created with the name _domain_. _tenant_. _template-type_.
This option is enabled only if a workload management administrator is defined for the domain.
The workload management administrator must complete the workload management pool definition
by using the Workload Management task, in the Performance category.
See the documentation from the software provider for information about whether the template
requires a workload management pool. This documentation can include:

- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.
**Service Level Agreement (standard templates only)** Select a value to specify the level of
performance that the software services instance requires.
**PLATINUM**
    Highest
**GOLD**
    High
**SILVER**
    Intermediate
**BRONZE**
    Low
The WLM administrator must associate the service level agreement that is specified in the WLM
resource pool for the tenant with a service class that provides the appropriate level of performance.
This option is available only if a workload administrator was specified for the domain.

**Create storage resource pool**
Check this box to create a storage resource pool to manage your storage resources. This option
creates a table that allows you to add, modify, or remove data set attributes for your storage
resources. After the storage resource pool is defined with the appropriate data set attributes as
described by the template, at provisioning time the template can dynamically obtain data set
attributes by using the Resource Management services _Get data set attributes_ REST API. See _IBM z/OS
Management Facility Programming Guide_ for information about the REST API. See “Create storage
resource pool” on page 65 for details about the data set attributes table.S

**Create LPAR resource pool**
Select this option to cause a logical partition (LPAR) resource pool for the template to be created. An
LPAR pool defines LPAR resources within the domain. This option creates a table that allows you to
add, modify, or remove volumes and other resources for the LPAR pool.
The LPAR pool can only be used by z/OS provisioning templates.

**Systems**

**System selection for provisioning**
Select an option for selecting the system on which the software service is provisioned.

```
Resource Management task   49
```

```
Use a specific system
Select a system on which the template is to be provisioned, in the System field.
Assign system automatically
Select a system from a list of available systems.
Systems for domain: domain-name
The available systems are shown in the form sysplex-name. system-name. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use Add or Remove to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
Systems for automatic assignment
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
Prompt user for system
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the Run or Test Run action for a template.
Systems for domain: domain-name
The Systems for domain table shows the full set of systems for the domain, in the form
sysplex-name. system-name. LOCAL indicates the system that you are logged on to.
Use Add or Remove to build the list of systems that will be included in the user prompt. The
user can select from that list.
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
Allow resources to be relocated to other systems
Select this to specify that the template's instances can be relocated to another system in the sysplex,
meaning that the template's instances can each run on a system in the sysplex other than the system
that it was provisioned on. The candidate systems are managed in the resource pool for the tenant
in which the template is created. You cannot select this option for a standard template if there are
provisioned instances for the template.
```
#### View template and resource pool

```
To view a template and resource pool, use the Template and Resource Pool action of the Tenants table.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **View**.
4. Click the Tenants tab.
5. In the Tenants table, select a tenant.
6. Click **Actions** , then select **View**.
7. Click the tab for a shared or dedicated resource pool.
8. Select a row in the table.
9. Click **Actions** , then select the appropriate View action.

**50**   Resource Management task


**Values on the View Template and Resource Pool window**

**Template Details**

**Template name**
Name of the selected template.

**Template type**
Type of the template to add to the tenant. The type affects the fields that are displayed on the rest of
the page.

**Template information**
Table showing the versions of the template.

**Resource Pool Details**

**Resource pool name**
Name of the resource pool that is associated with the template. The name is in the form _domain-
name_. _tenant-name_. _template-name_.

**Resource pool ID**
An internal identifier that z/OSMF assigned to the resource pool.

**Resource pool ready**

```
true
The resource pool is ready.
false
The resource pool is not ready.
```
**Resource pool quiesced**

```
true
The resource pool is quiesced. No new resources are provisioned for the resource pool.
false
The resource pool is not quiesced.
```
**Instance Details**

**Use SNA APPLID (standard templates only)**

```
true
Derive the software service instance name prefix from the SNA application ID.
false
Do not derive the software service instance name prefix from the SNA application ID.
This value is always false if a network administrator was not specified for the domain.
```
**Software service instance name prefix**
Character string to be used as the software service instance name prefix. This is used as the beginning
of the names of software services instances that are created from templates. This value is blank if Use
SNA APPLID is true.

**Maximum number of software services instances**
Maximum number of software services instances that are allowed: up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.

**Maximum number of software services instances for a user**
Maximum number of software services instances that are allowed for a single user. If no value is
specified, the only limit for a standard template is the one for Maximum number of software services
instances.

```
Resource Management task   51
```

```
Maximum days to keep provisioned software services instances
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in provisioned-expired state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this value to extend or reduce the time limit as needed. Doing
so changes the time limit for provisioned instances that are created after the modification. Existing
instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.
Allow members of the tenant to access and run actions for software services instances
Indicates whether members of the tenant can view and perform actions against software services
instances that are provisioned from the template. If this option is not selected, users must be owners
of the template or domain administrators to have that authority.
Actual number of software services instances
Actual number of software services instances that exist.
Provisioned software services instances
Shows the instances that have the “provisioned” state and are associated with the resource pool.
```
```
Table 48. Columns in the Provisioned Software Service Instances table
```
```
Column Description
```
```
Instance name Name of the software services instance.”
```
```
State State of the software services instance.
```
```
Last Action Status The state of the last action that was performed.
```
```
System System that the software is provisioned on.
```
```
Cluster Name of the cluster instance.
```
```
Software Type Type of the software. The value is null for composite parent registry instances.
```
```
Template Name Name of the template that was used when partitioning the software represented
by this instance.
```
```
Domain Name of the domain.
```
```
Tenant Name of the tenant.
```
```
Created On Date and time the software services instance was created.
```
```
Expiration Date Date and time the software services instance expires.
```
```
Created By User that created the software services instance.
```
```
Composite Related Indicates whether the instance is either a composite cluster parent or a member.
```
```
Managed By Primary or managing system for this domain, in the format sysplex-name.system-
name. If the domain is not managed from another sysplex, this field is blank.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Indicates if the account information can be modified when a template is provisioned with a Test Run
or Run action. For a composite template, this option is true if it is true for any of its child templates.
```
**52**   Resource Management task


```
History
The History tab shows a history of the actions that were performed on the template and resource pool.
```
_Table 49. Columns in the History table_

**Column Description**

**Type** Type of action that is taken on the template or resource pool, such as "modify.”

**Ran by User** User ID under which the action was performed.

**Ran at Time** Time at which the action occurred.

**Details** Description of the action.

```
Job Statement JCL
Customized JOB statement JCL (standard templates only)
JCL that will be used in jobs for the resource pool. The job name can use workflow variables:
${_workflow-softwareServiceInstanceName}
Software service instance name
${_workflow-workflowOwner}
Workflow owner
${_step-stepOwner}
Workflow step owner
```
```
Resource Pools
Create network resource pool (standard templates only)
Indicates if a network pool should be created. This value is always false if a network administrator
was not specified for the domain.
Network pool status
Status of the network pool.
Create workload management pool (standard templates only)
Indicates if a workload management pool should be created.
Workload management pool status
Status of the workload management pool.
Service level agreement (standard templates only)
Service level agreement for the workload management pool. Specifies the level of performance that
the software services instance requires.
PLATINUM
Highest
GOLD
High
SILVER
Intermediate
BRONZE
Low
Report class
WLM report class for the workload management pool.
Create storage resource pool
If you have created a storage resource pool, the data set attributes table is displayed.
```
```
Resource Management task   53
```

```
Systems
System selection for provisioning
Select an option for selecting the system on which the software service is provisioned.
Use a specific system
Select a system on which the template is to be provisioned, in the System field.
Assign system automatically
Select a system from a list of available systems.
Systems for domain: domain-name
The available systems are shown in the form sysplex-name. system-name. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use Add or Remove to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
Systems for automatic assignment
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
Prompt user for system
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the Run or Test Run action for a template.
Systems for domain: domain-name
The Systems for domain table shows the full set of systems for the domain, in the form
sysplex-name. system-name. LOCAL indicates the system that you are logged on to.
Use Add or Remove to build the list of systems that will be included in the user prompt. The
user can select from that list.
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
Allow resources to be relocated to other systems
Select this to specify that the template's instances can be relocated to another system in the sysplex,
meaning that the template's instances can each run on a system in the sysplex other than the system
that it was provisioned on. The candidate systems are managed in the resource pool for the tenant
in which the template is created. You cannot select this option for a standard template if there are
provisioned instances for the template.
```
#### Create a shared resource pool

```
To create a shared resource pool, use the Shared Resource Pool action.
```
```
Before you begin
You must be a domain administrator.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed in the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. To create a shared resource pool for a tenant or domain, select the appropriate action, as follows:

**54**   Resource Management task


- For a tenant-shared resource pool:
    a. Click the **Tenants** tab. In the Tenants table, select a tenant.
b. Click **Actions** , then select **Shared Resource Pools** , then select **Create Shared Pool**.
- For a domain-shared resource pool:
    a. Click the **Shared Resource Pool** tab.
b. In the table, click **Actions** , then select **Create Shared Pool**.
You can also create a shared resource pool when you create a tenant or a domain.
5. On the **Create Shared Resource Pool** window, supply values, then click **OK**. See “Values on the Create
Shared Resource Pool window ” on page 55.
The shared resource pool is created. In the tenants table, an asterisk (*) is displayed for the template
name until you associate templates with the template and resource pool.

**What to do next**

To associate a template with a shared resource pool:, in the Tenants table or Domains table, click **Actions** ,
then select **Shared Resource Pool** , then select **Add Template**. On the resulting window, select a tenant
from the list.

To remove a template and the associated shared resource pool, in the Tenants table or Domains table,
select **Shared Resource Pool** , then select **Remove Template**.

**Values on the Create Shared Resource Pool window**

**Instance Details**

**Software services instance name prefix**
Character string to use as the beginning of the names of instances when they are created from
templates. The requirements and the fields that are displayed for the prefix vary with the software
type and vendor. For a shared resource pool, all three fields are required because the shared resource
pool might be used when you provision any software type, for example, CICS, Db2, or WebSphere
Application Server Liberty. For help on specifying the prefix, you can also hover the mouse pointer on
for the field.
**Use SNA APPLID**
Indicates that the character string should be derived from the SNA application ID. This option
requires a network pool to be created, and is automatically selected if a network administrator
was specified for the domain. This prefix is used for CICS templates when the SNA APPLID is
available.
**Specify general name prefix**
Specify a character string that is up to six alphanumeric characters. The first character must be
alphabetic. You can specify a wildcard character (*) as the last character.
**Specify subsystem name prefix**
Specify a character string that is up to 2 characters.

**Maximum number of software services instances**
Maximum number of software services instances that are allowed: Up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.

**Maximum number of software services instances for a user**
Maximum number of software services instances that are allowed for a single user. If you do not
specify a value, the only limit for a standard template is the one that is specified for Maximum number
of software services instances. For a composite template, if a child template set a maximum other
than 1, the valid maximum is shown in parentheses.

```
Resource Management task   55
```

```
Maximum days to keep provisioned software services instances
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in provisioned-expired state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this time limit. Doing so changes the time limit for provisioned
instances that are created after the modification. Existing instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.
Allow members of the tenant to access and run actions for software services instances
Allow members of the tenant to view and perform actions against software services instances that are
provisioned from the template. If you do not select this option, users must be owners of the template
or domain administrators to have that authority.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Specifies whether the account information can be modified when a template is provisioned, with a
Test Run or Run action. For a composite template, this option is selected if it is selected for any of the
child templates.
```
```
Job Statement JCL
Specify customized JOB statement JCL (standard templates only)
Select this to supply JOB statement JCL that will be used in all provisioning jobs. Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-softwareServiceInstanceName}**
       Software service instance name
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Click **Restore Default** to discard any changes you have made and restore the default JCL.

```
Resource
Create network resource pool
Select this option to cause a resource pool for the template to be created with network resources. A
network resource pool defines shared network resources within the domain.
This option is enabled only if a network administrator is defined for the domain and the template is a
standard template or a composite cluster template.
The network administrator must complete the network resource pool definition by using the Network
Configuration Assistant task, in the Configuration category.
See the documentation from the software provider for information about whether the template
requires a network pool. This documentation can include:
```
- A readme file

**56**   Resource Management task


- Administrator documentation, which you can access by viewing the template with the Software
    Services task.

**Create workload management pool (standard templates only)**
Select this option to cause a workload management resource pool to be created. The resource pool is
created with the name _domain_. _tenant_. _template-type_.
This option is enabled only if a workload management administrator is defined for the domain.
The workload management administrator must complete the workload management pool definition
by using the Workload Management task, in the Performance category.
See the documentation from the software provider for information about whether the template
requires a workload management pool. This documentation can include:

- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.
**Service Level Agreement (standard templates only)** Select a value to specify the level of
performance that the software services instance requires.
**PLATINUM**
    Highest
**GOLD**
    High
**SILVER**
    Intermediate
**BRONZE**
    Low
The WLM administrator must associate the service level agreement that is specified in the WLM
resource pool for the tenant with a service class that provides the appropriate level of performance.
This option is available only if a workload administrator was specified for the domain.

**Create storage resource pool**
Check this box to create a storage resource pool to manage your storage resources. This option
creates a table that allows you to add, modify, or remove data set attributes for your storage
resources. After the storage resource pool is defined with the appropriate data set attributes as
described by the template, at provisioning time the template can dynamically obtain data set
attributes by using the Resource Management services _Get data set attributes_ REST API. See _IBM z/OS
Management Facility Programming Guide_ for information about the REST API. See “Create storage
resource pool” on page 65 for details about the data set attributes table.S

**Create LPAR resource pool**
Select this option to cause a logical partition (LPAR) resource pool for the template to be created. An
LPAR pool defines LPAR resources within the domain. This option creates a table that allows you to
add, modify, or remove volumes and other resources for the LPAR pool.
The LPAR pool can only be used by z/OS provisioning templates.

**Systems**

**System selection for provisioning**
Select an option for selecting the system on which the software service is provisioned.
**Use a specific system**
Select a system on which the template is to be provisioned, in the System field.
**Assign system automatically**
Select a system from a list of available systems.

```
Resource Management task   57
```

```
Systems for domain: domain-name
The available systems are shown in the form sysplex-name. system-name. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use Add or Remove to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
Systems for automatic assignment
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
Prompt user for system
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the Run or Test Run action for a template.
Systems for domain: domain-name
The Systems for domain table shows the full set of systems for the domain, in the form
sysplex-name. system-name. LOCAL indicates the system that you are logged on to.
Use Add or Remove to build the list of systems that will be included in the user prompt. The
user can select from that list.
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
```
#### Modify a shared resource pool

```
To modify a shared resource pool, use the Shared Resource Pool action. Modifying a shared resource
pool affects all of the templates that are associated with the shared resource pool. For a domain-shared
resource pool, this modification affects all of the tenants and templates that are associated with the
shared resource pool.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed in the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. To modify the shared resource pool for a tenant or domain, select the appropriate action, as follows:
    - For a tenant-shared resource pool:
       a. Click the **Tenants** tab. In the Tenants table, select the tenant with the shared resource pool.
b. Click **Actions** , then select **Shared Resource Pools** , then select **Modify Shared Pool**.
    - For a domain-shared resource pool:
       a. Click the **Shared Resource Pool** tab.
b. In the table, click **Actions** , then select **Modify Shared Pool**.
    You can also modify a shared resource pool when you modify a tenant or a domain.
5. Supply values on the **Modify Shared Resource Pool** window. See “Values on the Modify Shared
    Resource Pool window ” on page 59.

**58**   Resource Management task


**What to do next**

To associate a template with a shared resource pool:, in the Tenants table or Domains table, click **Actions** ,
then select **Shared Resource Pool** , then select **Add Template**. On the resulting window, select a tenant
from the list.

To remove a template and the associated shared resource pool, in the Tenants table or Domains table,
select **Shared Resource Pool** , then select **Remove Template**.

For more information, see “Removing systems from a domain” on page 17.

**Values on the Modify Shared Resource Pool window**

**Instance Details**

**Software services instance name prefix**
Character string to use as the beginning of the names of instances when they are created from
templates. The requirements and the fields that are displayed for the prefix vary with the software
type and vendor. For a shared resource pool, all three fields are required because the shared resource
pool might be used when you provision any software type, for example, CICS, Db2, or WebSphere
Application Server Liberty. For help on specifying the prefix, you can also hover the mouse pointer on
for the field.
**Use SNA APPLID**
Indicates that the character string should be derived from the SNA application ID. This option
requires a network pool to be created, and is automatically selected if a network administrator
was specified for the domain. This prefix is used for CICS templates when the SNA APPLID is
available.
**Specify general name prefix**
Specify a character string that is up to six alphanumeric characters. The first character must be
alphabetic. You can specify a wildcard character (*) as the last character.
**Specify subsystem name prefix**
Specify a character string that is up to 2 characters.

**Maximum number of software services instances**
Maximum number of software services instances that are allowed: Up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.

**Maximum number of software services instances for a user**
Maximum number of software services instances that are allowed for a single user. If you do not
specify a value, the only limit for a standard template is the one that is specified for Maximum number
of software services instances. For a composite template, if a child template set a maximum other
than 1, the valid maximum is shown in parentheses.

**Maximum days to keep provisioned software services instances**
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in _provisioned-expired_ state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this time limit. Doing so changes the time limit for provisioned
instances that are created after the modification. Existing instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.

```
Resource Management task   59
```

```
Allow members of the tenant to access and run actions for software services instances
Allow members of the tenant to view and perform actions against software services instances that are
provisioned from the template. If you do not select this option, users must be owners of the template
or domain administrators to have that authority.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Specifies whether the account information can be modified when a template is provisioned, with a
Test Run or Run action. For a composite template, this option is selected if it is selected for any of the
child templates.
```
```
Job Statement JCL
Specify customized JOB statement JCL (standard templates only)
Select this to supply JOB statement JCL that will be used in all provisioning jobs. Job names:
```
- Can be up to 8 characters, consisting of A-Z, a-z, 0-9, and these special characters: # $ @
- Must start with an alphabetic character or one of these special characters: # $ @
- Can use workflow variables, which you specify as follows:
    **${_workflow-softwareServiceInstanceName}**
       Software service instance name
    **${_workflow-workflowOwnerUpper}**
       Workflow owner
    **${_step-stepOwnerUpper}**
       Workflow step owner
Click **Restore Default** to discard any changes you have made and restore the default JCL.

```
Resource Management
Create network resource pool
Select this option to cause a resource pool for the template to be created with network resources. A
network resource pool defines shared network resources within the domain.
This option is enabled only if a network administrator is defined for the domain and the template is a
standard template or a composite cluster template.
The network administrator must complete the network resource pool definition by using the Network
Configuration Assistant task, in the Configuration category.
See the documentation from the software provider for information about whether the template
requires a network pool. This documentation can include:
```
- A readme file
- Administrator documentation, which you can access by viewing the template with the Software
    Services task.
**Create workload management pool (standard templates only)**
Select this option to cause a workload management resource pool to be created. The resource pool is
created with the name _domain_. _tenant_. _template-type_.
This option is enabled only if a workload management administrator is defined for the domain.
The workload management administrator must complete the workload management pool definition
by using the Workload Management task, in the Performance category.
See the documentation from the software provider for information about whether the template
requires a workload management pool. This documentation can include:
- A readme file

**60**   Resource Management task


- Administrator documentation, which you can access by viewing the template with the Software
    Services task.
**Service Level Agreement (standard templates only)** Select a value to specify the level of
performance that the software services instance requires.
**PLATINUM**
    Highest
**GOLD**
    High
**SILVER**
    Intermediate
**BRONZE**
    Low
The WLM administrator must associate the service level agreement that is specified in the WLM
resource pool for the tenant with a service class that provides the appropriate level of performance.
This option is available only if a workload administrator was specified for the domain.

**Create LPAR resource pool**
Select this option to cause a logical partition (LPAR) resource pool for the template to be created. An
LPAR pool defines LPAR resources within the domain. This option creates a table that allows you to
add, modify, or remove volumes and other resources for the LPAR pool.
The LPAR pool can only be used by z/OS provisioning templates.

**Systems**

**System selection for provisioning**
Select an option for selecting the system on which the software service is provisioned.
**Use a specific system**
Select a system on which the template is to be provisioned, in the System field.
**Assign system automatically**
Select a system from a list of available systems.
**Systems for domain:** **_domain-name_**
The available systems are shown in the form _sysplex-name_. _system-name_. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use **Add** or **Remove** to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
**Systems for automatic assignment**
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
**Prompt user for system**
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the **Run** or **Test Run** action for a template.
**Systems for domain:** **_domain-name_**
The Systems for domain table shows the full set of systems for the domain, in the form
_sysplex-name_. _system-name_. LOCAL indicates the system that you are logged on to.
Use **Add** or **Remove** to build the list of systems that will be included in the user prompt. The
user can select from that list.

```
Resource Management task   61
```

```
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
```
#### View a shared resource pool

```
To view a shared resource pool, use the Shared Resource Pool action.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. To view the shared resource pool for a tenant or domain, select the appropriate action, as follows:
    - For a tenant-shared resource pool:
       a. Click the **Tenants** tab. In the Tenants table, click the name of the tenant with the shared
          resource pool.
b. Click the **Shared Resource Pools** tab. In the Tenants table, select the tenant with the shared
resource pool.
       c. Click **Actions** , then select **Shared Resource Pools** , then select **View**.
    - For a domain-shared resource pool:
       a. Click the **Shared Resource Pool** tab.
b. In the table, click **Actions** , then select **View Shared Pool**.

**Values on the View Shared Resource Pool window**

**Template Details**

```
A table shows information about templates that are associated with the shared resource pool.
```
```
Resource Pool Details
Resource pool name
Name of the resource pool that is associated with the templates. The name is in the form domain-
name. tenant-name. template-name.
Resource pool ID
An internal identifier that z/OSMF assigned to the resource pool.
Resource pool ready
true
The resource pool is ready.
false
The resource pool is not ready.
Resource pool quiesced
true
The resource pool is quiesced. No new resources are provisioned for the resource pool.
false
The resource pool is not quiesced.
```
**62**   Resource Management task


```
Instance Details
Use SNA APPLID (standard templates only)
true
Derive the software service instance name prefix from the SNA application ID.
false
Do not derive the software service instance name prefix from the SNA application ID.
This value is always false if a network administrator was not specified for the domain.
Software service instance subsystem name prefix
The appropriate value is used in the name of a software services instance when it is created from a
template that is associated with the shared resource pool.
Maximum number of software services instances
Maximum number of software services instances that are allowed: up to 1296 for a standard
template, or up to the lowest maximum that was set for the associated child templates, for a
composite template.
Maximum number of software services instances for a user
Maximum number of software services instances that are allowed for a single user. If no value is
specified, the only limit for a standard template is the one for Maximum number of software services
instances.
Actual number of software services instances
Actual number of software services instances that exist.
Maximum days to keep provisioned software services instances
Maximum number of days until a provisioned instance expires. When a provisioned instance exceeds
this time limit, it is marked as expired, and the instance is placed in provisioned-expired state. This
limit applies to both standard and composite templates.
When an instance for which a time limit is set nears its time limit, z/OSMF notifies the consumer, who
can then deprovision the instance. By default, no time limit is set; a provisioning instance is retained
until it is deleted explicitly by the domain administrator.
The domain administrator can modify this time limit. Doing so changes the time limit for provisioned
instances that are created after the modification. Existing instances are not affected.
If you do not specify a value, the provisioned instance does not expire automatically unless a time
limit is set for the template that creates the instance.
Allow members of the tenant to access and run actions for software services instances
Indicates whether members of the tenant can view and perform actions against software services
instances that are provisioned from the template. If this option is not selected, users must be owners
of the template or domain administrators to have that authority.
```
```
Allow Modify Account
Allow account information to be modified when the template is provisioned
Indicates if the account information can be modified when a template is provisioned with a Test Run
or Run action. For a composite template, this option is true if it is true for any of its child templates.
```
**History**

```
The History tab shows a history of the actions that were performed on the template and resource pool.
```
_Table 50. Columns in the History table_

**Column Description**

**Type** Type of action that is taken on the template or resource pool, such as "modify.”

**Ran by User** User ID under which the action was performed.

```
Resource Management task   63
```

```
Table 50. Columns in the History table (continued)
```
```
Column Description
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
```
Job Statement JCL
Customized JOB statement JCL (standard templates only)
JCL that will be used in jobs for the resource pool. The job name can use workflow variables:
${_workflow-softwareServiceInstanceName}
Software service instance name
${_workflow-workflowOwner}
Workflow owner
${_step-stepOwner}
Workflow step owner
```
```
Resource Management
Create network resource pool (standard templates only)
Indicates if a network pool should be created. This value is always false if a network administrator
was not specified for the domain.
Network pool status
Status of the network pool.
Create workload management pool (standard templates only)
Indicates if a workload management pool should be created.
Workload management pool status
Status of the workload management pool.
Service level agreement
Service level agreement for the workload management pool. Specifies the level of performance that
the software services instance requires.
PLATINUM
Highest
GOLD
High
SILVER
Intermediate
BRONZE
Low
Report class
WLM report class for the workload management pool.
Create LPAR resource pool
Select this option to cause a logical partition (LPAR) resource pool for the template to be created. An
LPAR pool defines LPAR resources within the domain. This option creates a table that allows you to
add, modify, or remove volumes and other resources for the LPAR pool.
The LPAR pool can only be used by z/OS provisioning templates.
```
```
Systems
System selection for provisioning
Select an option for selecting the system on which the software service is provisioned.
```
**64**   Resource Management task


```
Use a specific system
Select a system on which the template is to be provisioned, in the System field.
Assign system automatically
Select a system from a list of available systems.
Systems for domain: domain-name
The available systems are shown in the form sysplex-name. system-name. LOCAL indicates the
system that you are logged on to.
The Systems for domain table shows the set of systems for the domain, for a standard
template, and the systems that are common to all of the child templates, for a composite
template.
Use Add or Remove to build the set of systems from which one will be automatically assigned
for provisioning.
For a clustered composite template, all of the selected systems must exist in the same
sysplex.
Systems for automatic assignment
The Systems for automatic assignment table shows the set of systems from which a system is
assigned.
Prompt user for system
Use tables of available and selected systems to control the systems to be displayed in a prompt in
response to the Run or Test Run action for a template.
Systems for domain: domain-name
The Systems for domain table shows the full set of systems for the domain, in the form
sysplex-name. system-name. LOCAL indicates the system that you are logged on to.
Use Add or Remove to build the list of systems that will be included in the user prompt. The
user can select from that list.
Systems for user prompt
The Systems for user prompt table shows the systems that are included in the user prompt.
Allow resources to be relocated to other systems
Select this to specify that the template's instances can be relocated to another system in the sysplex,
meaning that the template's instances can each run on a system in the sysplex other than the system
that it was provisioned on. The candidate systems are managed in the resource pool for the tenant
in which the template is created. You cannot select this option for a standard template if there are
provisioned instances for the template.
```
#### Create storage resource pool

```
When you add or modify a template and resource pool for tenants, or for a domain-shared resource pool,
you have the option to create a storage resource pool. To do so, use the Resource Pools tab.
```
**Data set attributes table**

```
When you check the box to create a storage resource pool while on the Resource Pools tab, you are able
to use the data set attributes table to add, modify, or remove data set attributes associated with your
storage resources. After the storage resource pool is defined with the appropriate data set attributes as
described by the template, at provisioning time the template can dynamically obtain data set attributes by
using the Resource Management services Get data set attributes REST API. See the IBM z/OS Management
Facility Programming Guide for information about the REST API. See Table 51 on page 65 for details
about the data set attributes table.
```
```
Table 51. Fields on the data set attributes table
```
```
Field Description
```
```
Type The type of data set to be allocated.
```
```
Resource Management task   65
```

```
Table 51. Fields on the data set attributes table (continued)
```
```
Field Description
```
```
Size The size of the allocated data set. You can allocate
a SMALL, MEDIUM, or LARGE data set.
```
```
Volume The volume on which the data set resides.
```
```
Data Class The name of the data set allocation attribute that
SMS assigns to a data set when it is created.
```
```
Storage Class The name of the data set storage service attribute
that identifies performance and availability
requirements. SMS uses these attributes to control
data placement.
```
```
Management Class The name of the management attribute that
SMS uses to control DFSMShsm actions for data
set retention, migration, backup, and release of
allocated but unused space.
```
```
Description A description of the storage resource.
```
```
Table 52. Actions on the data set attributes table
```
```
Action Description
```
```
Add Using the Add action, you can add storage
resources to the data set attributes table. See “Add
storage resources to the data set attributes table”
on page 66.
```
```
Modify Using the Modify action, you can modify storage
resources on the data set attributes table.
See “Modify storage resources on the data set
attributes table” on page 68.
```
```
Remove Storage resources on the data set attributes
table can be removed by selecting Remove
from the table actions menu. You can also
remove everything in the data attributes table by
unchecking the checkbox next to Create storage
resource pool. If you click OK, all of the entries
from the data set attributes table are removed.
```
```
Add storage resources to the data set attributes table
When you create a shared or dedicated pool, you can add storage resources. Storage resources can be
added to the data set attributes table by selecting Add from the table actions menu.
```
**Add storage resource**

```
Table 53. Fields on the add storage resource page
```
```
Field Description
```
```
Type Type of data set to be allocated. You can select
from one of the predefined types: SEQUENTIAL,
PDS, PDSE, VSAM. Or, you can define a different
data set type in this field.
```
**66**   Resource Management task


_Table 53. Fields on the add storage resource page (continued)_

**Field Description**

Size Size of the allocated data set. Select SMALL,
MEDIUM, or LARGE.

Volume If you plan to use a volume for the data set, enter
the volume name in this field. It must follow the
z/OS naming convention. If you specify a volume,
it is assumed that the storage resource is non-SMS
managed.
Otherwise, if you plan to use SMS-managed
storage, leave this field empty.

Data Class If you plan to use SMS-managed storage, you must
enter a data class, storage class, or both. You can
enter the data class in this field. This value is the
data set allocation attribute that SMS assigns to
the data set when it is created.
This field is disabled if you specify a volume.

Storage Class If you plan to use SMS-managed storage, you
must enter a data class, storage class, or both.
You can enter the storage class in this field.
This value is the name of the data set storage
service attribute that identifies performance
and availability requirements. SMS uses these
attributes to control data placement.
This field is disabled if you specify a volume.

Management Class If you plan to use SMS-managed storage, you
can optionally specify a management class for
the storage resource. This value is the name
of the management attribute that SMS uses to
control DFSMShsm actions for data set retention,
migration, backup, and release of allocated but
unused space.
Otherwise, you can leave this field empty.
This field is disabled if you specify a volume.

Description You can optionally provide a description of the
storage resource.

```
Resource Management task   67
```

```
Modify storage resources on the data set attributes table
When you create a shared or dedicated pool, you can add storage resources. Storage resources on the
data set attributes table can be modified by selecting Modify from the table actions menu.
```
**Modify storage resource**

```
Table 54. Fields on the Modify storage resource page
```
```
Field Description
```
```
Type Type of data set to be allocated. You can select
from one of the predefined types: SEQUENTIAL,
PDS, PDSE, VSAM. Or, you can define a different
data set type.
```
```
Size Size of the allocated data set. Select SMALL,
MEDIUM, or LARGE.
```
```
Volume If you plan to use a volume for the data set, enter
the volume name in this field. It must follow the
z/OS naming convention. If you specify a volume,
it is assumed that the storage resource is non-SMS
managed.
Otherwise, if you plan to use SMS-managed
storage, leave this field empty.
```
```
Data Class If you plan to use SMS-managed storage, you must
enter a data class, storage class, or both. You can
enter the data class in this field. This value is the
data set allocation attribute that SMS assigns to
the data set when it is created.
This field is disabled if you specify a volume.
```
```
Storage Class If you plan to use SMS-managed storage, you
must enter a data class, storage class, or both.
You can enter the storage class in this field.
This value is the name of the data set storage
service attribute that identifies performance
and availability requirements. SMS uses these
attributes to control data placement.
This field is disabled if you specify a volume.
```
```
Management Class If you plan to use SMS-managed storage, you
can optionally specify a management class for
the storage resource. This value is the name
of the management attribute that SMS uses to
control DFSMShsm actions for data set retention,
migration, backup, and release of allocated but
unused space.
Otherwise, you can leave this field empty.
This field is disabled if you specify a volume.
```
```
Description You can optionally provide a description of the
storage resource.
```
**68**   Resource Management task


#### Add LPAR pool entry

```
When you add or modify a template and resource pool for tenants or a shared resource pool, you have the
option to create a logical partition (LPAR) resource pool. To do so, use the Resource Pools tab.
When you provision a z/OS instance, you must associate the instance with a logical partition (LPAR) in
your enterprise. Using the Hardware Management Console (HMC), locate an existing LPAR for provisioning
a z/OS instance, or define a new LPAR for this purpose.
To define an LPAR to the LPAR resource pool, select the table action Add Entry while on the Resource
Pools tab. Doing so displays a tabbed window that you can use to add, modify, or remove attributes that
are associated with an LPAR pool.
The Add LPAR pool entry window displays tabbed sections for specifying the following attributes of an
LPAR:
```
- General attributes; see “About the General tab” on page 69.
- System residence (SYSRES) volume; see “SYSRES tab” on page 70.
- Operational data sets; see “Operational tab” on page 71.
- Storage management subsystem (SMS) data sets; see SMS tab
- Job entry subsystem (JES) data sets; see “JES2 tab” on page 73.
- Coupling facility couple data sets; see “Couple Data Sets tab” on page 75.
- Network resources; see “Network tab” on page 75.
You can work with the different attributes of the LPAR by selecting the appropriate tab. The **General** tab is
selected by default.

**About the General tab**

```
The General tab shows in tabular format the general attributes for an LPAR to be defined to the LPAR
pool. If an attribute is not currently defined, the associated field is blank.
To define the general attributes for the LPAR pool, specify values in the input fields, as follows:
Partition name
Specify the name of the partition, which can be 1 - 64 characters in length. Supported characters are
alphanumerics, blanks, periods, underscores, dashes, or at symbols (@). Names cannot start or end
with blank characters. A partition name must uniquely identify the partition from all other partitions
that are defined on the same IBM Z server.
CPC name
Specify the name of the central processing complex (CPC) or server.
System name
Specify the name of the provisioned z/OS system. The name must be 1 - 8 characters long; the valid
characters are A-Z, 0-9, $, @, and #. The name that is specified remains in effect during the IPL.
Size
Specify the size of real storage assigned to each LPAR as defined by the system initialization
parameter:
```
- Small (1-2 CPs)
- Medium (3-4 CPs)
- Large (5 or more CPs)
**Group**
Optionally, specify a string value for the LPAR group name. You might use this field to group or
categorize the LPAR entries that you create, such as "DevOps Systems" or "QA Systems."
**Description**
Optionally, enter a user-supplied description of the partition. The description can be up to 1024
characters in length.

```
Resource Management task   69
```

```
Ensure that the values you specify are valid.
When you finish entering information in this tab, use one of the available actions to save the input data or
click Cancel to cancel your changes. Table 55 on page 70 describes the available actions for the General
tab.
```
```
Table 55. Available actions for the General tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Cancel Cancel the changes and exit the tab.
```
```
SYSRES tab
The SYSRES tab in the Add LPAR pool entry window displays information about one or more SYSRES
volumes on the source z/OS system. On this tab, you can add or remove SYSRES volumes for the LPAR
pool.
```
**About the SYSRES tab**

```
The z/OS software as supplied by IBM is installed in a series of disk volumes that are known as the system
residence (SYSRES) volumes. The SYSRES tab shows in tabular format the SYSRES volumes and SYSRES
distribution library (DLIB) volumes for the LPAR pool. If no volumes are currently defined, the volume
tables are blank.
To add a SYSRES volume to the LPAR pool, specify the volume serial (VOLSER) number and device
address in the input fields. Then click Add to add the volume to the volume table.
```
- In the **SYSRES** section, define the system residence volumes for the provisioned system. If all the
    SYSRES data sets do not fit on a single DASD volume, you can use additional volumes as "logical
    extensions" to SYSRES.
- In the **SYSRES DLIB** section, define the volumes to be used for the distribution library data sets for the
    z/OS system.
Notice that you can remove a volume by using the **Remove** action.
Ensure that the values you specify are valid. The volume serial number of a volume must be 6 characters
of uppercase letters or numbers, and can include the characters @, #, and $. The device number is a 3- or
4-character hexadecimal number.
Ensure that the volumes you specify are large enough to store the operational data sets and distribution
library data sets.
When you finish entering information in this tab, use one of the available actions to save the input data or
click **Cancel** to cancel your changes. Table 56 on page 71 describes the available actions for the **SYSRES**
tab.

**70**   Resource Management task


```
Table 56. Available actions for the SYSRES tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Cancel Cancel the changes and exit the tab.
```
**Operational tab**

The **Operational** tab in the **Add LPAR pool entry** window displays information about the operational
volumes on the source z/OS system. On this tab, you can define operational volumes for the LPAR pool.

**About the Operational tab**

In a z/OS system, the operational data is contained in system data sets, such as parmlib and proclib,
and page and dump data sets. These data sets are known collectively as the _operational data sets_.
The **Operational** tab shows in tabular format the operational data set volumes for the LPAR pool. If no
volumes are currently defined, the volume tables are blank.

To specify volumes for the LPAR pool, specify each volume and device address in the input fields, as
follows:

**Operational section**
Specify the volume and device address for the operational data sets.

**Operational zFS section**
Specify the volume and device address for the operational z/OS file system (zFS) data sets.

**Standalone dump**
Specify the volume and device address for the standalone dump. A standalone dump is used to store
a copy of the system storage for debugging a programming error.

Ensure that the values you specify are valid. The volume serial number of a volume must be 6 characters
of uppercase letters or numbers, and can include the characters @, #, and $. The device number is a 3- or
4-digit number.

Ensure that the volumes you specify are large enough to store the operational data sets and standalone
dump.

When you finish entering information in this tab, use one of the available actions to save the input data
or click **Cancel** to cancel your changes. Table 57 on page 71 describes the available actions for the
**Operational** tab.

```
Table 57. Available actions for the Operational tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Resource Management task   71
```

```
Table 57. Available actions for the Operational tab (continued)
```
```
Action Description
```
```
Cancel Cancel the changes and exit the tab.
```
```
SMS tab
The SMS tab in the Add LPAR pool entry window displays information about the SMS volumes. On this
tab, you can define the SMS volumes for the LPAR pool.
```
**About the SMS tab**

```
In a z/OS system, the Storage Management Subsystem (SMS) changes the storage management approach
from user-managed volumes to SMS-managed data sets residing in SMS-managed storage groups. The
system, rather than the user, determines data placement and handles data backup, movement, space,
and security. For a provisioned z/OS system, you must define the volume and device address for the SMS
system, as well as the source control data set, active control data set, and communications data set.
To specify the SMS volume for the LPAR pool, specify the volume serial and device address in the input
fields, as follows:
Volume
Specify the volume serial for the volume to be added to the storage pool. The volume names consist
of up to six uppercase alphanumeric characters.
Device address
Specify the device address for the volume to be added to the storage pool. The device address
consists of up to four uppercase alphanumeric characters.
A basic SMS configuration will be provided for the target LPAR. This will define the SMS automatic class
selection (ACS) routines, which automatically assign the SMS classes and storage groups to data sets. It
will also provide the following storage classes and groups required for configuration:
```
- **Data class** : A list of allocation attributes that the system uses for the creation of data sets.
- **Storage class** : A list of storage performance and availability service requests.
- **Management class** : A list of data set migration, backup, and retention attributes that DFSMShsm uses
    to manage storage at the data set level.
- **Storage group** : A list of real DASD volumes, or a list of serial numbers of volumes that no longer reside
    on a system but that end users continue to refer to in their JCL.
For an LPAR pool, you must specify the operational volume for the SMS active control data set (ACDS)
and communications dataset (COMMDS) , as well as the operational volume for the source control dataset
(SCDS). The same volume and device may be specified for both fields if you so choose.
**SMS 1 volume**
    Specify the volume that will be used to allocate the ACDS and COMMDS.
**SMS 1 device address**
    The device for the SMS ACDS and COMMDS.
**SMS 2 volume**
    Specify the volume that will be used to allocate the SCDS.
**SMS 2 device address**
    The device for the SMS CDS.
When you finish entering information in this tab, use one of the available actions to save the input data
or click **Cancel** to cancel your changes. Table 58 on page 73 describes the available actions for the **SMS**
tab.

**72**   Resource Management task


```
Table 58. Available actions for the SMS tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Cancel Cancel the changes and exit the tab.
```
**JES2 tab**

The **JES2** tab in the **Add LPAR pool entry** window displays information about the JES2 volumes. On this
tab, you can define the JES2 volumes for the LPAR pool.

**About the JES2 tab**

In a z/OS system, the Job Entry Subsystem (JES2) receives jobs for the operating system, schedules
them, and manages their output. For a provisioned z/OS system, you must define volumes for the JES2
checkpoint and spool data sets.

Checkpoint data sets are used for backup to the in-storage job and output queues. The checkpoint data
sets should reside on high-speed, low-usage devices. If available, the best location for each data set is on
a dedicated 3390 device. To obtain optimum performance, the checkpoint data sets should be the only
data sets on their respective DASD volumes.

To specify the checkpoint volumes for the LPAR pool, specify each volume and device address in the input
fields, as follows:

**Checkpoint 1 volume**
Specify the volume for the checkpoint 1 (CKPT1) data set. The checkpoint 1 data set is the primary
data set copy of the JES2 checkpoint information.

**Checkpoint 2 volume**
Specify the volume for the checkpoint 2 (CKPT2) data set. The checkpoint 2 data set is used for
either the duplex data set copy (if operating in DUPLEX mode) or the second primary data set copy (if
operating in DUAL mode).

IBM suggests placing the checkpoint data sets on separate volumes to ease recovery. When checkpoint
data sets are physically removed from one another, they have separate power sources, separate control
units, and no single common point of failure.

In a z/OS system, the spool (or _simultaneous peripheral operations online_ ) is the repository for all input
jobs and all system output (SYSOUT) that JES2 manages. It is where JES2 stores bulk data (SYSOUT/
SYSIN/JCL data sets) and major control blocks (JCT, IOT, and others). The spool consists of 1 or more
volumes, with each volume containing one SPOOL data set.

Spool volumes are identified to JES2 by a volume serial number, the first four or five characters of which
are specified by the VOLUME= parameter on the SPOOLDEF statement during JES2 initialization. The first
four or five characters of each volume serial number must be identical to the characters specified by the
VOLUME= parameter. The fifth and sixth characters can be assigned to designate individual spool volumes
and can be any characters that are valid in a volume serial number.

For an LPAR pool, you must specify at least one spool volume, and optionally a second spool volume. The
spool volume names consist of six uppercase letters, numbers, or the characters @, #, and $. The device
number is a 3- or 4-digit number.

**Spool 1 volume**
Specify the volume for the spool data sets.

```
Resource Management task   73
```

```
Spool 2 volume
Optionally specify a second volume for spool data sets.
If you specify a second volume for spool data sets, ensure that each volume name matches in the first 4
or 5 characters. This convention allows the JES2 spool definition to use multiple volumes.
Ensure that the volumes you specify are large enough to store the JES2 data sets. For considerations, see
JES2 Initialization and Tuning Guide.
Performance can be degraded if the checkpoint data sets reside on a SPOOL volume; avoid placing a
checkpoint data set on a volume with a SYS1.HASPACE data set. SYS1.HASPACE is used for storing JES2–
maintained data and control blocks. SYS1.HASPACE is the JES2 default name, but your installation can
specify a different name on the DSNAME= parameter of the SPOOLDEF initialization statement.
You can also configure Network job entry (NJE) with Transmission Control Protocol/Internet Protocol
(TCP/IP) support to allow transmitting commands, messages, and jobs between the provisioned target
LPAR and NJE configured nodes.
For each LPAR pool entry, you must specify the node name and OWNNODE values for each instance that
represents the local node. The node name consists of up to eight uppercase alphanumeric or special ($,
#, or @) characters. The OWNNODE is an integer with valid values of 1 to 32767. The value must be less
than or equal to the NODENUM value and must be unique for each NJE node.
The requested action cannot be performed because the action failed during field substitution.
Node name
The JES2 local node name.
OWNNODE
The JES2 node number that is assigned to the local node.
You can specify the NJE target nodes to configure by adding value pairs of Node name and IP address /
hostname to the NJE target nodes table. The node name consists of up to eight uppercase alphanumeric
or special ($, #, or @) characters. Values must be unique for each node.
Node name
The JES2 local node name.
IP address / hostname
The IP address or fully qualified hostname of the node.
When you finish entering information in this tab, use one of the available actions to save the input data or
click Cancel to cancel your changes. Table 59 on page 74 describes the available actions for the JES2
tab.
```
```
Table 59. Available actions for the JES2 tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Cancel Cancel the changes and exit the tab.
```
**74**   Resource Management task


**Couple Data Sets tab**

The **Couple Data Sets** tab in the **Add LPAR pool entry** window displays information about the couple data
set volumes. On this tab, you can define couple data set volumes for the LPAR pool.

**About the Couple Data Sets tab**

In a z/OS system, a couple data set (CDS) provides a central shared repository of data that must be visible
to every system in the sysplex. A sysplex requires a sysplex couple data set to store information about
its systems, the XCF groups and members that are running in the sysplex, and general status information.
For a provisioned z/OS system, you must define volumes for both the primary couple data set and the
alternate couple data set.

To avoid a single point of failure in the sysplex, specify an alternate couple data set on a different volume
than the primary. Information about the sysplex and the services that use couple data sets is maintained
in both the primary and alternate couple data sets concurrently. If the primary data set fails, the sysplex
automatically makes the alternate the primary.

To specify the couple data set volumes for the LPAR pool, specify each volume and device address in the
input fields, as follows:

**Primary couple data set**
Specify the volume and device address for the primary couple data set.

**Alternate couple data set**
Specify the volume and device address for the alternate couple data set.

Ensure that the values you specify are valid. The volume serial number of a volume must be 6 characters
of uppercase letters or numbers, and can include the characters @, #, and $. The device number is a 3- or
4-digit number.

Ensure that the volumes you specify are large enough to store the couple data sets. For considerations,
see _z/OS MVS Setting Up a Sysplex_.

When you finish entering information in this tab, use one of the available actions to save the input data or
click **Cancel** to cancel your changes. Table 60 on page 75 describes the available actions for the **Couple
Data Sets** tab.

```
Table 60. Available actions for the Couple Data Sets tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
```
Cancel Cancel the changes and exit the tab.
```
**Network tab**

The **Network** tab in the **Add LPAR pool entry** window displays information about the network resources.
On this tab, you can define the network resources for the LPAR pool.

**About the Network tab**

You must identify the network resources to be associated with the LPAR.

To specify the IPv4 address for the LPAR pool, specify values for the following input fields:

```
Resource Management task   75
```

```
IP address
Specify the IP address to be used as the home address for the system.
Route
Specify the route address. The networks to which the host is directly attached are called direct routes.
Default route
Specify the default route address. The default route entry contains the IP address of the first router
(the next hop) to be used when the destination IP address or network is not found in the direct or
indirect routes.
A domain name system (DNS) is a standard by which names that are used on the internet are resolved
to their corresponding IP addresses. A DNS hostname is a unique name for the server. It consists of a
hostname and a domain name.
To define a DNS for the LPAR pool, specify the DNS information, as follows:
Hostname
Specify the hostname for the system (the endpoint).
Domain name
Specify the domain name for the system network.
Enter the virtual network ID for this logical partition (LPAR) in the VLAN ID field. The valid range for the
ID is 1 to 4096. This field is valid with the installation of the PTF for APAR PH40058, which is available for
z/OS V2R3, V2R4, and V2R5.
In an LPAR, each port must have its own unique TRLE definition, with unique read, write, and datapath
channel unit addresses. The port name is the name that is assigned to this port. To define the TRLE
information for the LPAR pool, specify the following information:
TRLE name
Specify the Transport Resource List Element (TRLE) name, which is 1 - 5 characters. The first 1 - 4
characters determine the prefix for the TRLE names that are added to the TRL major node (ISTTRL).
The last character must be an asterisk (*).
TRLE portname
Specify the Transport Resource List (TRL) port name, which is 1- 8 characters.
TRLE device read
Specify the channel-unit address for the network communication read function (4 characters).
TRLE device write
Specify the channel-unit address for the network communication write function (4 characters).
TRLE device datapath
Specify the channel-unit address for the network communication data flow (4 characters).
SSCPID
Specify the SSCPID, which is a unique numeric identifier for the VTAM configuration. The SSCPID
value is used by some physical units to identify the VTAM with which it is in session.
When you finish entering information in this tab, use one of the available actions to save the input data
or click Cancel to cancel your changes. Table 61 on page 76 describes the available actions for the
Network tab.
```
```
Table 61. Available actions for the Network tab
```
```
Action Description
```
```
Save Save the information that is specified in the tab.
If not all required fields are completed, this action
saves the partial input so that you can return later
to complete this tab.
```
```
Complete Save the information that is specified in the tab,
and exit the tab. The data cannot be saved until
you complete all of the required fields.
```
**76**   Resource Management task


```
Table 61. Available actions for the Network tab (continued)
```
```
Action Description
```
```
Cancel Cancel the changes and exit the tab.
```
#### Quiesce a resource pool

```
To pause the provisioning of new resources for a resource pool, you can use the Quiesce action. You
might quiesce a resource pool in preparation for deleting it, when there are no resources provisioned for
the resource pool.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. Click **Actions** , then select **Modify**.
4. To quiesce a resource pool for a tenant or domain, select the appropriate action, as follows:
    - For a tenant:
       a. Click the **Tenants** tab.
b. In the Tenants table, select the appropriate row, click **Actions** , and then select the appropriate
action, as follows:
- For a shared resource pool, select the tenant and then use the **Shared Resource Pool** action
with a Quiesce option. Shared resource pools have names ending with an asterisk (*).
- For a dedicated resource pool, select the tenant, then use the **Modify** action for the tenant.
On the **Modify Tenant** window, click the Dedicated Resource Pools tab. In the resulting table,
select the appropriate row, then use the **Quiesce Dedicate Pool** action.
- Click **Actions** , then select **Shared Resource Pools** , then select **Quiesce Shared Pool**.
    - For a domain-shared resource pool:
       a. Click the **Shared Resource Pool** tab.
b. In the table, click **Actions** , then select **Quiesce Shared Pool**.

```
Results
The shared resource pool is quiesced, which is indicated by this before the resource pool name.
```
```
What to do next
You can unquiesce a quiesced resource pool. Use the Unquiesce option of the appropriate action.
If you want to delete the shared resource pool, there must not be any currently provisioned resources for
the pool.
```
#### Metering and capping

```
You can enable metering and capping for a tenant.
Metering provides CPU consumption for the tenant. Capping provides the ability to cap CPU resource
consumption by the tenant for all services that are deployed by the tenant. You can enable either or both.
To enable metering or capping, you use fields on the Create Tenant or Modify Tenant pages. A workload
administrator must have been specified for the domain that the tenant is associated with.
For capping, you specify a CPU capping type (based on LPAR share percentage, service units, number of
CPs, or MSUs) and a CPU capping limit. For details, see “Create a tenant” on page 39.
```
```
Resource Management task   77
```

```
When metering is enabled, you can view the metered CPU use for a tenant by using the View Metered
Usage action for the tenant in the tenant's table. Data for this view is retrieved from a single data server
on one system in the sysplex. That data server gathers data from the RMF™ Monitor III data gatherer on
each image in the sysplex. This function is called the Distributed Data Server (DDS). For more information,
see the help for the Resource Monitoring task.
```
**Enabling metering**

```
Before you begin
A workload administrator must have been defined for the domain.
```
```
About this task
You can enable metering when you create or modify a tenant. Use this procedure as a quick way to control
metering.
```
**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. In the Tenants table, select a tenant.
4. Click **Actions** , select **Metering** , then select **Enable**.
    A WLM tenant resource group is created when a tenant is created with metering (or capping) enabled.
    For more information, see “Restrictions and other considerations for Solution ID, Metering, and
    Capping” on page 80.

```
What to do next
You can view metered CPU use for the tenant by selecting the View Metered Usage action for the tenant.
```
```
View Metered Usage window
Use the View Metered Usage window to specify values for viewing CPU and memory use for the tenant.
Time frame
Using the time zone of the system the RMF DDS server is running on, specify either a beginning date
and time or a date and time range for the data.
The view cannot include data for a time prior to when metering was enabled for the tenant.
Data sample range
Specify the range of a sample, in hh : mm format, where hh is a number of hours and hh is a number of
minutes. The default is 00:15 (15 minutes).
```
```
Viewing metered usage
The View Metered Usage page shows metered CPU use for the tenant in graphical form.
Each bar in the graph indicates a sample, the range (interval) for which you specified on the View Metered
Usage window. A key below the graph describes the colors used in the graph, and lets you select either
or both types of processor to include in the graph. When you select both, the bar is stacked, with IBM
z Integrated Information Processor (zIIP) use on the top and general processor (CP) use on the bottom.
Hover the mouse pointer over the bar to see the numerical value.
The time and date of the sample is indicated on the X (horizontal) axis. Use the X axis scroll to scroll the
graph right and left.
Use the Y axis scroll to zoom the Y (vertical) axis. For example, when the bars are too short to be useful,
zoom in to make them taller. You can control the units of the Y axis with the value that you select for
Metrics Display.
```
**78**   Resource Management task


There is a tab for each system, above the graph. Click a tab to see the graph for that system.

**Enabling memory and CPU capping**

Use capping to limit the use of resources by a tenant.

**Memory capping**

To enable memory capping, specify the value for the capping limit, in gigabytes.

**CPU capping**

To enable CPU capping, specify a capping type and then specify the value for the capping limit.

```
Table 62. CPU capping types and values
```
```
CPU Capping Type Description Values for
Capping Limit
```
```
LPAR share percentage The capacity is specified as a percentage of the LPAR
share in the general-purpose processor pool.
```
##### 0.01-999.99

```
Service unit The capacity is specified in unweighted CPU service
units per second.
```
##### 1-99,999,999

```
CP A number of general-purpose processors (CPs),
including numbers with up to two decimal places.
```
```
0.01 to 9,999.99
```
```
MSU The capacity is specified as millions of service units per
hour.
```
##### 1-999,999

**How to enable capping**

**Before you begin**
A workload administrator must have been defined for the domain.

**About this task**
You can enable capping when you create or modify a tenant. Use this procedure as a quick way to control
capping.

**Procedure**

1. Select and double-click the **Resource Management** task from the z/OSMF desktop. If the **Resource**
    **Management** task is not displayed on the desktop, select it from the App Center in the taskbar.
2. In the Domains table, select a domain.
3. In the Tenants table, select a tenant.
4. Click **Actions** , select **Capping** , then select **CPU** or **Memory** , then **Enable**.
5. On the resulting window, supply values. See Table 62 on page 79.
6. Click **OK** to enable capping.
    A WLM tenant resource group is created when a tenant is created with capping (or metering) enabled.
    For more information, see “Restrictions and other considerations for Solution ID, Metering, and
    Capping” on page 80.

```
Resource Management task   79
```

**Restrictions and other considerations for Solution ID, Metering, and Capping**

```
In some cases, the Resource Management task handles the creation or deletion of tenant resource groups
in the WLM service definition for you. This has implications for modifying the solution ID, metering and
capping.
Supplying values or enabling options: Supplying a solution ID or enabling metering or capping causes
a tenant resource group to be created in the WLM service definition. A tenant resource group cannot be
created when software instances are already provisioned for the tenant. So, you cannot supply a value for
Solution ID, or enable metering or capping, if all of the following are true:
```
- Software instances have already been provisioned for the tenant
- No solution ID was previously supplied
- Metering was not previously enabled
- Capping was not previously enabled.
When you successfully supply a solution ID or enable metering or capping, the effect is as follows:
- If you specify a Solution ID, CPU use by current and future software instances that are associated with
    templates that exploit the WLM classification rule REST API is associated with the pricing container that
    is identified by the solution ID.
- If you enable metering, CPU use by current and future software instances that are associated with
    templates that exploit the WLM classification rule REST API is displayed with the **View Metered CPU**
    **Use** action for a tenant.
- If you enable capping, CPU use by current and future software instances that are associated with
    templates that exploit the WLM classification rule REST API is capped to the capping value that is
    specified for the tenant.
**Removing values or disabling options:** Similarly, removing a solution ID and disabling metering or
capping causes a tenant resource group to be deleted from the WLM service definition. A tenant resource
group cannot be deleted when software instances are already provisioned for the tenant. So, you cannot
remove the Solution ID, or disable metering or capping, if all of the following are true:
- Software instances have already been provisioned for the tenant
- Removing the solution ID or disabling metering or capping would mean that the value for Solution
    ID would be blank and both metering or capping would be disabled. For example, if a solution ID
    is provided and both options are disabled, you can remove the solution ID and disable capping. You
    cannot then disable metering. Or, you could disable both options, but not then remove the solution ID.
When you successfully remove the solution ID or disable metering or capping, the effect is as follows:
- If the you remove a solution ID, all software instances that were previously associated with the pricing
    container are disassociated from the pricing container.
- If you disable metering, CPU use of current and future software instances is not reported when you use
    the **View Metered CPU Use** action for a tenant.
- If you disable capping, CPU use of current and future software instances is not capped.

**80**   Resource Management task


## Index

**A**

adding
resource pools to tenants 42
shared resource pools to tenants 54
templates to tenants 42

**C**

capping CPU consumption
tenants 77
Cloud Provisioning tasks
Resource Management 1
CPU consumption of tenants
capping 77
metering 77
creating
domains 1, 23
shared resource pools for tenants 54
tenants 1, 39

**D**

defining
domains 1
tenants 1
domains
creating 23
defining 1
modifying properties of 14
viewing properties of 6

**M**

metering CPU consumption
tenants 77
modifying
properties of domains 14
properties of tenants 35
resource pools for tenants 46
shared resource pools for tenants 58
templates for tenants 46

**Q**

quiescing
resource pools for tenants 77

**R**

Resource Management task
procedure for using 4
resource pools
adding templates
removing templates 58
adding to tenants 42, 54, 58

```
resource pools (continued)
modifying 58
modifying for tenants 46
quiescing 77
shared 54, 58, 62
viewing 62
viewing for tenants 50
resources for Cloud Provisioning
managing 4
```
**S**

```
shared resource pools
adding templates 54, 58
creating 54
modifying 58
removing templates 58
viewing 62
```
**T**

```
templates
adding to shared resource pools 54, 58
adding to tenants 42
modifying for tenants 46
removing from shared resource pools 58
viewing for tenants 50
tenants
adding resource pools 42
adding templates 42
capping CPU consumption 77
creating 39
creating shared resource pools 54
defining 1
metering CPU consumption 77
modifying properties of 35
modifying resource pools 46
modifying shared resource pools 58
modifying templates 46
quiescing resource pools 77
viewing properties of 30
viewing resource pools 50
viewing shared resource pools 62
viewing templates 50
```
**V**

```
viewing
properties of domains 6
properties of tenants 30
resource pools for tenants 50
shared resource pools for tenants 62
templates for tenants 50
```
```
Index   81
```

IBM®


## Software Services task

# IBM


## Contents

```
Software Services task.......................................................................................... 1
Software Services.........................................................................................................................................1
Composite templates............................................................................................................................. 2
How to use the Software Services task to provision and deprovision software.........................................5
Prepare and publish a template.............................................................................................................5
Use a template to provision software.................................................................................................... 9
Templates ..................................................................................................................................................10
Add a template..................................................................................................................................... 15
Files used to define software services templates...............................................................................20
Create a template based on another template................................................................................... 21
Values on the Create Based On window ............................................................................................21
Create a new version of a template..................................................................................................... 22
View a template....................................................................................................................................26
Modify a template.................................................................................................................................39
Edit an actions definition file................................................................................................................42
Using the Edit Actions File window ................................................................................................... 43
Associate a tenant with a template..................................................................................................... 51
Values on the Associate Tenant window ........................................................................................... 51
Approve a template..............................................................................................................................52
Values on the Approvals window ....................................................................................................... 52
Test Run a template............................................................................................................................. 55
Fixing problems with provisioning....................................................................................................... 58
Publish a template............................................................................................................................... 58
Run a template..................................................................................................................................... 60
Archive a template............................................................................................................................... 62
Instances....................................................................................................................................................63
View instance........................................................................................................................................65
Perform an action for an instance........................................................................................................70
Values on the Perform window ...........................................................................................................71
Working with actions............................................................................................................................72
View actions in a software services template..................................................................................... 72
Change the actions definition file for a software services template...................................................72
Create the actions definition file for a software services template.................................................... 73
Edit actions for a software services template..................................................................................... 73
Perform actions for a software services instance............................................................................... 74
```
**Index.................................................................................................................. 75**

**ii**


**Software Services task**

```
The Software Services task provides function for IBM Cloud Provisioning and Management for z/OS. Use
it along with the Resource Management task to provision z/OS® software and to manage the provisioned
software, including deprovisioning.
To get started with the Software Services task, expand the Cloud Provisioning category in the navigation
area, then select Software Services.
```
### Software Services

```
You can use the Software Services task, along with the Resource Management task, to provision z/OS
software such as IBM middleware. You can then manage the software services instances.
```
**Templates and instances**

```
In the Software Services task, you work with:
Templates
A software services template consists of workflows and associated actions and variables that can
be used to provision z/OS software. The original source of the workflow and action definitions is the
software provider. You might modify the files supplied by the provider for your installation. Then, using
the Software Services task, you add (create) a template for your installation.
The list of templates is maintained in the software services catalog.
You define the domain, and add a template to a tenant, using the Resource Management task.
There are these types of templates:
Standard
Use these to provision a single software service.
Composite
Use these to provision more than one type of software service with a single Run operation or to
provision clustered software services. For more information, see “Composite templates” on page
2.
Instances
A software services instance represents software that has been provisioned through the use of
templates. It might be a middleware instance or middleware resource.
To create a software instance from a template, you test run a draft template or run a published
template.
An instance is registered as provisioned in the software services registry. The software services
registry is maintained in the z/OSMF data repository and has a sysplex-wide scope.
```
```
Tabs for the Software Services page
The Software Services page contains an Overview tab, a Templates tab, and an Instances tab.
Overview
This is the initial tab. It provides an overview of software services instances and software services
templates, including:
```
- The templates and instances, grouped by type (for example, IMS or CICS®, or Composite Template,
    for composite templates that include multiple standard templates).
- For each type, a count of templates that are in the draft, published, and archived states.

```
Software Services task   1
```

- Templates that are in a draft state can be modified as needed and then published using the
    Publish action.
- Templates that are in a published state are locked, meaning that they cannot be modified.
    Publishing a template makes it available for consumers. Using the **Run** action for a published
    template provisions the software and creates a corresponding instance.
- For each type, a count of instances that provisioned or deprovisioned.
Click links in the summary information to see associated details. For example, click the number
for **Drafts** to display templates of the same type that are in a draft state, or click the number for
**Published** to see templates of the same type that are in the published state.
**Templates**
This tab shows the software services templates.
**Instances**
This tab shows the software services instances.
**Related tasks**
Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
**Related information**
How to use the Software Services task to provision and deprovision software
This topic provides an overview of the steps for provisioning and deprovisioning software using the Cloud
Provisioning tasks.

#### Composite templates

```
Use composite templates to provision multiple software services with a single Run operation. Use
clustered composite templates to provision multiple software services instances on different systems
within a sysplex. The instances use resources that are defined in the associated resource pool.
```
**Composite templates**

```
Use a composite template to provision multiple related software services with a single Run operation. For
example, you might use a composite template to provision CICS and z/OS Connect. A composite template
contains other templates that are:
```
- Published
- Standard type. A composite template cannot contain other composite templates.
A composite template is associated with a specific domain. The published standard templates that it
contains must be in that domain.
The standard templates that are members of a composite template dictate the sequence that they
provisioned in.
**Variables:** A provider can satisfy prompt variables that are associated with the standard template using
the connectors field. If a prompt variable is also specified as a connector variable, the prompting of that
variable is automatically disabled, because it is satisfied through the connectors field.
The composite template can also take in an optional variable input file, the composite properties file.
This file contains atCreate variable values that are associated with the member standard templates. It
is an alternative to providing the atCreate values with the Run action. The atCreate variable names are
in this format: < _standard-template_ >.< _atcreate-variable-name_ >. If the composite properties file includes
any variables that are associated with standard templates that are not members of the composite,
those variables are ignored. All other variable names are validated to ensure they are atCreate variables
associated with the member template. No validation is done on the values that are associated with the
atCreate variables.

**2**   Software Services task


The precedence of values for the provisioning workflow is as follows. Values that are earlier in the list
override values that are later in the list.

1. Connector and prompt values.
2. Values in the composite properties file.

The precedence of values for the action workflow is as follows:

1. Prompt values.
2. wfVar values that are specified in the actions definition.
3. Values in the composite properties file.

**Resource pools:** Like standard templates, composite templates must be associated with a tenant prior to
being test run and run. The following describes values for the resource pools of a composite template:

**instance name prefix**
Specified by the resource pool for the composite template.

**maximum number of instances**
Specified by the resource pool for the composite template. It cannot exceed the smallest maximum of
all of the standard template resource pools.

**system selection**
Specified by the resource pool for the composite template. The system selection is limited to the
common systems that are referenced by the resource pools of standard templates that are associated
with the composite template. All of the standard templates that are associated with the composite
template are provisioned on the same system.

**account information**
Obtained from the resource pool that is associated with the standard template.

**network resource pool**
Not specified by the resource pool for the composite template.

**workload management resource pool**
Not specified by the resource pool for the composite template.

The resource pools that are associated with the standard templates that are referenced by the composite
template must exist in the same tenant as the composite template.

**Software services instances:** When you use the Run operation for a composite template, multiple
catalog type registry instances are created, one parent and a child for each standard template in the
sequence.

The composite resource pool prefix is applied to the parent software services instance only. The standard
template resource pool prefix is applied to each child software services instance.

An instance count is updated for both the composite resource pool and for each of the standard template
resource pools.

The parent software services instance contains an array of composite registry objects, and each child
includes the parent registry instance object ID.

Once all of the child software services instances are provisioned, the parent software services instance
moves to the provisioned state, and you can use the child software services instances, that is, you can
perform actions against them. The deprovisioning action is allowed only against the parent instance. The
deprovisioning sequence is the opposite of the provisioning sequence.

If any of the children fail provisioning, you can either:

- Deprovision the failed provisioning child along with any child instances that have already been
    provisioned. Any child in the being-initialized state will remain as is – no deprovision action is run
    against it.
- Restart the failed child instance. If the restart is successful, it resumes the provisioning of the remaining
    children instances.

```
Software Services task   3
```

```
Once you have deprovisioned the parent instance (by using the Perform deprovision action against it),
you can delete the parent instance, which also deletes all of the child instances.
Template Versions: When a new version of a standard template that is included in a composite template
is published, any composite template that includes the standard template as a member is archived. The
user then has the option to either re-publish one or more of the affected composite templates or create a
new version of them.
When a standard template that is a member of one or more composite templates is moved out of
published state (with the Archive or Delete actions) and a new standard template is not provided
simultaneously, all affected composite templates are put into missing_required_member state. The
composite templates remain in that state until a version of the missing member is published. The
new version must be a version of the original member that was included in the composite definition.
Once the missing member template is in publish state, the composite template is put into archive
state if only that member template was missing. Otherwise, the composite template remains in
missing_required_member state until all of the member templates are present. From the archive state,
the provider or user can chose to re-publish the archived composite templates if the content of the
standard templates and the connector information is still valid. If the content of the standard templates
and the connector information is no longer valid, the user can create a new version of the archived
composite template. The user should delete the previous version if it is no longer needed.
When all versions of a member template are deleted and a new unrelated standard template is published,
all affected composite templates are put into missing_required_member state. The composite templates
remain in that state indefinitely because there are no versions of the missing member template, and so
the requirement that the member must be a version of the original member of the composite definition
cannot be satisfied. The user can either delete the composite template or create a new version of it.
Usage scenario: Two published templates, template1 and template2, are located in the same domain,
and are associated with the same tenant, with at least one system in common.
```
1. A provider creates a composite template from the published standard templates, specifying template1
    as sequence 1, and template2 as sequence 2, with a connector value, TEMP2_VAR1 = TEMP1_VAR1
    from template1.
2. The provider associates the composite template with the tenant, creates the resource pool, and then
    test runs the template.
3. The provider displays the instances table in the Software Services task. After the parent instance is in a
    provisioned state, the provider performs actions against the child instance for template1.
4. When the instance is no longer needed, the provider uses an action to deprovision the parent instance.
5. Once the parent instance is in a deprovisioned state, the provider removes it. This also removes all of
    the child instances.

```
Clustered composite templates
Clustered composite templates allow you to leverage sysplex capabilities to provision a continuously
available middleware environment. With a single provisioning action, you provision network-clustered
instances of a specific middleware in a sysplex. Similarly, a single deprovision action releases all of the
member instances that are associated with the clustered composite template instance.
You create a clustered composite template from a single published template or from multiple published
templates that use the Use the composite template to cluster instances on systems in a sysplex option
when adding a template. The published templates must all be of the same software type (that is, they
provision the same middleware).
Provisioning a clustered composite template results in each instance of the member templates being
provisioned on a separate system. As a result, the total number of instances defined in a clustered
composite template is limited, based on several factors, including whether the composite template
resides in a single sysplex domain or a multiple sysplex domain. In a single sysplex domain, the total
number of instances cannot exceed the number of systems in the domain or the number of systems
in any of the resource pools that are associated with the clustered composite template definition. In a
multiple-sysplex domain, the maximum number is based on the sysplex that contains the most systems
```
**4**   Software Services task


```
in the domain; the instances will be created in this sysplex. As an example, assume that a domain
encompasses systems on two sysplexes: System 1 on Sysplex A and Systems 2 and 3 on Sysplex B.
Here, the maximum number of clustered instances that can be created is two because Sysplex B has two
systems in the domain.
Clustered composite templates have their own resource pools. z/OS resources for all of the member
instances are obtained from the same resource pool when the clustered composite template is
provisioned. All of the systems in the resource pool must be a member of the same sysplex.
```
### How to use the Software Services task to provision and deprovision

### software

```
This topic provides an overview of the steps for provisioning and deprovisioning software using the Cloud
Provisioning tasks.
The process for provisioning software varies depending on your role.
```
- As a service provider, you prepare a software services template that provisions software. This process
    is described in “Prepare and publish a template” on page 5. Other users, such as a network
    administrator, may also need to be involved to complete this task.
- As a consumer, you provision software using the template that was prepared for you. This process is
    described in “Use a template to provision software” on page 9.
To deprovision software, you use an action on the Instances table. Select **Perform** , then **deprovision**.
You cannot deprovision the child instances of a composite instance (that is, an instance created from a
composite template). Instead, use the **Perform deprovision** action against the composite instance.
**Related tasks**
Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
**Related reference**
Software Services
You can use the Software Services task, along with the Resource Management task, to provision z/OS
software such as IBM middleware. You can then manage the software services instances.

#### Prepare and publish a template

```
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
```
```
Before you begin
You must be a domain administrator, and a suitable domain and tenant must be available.
```
```
About this task
Use the workflow and other files that are provided by the software vendor to create a standard software
services template.
Completing the procedure typically requires users who fulfill several roles: middleware system
programmers, network administrators, and security administrators.
The following procedure describes the basic steps. For more details, see the links for related topics that
follow this topic.
Preparing and publishing a composite template, which contains multiple published standard templates, is
very similar. For more information, see “Add a template” on page 15.
```
```
Software Services task   5
```

```
Procedure
Review and modify the source files. You might need to modify the template, typically using a properties
file, or the input variable file that was supplied by the software provider, to customize things like high-
level qualifiers, security options, other variables, or JCL, and to add approver elements to runAsUser
elements. See the information that is provided by the software provider about what you need to
customize.
You might want to modify a supplied documentation file, or create a documentation file, for use by
consumers or administrators.
You might also want to modify the actions definitions, typically through a properties file that was supplied
by the software provider, to customize the actions for your installation, and to add approver elements
to runAsUser elements. This is discussed in a later step, when you can use an actions editor that is
integrated into the z/OSMF task.
```
1. Before making any changes, make copies of the files, so that you keep a set of files as they were
    originally supplied by the software vendor.
2. Review and modify the source files, typically by modifying properties files and input variables files.
**Ensure that the required IDs have access to the template source files.** Your user ID and the z/OSMF
server user ID both require at least READ authority to the workflow definition file, the workflow variable
input file, and the actions definition file.
3. To verify that the server has access to these files, contact your z/OSMF administrator. By default, the
server user ID is IZUSVR, but your installation might have specified another value for this user ID
during the z/OSMF configuration process.
**Add a template.** You add a template, specifying the files that you customized. To perform this step, you
must be a domain administrator. Domain administrators are defined with the Resource Management task.
4. Expand the Cloud Provisioning category in the z/OSMF navigation area, then select **Software
Services**.
5. Select the **Templates** tab.
6. In the table, click **Add Template** , then **Standard**. If **Add Template** is unavailable, you are not defined
as a domain administrator.
7. On the **Add Template** page, supply the values as appropriate, including the workflow definition file
and the actions definition file that are to be used in provisioning the software, and the domain. Then,
click **OK**. For more information, see “Add a template” on page 15.
**Review the administrator documentation file.** The template may include a documentation file for
administrators. Now that you have added the template, refer to that file for any considerations that might
apply to the remaining steps.
8. In the templates table, click the template name to view the template properties.
9. On the View template page, find the field for the administrator documentation file. If a value is
displayed there as a link, click the link to open the file.
Review the file for anything that you need to do or consider, and respond as appropriate.
**Modify the actions definition file.** Now that you have added the template, you can use an editor in
z/OSMF to modify the actions definition file.
10. On the templates table, select the template, click **Actions** , then select **Modify Template**.
11. On the **Modify Template** window, click **Edit** for the Actions file field.
Use the editor to make changes. Note that there is also an Edit button for the Workflow file field.
**Associate the template with a tenant.** Tenants are created with the Resource Management task.
12. On the templates table, select the template, click **Actions** , then select **Associate Tenant**.
13. On the **Associate Tenant** window, supply values. For more information, see “Associate a tenant with
a template” on page 51. Click **OK** to display the **Add Template and Resource Pool** window of the
Resource Management task.
14. On the **Add Template and Resource Pool** window, supply values to describe resource pools and the
selection of the target system. Then click **OK**.

**6**   Software Services task


Having used the Resource Management task to add a template to the tenant, return now to the Software
task.

15. Click the Software Services tab.
16. In the templates table, select the new template.

**Perform approvals** as needed. If the template is in the Draft state, you can skip the steps that are related
to approvals, and proceed to Test run and publish, which describes the **Test Run** action. Otherwise, you
need to address approvals first.

17. Take the appropriate action for a template state that involves approvals.
    - A Draft state indicates that the template has no approval records that must be approved. It is
       ready for the next step.A Draft pending approvals state indicates that the template has approval
       records that must be approved. Approval records are created when a workflow or action definition
       file contains an element that identifies a user ID under which a workflow step or action is to be
       performed. Approval records can also be created for the template as a whole, or based on the
       domain. The middleware administrator and security administrator might be required to complete
       the approvals. Those users review the approvals for the workflow or action command, and make
       changes to runAsUser or approver elements for the installation. Domain or template approvers
       review the provisioning workflow and all of the actions.
          a. On the templates table, select the template, click **Actions** , then select **Approvals**.
          b. On the **Approve** window, review and modify the runAsUser and approval elements, and any
             other elements, as needed. To review a workflow step or action, click the link in the Item to
             Approve column to open that item in the appropriate editor.
c. If needed, notify the approvers that they have items to approve.
       The approvers do the following:
          a. On the templates table, select the template, click **Actions** , then select **Approvals**.
          b. On the **Approve** window, review the items that require approval. If the item is a link, click the
             link to open that item in the appropriate editor.
c. To approve an item, select the row, then click **Actions** , then select **Approve**.
          d. After returning to the templates table, if the state of the template is now Pending security
             update, click **Refresh** to see an updated state that reflects the approvals.
    - A Draft missing required approver state indicates that a runAsUser element in a definition file
       has no approval elements. This state, in the templates table, is a link. To identify the missing
       approver, click the state to view the details. When the details are displayed, click a link in the Item
       to Approve column to display the element in read-only mode using the Workflow Editor or actions
       editor, as appropriate. To resolve the missing required approver state, either:
       - Edit the definition using the appropriate editor and add an approver.
       - Add a domain approver, with the Resource Management task.
       - Add a template approver. Modify the template using the **Modify** action, then, on the Modify
          Template window, use the Template Approvers field.
       For more information, see “Approvals” on page 54.

**Test run and publish.** These steps can be completed only when the approvals have been approved.
Publish makes the template available for consumers. For example, you might make a published template
available as an offering in a web portal.

18. In the templates table, with the template selected, click **Actions** , then select **Test Run**. Review the
    information that is displayed on the **Test Run** window, then click **Test Run**.
    You test run a template to confirm that it successfully creates a software services instance, while
    leaving the template open for further changes.
    **Test Run** creates a workflow, starts the workflow, and creates a software services instance.
19. On the Instances tab, check the table for the instance that you created with **Test Run**.
    The name of the instance is :

```
Software Services task   7
```

- For a standard template: _software-type_ _ _prefix-for-resource-poolnumber_ , for example,
    Standard_M03.
- For a composite template: _prefix-for-resource-pool_ _ _prefix-for-resource-poolnumber_ , for example,
    C_C03. For a clustered composite, a suffix of _ _software-service-instance-name_ is added.
In the name, _prefix-for-resource-pool_ is the value that is specified for software service instance name
prefix field on the **Add Template and Resource Pool** page or the **Create Shared Resource Pool** page,
and _number_ is assigned by z/OSMF.
To identify the instance that you created, you might use the information in the Created On and
Created By columns, in addition to the name.
The status of the instance should be either Being-Provisioned or Provisioned. Provisioned indicates
success. You might need to click **Refresh** to see the status change to Provisioned.
You might want to try one or more actions against the instance to ensure that they work as expected.
Click **Actions** , then select **Perform** , then select an action.
You might also click the instance name to view the properties, then review the variables that are
shown in a table. If the variables include an IP address for a server, you might test the IP address in a
browser.
- If the instance was created successfully, with a status of Provisioned, and the actions perform as
    expected, you are now ready to publish the template. You may want to first clean up the results of
    your test, that is, deprovision and remove the instance that you created with **Test Run**.
       a. Select the instance, then click **Perform**. If a **deprovision** action is available, select it.
          You cannot deprovision the child instances of a composite instance (that is, an instance
          created from a composite template). Instead, use the **Perform deprovision** action against
          the composite instance.
       b. Once the instance is in a Deprovisioned state, click **Actions** , then select **Remove**.
          c. Proceed to the next step to publish the template.
- If the status is Provisioning-Failed, or the actions do not perform as expected, determine the
    cause of the problem, and make appropriate changes. For more information, see “Fixing problems
    with provisioning” on page 58.
20. To make the template available to consumers, select the template on the templates table, click
**Actions** , then select **Publish**. On the confirmation window, select the desired options, then click **OK**.
This action locks the template, allowing only limited modification, and puts it in the published state.
**Run the template.** You might perform this step as a further check before notifying consumers that the
template is available.
21. To create an instance from the published template, click **Actions** , then select **Run**.
**Run** has the same effect as **Test Run** : It creates a workflow, starts the workflow, and creates a
software services instance. The instance is displayed on the Instances tab. When the instance is in
the provisioned state, the workflow is automatically deleted.

```
What to do next
From the Instances tab, you can manage your software services instances. You can modify them, view
their properties, and perform actions that were defined for them, using the Perform action. These
typically include a deprovision action, which you use to deprovision the software. To confirm the results
of the action, check the Status column on the Instances table. Use the View action for an instance to see
properties for an instance, including the variables and action history, and to display the workflow for the
instance using a link to the Workflows task.
When making your template available to consumers, you add consumer user IDs to the tenant, with the
Resource Management task.
You can create a composite template from multiple published standard templates. Click Add Template
then Composite , then complete the resulting dialog.
```
**8**   Software Services task


```
Related concepts
Approvals
Approval records for a software services template must be approved before the template can be
published. The State column of the templates table indicates if approvals are required.
Fixing problems with provisioning
When the status of a software services instance is Provisioning-Failed, you may need to make changes in
the workflow definition.
Related reference
Files used to define software services templates
A standard software services template is defined with workflow definition files, action definition files, and
variable input files. Documentation files describe the software services template, the content of the other
files and the values that you might need to change. A composite software services template does not
include workflow or action definition files, but includes a composite variable input file.
Software Services
You can use the Software Services task, along with the Resource Management task, to provision z/OS
software such as IBM middleware. You can then manage the software services instances.
Related information
Publish a template
Publish makes a template available to consumers and prepares it for the Run action. It locks the
template, allowing only limited modification, and puts it in the published state.
How to use the Software Services task to provision and deprovision software
This topic provides an overview of the steps for provisioning and deprovisioning software using the Cloud
Provisioning tasks.
```
#### Use a template to provision software

```
This topic provides an overview of the steps a consumer uses to provision software using a template.
```
```
Before you begin
A template must have been prepared and published, as described in “Prepare and publish a template” on
page 5.
```
```
About this task
Use the template prepared by the service provider to create the provisioned software, called a software
services instance.
The following procedure describes the basic steps using the Software Services task. As an alternative, you
might use a consumer portal, like the sample Marketplace provided for z/OSMF.
```
**Procedure**

1. In the templates table, click the template name to view the template properties.
2. On the View template page, find the field for the consumer documentation file. If a value is displayed
    there as a link, click the link to open the file.
    Review the file for anything that you need to do or consider, and respond as appropriate.
3. Click **Actions** , then select **Run**.
    **Run** creates a workflow, starts the workflow, and creates a software services instance. The instance is
    displayed on the Instances tab.

```
What to do next
From the Instances tab, you can manage your software services instances. You can modify them, view
their properties, and perform actions that were defined for them, using the Perform action. These
typically include a deprovision action, which you use to deprovision the software. To confirm the results
```
```
Software Services task   9
```

```
of the action, check the Status column on the Instances table. Use the View action for an instance to see
properties for an instance, including the variables and action history, and to display the workflow for the
instance using a link to the Workflows task.
```
### Templates

```
You can use the Templates tab of Software Services to work with software services templates. The
templates can be used to provision z/OS software.
```
```
Templates
Use standard templates to provision a single software instance. Use composite templates to provision
more than one software instance with a single Run operation, or to provision clustered software services.
For more information, see “Composite templates” on page 2.
Basic properties of the software services templates are shown in a table. You can display additional
information for a template with the View action.
Domain administrators can use View By Domain to control which templates are included in the table.
Select a domain from the list to cause the table to include just the templates that are associated with that
domain.
For a description of the columns in the table, see “Columns in the Templates table” on page 10. For a
description of the actions that you can take for templates, refer to “Actions for templates” on page 12.
```
**Columns in the Templates table**

```
Table 1. Columns in the Templates table
```
```
Column Description
```
```
Template Name Name of the template. For composite templates, you can expand the row to display
the standard templates that it contains by clicking. Click the template name
to view the properties of the template. If the name is not a link, you are not
authorized to view that template.
```
```
Version Version of the template.
```
```
State State of the template, which might indicate actions that are required.
Archived
The template is archived. An archived template is not visible to consumers. You
can make it available to consumers again with the Publish action.
Corrupted
The contents of the software services template are missing or incorrect. Delete
the template.
Draft
The template has no approval records that must be approved. It is ready for the
next step.
Draft approved
All of the approval records that are associated with the template and the
respective runAsUser IDs are approved. The template is ready for the next
step.
```
**10**   Software Services task


_Table 1. Columns in the Templates table (continued)_

**Column Description**

**State Draft missing required approver**

```
A runAsUser element in a definition file has no approval elements. This state,
in the templates table, is a link. To identify the missing approver, click the
state to view the details. When the details are displayed, click a link in the
Item to Approve column to display the element in read-only mode using
the Workflow Editor or actions editor, as appropriate. To resolve the missing
required approver state, either:
```
- Edit the definition using the appropriate editor and add an approver.
- Add a domain approver, with the Resource Management task.
- Add a template approver. Modify the template using the **Modify** action, then,
    on the Modify Template window, use the Template Approvers field.
- Edit the definition using the Workflow Editor task or the actions editor, as
    appropriate, and add an approver.
- Add a domain approver, with the Resource Management task.
- Add a template approver for the template. Use the **Modify** action, and specify
    a value for Template Approver.
**Draft pending approvals**
The template has one or more approval records that must be approved.
**Draft rejected**
One or more approvers rejected an approval. All approval records must be
approved before the template is ready for the next step.
**Missing**
Applies only to standard templates that are members of composite templates.
It indicates that the template is referenced in a composite definition but the
template is not available.
**Missing member**
Applies only to published or archived composite templates. It indicates that
one or more of the member templates that was referenced in the composite
definition is not available.
To resolve the missing member condition, expand the composite template in
the templates table and identify the missing member. Then, you can either:
- Publish a new version of the member that is missing. (The version that
you publish must be a version of the member that was included when
the composite template was created.) This puts the composite template
into Archived state. Then, if the content of the member templates and the
connector information is still valid, you can publish the archived composite
template.
If the content of the member templates and the associated connector
information is still not valid, rather than publishing the archived composite
template, create a new version of it and make the appropriate updates.
- Create a new version of the composite template and remove the template
that is missing. That is, on the second page of Create New Version of
_template_ , select the missing member template in the table of member
templates, then click **Actions** , then **Remove**.

```
Software Services task   11
```

```
Table 1. Columns in the Templates table (continued)
```
```
Column Description
```
```
State Pending security update
Security permissions are being processed. No requests are allowed against
the template while it is in this state, so some actions might be disabled. If
automatic security is in effect for the associated domain, the state changes
automatically when the security update for the domain is complete. If manual
security is in effect for the associated domain, use the Set Security Complete
action to change the state after all manual security setup for the domain has
been performed.
Published
The template is locked and is visible to consumers.
Security update failed
A failure occurred in processing security permissions. Some actions might be
unavailable.
```
```
Software Type Type of software, for example DB2® or MQ. This is not displayed for composite
template, but is displayed for the members of the composite template.
```
```
Domain Domain that the template is associated with.
```
```
Description Description of the template.
```
```
Last Modified Time and date that the template was last modified.
```
```
Created On Time and date that the template was created.
```
```
Created By User ID of the user who created the template.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
```
Actions for templates
The actions are described in the following tables:
```
- General actions. Actions that apply to templates. No selection is required. See Table 2 on page 13.
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 3 on page 13.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 4
    on page 14.
The Software Services task saves a provisioning version with each template object. For an action to be
valid for a template, the provisioning version associated with the template object must not be higher than
the provisioning version of the code for the Software Services task.

**12**   Software Services task


_Table 2. General actions for the Templates table_

**Action Description**

**Add Template** Displays a menu of choices for the type of template that you want to create. A
standard template represents a single service. A composite template is made up
of multiple published, standard templates that can be provisioned with a single
Run operation. Select a choice to display a window to supply the attributes of the
template that you want to create. You must be a domain administrator.

_Table 3. Targeted actions for the Templates table_

**Action Description**

**View** Display more properties of a template, including information about variables for
use with the workflow, approvers, and actions that are defined with the actions
definition XML file. If View is disabled, you are not authorized to view that template.

**Modify** Display the **Modify** window so that you can modify the properties of the selected
template, including the workflow definition file, for a standard template, and the
member templates, for a composite template.
The template must be in one of the draft states, or in the published state.

**Set Security Complete** Indicate that manual security setup has been performed for a template with a state
of Pending Security Update. This action is available only if manual security is in
effect for the template.

**Refresh Template** Refresh any workflow definition, action definition, composite variable input, or
workflow variable input files that were modified outside of z/OSMF since the
template was created. If the files were changed outside of z/OSMF, **Refresh
Template** is required for the **Publish** action. If you use the Workflow Editor task
to modify the files, then **Refresh Template** is not required.
The template must be in one of the draft states.

**Associate Tenant** Display the Associate Tenant pop-up window, which allows you to associate a
tenant with the template, using the Resource Management task.

**Approvals** Displays the **Approve** window for approving the pending approval records
associated with the template. Pending approval records are indicated in the State
column of the table.

**Test Run** Display the **Test Run** window to test run the template. You can test run a template
to confirm that it successfully creates a software services instance. The template
remains open for further changes. Test Run creates a workflow, starts the workflow,
and creates a software services instance in being-provisioned state.
Before you use Test Run, all approval records must be approved. The template
must have been added to a tenant, which you do with the Resource Management
task.
The template must be in a draft or draft approved state.

```
Software Services task   13
```

```
Table 3. Targeted actions for the Templates table (continued)
```
```
Action Description
```
```
Publish Publish a template. This action locks the template, allowing only limited
modification, and puts it in the published state. You can then use the Run action to
create a software instance.
Before you use Publish , all approval records must be approved.
The template must be in the draft, draft approved, or archived state.
Note: For templates in a draft or draft approved state, if the workflow definition,
action definition, composite variable input, or workflow variable input files were
modified since the template was created, you must use the Refresh Template
action before the Publish action to use the modified files.
```
```
Run Run the template. The template must be in the published state (or missing member
state for a composite template), and must have been added to a tenant, which
you do with the Resource Management task. For a standard template, Run creates
a workflow, starts the workflow, and creates a corresponding software services
instance. For a composite template, Run creates all of the instances and initiates
orchestration to provision the child instances in the defined sequence, which
includes creating and starting their respective provisioning workflows.
```
```
Create Based On Create a new standard template based on an existing template. The new template
has the same associated files (workflow definition, action definition, variable input,
and documentation) as the original.
```
```
Create New Version Create a new version of an existing template. The new version has the same name
as the original entry, and is associated with the same domain and tenants. However,
it has new source files. The version is reflected in the Version column of the
templates table.
For a standard template, the template that you create a new version of must be in
the published or archived state. For a composite template, the template that you
create a new version of can also be in the missing member state.The new version is
created in the draft state. There cannot already be a version in the draft state.
When there is invalid data for a connector, the new version is created without the
invalid data.
```
```
Archive Archive a published template. The state is changed to archived. No further
instances can be created from the template. Any existing instances continue to
function. Use the Publish action to return the template to the Published state.
```
```
Remove Remove the template or templates from the software services catalog. All system
resources that were generated for the template are also removed.You cannot
remove the member templates of a composite template. Remove the composite
template instead.
```
```
Table 4. Table actions for the Templates table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
**14**   Software Services task


```
Table 4. Table actions for the Templates table (continued)
```
```
Action Description
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Add a template

```
To add template, click Add Template in the Templates table, then select either Standard or Composite to
specify the type of template that you want to create. This is the first step in preparing a template for use in
provisioning software.
```
```
Before you begin
You must be a domain administrator to add a template. If you want to use a domain other
than the default domain, you must have defined the domain with the Resource Management
task. To create a composite template, you must have more than one standard template in the
published state. If you would like to complete these steps using a video see How to create
a template for IBM Cloud Provisioning and Management for z/OS (mediacenter.ibm.com/media/
How+to+create+a+template+in+IBM+Cloud+Provisioning+and+Management+for+z+OS/0_ds5t1cbr/
101043781).
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Services**.
2. Select the **Templates** tab.
3. In the table, click **Add Template** , then select either **Standard** or **Composite** to specify the type of
    template that you want to create.
    If **Add Template** is not available, it might be because you are not a domain administrator.
4. On the page that is displayed, supply values. The page varies depending on the type of template that
    you are adding. See “Values on the Add Standard Template window ” on page 15 or “Values on the
    Add Composite Template window ” on page 17.

```
Results
An entry for the template is created in the software services catalog.
```
```
What to do next
To add the template to a tenant, use the Resource Management task.
```
**Values on the Add Standard Template window**

```
Template source file
Optional file that describes the template and provides a shortcut for supplying values for other fields
on the window. Specify the absolute z/OS UNIX path of the file, beginning with the forward slash (/)
and including the file name, for example, /u/jsmith/loadmeup.prop, or the name of a partitioned or
sequential data set. Then, click Load to supply values for other fields on the window.
```
```
Software Services task   15
```

```
The file must be in Java™ property file format:
```
- Each entry is a single line, in _property_ = _value_ or _property_ : _value_ format.
- The \ character is a continuation character so that a value can span lines.
- For newline, carriage return, and tab, use \n, \r, and \t.
- Comment characters are! and #. Lines that start with those characters are ignored.
Example:

```
workflow-definition-file:/u/jsmith/workflow_definition.xml
workflow-variable-input-file:/u/jsmith/var_input_file
action-definition-file:/u/jsmith/actions_definition.xml
admin-documentation-file:/u/jsmith/documentation.txt
consumer-documentation-file:/u/jsmith/documentation.txt
```
```
Note: All relative paths that are specified in the manifest file are treated as being relative to the
manifest file location.
Target domain
Name of the domain to associate with the template. Select a domain name from the list or accept
the default domain. A domain name is required. Domains are defined with the Resource Management
task.
Template name
Name of the template. A template name is required.
The name must be unique. It can include alphanumeric characters, or these special characters:
$
@
_
```
-
It can be up to 48 characters long.
**Workflow file**
Path for the workflow definition file. Specify the absolute z/OS UNIX path of the file, beginning
with the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/V2R2/workflows/
workflow_sample.xml, or the name of a partitioned or sequential data set. A workflow file is required.
**Actions file**
Path for the actions definition file for use with the workflow. This file describes the actions that can
be performed against the instance that is created from the template. Specify the absolute z/OS UNIX
path of the file, beginning with the forward slash (/) and including the file name, for example, /usr/lpp/
zosmf/V2R2/workflows/workflow_actions.xml, or the name of a partitioned or sequential data set. An
actions file is required.
To create an actions definition file, click **Create New**. The Actions file field must be blank.
For more information, see “Working with actions” on page 72.
**Workflow variables input file**
Path for the variables input file to use with the workflow. Specify the absolute z/OS UNIX path of
the file, beginning with the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/
V2R2/workflows/workflow_variables.xml, or the name of a partitioned or sequential data set.
**Consumer documentation file**
Path for the documentation file for consumers. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.
**Administrator documentation file**
Path for the documentation file for administrators. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.

**16**   Software Services task


**Template approver (groups or users)**
List of the user IDs or SAF groups of the template approvers. Separate these values with commas or
blanks, for example zosmfad,ibmuser,zmfgrp. These are approvers for the template (sometimes
called general approvers) as opposed to approvers for a specific step or action. Approvers receive a
z/OSMF notification.

**Template description**
Description of the template.

**Workflows disposition**
Indicates the disposition of the workflow after the software is provisioned. This selection applies to
the workflow that is used to provision the software, and its associated action workflows. Choose one
of the following options:
**Archive successful workflows on completion**
Workflows are archived in the Workflows task after they complete. This option is the default.
**Delete successful workflows on completion**
Workflows are deleted after they complete.
**Keep successful workflows on completion**
Workflows are retained after they complete. You can manually delete them from the workflows
table in the Workflows task.
If you do not specify a workflows disposition, the workflows are archived by default.
For action workflows, this setting can be overridden in the actions definition file.

**Jobs disposition**
Select **Delete jobs on completion** to cause the jobs that are dynamically submitted to be deleted
automatically after they complete. The default is to keep the jobs.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.

**Instances disposition**
Select **Delete deprovisioned instances on completion** to cause the instance to be deleted
automatically when it is deprovisioned. The default is to keep the instance.
The instances disposition is also applicable for composite templates. It applies to the instances for
the composite instance and composite member instances.
If you do not specify that deprovisioned instances should be deleted automatically, you can manually
delete them. To do so, navigate to the instances table, click **Actions** , then select **Remove**.

**Values on the Add Composite Template window**

To create a composite template, you must have multiple published standard templates that will be the
members of the composite template. On the **Add Composite Template** window, specify properties of the
composite template, then click **Next** to display a second page for specifying the member templates. Click
**Finish** when you are done specifying values. **Finish** is available only when you have supplied all of the
required values.

**Target domain**
Name of the domain to associate with the template. Select a domain name from the list or accept
the default domain. A domain name is required. Domains are defined with the Resource Management
task.

**Template name**
Name of the template. A template name is required.
The name must be unique. It can include alphanumeric characters, or these special characters:
$
@
_

-

```
Software Services task   17
```

```
It can be up to 48 characters long.
Use composite template to cluster instances on systems in a sysplex
The template is a clustered composite template. It provisions clustered software services instances.
Clustered software services instances are collections of instances that use the resources defined in
a common resource pool that is associated with the clustered composite template. The instances
are provisioned on the systems in the sysplex that are identified in the resource pool. For more
information, see “Clustered composite templates” on page 4.
Composite variables input file
Location of the properties file that you can use to specify in advance values for one or more of the
atCreate variables that are defined in the member standard template workflow definition files.
Specify the fully qualified z/OS UNIX path of the file, beginning with the forward slash (/) and including
the file name. For example, specify /usr/lpp/zosmf/samples/composite.properties
The variable names are in the following format: <standard-template-name>.<atcreate-variable>
For example: CICS.startup=10
If the file includes any variables that are associated with standard templates that are not members of
the composite, those variables are ignored. All other variable names are validated to ensure they are
atCreate variables that associated with the member standard template. No validation is performed on
the provided values.
Consumer documentation file
Path for the documentation file for consumers. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
Administrator documentation file
Path for the documentation file for administrators. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
Template approver (groups or users)
List of the user IDs or SAF groups of the template approvers. Separate these values with commas or
blanks, for example zosmfad,ibmuser,zmfgrp. These are approvers for the template (sometimes
called general approvers) as opposed to approvers for a specific step or action. Approvers receive a
z/OSMF notification.
Template description
Description of the template.
Click Next to display the window for adding published, standard templates to the composite template.
```
```
Add Composite Template: Working with published templates in the composite template
Use Add Published Template to add published standard templates to the composite template.
```
- When you add the first template to the composite template, you select a published, standard template
    on the **Add Published Template** dialog.
- When you add subsequent templates, you select a standard, published template to add it to the
    composite template. If the controls are displayed, you can also define connector variables. Connector
    variables connect the new template to previous templates in the sequence.
For each published template in a clustered composite template, specify the number of clustered
instances to create from that published template. The maximum number of clustered instances that
you can specify depends on whether the domain in which the composite template resides is in a single
sysplex or extends across multiple sysplexes. In a single-sysplex domain, the maximum number of
clustered instances is equal to the number of systems in the domain. In a multiple sysplex domain, the
maximum number is based on the sysplex that contains the most systems in the domain; the instances
will be created in this sysplex. For example, assume that a domain encompasses System 1 on Sysplex A
and Systems 2 and 3 on Sysplex B. Here, the maximum number of clustered instances that can be created
is two because Sysplex B has two systems in the domain.

**18**   Software Services task


The standard templates in the composite template (sometimes referred to as member templates) are
displayed in a table. The table shows, for each member template, the sequence in which the template
will be provisioned, the name of the template, the number of clustered instances (for clustered composite
templates), and the name of the templates that it is connected to through connector variables.

**Actions for the table of member templates in the composite template**

```
Table 5. Actions for the table of member templates in the composite template
```
```
Action Description
```
```
Add Published Template Display a page to allow you to specify a published, standard template to
add to the composite template.
```
```
Modify Display a page to allow you to modify the connector variables. This
action is not available for the first template in the list, or if there are
no atCreate variables for the templates that follow the first template. For
more information, see “Modify Connector Variables” on page 19.
```
```
Move Select Move and Up or Down to move the selected template up or down
in the sequence. Connector variables connect a template to templates
that precede it, so be sure that you understand any possible effects on
connector variables when reordering the templates.
```
```
Remove Remove a published, standard template from the composite template. Be
sure that you understand any possible effects on connector variables.
```
_Modify Connector Variables_

A list of variables shows atCreate variables for the indicated template. Use **Add** or **Remove** to build the
set of connector variables that connect the template to previous templates in the sequence. In the table
of variables, you can select a different source template, from the other templates in the composite, to
override the original value for the variable. If a template appears multiple times in the list, values for
variables always come from the first of those templates.

When you add a variable to the list of connector variables, you can then select the source variable name
for it.

The registry-instance-Name constant (the default) evaluates to the instance name that is associated with
the instance that was created for the source template. You can code a workflow to perform a GET REST
request against the instance name and obtain whatever variables are required. For more information on
the REST API, see z/OS instance variables REST interface in _IBM z/OS Management Facility Programming
Guide_.

When you are finished building the set of connector variables for a template, click **OK**. Then, add
additional published templates as needed.

**Create New Actions File window**

Supply values in the fields.

**Target file path or data set**
The location of the actions file that you want to create. Specify the file path or fully qualified data set
name.

**Deprovisioning workflow definition file**
If a workflow definition file exists for deprovisioning, specify the file path or fully qualified data
set name. If you do not specify this value, the actions editor opens with a placeholder instruction
deprovision action defined. If necessary, you can use the actions editor to delete the instruction
deprovision action and replace it with a workflow action for deprovisioning.

For more information, see “Edit an actions definition file” on page 42.

```
Software Services task   19
```

#### Files used to define software services templates

```
A standard software services template is defined with workflow definition files, action definition files, and
variable input files. Documentation files describe the software services template, the content of the other
files and the values that you might need to change. A composite software services template does not
include workflow or action definition files, but includes a composite variable input file.
```
**Workflow definition file (standard templates)**

```
A workflow definition file is the primary XML file for a workflow definition. It includes information about
the workflow, such as name and version, as well as step and variable definitions.
For information, see creating workflow definitions in IBM z/OS Management Facility Programming Guide.
You can use the Workflow Editor task to edit a workflow definition file.
You can also edit the workflow definition file for a template from the templates table. (The template must
be in the draft or draft pending approvals state.) Select the Modify action for a template to display the
Modify window. Then, click Edit for the workflow field to open the file in the workflow editor.
```
```
Action definition file (standard templates)
An action definition file describes the actions that can be performed against the software services
instance that is created from the software services templates.
For information about performing actions against software instances, see “Working with actions” on page
72.
You can use the actions editor to edit or create an actions definition file when modifying or adding a
template. For more information, see “Edit an actions definition file” on page 42 and “Add a template” on
page 15.
```
**Variable input file (standard templates)**

```
A workflow variable input file is a properties file that is used to specify in advance one or more of the input
variables that are defined in the workflow definition.
For more information about variable input files, see Defining variables for your workflow in IBM z/OS
Management Facility Programming Guide.
```
```
Composite variable input file (composite templates)
Properties file that is used to specify in advance one or more of the input variables file for the composite
template.
```
**Documentation files (standard and composite templates)**

```
A documentation file is an optional text or PDF file that you can use to describe a template. There can be
one for consumers and one for administrators.
You can use an editor of your choice to modify or create documentation files.
```
**Refreshing the files**

```
You can use the Refresh Template action in the templates table to refresh any workflow definition, action
definition, input variable, or documentation files that have been modified since the software services
templates was created. Refresh Template is required before you use the Publish action, if those files
have been modified since the software services templates was created.
Related concepts
Approvals
```
**20**   Software Services task


```
Approval records for a software services template must be approved before the template can be
published. The State column of the templates table indicates if approvals are required.
Related tasks
Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
Related information
Publish a template
Publish makes a template available to consumers and prepares it for the Run action. It locks the
template, allowing only limited modification, and puts it in the published state.
```
```
Access to template files
You must ensure that the required IDs have authority to access the template source files.
Your user ID and the z/OSMF server user ID both require at least READ authority to the workflow
definition file, the workflow variable input file, and the actions definition file.
To verify that the server has access to these files, contact your z/OSMF administrator. By default, the
server user ID is IZUSVR, but your installation might have specified another value for this user ID during
the z/OSMF configuration process.
```
#### Create a template based on another template

```
To create a template based on another template, use the Create Based On action in the Templates table.
The new template will have the same associated files (workflow definition, action definition, variable
input, and documentation) as the original.
```
```
Before you begin
You must be a domain administrator to create a template based on another template.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Services**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then click **Create Based On**.
    If **Create Based On** is not available, it might be because you are not a domain administrator or
    because the template is a composite template.
5. On the **Create Based On** page, supply values. Values that are required are indicated by a * preceding
    the label for the field. See “Values on the Create Based On window ” on page 21.
6. Click **OK** to create the template. The template is created in a draft state.

```
What to do next
To add the template to a tenant, use the Resource Management task.
```
#### Values on the Create Based On window

```
Template name
Name of the template to be created.
The name must be unique. It can include alphanumeric characters, or these special characters:
$
@
_
```
```
Software Services task   21
```

##### -

```
It can be up to 48 characters long.
Target file path
Absolute path name for a directory to which the definition files are to be copied. If the directory does
not exist, z/OSMF attempts to create it.
Domain
Name of the domain that will be associated with the new template.
Template approver (groups or users)
List of the user IDs or SAF groups of the template approvers. Separate these values with commas or
blanks, for example zosmfad,ibmuser,zmfgrp. These are approvers for the template (sometimes
called general approvers) as opposed to approvers for a specific step or action. Approvers receive a
z/OSMF notification.
```
#### Create a new version of a template

```
To create a new version of a template, use the Create New Version action in the Templates table.
```
```
Before you begin
You must be a domain administrator to create a new version of a template.
For a standard template, the template that you create a new version of must be in the published or
archived state. For a composite template, the template that you create a new version of can also be in the
missing member state.The new version is created in the draft state. There cannot already be a version in
the draft state.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Services**.
2. Select the **Templates** tab.
3. In the table, select the template that you want to make a new version of.
4. Click **Actions** , click **Create** , then click **New Version**.
    If the action is not available, it might be because you are not a domain administrator.
5. On the **Create New Version** page, supply new values for any that you want to change. Values that are
    required are indicated by a * preceding the label for the field. See “Values on the Create New Version
    window for a standard template ” on page 22 or “Values on the Create New Version window for a
    composite template ” on page 24.
6. Click **OK** to create the new version of the template. The new version is created in a draft state.
    For a composite template, when there is invalid data for a connector, the new version is created
    without the invalid data.

```
What to do next
To add the template to a tenant, use the Resource Management task.
```
**Values on the Create New Version window for a standard template**

```
Template name
Name of the template for which you are creating a new version.
Domain
Name of the domain that will be associated with the template.
Template source file
Optional file that describes the template and offers a shortcut for providing new values for other fields
on the window. Specify the fully qualified z/OS UNIX path of the file, beginning with the forward slash
```
**22**   Software Services task


```
(/) and including the file name, for example, /u/jsmith/loadmeup.prop, or the name of a partitioned or
sequential data set. Then, click Load to supply values for other fields on the window.
The file must be in Java property file format:
```
- Each entry is a single line, in _property_ = _value_ or _property_ : _value_ format.
- The \ character is a continuation character so that a value can span lines.
- For newline, carriage return, and tab, use \n, \r, and \t.
- Comment characters are! and #. Lines that start with those characters are ignored.
Example:

```
workflow-definition-file:/u/jsmith/workflow_definition.xml
workflow-variable-input-file:/u/jsmith/var_input_file
action-definition-file:/u/jsmith/actions_definition.xml
admin-documentation-file:/u/jsmith/documentation.txt
consumer-documentation-file:/u/jsmith/documentation.txt
```
**Workflow file**
Path for the workflow definition file. Specify the fully qualified z/OS UNIX path of the file, beginning
with the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/V2R2/workflows/
workflow_sample.xml, or the name of a partitioned or sequential data set. A workflow file is required.

**Actions file**
Path for the actions definition file for use with worfklow. This file describes the actions that can
be performed against the instance that is created from the template. Specify the fully qualified
z/OS UNIX path of the file, beginning with the forward slash (/) and including the file name,
for example, /usr/lpp/zosmf/V2R2/workflows/workflow_actions.xml, or the name of a partitioned or
sequential data set. An actions file is required.
For more information, see “Working with actions” on page 72.

**Workflow variables input file**
Path for the variables input file to use with the workflow. Specify the fully qualified z/OS UNIX path of
the file, beginning with the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/
V2R2/workflows/workflow_variables.xml, or the name of a partitioned or sequential data set.

**Consumer documentation file**
Path for the documentation file for consumers. Specify the fully qualified z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.

**Administrator documentation file**
Path for the documentation file for administrators. Specify the fully qualified z/OS UNIX path of the
file, beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.

**Template approver (groups or users)**
List of the user IDs or SAF groups of the template approvers. Separate these values with commas or
blanks, for example zosmfad,ibmuser,zmfgrp. These are approvers for the template (sometimes
called general approvers) as opposed to approvers for a specific step or action. Approvers receive a
z/OSMF notification.

**Template description**
Description of the template.

**Workflows disposition**
Indicates the disposition of the workflow after the software is provisioned. This selection applies to
the workflow that is used to provision the software, and its associated action workflows. Choose one
of the following options:
**Archive successful workflows on completion**
Workflows are archived in the Workflows task after they complete. This option is the default.
**Delete successful workflows on completion**
Workflows are deleted after they complete.

```
Software Services task   23
```

```
Keep successful workflows on completion
Workflows are retained after they complete. You can manually delete them from the workflows
table in the Workflows task.
If you do not specify a workflows disposition, the workflows are archived by default.
For action workflows, this setting can be overridden in the actions definition file.
Jobs disposition
Select Delete jobs on completion to cause the jobs that are dynamically submitted to be deleted
automatically after they complete. The default is to keep the jobs.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.
Instances disposition
Select Delete deprovisioned instances on completion to cause the instance to be deleted
automatically when it is deprovisioned. The default is to keep the instance.
The instances disposition is also applicable for composite templates. It applies to the instances for
the composite instance and composite member instances.
If you do not specify that deprovisioned instances should be deleted automatically, you can manually
delete them. To do so, navigate to the instances table, click Actions , then select Remove.
```
**Values on the Create New Version window for a composite template**

```
Target Domain
Name of the domain that is associated with the template.
Template name
Name of the template.
Use composite template to cluster instances on systems in a sysplex
The template is a clustered composite template. It provisions clustered software services instances.
Clustered software services instances are collections of instances that use the resources defined in
a common resource pool that is associated with the clustered composite template. The instances
are provisioned on the systems in the sysplex that are identified in the resource pool. For more
information, see “Clustered composite templates” on page 4.
Composite variables input file
Location of the properties file that you can use to specify in advance values for one or more of the
atCreate variables that are defined in the member standard template workflow definition files.
Specify the fully qualified z/OS UNIX path of the file, beginning with the forward slash (/) and including
the file name. For example, specify /usr/lpp/zosmf/samples/composite.properties
The variable names are in the following format: <standard-template-name>.<atcreate-variable>
For example: CICS.startup=10
If the file includes any variables that are associated with standard templates that are not members of
the composite, those variables are ignored. All other variable names are validated to ensure they are
atCreate variables that associated with the member standard template. No validation is performed on
the provided values.
Consumer documentation file
Path for the documentation file for consumers. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
Administrator documentation file
Path for the documentation file for administrators. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
```
**24**   Software Services task


**Template approver (groups or users)**
List of the user IDs or SAF groups of the template approvers. Separate these values with commas or
blanks, for example zosmfad,ibmuser,zmfgrp. These are approvers for the template (sometimes
called general approvers) as opposed to approvers for a specific step or action. Approvers receive a
z/OSMF notification.

**Template description**
Description of the template.

Click **Next** to display the window for adding published, standard templates to the composite template.

**_Add Composite Template: Working with published templates in the composite template_**

Use **Add Published Template** to add published standard templates to the composite template.

- When you add the first template to the composite template, you select a published, standard template
    on the **Add Published Template** dialog.
- When you add subsequent templates, you select a standard, published template to add it to the
    composite template. If the controls are displayed, you can also define connector variables. Connector
    variables connect the new template to previous templates in the sequence.

For each published template in a clustered composite template, specify the number of clustered
instances to create from that published template. The maximum number of clustered instances that
you can specify depends on whether the domain in which the composite template resides is in a single
sysplex or extends across multiple sysplexes. In a single-sysplex domain, the maximum number of
clustered instances is equal to the number of systems in the domain. In a multiple sysplex domain, the
maximum number is based on the sysplex that contains the most systems in the domain; the instances
will be created in this sysplex. For example, assume that a domain encompasses System 1 on Sysplex A
and Systems 2 and 3 on Sysplex B. Here, the maximum number of clustered instances that can be created
is two because Sysplex B has two systems in the domain.

The standard templates in the composite template (sometimes referred to as member templates) are
displayed in a table. The table shows, for each member template, the sequence in which the template
will be provisioned, the name of the template, the number of clustered instances (for clustered composite
templates), and the name of the templates that it is connected to through connector variables.

**Actions for the table of member templates in the composite template**

```
Table 6. Actions for the table of member templates in the composite template
```
```
Action Description
```
```
Add Published Template Display a page to allow you to specify a published, standard template to
add to the composite template.
```
```
Modify Display a page to allow you to modify the connector variables. This
action is not available for the first template in the list, or if there are
no atCreate variables for the templates that follow the first template. For
more information, see “Modify Connector Variables” on page 19.
```
```
Move Select Move and Up or Down to move the selected template up or down
in the sequence. Connector variables connect a template to templates
that precede it, so be sure that you understand any possible effects on
connector variables when reordering the templates.
```
```
Remove Remove a published, standard template from the composite template. Be
sure that you understand any possible effects on connector variables.
```
```
Software Services task   25
```

#### View a template

```
To view the properties of a template, use the View action in the Templates table, or click the name of the
template in the table.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **View**.
    For composite templates, you can expand the row to display the standard templates that it contains.
    Click. You can then click the name of a standard template to view it. If the standard template name
    is not a link, you are not authorized to view that template.

**Values on the View window for a standard template**

```
The values are grouped on tabs.
```
```
Template Details
Template name
Name of the template.
State
State of the template.
Archived
The template is archived. An archived template is not visible to consumers. You can make it
available to consumers again with the Publish action.
Corrupted
The contents of the software services template are missing or incorrect. Delete the template.
Draft
The template has no approval records that must be approved. It is ready for the next step.
Draft approved
All of the approval records that are associated with the template and the respective runAsUser IDs
are approved. The template is ready for the next step.
Draft missing required approver
A runAsUser element in a definition file has no approval elements. To resolve the missing required
approver status, either:
```
- Edit the definition by using the Workflow Editor task, and add an approver.
- Add a domain approver, with the Resource Management task.
**Draft pending approvals**
The template has one or more approval records that must be approved.
**Draft rejected**
One or more approvers rejected an approval. All approval records must be approved before the
template is ready for the next step.
**Missing**
Applies only to standard templates that are members of composite templates. It indicates that the
template is referenced in a composite definition but the template is not available.
**Pending security update**
Security permissions are being processed. No requests are allowed against the template while
it is in this state, so some actions might be disabled. If automatic security is in effect for the
associated domain, the state changes automatically when the security update for the domain

**26**   Software Services task


```
is complete. If manual security is in effect for the associated domain, use the Set Security
Complete action to change the state after all manual security setup for the domain has been
performed.
Published
The template is locked and is visible to consumers.
Security update failed
A failure occurred in processing security permissions. Some actions might be unavailable.
```
**Domain**
Domain to which the template belongs.

**Tenants**
Tenants to which the template has been added.

**Software name**
Name of the software with which the template is associated.

**Software type**
Type of software that the template can provision.

**Software version**
Version of the software that the template can provision.

**Template version**
Version of the template.

**Template description**
Description of the template.

**Included in composites**
Composite templates that include this standard template.

**Workflow file**
Location of the workflow definition file. This file is the primary XML file for the workflow definition.
The location is displayed as a link. Click the link to open the file with the Workflow Editor in view-only
mode.

**Workflow variables input file**
Location for the variables input file to use with the workflow. Click the link to view the properties file.

**Actions file**
Location of the XML file that contains action definitions. Click the link to view details about the actions.
See “Using the View Actions File window ” on page 36.

**Administrator documentation file**
Path for the documentation file for administrators. (Not displayed if you are logged in as a consumer.)
The path is displayed as a link. Click the link to open the file.

**Consumer documentation file**
Path for the documentation file for consumers. The path is displayed as a link. Click the link to open
the file.

**Workflows disposition**
Indicates the disposition of the provisioning workflow. The following values are valid:
**Archive successful workflows on completion**
Workflow is archived in the Workflows task after it completes. This option is used by default.
**Delete successful workflows on completion**
Workflow is deleted automatically after the software is provisioned. The workflow is deleted only if
it completes successfully.
**Keep successful workflows on completion**
Workflow is retained after the software is provisioned. You can display the workflow with the
Workflows task.
This option does not affect workflows that are associated with actions. Whether those workflows are
deleted is specified in the actions definition file.

```
Software Services task   27
```

```
Jobs disposition
Indicates the disposition of jobs that are dynamically submitted for provisioning.
Delete jobs on completion indicates that the jobs are to be deleted automatically after they
complete.
Keep jobs on completion indicates that the jobs are to be kept after they complete. You can delete
them manually.
Instances disposition
Indicates the disposition of instances after they are deprovisioned. The default is to keep the instance.
Delete deprovisioned instances on completion indicates that the instances are to be deleted
automatically when deprovisioning completes.
Keep deprovisioned instances on completion indicates that the instances are to be kept after they
are deprovisioned. You can delete them manually. To do so, navigate to the instances table, click
Actions , then select Remove.
```
```
Associated Resource Pools
Pool Name
Name of the resource pool that is associated with the template.
Pool type
Type of resource pool that is associated with the template.
Tenant
Name of the tenant that the resource pool is associated with.
Instance Limit
Maximum number of software services instances that are allowed to be created from the template.
Instance actual
Actual number of software services instances that exist.
Network Pool Status
Status of the network pool.
Workload Management Pool Status
Status of the workload management pool.
Sysplex System
Sysplex and system for provisioning.
Managed By
Primary or managing system for this domain, in the format sysplex-name.system-name. If the domain
is not managed from another sysplex, this field is blank.
```
**Metadata**

```
Created by
User ID of the user who created the template.
Created on
Time and date that the template was created.
Modified by
User ID of the user who modified the template.
Modified on
Time and date that the template was modified.
Managed by
Primary or managing system for this domain, in the format sysplex-name.system-name. If the domain
is not managed from another sysplex, this field is blank.
```
**28**   Software Services task


```
Managed by domain ID
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.
Managed by z/OSMF URL
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.
```
```
Variables
Prompt variables
Table that shows the prompt variables, that is, properties that are prompted for at run time. It shows
the name and default value for each variable.
```
**Actions**

```
Actions
Table that shows the actions that are provided for the instance. The actions are defined in the actions
file associated with the template. The table shows the name, type, description, and command (if
appropriate) for each action.
```
**History**

```
Table that shows a history of the actions that were performed on the template.
```
_Table 7. Columns in the History table_

**Column Description**

**Type** Type of action that was taken on the template, such as "modify.”

**Ran by User** User ID under which the action was performed.

**Ran at Time** Time at which the action occurred.

**Details** Description of the action.

```
Approvers
Template Approvers
Table that shows the approvers for the template and for specific approval records for the template.
```
_Table 8. Columns in the Approvers table_

**Column Description**

**Approvers (Groups and
Users)**

```
User IDs and SAF groups of the approvers. Any one of the users can approve or
reject the item.
If no approver user ID or no user in an approver group ID matches the user
ID specified with the runAsUser user ID, an approval record for Security
Administrator is generated by z/OSMF. This Security Administrator
approver record must be approved by a user with z/OSMF security administrator
authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN
resource in the ZMFCLOUD class. The Security Administrator approver should
review the contents of the templates, focusing on the use of runAsUser in the
workflow definition and actions definition files.
```
**Status** Status of the approval.

```
Software Services task   29
```

```
Table 8. Columns in the Approvers table (continued)
```
```
Column Description
```
```
Run As User User ID under which the current workflow step or command is to be performed.
indicates that the value for the ID is dynamic, meaning that it was assigned by a
workflow.
```
```
Description Description of the item.
```
```
Item to Approve Item (workflow step, action, or both) that requires approval, or an indication that
the approval is for the template as a whole or for the template based on the
domain that it is associated with. Click a link to open the item in read-only mode in
the appropriate editor. For domain and general approvals, the link is a text string,
for example, Workflow definition file.
```
```
Modified By User ID of the user who last acted on the item.
```
```
Comment Text of a comment that was added for the approval.
```
```
Modified Time that the item was last modified.
```
```
Run As Users
Run As User
Table that shows the runAsUser elements for the template, along with their approvers. A runAsUser
element identifies a user ID under which a workflow step or action is to be performed.
```
```
The runAsUser elements are grouped by runAsUser ID. Click to expand a row to see the elements
for that runAsUser ID.
Click the link for a runAsUser element to open it in read-only mode with the Workflow Editor or actions
editor, as appropriate.
```
```
indicates that the value for the ID is dynamic, meaning that it was assigned by a workflow.
```
```
SAF Resources
SAF Resources
Table that shows information about SAF resources that protect the template. You can expand or
collapse the sections for all resources, or for a single resource, to show or hide details.
Security definition
Setting for Security definition for the domain.
Automatic
z/OSMF uses a workflow to perform security setup dynamically. This is the default.
Manual
Security setup must be performed manually. The state of the template is initially set to
Pending Security Update.
User Access
Access level that is required for the resources.
resource-name
Name of the SAF resource. Expand the resource to see details:
Auditing
Indicates that if auditing is desired, the security administrator can perform set up for the
resource to be audited on successful read attempts.
Class
Class the resource belongs to.
```
**30**   Software Services task


```
Group
Group that requires access to the resource.
User IDs
User IDs that require access to the resource.
Inherited User IDs
Indicates users who are permitted to the SAF resource from a different version of the template
and might not be associated with the version that is being viewed. Deleting the SAF resource
would affect permissions for a different version of this template.
Roles
Roles for the user IDs.
```
**Values on the View window for a composite template**

The values are grouped on tabs.

**Template Details**

**Template name**
Name of the template.

**State**
State of the template.
**Archived**
The template is archived. An archived template is not visible to consumers. You can make it
available to consumers again with the **Publish** action.
**Corrupted**
The contents of the software services template are missing or incorrect. Delete the template.
**Draft**
The template has no approval records that must be approved. It is ready for the next step.
**Draft approved**
All of the approval records that are associated with the template and the respective runAsUser IDs
are approved. The template is ready for the next step.
**Draft missing required approver**
A runAsUser element in a definition file has no approval elements. To resolve the missing required
approver status, either:

- Edit the definition by using the Workflow Editor task, and add an approver.
- Add a domain approver, with the Resource Management task.
**Draft pending approvals**
The template has one or more approval records that must be approved.
**Draft rejected**
One or more approvers rejected an approval. All approval records must be approved before the
template is ready for the next step.
**Missing member**
Applies only to published or archived composite templates. It indicates that one or more of the
member templates that was referenced in the composite definition is not available.
To resolve the missing member condition, expand the composite template in the templates table
and identify the missing member. Then, you can either:
- Publish a new version of the member that is missing. (The version that you publish must be a
version of the member that was included when the composite template was created.) This puts
the composite template into Archived state. Then, if the content of the member templates and
the connector information is still valid, you can publish the archived composite template.

```
Software Services task   31
```

```
If the content of the member templates and the associated connector information is still not
valid, rather than publishing the archived composite template, create a new version of it and
make the appropriate updates.
```
- Create a new version of the composite template and remove the template that is missing. That
    is, on the second page of Create New Version of _template_ , select the missing member template
    in the table of member templates, then click **Actions** , then **Remove**.
**Pending security update**
Security permissions are being processed. No requests are allowed against the template while
it is in this state, so some actions might be disabled. If automatic security is in effect for the
associated domain, the state changes automatically when the security update for the domain
is complete. If manual security is in effect for the associated domain, use the **Set Security
Complete** action to change the state after all manual security setup for the domain has been
performed.
**Published**
The template is locked and is visible to consumers.
**Security update failed**
A failure occurred in processing security permissions. Some actions might be unavailable.
**Domain**
Domain to which the template belongs.
**Tenants**
Tenants to which the template has been added.
**Template version**
Version of the template.
**Template description**
Description of the template.
**Administrator documentation file**
Path for the documentation file for administrators. (Not displayed if you are logged in as a consumer.)
The path is displayed as a link. Click the link to open the file.
**Consumer documentation file**
Path for the documentation file for consumers. The path is displayed as a link. Click the link to open
the file.
**Composite clustered instance**
Indicates if the template is a clustered composite template.
**true**
The template is a clustered composite template. It will provision a cluster of software services
instances with a common resource pool.
**false**
The template is not a clustered composite template.
**Composite variables input file**
Path for the input variables file for the composite template. Click the link to view the properties file.
**Composite definition**
Description of the member templates for the composite template, including the provisioning
sequence and name. For clustered composite templates, the number of clustered instances for
the template is also shown. Click the template name to view template details. If the member is
referenced in the composite definition but is not available, the template is labeled as missing.

```
Associated Resource Pools
Pool Name
Name of the resource pool that is associated with the template.
Pool type
Type of resource pool that is associated with the template.
```
**32**   Software Services task


**Tenant**
Name of the tenant that the resource pool is associated with.

**Instance Limit**
Maximum number of software services instances that are allowed to be created from the template.

**Instance actual**
Actual number of software services instances that exist.

**Network Pool Status**
Status of the network pool.

**Workload Management Pool Status**
Status of the workload management pool.

**Sysplex System**
Sysplex and system for provisioning.

**Managed By**
Primary or managing system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Metadata**

**Created by**
User ID of the user who created the template.

**Created on**
Time and date that the template was created.

**Modified by**
User ID of the user who modified the template.

**Modified on**
Time and date that the template was modified.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Connectors**

**Connectors for** **_template_**
There is a table for each standard template that is a member of the composite template. You can
expand or collapse the section for each template. The table shows the connector variables that
connect the template to previous templates in the sequence. It includes the following:
**Variable Name**
Name of the connector variable.
**Source**
Name of the template that is the source of the connector variable.
**Source Variable Name**
Name of the variable that is the source of the connector variable.
**State**
Indication of whether the value is valid or not. Not Valid indicates that one or more of the values
for that connector is not valid.

```
Software Services task   33
```

```
Variables
Prompt variables for template
Table that shows the prompt variables, that is, properties that are prompted for at runtime. It shows
the name and default value for each variable. There is a table for each standard template that is a
member of the composite template. You can expand or collapse the section for each template. The
table shows the connector variables that connect the template to previous templates in the sequence.
```
**Actions**

```
Actions for template
Table that shows the actions that are provided for the instance. The actions are defined in the actions
file associated with the template. The table shows the name, type, description, and command (if
appropriate) for each action. There is a table for each standard template that is a member of the
composite template. You can expand or collapse the section for each template. The table shows the
connector variables that connect the template to previous templates in the sequence.
```
**History**

```
Table that shows a history of the actions that were performed on the template.
```
```
Table 9. Columns in the History table
```
```
Column Description
```
```
Type Type of action that was taken on the template, such as "modify.”
```
```
Ran by User User ID under which the action was performed.
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
```
Approvers
Template Approvers
Table that shows the approvers for the composite template and for specific approval records for the
template. To see information about approvers for the standard templates that are members of this
composite template, view the standard templates.
```
```
Table 10. Columns in the Approvers table
```
```
Column Description
```
```
Approvers (Groups and
Users)
```
```
User IDs and SAF groups of the approvers. Any one of the users can approve or
reject the item.
If no approver user ID or no user in an approver group ID matches the user
ID specified with the runAsUser user ID, an approval record for Security
Administrator is generated by z/OSMF. This Security Administrator
approver record must be approved by a user with z/OSMF security administrator
authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN
resource in the ZMFCLOUD class. The Security Administrator approver should
review the contents of the templates, focusing on the use of runAsUser in the
workflow definition and actions definition files.
```
```
Status Status of the approval.
```
```
Run As User User ID under which the current workflow step or command is to be performed.
indicates that the value for the ID is dynamic, meaning that it was assigned by a
workflow.
```
**34**   Software Services task


_Table 10. Columns in the Approvers table (continued)_

**Column Description**

**Description** Description of the item.

**Item to Approve** Item (workflow step, action, or both) that requires approval, or an indication that
the approval is for the template as a whole or for the template based on the
domain that it is associated with. Click a link to open the item in read-only mode in
the appropriate editor. For domain and general approvals, the link is a text string,
for example, Workflow definition file.

**Modified By** User ID of the user who last acted on the item.

**Comment** Text of a comment that was added for the approval.

**Modified** Time that the item was last modified.

```
SAF Resources
SAF Resources
Table that shows information about SAF resources that protect the template. You can expand or
collapse the sections for all resources, or for a single resource, to show or hide details.
Security definition
Setting for Security definition for the domain.
Automatic
z/OSMF uses a workflow to perform security setup dynamically. This is the default.
Manual
Security setup must be performed manually. The state of the template is initially set to
Pending Security Update.
User Access
Access level that is required for the resources.
resource-name
Name of the SAF resource. Expand the resource to see details:
Auditing
Indicates that if auditing is desired, the security administrator can perform set up for the
resource to be audited on successful read attempts.
Class
Class the resource belongs to.
Group
Group that requires access to the resource.
User IDs
User IDs that require access to the resource.
Inherited User IDs
Indicates users who are permitted to the SAF resource from a different version of the template
and might not be associated with the version that is being viewed. Deleting the SAF resource
would affect permissions for a different version of this template.
Roles
Roles for the user IDs.
```
```
Software Services task   35
```

```
View an actions definition file
You can view the actions definition file when viewing a template.
```
```
Before you begin
The template must be a standard template.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. View a template.
    a) In the templates table, select a template.
b) Click **Actions** , then select **View**.
4. On the Template Details tab, click the link for the actions file.

```
What to do next
For more information, see “Using the View Actions File window ” on page 36.
```
**Using the View Actions File window**

```
In the View Actions File window, a table displays the actions in the selected action definition file. To view
the properties of an action, select the action in the table. You can select one action only. The format and
content of the table is described in “Actions table” on page 36.
When you select an action, the editor opens a new area to the right of the table for editing the action
properties. The contents of that area varies with the type of action that is selected. See “View Action area
for a command action” on page 36, “View Action area for an instructions action” on page 38, and “View
Action area for a workflow action” on page 38.
```
**Actions table**

```
For a description of the columns in the Actions table, see Table 11 on page 36.
```
```
Table 11. Columns in the actions table.
```
```
Column Description
```
```
Name Name of the action.
```
```
Type Type of the action.
```
**History**

```
Table that shows a history of the actions that were performed on the template.
```
```
Table 12. Columns in the History table
```
```
Column Description
```
```
Type Type of action that was taken on the template, such as "modify.”
```
```
Ran by User User ID under which the action was performed.
```
```
Ran at Time Time at which the action occurred.
```
```
Details Description of the action.
```
**View Action area for a command action**

**36**   Software Services task


**Metadata tab**

The fields on the Metadata tab are described below.

**Action name**
Name of the action, which is displayed with the **Perform** action on the Instances table.

**Action type**
Type of action.

**Description**
Description of the action. This value is optional. If not provided, the Description field is empty.

**Command value**
System command.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.

**Solicited key**
Key to search for in the solicited messages of the command response.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.

**Unsolicited key**
Key to search for in the unsolicited messages of the command response.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.

**Detect time**
Time in seconds to search for the Unsolicited key value in the unsolicited messages. Also, the
minimum time before a command response is checked for after the command is submitted for
execution.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.

**Security tab**

The fields on the Security tab are described below.

**Run action under user ID**
The user ID under which the action is to be performed.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.

**Approvers**
A table of user and group IDs that can approve the action on behalf of the user ID that is specified
with **Run action under user ID**.
User IDs must have a security profile with an OMVS segment and a UID assigned. Group IDs must
have a security profile with an OMVS segment and a GID assigned.
This field can contain substituted values (variables). Variables are resolved from the variables stored
with the provisioned service at the time that the action is performed. See “Variable substitution” on
page 51.
When there are multiple user or group IDs for a row in the table, at least one of those user or group
IDs must approve. When there are multiple rows in the table, each represents a required approval. For

```
Software Services task   37
```

```
example, when the table shows the following, three approvers are required: usera, userb, and either
groupc or userd.
```
```
User ID
```
```
usera
```
```
userb
```
```
groupc userd
```
```
View Action area for an instructions action
Action name
Name of the action, which is displayed with the Perform action on the Instances table.
Action type
Type of action.
Description
Description of the action. This value is optional. If not provided, the Description field is empty.
Instructions
Text that describes how to perform a task, to be displayed in a window when the action is selected.
Allow substitution indicates that variable substitution is allowed, with variables resolved from the
variables stored with the provisioned service at the time that the action is performed.
```
```
View Action area for a workflow action
Action name
Name of the action, which is displayed with the Perform action on the Instances table.
Action type
Type of action.
Description
Description of the action. This value is optional. If not provided, the Description field is empty.
Workflow definition file
Path for the workflow definition file.
Click Edit to open the workflow with the Workflow Editor task.
Workflow variable input file
Path for the variable input file to use with the workflow.
Variables
Table of input variables, that is, properties that are required at runtime. It shows the name and value
for each variable.
Workflow disposition
Option for the disposition of workflows.
Delete successful workflows on completion
Causes the workflow to be deleted automatically after it completes. This is the default.
Keep successful workflows on completion
Causes the workflow to be kept after it completes. You can view it with the Workflows task.
Inherit from template
Use the workflow disposition that is defined in the template. See “View a template” on page 26 for
more information.
```
**38**   Software Services task


```
View the workflow variables input file
You can view the workflow variables input file when viewing a template.
```
```
Before you begin
The template must be a standard template.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. View a template.
    a) In the templates table, select a template.
b) Click **Actions** , then select **View**.
4. On the Template Details tab, click the link for the workflow variables input file.

```
What to do next
For more information, see “Using the workflow variables input file window ” on page 39.
```
**Using the workflow variables input file window**

```
In the workflow variables input file window, the contents of the file are displayed. The view is read-only.
You can use the browser's Find function to search the contents of the file.
```
#### Modify a template

```
To modify a template, use the Modify action provided in the Templates table.
```
```
Before you begin
The template must be in one of the draft states, or in the published state.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Modify**.
5. On the **Modify** window, supply values. Values that are required are indicated by a * preceding the label
    for the field. See “Values on the Modify window for a standard template ” on page 39 or “Values on
    the Modify Composite window ” on page 41.
6. Click **OK**.

**Values on the Modify window for a standard template**

```
Template name
Name of the template.
Domain
Name of the domain that is associated with the template.
Workflow file
Location of the workflow definition file. This file is the primary XML file for the workflow definition.
Specify the fully qualified path name of the file, beginning with the forward slash (/) and including
the file name, for example, /usr/lpp/zosmf/V2R2/samples/workflow_sample_automation.xml, or the
name of a partitioned or sequential data set.
```
```
Software Services task   39
```

```
Click Edit to open the workflow definition file in the workflow editor.
A workflow file is required.
Actions file
Location of the XML file that contains action definitions. Specify the fully qualified path name of the
file, beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. An actions file is required.
Click Edit to open the actions file in an editor.
Workflow variables input file
Location for the variables input file to use with the workflow. Specify the fully qualified path name of
the file, beginning with the forward slash (/) and including the file name, or the name of a partitioned
or sequential data set.
Consumer documentation file
Path for the documentation file for consumers. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
Administrator documentation file
Path for the documentation file for administrators. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the File Type field.
Template approver (Groups or Users)
List of the user IDs or SAF groups of the template approvers. You can add or remove approvers.
Separate these values with commas or blanks, for example zosmfad,ibmuser,zmfgrp. New
approvers receive a z/OSMF notification.
Template description
Description of the template.
This setting can be modified for a published template.
Workflows disposition
Indicates the disposition of the workflow after the software is provisioned. This selection applies to
the workflow that is used to provision the software, and its associated action workflows. Choose one
of the following options:
Archive successful workflows on completion
Workflows are archived in the Workflows task after they complete. This option is the default.
Delete successful workflows on completion
Workflows are deleted after they complete.
Keep successful workflows on completion
Workflows are retained after they complete. You can manually delete them from the workflows
table in the Workflows task.
If you do not specify a workflows disposition, the workflows are archived by default.
For action workflows, this setting can be overridden in the actions definition file.
This setting can be modified for a published template.
Jobs disposition
Select Delete jobs on completion to cause the jobs that are dynamically submitted to be deleted
automatically after they complete. The default is to keep the jobs.
If you do not specify that the jobs should be deleted automatically, you can manually delete the jobs.
This setting can be modified for a published template.
Instances disposition
Select Delete deprovisioned instances on completion to cause the instance to be deleted
automatically when it is deprovisioned. The default is to keep the instance.
```
**40**   Software Services task


```
The instances disposition is also applicable for composite templates. It applies to the instances for
the composite instance and composite member instances.
If you do not specify that deprovisioned instances should be deleted automatically, you can manually
delete them. To do so, navigate to the instances table, click Actions , then select Remove.
This setting can be modified for a published template.
```
**Values on the Modify Composite window**

**Target Domain**
Name of the domain that is associated with the template.

**Template name**
Name of the template.

**Use composite template to cluster instances on systems in a sysplex**
The template is a clustered composite template. It provisions clustered software services instances.
Clustered software services instances are collections of instances that use the resources defined in a
common resource pool that is associated with the clustered composite template. The instances are
provisioned on the systems in the sysplex that are identified in the resource pool.

**Composite variables input file**
Location of the properties file that you can use to specify in advance values for one or more of the
atCreate variables that are defined in the member standard template workflow definition files.
Specify the fully qualified z/OS UNIX path of the file, beginning with the forward slash (/) and including
the file name. For example, specify /usr/lpp/zosmf/samples/composite.properties
The variable names are in the following format: <standard-template-name>.<atcreate-variable>
For example: CICS.startup=10
If the file includes any variables that are associated with standard templates that are not members of
the composite, those variables are ignored. All other variable names are validated to ensure they are
atCreate variables that associated with the member standard template. No validation is performed on
the provided values.

**Consumer documentation file**
Path for the documentation file for consumers. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.

**Administrator documentation file**
Path for the documentation file for administrators. Specify the absolute z/OS UNIX path of the file,
beginning with the forward slash (/) and including the file name, or the name of a partitioned or
sequential data set. Select the file type with the **File Type** field.

**Template approver (Groups or Users)**
List of the user IDs or SAF groups of the template approvers. You can add or remove approvers.
Separate these values with commas or blanks, for example zosmfad,ibmuser,zmfgrp. New
approvers receive a z/OSMF notification.

**Template description**
Description of the template.

Click **Next** to display the window for adding published, standard templates to the composite template.

**_Modify Composite Template: Working with published templates in the composite_**

**_template_**

Use **Add Published Template** to add published standard templates to the composite template.

The standard templates in the composite template (sometimes referred to as member templates) are
displayed in a table. The table shows, for each member template, the sequence in which the template

```
Software Services task   41
```

```
will be provisioned, the name of the template, the number of clustered instances (for clustered composite
templates), and the name of the templates that it is connected to through connector variables.
```
**Actions for the table of member templates in the composite template**

```
Table 13. Actions for the table of member templates in the composite template
```
```
Action Description
```
```
Add Published Template Display a page to allow you to specify a published, standard template to
add to the composite template.
```
```
Modify Display a page to allow you to modify the connector variables. This
action is not available for the first template in the list, or if there are
no atCreate variables for the templates that follow the first template. For
more information, see “Modify Connector Variables” on page 19.
```
```
Move Select Move and Up or Down to move the selected template up or down
in the sequence. Connector variables connect a template to templates
that precede it, so be sure that you understand any possible effects on
connector variables when reordering the templates.
```
```
Remove Remove a published, standard template from the composite template. Be
sure that you understand any possible effects on connector variables.
```
```
Modify Connector Variables
A list of variables shows atCreate variables for the indicated template. Use Add or Remove to build the
set of connector variables that connect the template to previous templates in the sequence. In the table
of variables, you can select a different source template, from the other templates in the composite, to
override the original value for the variable. If a template appears multiple times in the list, values for
variables always come from the first of those templates.
When you add a variable to the list of connector variables, you can then select the source variable name
for it.
The registry-instance-Name constant (the default) evaluates to the instance name that is associated with
the instance that was created for the source template. You can code a workflow to perform a GET REST
request against the instance name and obtain whatever variables are required. For more information on
the REST API, see z/OS instance variables REST interface in IBM z/OS Management Facility Programming
Guide.
When you are finished building the set of connector variables for a template, click OK. Then, add
additional published templates as needed.
```
#### Edit an actions definition file

```
You can use the actions editor to edit an actions definition file when modifying a template.
```
```
Before you begin
The template must be in one of the draft states.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. Modify a template.
    a) In the templates table, select a template.
b) Click **Actions** , then select **Modify**.

**42**   Software Services task


```
c) On the Modify window, click Edit for the Actions file field. The Edit Actions File window is
displayed.
```
- You can create a new actions file when adding a template. For more information, see “Add a
    template” on page 15.

```
What to do next
For more information, see “Using the Edit Actions File window ” on page 43.
```
#### Using the Edit Actions File window

```
In the Edit Actions File window, a table displays the actions in the selected action definition file. To view
or edit the properties of an action, select the action in the table. You can select one action only. The
format and content of the table is described in “Actions table” on page 43.
When you select an action, the editor opens a new area to the right of the table for editing the action
properties. The contents of that area varies with the type of action that is selected. See “Edit Action area
for a command action” on page 44, “Edit Action area for an instructions action” on page 45, and “Edit
Action area for a workflow action” on page 45.
```
```
Actions table
For a description of the columns in the Actions table, see Table 14 on page 43. For a description of the
actions that you can take for actions, see Table 15 on page 43 and Table 16 on page 44.
```
```
Table 14. Columns in the actions table.
```
```
Column Description
```
```
Name Name of the action.
```
```
Type Type of the action.
```
```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected item. To use a targeted action, you must select an
    item.
- Table actions. Actions that apply to the entire table. No selection of table items is required.

```
Table 15. Targeted actions for the Actions table.
```
```
Action Description
```
```
Create New Action Create an action and add it to the actions definition file.
Choose one of the following types:
```
- Command. This issues a system command.
- Instruction. This displays text that describes how to perform a task.
- Workflow. This causes a workflow to be run.
z/OSMF opens the **Add Action** area, where you can supply information about the
new action. For information, see “Add a command action to the actions definition
file” on page 46, “Add an instructions action to the actions definition file” on page
48 , or “Add a workflow action to the actions definition file” on page 49.

```
Delete Delete the selected action from the actions definition file.
You cannot undo a delete. A prompt lets you confirm the deletion before it is
performed.
```
```
Software Services task   43
```

```
Table 16. Table actions for the Actions table.
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Edit Action area for a command action
The Edit Action area displays the following fields, where you can type or select values.
```
**Metadata tab**

```
The fields on the Metadata tab are described below.
Action name
Name of the action, which is displayed with the Perform action on the Instances table.
For actions that deprovision software services instances, select This is a deprovision action. A
deprovision action is required.
Action type
Type of action.
Description
Description of the action.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
Command value
System command.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
Solicited key
Key to search for in the solicited messages of the command response.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
Unsolicited key
Key to search for in the unsolicited messages of the command response.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
Detect time
Time in seconds to search for the Unsolicited key value in the unsolicited messages. Also, the
minimum time before a command response is checked for after the command is submitted for
execution.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
```
**44**   Software Services task


**Security tab**

The fields on the Security tab are described below.

**Run action under user ID**
Specify the user ID under which the action is to be performed.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
You are responsible for ensuring that the value you enter is a valid z/OS user ID. The editor checks the
value for syntax, but it does not verify that the user ID is defined to the security management product
on your system.

**Approvers**
A table of user and group IDs that can approve the action. At least one approver must approve the
action before it is performed on behalf of the user ID that is specified with **Run action under user ID**.
Use **Actions** to add or delete approvers.
User IDs must have a security profile with an OMVS segment and a UID assigned. Group IDs must
have a security profile with an OMVS segment and a GID assigned.
When you specify the approver name on the **Add approver** window, the field can contain substituted
values (variables). If you include variables in this field, select **Allow substitution**. Variables are
resolved from the variables that are stored with the provisioned service at the time that the action is
performed. See “Variable substitution” on page 51.
If no approver user ID or no user in an approver group ID matches the user ID specified with **Run
action under user ID** , an approval record for Security Administrator is generated by z/OSMF.
This Security Administrator approver record must be approved by a user with z/OSMF security
administrator authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN resource
in the ZMFCLOUD class.
For more information about approvals, see “Approvals” on page 54.

**Edit Action area for an instructions action**

The **Edit Action** area displays the following fields, where you can type or select values.

**Action name**
Name of the action, which is displayed with the **Perform** action on the Instances table.
For actions that deprovision software services instances, select **This is a deprovision action**. A
deprovision action is required.

**Action type**
Type of action.

**Description**
Description of the action.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Instructions**
Text that describes how to perform a task, to be displayed in a window when the action is selected.
Select **Allow substitution** to allow variable substitution, with variables resolved from the variables
stored with the provisioned service at the time that the action is performed.

**Edit Action area for a workflow action**

The **Edit Action** area displays the following fields, where you can type or select values.

```
Software Services task   45
```

```
Action name
Name of the action, which is displayed with the Perform action on the Instances table.
For actions that deprovision software services instances, select This is a deprovision action. A
deprovision action is required.
Action type
Type of action.
Description
Description of the action.
Workflow definition file
Path for the workflow definition file. Specify the absolute path of the file, beginning with
the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/samples/
workflow_sample_basic.xml, or the name of a partitioned or sequential data set.
Click Edit to open the workflow with the Workflow Editor task.
Workflow variable input file
Path for the variable input file to use with the workflow. Specify the absolute path of the file, beginning
with the forward slash (/) and including the file name, for example,/usr/lpp/zosmf/samples/
workflow_sample_variables.xml, or the name of a partitioned or sequential data set.
Variables
Table of input variables, that is, properties that are required at runtime. It shows the name and value
for each variable.
Click Edit Variables to display a window that lets you add or remove variables from the set of selected
variables.
Workflow disposition
Select an option.
Delete successful workflows on completion
Causes the workflow to be deleted automatically after it completes. This is the default.
Keep successful workflows on completion
Causes the workflow to be kept after it completes. You can view it with the Workflows task.
Inherit from template
Use the workflow disposition that is defined in the template. See “View a template” on page 26 for
more information.
If you do not specify that the workflow should be deleted automatically, you can manually delete the
workflow from the workflows table in the Workflows task.
```
```
Add a command action to the actions definition file
To add a command-type action to the actions definition file, click Create New Action in the Actions table,
then select Command.
```
**Before you begin**

```
The template must be in one of the draft states.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Modify**.
5. On the **Modify** window, click **Edit** for the Actions file field.
    The **Edit Actions File** window is displayed.

**46**   Software Services task


6. In the Actions table, click **Create New Action** , then select **Command**.
    The **Add Action** area is displayed to the right of the Actions table.
7. Specify values, then click **Save** or **Save & Close**.
    See “Values for a command action” on page 47 for more information.

**Values for a command action**

For a command-type action, the values are displayed on tabs.

**Metadata tab**

The fields on the Metadata tab are described below.

**Action name**
Name of the action, which is displayed with the **Perform** action on the Instances table.
For actions that deprovision software services instances, select **This is a deprovision action**. A
deprovision action is required.

**Action type**
Type of action.

**Description**
Description of the action.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Command value**
System command.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Solicited key**
Key to search for in the solicited messages of the command response.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Unsolicited key**
Key to search for in the unsolicited messages of the command response.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Detect time**
Time in seconds to search for the Unsolicited key value in the unsolicited messages. Also, the
minimum time before a command response is checked for after the command is submitted for
execution.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Security tab**

The fields on the Security tab are described below.

```
Software Services task   47
```

```
Run action under user ID
Specify the user ID under which the action is to be performed.
This field can contain substituted values (variables). If you include variables in this field, select Allow
substitution. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.
You are responsible for ensuring that the value you enter is a valid z/OS user ID. The editor checks the
value for syntax, but it does not verify that the user ID is defined to the security management product
on your system.
Approvers
A table of user and group IDs that can approve the action. At least one approver must approve the
action before it is performed on behalf of the user ID that is specified with Run action under user ID.
Use Actions to add or delete approvers.
User IDs must have a security profile with an OMVS segment and a UID assigned. Group IDs must
have a security profile with an OMVS segment and a GID assigned.
When you specify the approver name on the Add approver window, the field can contain substituted
values (variables). If you include variables in this field, select Allow substitution. Variables are
resolved from the variables that are stored with the provisioned service at the time that the action is
performed. See “Variable substitution” on page 51.
If no approver user ID or no user in an approver group ID matches the user ID specified with Run
action under user ID , an approval record for Security Administrator is generated by z/OSMF.
This Security Administrator approver record must be approved by a user with z/OSMF security
administrator authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN resource
in the ZMFCLOUD class.
For more information about approvals, see “Approvals” on page 54.
```
```
Add an instructions action to the actions definition file
To add an instructions-type action to the actions definition file, click Create New Action in the Actions
table, then select Instructions.
```
**Before you begin**

```
The template must be in one of the draft states.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Modify**.
5. On the **Modify** window, click **Edit** for the Actions file field.
    The **Edit Actions File** window is displayed.
6. In the Actions table, click **Create New Action** , then select **Instructions**.
    The **Add Action** area is displayed to the right of the Actions table.
7. Specify values, then click **Save** or **Save & Close**.
    See “Values for an instruction action” on page 48 for more information.

**Values for an instruction action**

```
The Add Action area displays the following fields, where you can type or select values.
Action name
Name of the action, which is displayed with the Perform action on the Instances table.
```
**48**   Software Services task


```
For actions that deprovision software services instances, select This is a deprovision action. A
deprovision action is required.
```
**Action type**
Type of action.

**Description**
Description of the action.
This field can contain substituted values (variables). If you include variables in this field, select **Allow
substitution**. Variables are resolved from the variables stored with the provisioned service at the time
that the action is performed. See “Variable substitution” on page 51.

**Instructions**
Text that describes how to perform a task, to be displayed in a window when the action is selected.
Select **Allow substitution** to allow variable substitution, with variables resolved from the variables
stored with the provisioned service at the time that the action is performed.

**Add a workflow action to the actions definition file**

To add a workflow-type action to the actions definition file, click **Create New Action** in the Actions table,
then select Workflow.

**Before you begin**

The template must be in one of the draft states.

**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Modify**.
5. On the **Modify** window, click **Edit** for the Actions file field.
    The **Edit Actions File** window is displayed.
6. In the Actions table, click **Create New Action** , then select **Workflow**.
    The **Add Action** area is displayed to the right of the Actions table.
7. Specify values, then click **Save** or **Save & Close**.
    See “Values for a workflow action ” on page 49 for more information.

**Values for a workflow action**

The **Add Action** area displays the following fields, where you can type or select values.

**Action name**
Name of the action, which is displayed with the **Perform** action on the Instances table.
For actions that deprovision software services instances, select **This is a deprovision action**. A
deprovision action is required.

**Action type**
Type of action.

**Description**
Description of the action.

**Workflow definition file**
Path for the workflow definition file. Specify the absolute path of the file, beginning with
the forward slash (/) and including the file name, for example, /usr/lpp/zosmf/samples/
workflow_sample_basic.xml, or the name of a partitioned or sequential data set.

```
Software Services task   49
```

```
Click Edit to open the workflow with the Workflow Editor task.
Workflow variable input file
Path for the variable input file to use with the workflow. Specify the absolute path of the file, beginning
with the forward slash (/) and including the file name, for example,/usr/lpp/zosmf/samples/
workflow_sample_variables.xml, or the name of a partitioned or sequential data set.
Variables
Table of input variables, that is, properties that are required at runtime. It shows the name and value
for each variable.
Click Edit Variables to display a window that lets you add or remove variables from the set of selected
variables.
Workflow disposition
Select an option.
Delete successful workflows on completion
Causes the workflow to be deleted automatically after it completes. This is the default.
Keep successful workflows on completion
Causes the workflow to be kept after it completes. You can view it with the Workflows task.
Inherit from template
Use the workflow disposition that is defined in the template. See “View a template” on page 26 for
more information.
If you do not specify that the workflow should be deleted automatically, you can manually delete the
workflow from the workflows table in the Workflows task.
```
```
Edit Variables
You can edit the variables for an action workflow.
```
**Before you begin**

```
The template must be in one of the draft states, or in the published state.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then select **Modify**.
5. On the **Modify** window, click **Edit** for the Actions file field.
    The **Edit Actions File** window is displayed.
6. In the table, select an action that is type workflow.
    The Edit Action area is displayed.
7. Click **Edit Variables**.
    The **Edit Variables** window displayed.

```
What to do next
For more information, see “Values on the Edit Variables window ” on page 50.
```
**Values on the Edit Variables window**

```
Variables
Selected Variables
Define the variables to include. The Variables table shows the variables that are available to be
included.
```
**50**   Software Services task


```
Use Add or Remove to build the set of variables.
In the Selected Variables table, you can supply new values for variables. Select Save Value Updates
to specify that the new value is saved and is available to the instance after the action workflow
completes.
```
```
Variable substitution
You can use variable substitution with command actions.
Use variable substitution for fields on the Metadata tab, and for user IDs that you specify for approvers or
the Run action under user ID field on the Security tab. Specify the substitution string in the input field and
select the option to allow substitution. When the action is performed, the system performs the variable
substitution to derive the value.
The syntax for specifying a substitution variable is $!{ variable }. For example, to use variable substitution
for a user ID, you might specify the following variable:
```
```
$!{CONSOLE_USER}
```
#### Associate a tenant with a template

```
To associate a tenant with a template, use the Associate Tenant action in the Templates table.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Associate Tenant**.
5. On the **Associate Tenant** window, supply values. Click **OK** to display the **Add Template and Resource**
    **Pool** window of the Resource Management task.
6. On the **Add Template and Resource Pool** window, supply values. Then click **OK**.
7. Having used the Resource Management task to add a template to the tenant, return now to the
    Software task. Click the **Software Services** tab.

#### Values on the Associate Tenant window

```
Template Name
Name of the template.
Template Description
Description of the template.
Domain
Name of the domain that is associated with the template.
Tenant
Select a tenant. Tenants are defined for a domain with the Resource Management task.
Resource pool selection
Select an option:
Create a dedicated resource pool
Select this option to create a new resource pool that is dedicated to the template.
Use an existing tenant shared resource pool
Select this option to use a tenant shared resource pool, which can be shared between the
templates in a tenant. This option is available only when the tenant contains a shared resource
pool.
```
```
Software Services task   51
```

```
Use an existing domain shared resource pool
Select this option to use a domain shared resource pool, which can be shared between the
templates in all of the tenant in the domain. This option is available only when the domain
contains a shared resource pool.
If the tenant- or domain-shared resource pool does not exist, these selections are not selectable.
When a resource pool is selected for a template or tenant during provisioning, the following selection
order is used by default:
```
1. Dedicated resource pool.
2. Tenant shared resource pool.
3. Domain shared resource pool.

#### Approve a template

```
To approve a template, use the Approve action that is provided in the Templates table.
```
```
About this task
This task describes how to approve the approval records for a template. There can be multiple approvers
for a template, each of whom must complete this task. If there are no approvers for a template, this task
does not apply.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then, select **Approvals**.
5. On the **Approvals** window, find items in the Approvers table that you can approve, then use the
    **Approve** action to approve them.
    If the **Approve** action is not available, you cannot approve the selected item. To view an item before
    you approve it, click the value in the Item to Approve column to open it in the appropriate editor. For
    more information, see “Values on the Approvals window ” on page 52.
    If changes must be made to the definition files, use the **Reject** action to reject the item.
    **Note:** Modifying definition files causes all approvals to be reset.
    When all of the required approvals are entered for the template, z/OSMF sends a notification of the
    template approval status to each of the domain administrators. If one or more rejections are specified,
    z/OSMF sends a separate notification for each rejection to the domain administrators.

```
What to do next
When you return to the templates table, if the state of the template is now Pending Security Update, click
Refresh to see an updated state that reflects the approvals.
```
#### Values on the Approvals window

```
Template name
The name of the template.
Template description
Description of the template.
Approvers
Table of approval records for the templates. You can approve or reject each approval record.
```
**52**   Software Services task


```
When there are multiple user IDs for a row in the table, at least one of those user IDs must approve.
When there are multiple rows in the table, each represents a required approval. For example, when
the table shows the following, three approvers are required: usera, userb, and either userc or userd.
```
```
User ID
```
```
usera
```
```
userb
```
```
userc or userd
```
```
If no approver user ID or no user in an approver group ID matches the user ID specified with the
runAsUser user ID, an approval record for Security Administrator is generated by z/OSMF.
This Security Administrator approver record must be approved by a user with z/OSMF security
administrator authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN resource
in the ZMFCLOUD class. The Security Administrator approver should review the contents of the
templates, focusing on the use of runAsUser in the workflow definition and actions definition files.
```
**Columns in the Approvers table**

_Table 17. Columns in the Approvers table_

**Column Description**

**Approvers (Groups and
Users)**

```
User IDs and SAF groups of the approvers. Any one of the users can approve or
reject the item.
If no approver user ID or no user in an approver group ID matches the user
ID specified with the runAsUser user ID, an approval record for Security
Administrator is generated by z/OSMF. This Security Administrator
approver record must be approved by a user with z/OSMF security administrator
authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN
resource in the ZMFCLOUD class. The Security Administrator approver should
review the contents of the templates, focusing on the use of runAsUser in the
workflow definition and actions definition files.
```
**Status** Status of the approval.

**Run As User** User ID under which the current workflow step or command is to be performed.

```
indicates that the value for the ID is dynamic, meaning that it was assigned by a
workflow.
```
**Description** Description of the item.

**Item to Approve** Item (workflow step, action, or both) that requires approval, or an indication that
the approval is for the template as a whole or for the template based on the
domain that it is associated with. Click a link to open the item in read-only mode in
the appropriate editor. For domain and general approvals, the link is a text string,
for example, Workflow definition file.

**Modified By** User ID of the user who last acted on the item.

**Comment** Text of a comment that was added for the approval.

**Modified** Time that the item was last modified.

```
For a workflow step or action, you can click the link in the Item column to open it in the Workflow Editor.
```
**Actions for Approvers**

```
The actions are described in the following tables:
```
```
Software Services task   53
```

- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 18 on page 54.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 19
    on page 54.

```
Table 18. Targeted actions for the Approvers table
```
```
Action Description
```
```
Approve Approve the selected item. If the Approve action is not available, then you are not
permitted to approve that item.
```
```
Reject Reject the selected item. Adding a comment with the rejection might help in getting
any necessary changes made to the definition files. Modifying definition files causes
all approvals to be reset. You might need to remove and add the template, or
refresh the template files, using the Refresh Template action in the templates
table.
```
```
Table 19. Table actions for the Approvers table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
```
Approvals
Approval records for a software services template must be approved before the template can be
published. The State column of the templates table indicates if approvals are required.
Approval records can be:
```
- Specific to a workflow step or action. These are generated when a workflow or action definition file
    for a software services template contains a runAsUser element with approver elements. A runAsUser
    element identifies a user ID under which the current workflow step or command is to be performed.
    Approving an approval record for a workflow step or action allows the owner of the software services
    template to use the "run as" user ID in the software services template.
- For the template. To create a template approval, modify a template using the **Modify** action. Then, on
    the **Modify Template** window, use the Template Approvers field.
- For the domain. Domain approvals apply to the template while it is in one of the draft states. Domains
    are defined with the Resource Management task. You can define an approver for a domain when
    creating or modifying the domain.
Each approver record can contain multiple user and group IDs, separated by commas or blanks, for
example, zosmfad ibmuser. When there are multiple user or group IDs for an approver record, any one
of those user IDs or any user in any of the group IDs can approve. When there are multiple approver
records, each represents a required approver. For example, when the approval records are as follows,
three approvers are required: usera, userb, and either groupc or userd.

**54**   Software Services task


```
User ID
```
```
usera
```
```
userb
```
```
groupc userd
```
```
If no approver user ID or no user in an approver group ID matches the user ID specified with
the runAsUser user ID, an approval record for Security Administrator is generated by z/OSMF.
This Security Administrator approver record must be approved by a user with z/OSMF security
administrator authority, that is, a user with access to the IZUDFLT.ZOSMF.SECURITY.ADMIN resource in
the ZMFCLOUD class. The Security Administrator approver should review the contents of the templates,
focusing on the use of runAsUser in the workflow definition and actions definition files.
```
```
Missing required approvers
A Draft missing required approver state indicates that a runAsUser element in a definition file has no
approval elements. This state, in the templates table, is a link. To identify the missing approver, click the
state to view the details. When the details are displayed, click a link in the Item to Approve column to
display the element in read-only mode using the Workflow Editor or actions editor, as appropriate. To
resolve the missing required approver state, either:
```
- Edit the definition using the appropriate editor and add an approver.
- Add a domain approver, with the Resource Management task.
- Add a template approver. Modify the template using the **Modify** action, then, on the Modify Template
    window, use the Template Approvers field.
To approve the approval record, use the **Approvals** action in the templates table. Then, on the **Approvals**
window, select items in the table and use the **Approve** action.
**Related tasks**
Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
**Related reference**
Files used to define software services templates
A standard software services template is defined with workflow definition files, action definition files, and
variable input files. Documentation files describe the software services template, the content of the other
files and the values that you might need to change. A composite software services template does not
include workflow or action definition files, but includes a composite variable input file.
**Related information**
Publish a template
Publish makes a template available to consumers and prepares it for the **Run** action. It locks the
template, allowing only limited modification, and puts it in the published state.

#### Test Run a template

```
To test run a template before publishing it, use the Test Run action provided in the Templates table.
```
```
Before you begin
All approvals for the template must be approved.
The template must be in a draft or draft approved state.
If you would like to complete these steps using a video see How to test and publish
a template in IBM Cloud Provisioning and Management for z/OS (mediacenter.ibm.com/media/
How+to+test+and+publish+a+template+in+IBM+Cloud+Provisioning+and+Management+for+z+OS/
0_dxypa7uq/101043781).
```
```
Software Services task   55
```

**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then select **Test Run**.
5. On the **Test Run Template** window, supply values, then click **OK**. See “Values on the Test Run window
    for a standard template ” on page 56 and “Values on the Test Run window for a composite template ”
    on page 57.
    If there are additional input fields for prompt variables (based on the workflow definition and variable
    input files for this template), supply the required information. To display the tip for a field, click the tips
    icon ( ).
    Test Run creates a workflow, starts the workflow, and creates a corresponding instance. The Instances
    tab is displayed.

**What to do next**

```
On the Instances tab, check the table for the software services instance that you created with Test Run.
The name of the instance is :
```
- For a standard template: _software-type_ _ _prefix-for-resource-poolnumber_ , for example, Standard_M03.
- For a composite template: _prefix-for-resource-pool_ _ _prefix-for-resource-poolnumber_ , for example,
    C_C03. For a clustered composite, a suffix of _ _software-service-instance-name_ is added.
In the name, _prefix-for-resource-pool_ is the value that is specified for software service instance name
prefix field on the **Add Template and Resource Pool** page or the **Create Shared Resource Pool** page, and
_number_ is assigned by z/OSMF.
The status of the instance should be either Being-Provisioned or Provisioned. Provisioned indicates
success. You might need to click **Refresh** to see the status change to Provisioned.
You might want to try one or more actions against the instance to ensure that they work as expected. Click
**Actions** , then select **Perform** , then select an action.
If the instance was created successfully, with a status of Provisioned, and the actions perform as
expected, you are now ready to publish the template. You may want to first clean up the results of
your test, that is, deprovision and remove the instance that you created with **Test Run**.

**Values on the Test Run window for a standard template**

```
Template name
Name of the template.
Template description
Description of the template.
Associated tenant
Select the tenant whose resource pool is used to obtain resources during instance provisioning.
A tenant is a class of users, which is defined with the Resource Management task.
System selection for provisioning
If the value is Select system, you must select a system from the list. Otherwise, the field indicates how
the system is selected for you:
```
- **Assign a system automatically from the table below:** z/OSMF assigns a system from thesystems
    that are shown in the table.
- **System name:** The value indicates the system on which the template will be provisioned.

**56**   Software Services task


**Maximum days until a provisioned instance expires automatically**
Enter the number of days until the provisioned instance expires. When a provisioned instance expires,
it is marked as expired, and the instance remains in provisioned state. The **Instances** tab of the
Software Services task shows when an instance is expired in the "State" column as _"Provisioned -
Expired"_. When an instance for which a time limit is set nears its time limit, z/OSMF notifies the
consumer, who can then deprovision the instance.
This field is preset to the maximum time limit that is set in the resource pool for the template. You
cannot exceed this value. If this field is left blank, the maximum value for the resource pool is used by
default. If no limit is set for the resource pool, the provisioned instance does not expire automatically
unless a time limit is set for the template that creates the instance.

**Account information**
Specify account information to use in the JCL JOB statement. By default, it is the account information
that is associated with the tenant resource pool.
This field might not be shown as a result of an option set with the Resource Management task. (The
option is Allow account information to be modified when the template is provisioned, for adding or
modifying a template and resource pool.)

There might additional input fields for prompt variables, based on the workflow definition and variable

input files for the template. To display the tip for a field, click the tips icon ( ).

**Values on the Test Run window for a composite template**

**Template name**
Name of the template.

**Template description**
Description of the template.

**Associated tenant**
Select the tenant whose resource pool is used to obtain resources during instance provisioning.
A tenant is a class of users, which is defined with the Resource Management task.

**System selection for provisioning**
If the value is Select system, you must select a system from the list. Otherwise, the field indicates how
the system is selected for you:

- **Assign a system automatically from the table below:** z/OSMF assigns a system from thesystems
    that are shown in the table.
- **System name:** The value indicates the system on which the template will be provisioned.

**Maximum days until a provisioned instance expires automatically**
Enter the number of days until the provisioned instance expires. When a provisioned instance expires,
it is marked as expired, and the instance remains in provisioned state. The **Instances** tab of the
Software Services task shows when an instance is expired in the "State" column as _"Provisioned -
Expired"_. When an instance for which a time limit is set nears its time limit, z/OSMF notifies the
consumer, who can then deprovision the instance.
This field is preset to the maximum time limit that is set in the resource pool for the template. You
cannot exceed this value. If this field is left blank, the maximum value for the resource pool is used by
default. If no limit is set for the resource pool, the provisioned instance does not expire automatically
unless a time limit is set for the template that creates the instance.

**Account information**
Specify account information to use in the JCL JOB statement. The account information is supplied for
any member templates for which the Allow account information to be modified when the template
is provisioned option was selected when adding or modifying a template and resource pool to the
tenant. This is performed with the Resource Management task.
This field is not shown if Allow account information to be modified when the template is provisioned
was not selected for any templates.

```
Software Services task   57
```

```
There might additional input fields for prompt variables, based on the workflow definition and variable
input files for the member templates. To display the tip for a field, click the tips icon ( ).
```
#### Fixing problems with provisioning

```
When the status of a software services instance is Provisioning-Failed, you may need to make changes in
the workflow definition.
To determine the cause of the error in the workflow, you can examine the failed step using the Workflows
task of z/OSMF.
```
1. In the Instances table, click the instance name.
2. On the View page, click the value in the Workflow field. This opens the Workflows task.
In addition to correcting the workflow, you need to clean up the work that has been performed.
1. To remove the instance, select the instance in the instances table, click **Perform** , then select
**deprovision**.
2. When the instance is in a Deprovisioned state, click **Actions** , then select **Remove**.
3. Select the Templates tab to display the table of templates. Depending on the changes that you made,
either:
- Remove the template with the **Remove** action, then add the template with the **Add** action.
- If the only changes were to workflow or action definitions, you can refresh those files with the
**Refresh Template** action.
4. Resume the process for provisioning with the **Approvals** action, if the template has approval records,
or with the **Test Run** action.

```
Composite templates
If a composite template fails to provision, review the member templates to identify the member that
failed to provision and the problems with that member's provisioning workflow. You can view the details
of the failed composite instance, by clicking the name of the composite instance in the instances table, to
see all of the child instances and their workflows (if available).
If you manually move the failed member template into a provisioning complete state, this initiates an
attempt to provision the remaining members that are still in a being-initialized state.
You cannot deprovision the members. Instead, deprovision the composite instance.
Related tasks
Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.
```
#### Publish a template

```
Publish makes a template available to consumers and prepares it for the Run action. It locks the
template, allowing only limited modification, and puts it in the published state.
Publishing a new version of a standard template automatically archives any published composite
templates that include the standard as a member. You can then either publish one or more of the affected
composite templates again, or create a new version. The composite template can be published only if all
connector information is accurate.
Before you use Publish, all approval records must be approved.
The template must be in the draft, draft approved, or archived state.
Note: For templates in a draft or draft approved state, if the workflow definition, action definition,
composite variable input, or workflow variable input files were modified since the template was created,
you must use the Refresh Template action before the Publish action to use the modified files.
```
**58**   Software Services task


**Related concepts**

Approvals
Approval records for a software services template must be approved before the template can be
published. The State column of the templates table indicates if approvals are required.

**Related tasks**

Prepare and publish a template
This topic provides an overview of the steps for creating a standard template that can be used to provision
software.

**Related reference**

Files used to define software services templates
A standard software services template is defined with workflow definition files, action definition files, and
variable input files. Documentation files describe the software services template, the content of the other
files and the values that you might need to change. A composite software services template does not
include workflow or action definition files, but includes a composite variable input file.

**Confirm publish a template**

This topic describes the conditions and actions related to confirming the **Publish** action.

You have attempted to publish a template, and one of the following conditions exists.

- The template that you are attempting to publish has not been tested with the **Test Run** action. **Test**
    **Run** allows you to verify that a template successfully creates a software service instance, while leaving
    the template open for further changes. IBM recommends that you use **Test Run** before publishing a
    template.
    - To continue without first performing the **Test Run** , click **OK**.
    - To use **Test Run** before publishing the template, click **Cancel**.
- One or more source files for the template has been modified, but the modifications will not be used.
    - To continue without the changes to the source files, click **OK**.
    - To use the modified source files, click **Cancel** , then use the **Refresh** action for the template.
- There is already a published template with the same name. If you continue, that template will be
    archived.
    - To continue, click **OK**.
    - To cancel the Publish action, click **Cancel**.
    You can return an archived template to the published state with the **Publish** action.

**Publish Template Rejected**

A request to publish a template could not be completed because the template is a member of a
composite template that is in a draft state.

**About this task**

Before you publish the template, you must remove it from the composite template.

**Procedure**

1. Select the composite template in the templates table, then select **Actions** , then **Modify**.
    The Modify Composite Template page is displayed.
2. Click **Next** on the Modify Composite Template page.
    The list of published standard templates that are members of the composite template is displayed.
3. Select the template that you want to remove, then select **Actions** , then **Remove**.
    The confirmation dialog is displayed.

```
Software Services task   59
```

4. Click **OK** on the confirmation dialog.
    The Modify Composite Template page is displayed.
5. Click **Finish** on the Modify Composite Template page.
    The templates table is displayed.
6. Select the template that you want to publish, then select **Actions** , then **Publish**.

#### Run a template

```
To run a template, use the Run action provided in the templates table. This creates an instance.
```
```
Before you begin
The template must be published.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then select **Run**.
5. On the **Run Template** window, supply values, then click **OK**. See “Values on the Run window for a
    standard template” on page 60 and “Values on the Run window for a composite template ” on page
    61.
    If there are additional input fields for prompt variables (based on the workflow definition and variable
    input files for this template), supply the required information. To display the tip for a field, click the tips
    icon ( ).
    Run creates a workflow, starts the workflow, and creates a corresponding instance. The Instances tab
    is displayed. When the instance is in the provisioned state, the workflow is automatically deleted.

```
What to do next
On the Instances tab, check the table for the software services instance that you created with Run.
The name of the instance is :
```
- For a standard template: _software-type_ _ _prefix-for-resource-poolnumber_ , for example, Standard_M03.
- For a composite template: _prefix-for-resource-pool_ _ _prefix-for-resource-poolnumber_ , for example,
    C_C03. For a clustered composite, a suffix of _ _software-service-instance-name_ is added.
In the name, _prefix-for-resource-pool_ is the value that is specified for software service instance name
prefix field on the **Add Template and Resource Pool** page or the **Create Shared Resource Pool** page, and
_number_ is assigned by z/OSMF.
The status of the instance should be either Being-Provisioned or Provisioned. Provisioned indicates
success. You might need to click **Refresh** to see the status change to Provisioned.

**Values on the Run window for a standard template**

```
Template name
Name of the template.
Template description
Description of the template.
Associated tenant
Select the tenant whose resource pool is used to obtain resources during instance provisioning.
A tenant is a class of users, which is defined with the Resource Management task.
```
**60**   Software Services task


**System selection for provisioning**
If the value is Select system, you must select a system from the list. Otherwise, the field indicates how
the system is selected for you:

- **Assign a system automatically from the table below:** z/OSMF assigns a system from thesystems
    that are shown in the table.
- **System name:** The value indicates the system on which the template will be provisioned.

**Maximum days until a provisioned instance expires automatically**
Enter the number of days until the provisioned instance expires. When a provisioned instance expires,
it is marked as expired, and the instance remains in provisioned state. The **Instances** tab of the
Software Services task shows when an instance is expired in the "State" column as _"Provisioned -
Expired"_. When an instance for which a time limit is set nears its time limit, z/OSMF notifies the
consumer, who can then deprovision the instance.
This field is preset to the maximum time limit that is set in the resource pool for the template. You
cannot exceed this value. If this field is left blank, the maximum value for the resource pool is used by
default. If no limit is set for the resource pool, the provisioned instance does not expire automatically
unless a time limit is set for the template that creates the instance.

**Account information**
Specify account information to use in the JCL JOB statement. By default, it is the account information
that is associated with the tenant resource pool.
This field might not be shown as a result of an option set with the Resource Management task. (The
option is Allow account information to be modified when the template is provisioned, for adding or
modifying a template and resource pool.)

There may additional input fields for prompt variables, based on the workflow definition and variable

input files for the template. To display the tip for a field, click the tips icon ( ).

**Values on the Run window for a composite template**

**Template name**
Name of the template.

**Template description**
Description of the template.

**Associated tenant**
Select the tenant whose resource pool is used to obtain resources during instance provisioning.
A tenant is a class of users, which is defined with the Resource Management task.

**System selection for provisioning**
If the value is Select system, you must select a system from the list. Otherwise, the field indicates how
the system is selected for you:

- **Assign a system automatically from the table below:** z/OSMF assigns a system from thesystems
    that are shown in the table.
- **System name:** The value indicates the system on which the template will be provisioned.

**Maximum days until a provisioned instance expires automatically**
Enter the number of days until the provisioned instance expires. When a provisioned instance expires,
it is marked as expired, and the instance remains in provisioned state. The **Instances** tab of the
Software Services task shows when an instance is expired in the "State" column as _"Provisioned -
Expired"_. When an instance for which a time limit is set nears its time limit, z/OSMF notifies the
consumer, who can then deprovision the instance.
This field is preset to the maximum time limit that is set in the resource pool for the template. You
cannot exceed this value. If this field is left blank, the maximum value for the resource pool is used by
default. If no limit is set for the resource pool, the provisioned instance does not expire automatically
unless a time limit is set for the template that creates the instance.

```
Software Services task   61
```

```
Account information
Specify account information to use in the JCL JOB statement. The account information is supplied for
any member templates for which the Allow account information to be modified when the template
is provisioned option was selected when adding or modifying a template and resource pool to the
tenant. This is performed with the Resource Management task.
This field is not shown if Allow account information to be modified when the template is provisioned
was not selected for any templates.
There may additional input fields for prompt variables, based on the workflow definition and variable
input files for the templates. To display the tip for a field, click the tips icon ( ).
```
#### Archive a template

```
To archive a template, use the Archive action provided in the templates table. You can archive only
published templates.
```
```
Before you begin
The template must be published.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Templates** tab.
3. In the table, select a template.
4. Click **Actions** , then select **Archive**.

```
What to do next
To return an archived template to the published state, use the Publish action.
```
```
Archive Template Rejected
A request to archive a template could not be completed because the template is a member of a
composite template that is in a draft state.
```
```
About this task
Before you archive the template, you must remove it from the composite template.
```
**Procedure**

1. Select the composite template in the templates table, then select **Actions** , then **Modify**.
    The Modify Composite Template page is displayed.
2. Click **Next** on the Modify Composite Template page.
    The list of published standard templates that are members of the composite template is displayed.
3. Select the template that you want to remove, then select **Actions** , then **Remove**.
    The confirmation dialog is displayed.
4. Click **OK** on the confirmation dialog.
    The Modify Composite Template page is displayed.
5. Click **Finish** on the Modify Composite Template page.
    The templates table is displayed.
6. Select the template that you want to archive, then select **Actions** , then **Archive**.

**62**   Software Services task


```
Archive Template Confirmation Dialog
A request to archive a standard template caused a confirmation dialog to be displayed because the
template is a member of a composite template that is in a published state.
If you archive the template, it will be marked as missing from the composite template. You will no longer
be able to use the composite template for provisioning.
To return to the templates table without archiving the template, click Cancel.
To continue and archive the template, click OK. Later, to make the composite template usable for
provisioning again, you can publish the archived standard template (use the Publish action for the
archived standard template, and then for the composite template), or create a new version of the
composite template (with the Create New Version action). The new version will not include the missing
member template.
```
### Instances

```
Use the Instances tab of Software Services to work with software services instances, which represent
software on z/OS that was provisioned, typically through the use of software services templates, although
provisioning can be done manually. They may be middleware instances or middleware resources, such as
a Db2 database.
The instances are displayed in a table. Use View By to show the instances by type.
```
**Columns in the Instances table**

```
Table 20. Columns in the Instances table
```
```
Column Description
```
```
Instance Name Name of the instance.
The name of the instance is :
```
- For a standard template: _software-type_ _ _prefix-for-resource-poolnumber_ , for
    example, Standard_M03.
- For a composite template: _prefix-for-resource-pool_ _ _prefix-for-resource-_
    _poolnumber_ , for example, C_C03. For a clustered composite, a suffix of
    _ _software-service-instance-name_ is added.
In the name, _prefix-for-resource-pool_ is the value that is specified for software
service instance name prefix field on the **Add Template and Resource Pool** page
or the **Create Shared Resource Pool** page, and _number_ is assigned by z/OSMF.
For composite instances (created from composite templates), you can expand the
row to display the instances that it contains. Click.

```
State State of the instance. If actions were performed, this reflects the most recent
action. For a complete history of actions, use the View action for the instance.
Hover the mouse pointer over the state to display more information.
```
- If the instance is being provisioned, information about the current step is
    displayed.
- If provisioning failed, the owner of the associated template is displayed, along
    with the message returned from the provisioning workflow.

```
Last Action Status If actions were performed, reflects the most recent action. For a complete history
of actions, use the View action for the instance. Click the value to view details
about the action.
```
```
Software Services task   63
```

```
Table 20. Columns in the Instances table (continued)
```
```
Column Description
```
```
System Current system for the instance. This reflects any system selection on the most
recent action. The value is in this format: sysplex. system ( nickname ).
```
```
Cluster Name of the cluster instance that this instance belongs to. Shown only if the
instance is a clustered instance.
```
```
Software Type Type of the instance. This is blank for composite templates.
```
```
Template Name Name of the template that was used to create the instance.
```
```
Domain Domain for the instance.
```
```
Tenant Tenant for the instance.
```
```
Expiration Date Time and date the instance expires.
```
```
Created On Time and date that the instance was created.
```
```
Created By User ID of the user who created the instance.
```
```
Managed By For a domain that is managed by a primary z/OSMF instance on another sysplex,
this field indicates the URL of the primary z/OSMF system. If the domain is not
managed from another sysplex, this field is blank.
A domain can be defined to include systems from more than one sysplex. In this
configuration, creating and modifying templates and other objects is done from a
sysplex that you designate as the primary z/OSMF system. Objects that are created
on the secondary systems are managed by the primary z/OSMF system. Managed
objects are viewable and usable on the sysplex where they reside, but they can be
modified and removed only from the primary system.
To participate in a multi-sysplex domain, the systems must be defined through the
z/OSMF Systems task, and be enabled for single sign-on. For more information, see
Defining your systems to z/OSMF.
```
```
Actions for the instances
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 21 on page 64.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 22
    on page 65.
The Software Services task saves a provisioning version with each instance object. For an action to be
valid for an instance, the provisioning version associated with the instance object must not be higher than
the provisioning version of the code for the Software Services task.

```
Table 21. Targeted actions for the Instances table
```
```
Action Description
```
```
View Display the properties of a selected instance.
```
```
Perform Select an item from the list to perform an action on the instance. These are the
actions that are defined in the actions XML file for the instance. They may be either
workflows, commands, or instructions for manually performing an action. They
typically include a deprovision action. You cannot deprovision the child instances
of a composite instance (that is, an instance created from a composite template).
Instead, use the Perform deprovision action against the composite instance.
```
**64**   Software Services task


```
Table 21. Targeted actions for the Instances table (continued)
```
```
Action Description
```
```
Remove Remove the instance from the software services registry. The status of the instance
must be deprovisioned, deprovisioned-failed, or provisioned-failed. For composite
instances, Remove is valid only for the parent, not the child instances.
```
```
Resume Resume:
```
- Suspended provisioning of an instance. The suspended condition is reflected by
    Provisioning-Suspended in the State column.
- A suspended action. This is reflected by _action-name_ -Suspended in the Last
    Action Status column.
If neither the instance nor the last action is suspended, **Resume** is not available.

```
Retry Retry a failed provision or deprovision action. This restarts the failed provisioning or
action workflow. Use it with an instance for which the state is Provisioning-Failed or
Deprovisioning-Failed.
```
```
Change State Change the state of an instance. Select a state from the list. You must be a domain
administrator.
```
```
Table 22. Table actions for the Instances table
```
```
Action Description
```
```
Select All Select all of the items in the table.
```
```
Deselect All Clear all of the items in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### View instance

```
The View Instance window shows properties for an instance beyond what is shown in the instances
table, including instance variables and actions. It also includes a link to the workflow for the instance.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Instances** tab.
3. In the table, select an instance.
4. Click **Actions** , then select **View**.

```
Software Services task   65
```

```
The Software Properties window shows additional information.
```
```
Values on the View window for a standard instance
This page shows the values for a standard instance, including an instance that is a child in a composite
instance.
The values are grouped on tabs.
```
```
Instance Details
Composite clustered instance
Name of the clustered instance. Shown for clustered instances only.
Type
Type of software.
Current System
Current system for the instance. This reflects any system selection on the most recent action. The
value is in this format: sysplex. system ( nickname ).
Provisioned System
System on which the software was provisioned, in this format: sysplex. system ( nickname ).
State
Current state of the software:
```
- Being-Provisioned
- Provisioned
- Being-Deprovisioned
- Deprovisioned
- Provisioning-Suspended
- Provisioning-Expired
- Provisioning-Failed. For more information, see “Fixing problems with provisioning” on page 58.
- Deprovisioning-Suspended
- Deprovisioning-Failed.
**Domain**
Domain for the instance, defined with the Resource Management task.
**Tenant**
Tenant for the instance, defined with the Resource Management task.
**Template name**
The name of the software services template that the instance was created from.
**Template owner**
The user who created the template that the instance was created from.
**Template version**
The version of the software services template that the instance was created from.
**Resource Pool**
Links to the Resource Management task to **View Tenant and Resource Pool** for the instance.
**Composite parent instance**
The parent instance of the composite.
**Composite parent template**
The template that the composite parent instance was created from.
**Workflow**
Workflow that provisioned the instance. Click the link to open the Workflows task.

**66**   Software Services task


**Workflow duration**
Total elapsed time that the provision workflow took to run. It is displayed in the format _a_ hours _b_
minutes _c_ seconds, with units of time shown as appropriate.
The value includes any time that elapsed while the workflow was suspended.

**Current step**
The number of the step that is being processed automatically in the provisioning workflow, followed
by the total number of steps. Shown if the instance is being provisioned or if provisioning failed.

**Current step name**
The name of the step that is being processed automatically in the provisioning workflow. Shown if the
instance is being provisioned or if provisioning failed.

**Workflow message**
The message returned from the provisioning workflow, if provisioning failed.

**Metadata**

**Owner**
User ID that identifies the owner of the software.

**Provider**
User ID that identifies the provider of the software.

**Vendor**
Vendor of the software.

**Version**
Version of the software.

**Date created**
Date and time the instance was created.

**Last modified**
Date and time the instance was last modified.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Public Variables**

**Public Variables**
Contains a table of information about the public variables that belong to the instance.

**Private Variables**

**Private Variables**
Contains a table of information about the private variables that belong to the instance.

**Actions**

**Actions**
Contains a table of the actions that are available with the **Perform** action. They are defined in an
actions definition file.

```
Software Services task   67
```

```
To perform an action, select the action in the table, click Actions , then select an action from the list.
```
```
History
Actions History
Contains a table of information about Perform actions that have been performed.
You can use these actions:
View
Show details about the action. Alternatively, you can click the name of the action in the table.
Resume
Resume a suspended action.
Retry
Retry a failed provision or deprovision action. This restarts the failed provisioning or action
workflow.
```
```
Values on the View window for a composite instance
This page shows the values for a composite instance. For properties of the standard instances that are the
children in a composite instance, see “Values on the View window for a standard instance” on page 66.
```
```
The values are grouped on tabs. Composite instances are identified by preceding the name.
```
```
Instance Details
Composite clustered instance
Name of the clustered instance. Shown for clustered instances only.
State
Current state of the software:
```
- Being-Provisioned
- Provisioned
- Being-Deprovisioned
- Deprovisioned
- Provisioning-Suspended
- Provisioning-Expired
- Provisioning-Failed. For more information, see “Fixing problems with provisioning” on page 58.
- Deprovisioning-Suspended
- Deprovisioning-Failed.
**Composite cluster**
Indicates if the instance is a clustered composite. Not shown for child instances in a clustered
composite.
**Domain**
Domain for the instance, defined with the Resource Management task.
**Tenant**
Tenant for the instance, defined with the Resource Management task.
**Template name**
The name of the software services template that the instance was created from.
**Template owner**
The user who created the template that the instance was created from.
**Template version**
The version of the software services template that the instance was created from.

**68**   Software Services task


**Child instances**
A table showing the instances that make up this composite. Click the link for the name to show the
properties of the instance, or click the link for the workflow to open the Workflows task.

**Metadata**

**Owner**
User ID that identifies the owner of the software.

**Provider**
User ID that identifies the provider of the software.

**Date created**
Date and time the instance was created.

**Last modified**
Date and time the instance was last modified.

**Managed by**
Primary or _managing_ system for this domain, in the format _sysplex-name.system-name_. If the domain
is not managed from another sysplex, this field is blank.

**Managed by domain ID**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the domain ID. If the domain is not managed from another sysplex, this field is blank.

**Managed by z/OSMF URL**
For a domain that is managed by a primary z/OSMF instance on another sysplex, this field indicates
the URL of the primary z/OSMF system. If the domain is not managed from another sysplex, this field
is blank.

**Public Variables**

**Public Variables for** **_instance_**
Contains a table for the child instance that shows information about the public variables for that
instance. There is a table for each instance. You can expand or collapse the section for each instance.

**Private Variables**

**Private Variables for** **_instance_**
Contains a table for the child instance that shows information about the private variables for that
instance. There is a table for each instance. You can expand or collapse the section for each instance.

**Actions**

**Actions for** **_instance_**
Contains a table of the actions for the child instance that are available with the **Perform** action. The
actions are defined in an actions definition file. The table shows the name and type of the action
(command, instruction, workflow, or composite), description, and the command, if appropriate. There
is a table for each instance. You can expand or collapse the section for each instance.
To perform an action, select the action in the table, click **Actions** , then select an action from the list.

**History**

**Action History for** **_instance_**
Contains a table of information about **Perform** actions that have been performed.
You can use these actions:
**View**
Show details about the action. Alternatively, you can click the name of the action in the table.

```
Software Services task   69
```

```
Resume
Resume a suspended action.
Retry
Retry a failed provision or deprovision action. This restarts the failed provisioning or action
workflow.
```
```
View action
The View action window shows details for the last action that was performed for an instance.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Instances** tab.
3. In the table, click the value in the Last Action Status column for an instance.
    You can also display the **View action** window by using the **View** action for an instance, then clicking an
    action name in the table on the Action History tab.

**Values on the View action window**

```
Name
Name of the action.
Type
Type of the action, for a standard instance, or Composite, for a composite instance (created from a
composite template).
Description
Description of the action. This value is optional. If not provided, the Description field is empty.
System
System that the software is provisioned on.
Ran at time
Date and time the action was performed.
Ran by user
User ID that performed the action.
Workflow duration
Duration of the workflow that performed the action, if applicable.
State
Current state of the action.
Workflow
Workflow name, if applicable. Click the workflow name to open it in the Workflows task.
```
#### Perform an action for an instance

```
To peform an action for an instance, use the Perform action provided in the Instances table.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select **Software Configuration**.
2. Select the **Instances** tab.
3. In the table, select an instance.
4. Click **Actions** , select **Perform** , then select the action that you want to perform.
5. On the **Perform** window, supply values as needed for the fields that can be modified.
    Tips are available for some fields. To display the tip for a field, click the tips icon ( ).

**70**   Software Services task


6. Click **OK**.

#### Values on the Perform window

```
Fields on the Perform window indicate the name and type of the action (workflow, command, or
instructions).
When it is displayed, the System field lets you specify the system on which the action is to be performed.
The System field is displayed if both of these are true:
```
- **Allow resources to be relocated to other systems** was selected for the resource pool that is associated
    with the instance. This is not supported for composite instances (instances created from composite
    templates).
- More than one system is available in the resource pool.
The selected system is then reflected on the Instances table and on the View page for the instance. Local
in the system value indicates the system on which z/OSMF is running.
The action is not performed until you click **OK**. A state field, displayed after you click **OK** , indicates
whether or not the action has been performed.
For a standard instance (created from a standard template), a workflow field shows the workflow for the
action. Click the workflow name to open the workflow with the Workflow task.
For a composite instance (created from a composite template), a Child instances table shows the
instances that make up the composite. See Table 23 on page 71 and “Actions for the Child instances
table” on page 71.

```
Table 23. Columns in the Child instances table
```
```
Column Description
```
```
Name Name of the instance. Click the name to view the properties of the instance.
```
```
Action State Current state of the action. Click the value to view details.
```
```
Workflow Name of the workflow that performs the action, if applicable. Click the value to
open the workflow with the Workflows task.
```
```
System The system on which the action is to be performed. For child instances in a
clustered composite instance, the values may differ.
```
**Actions for the Child instances table**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected item. To use a targeted action, you must select an
    item. See Table 24 on page 71.
- Table actions. Actions that apply to the entire table. No selection of a table item is required. See Table
    25 on page 72.

```
Table 24. Targeted actions for the Child instances table
```
```
Action Description
```
```
View View the properties of the instance.
```
```
View Action View the properties of the action. Not available if the action has not been issued.
```
```
View Workflow Display the workflow using the Workflows task.
```
```
Resume Resume a suspended action. If the action is not suspended, Resume is not
available.
```
```
Software Services task   71
```

```
Table 24. Targeted actions for the Child instances table (continued)
```
```
Action Description
```
```
Retry Retry a failed provision or deprovision action. This restarts the failed provisioning or
action workflow.
```
```
Table 25. Table actions for the Child instances table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Sorts Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.
```
```
Clear Search Clear the search.
```
#### Working with actions

```
In addition to the actions that are provided with the table of instances, instance-specific actions can be
defined for instances, using an action definition file that is part of a template. These actions might either
start a workflow, issue a command, or provide instructions. They include a deprovision action.
```
#### View actions in a software services template

```
About this task
From the templates table, you can view the actions that are defined in the actions definition file.
```
**Procedure**

1. Select the **Templates** tab.
2. In the templates table, click a template name.
3. Scroll the window to view a table of the actions.

#### Change the actions definition file for a software services template

```
About this task
If the action definitions file for a template is changed, you must refresh the files for a template prior to
publishing the template.
```
**Procedure**

1. Select the **Templates** tab.
2. Select a template in the table.
3. Select **Actions** , then **Refresh Template**.

**72**   Software Services task


#### Create the actions definition file for a software services template

**About this task**

```
You can create an actions definition file with the actions editor when you add a template.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. In the table, click **Add Template**.
4. On the **Add Template** window, click **Create New** for the Actions file field.
    The **Create New Actions File** window is displayed.
5. Specify values and click **OK**.
    **Target file path or data set**
       The location of the actions file that you want to create. Specify the file path or fully qualified data
       set name.
    **Deprovisioning workflow definition file**
       If a workflow definition file exists for deprovisioning, specify the file path or fully qualified data
       set name. If you do not specify this value, the actions editor opens with a placeholder instruction
       deprovision action defined. If necessary, you can use the actions editor to delete the instruction
       deprovision action and replace it with a workflow action for deprovisioning.
    The **Edit Actions File** window is displayed.

```
What to do next
See “Using the Edit Actions File window ” on page 43.
```
#### Edit actions for a software services template

**About this task**

```
You can use the actions editor to edit an actions definition file when modifying or adding a template.
```
**Procedure**

1. Expand the Cloud Provisioning category in the navigation area, then select Software Services.
2. Select the **Templates** tab.
3. Modify a template.
    a) In the templates table, select a template.
b) Click **Actions** , then select **Modify**.
c) On the **Modify** window, click **Edit** for the Actions file field. The **Edit Actions File** window is
displayed.
- You can create a new actions file when adding a template. For more information, see “Add a
template” on page 15.

```
What to do next
See “Edit an actions definition file” on page 42.
```
```
Software Services task   73
```

#### Perform actions for a software services instance

```
About this task
From the Instances table, you can perform the actions that are defined in the actions definition file.
```
**Procedure**

1. Select the **Instances** tab.
2. In the instances table, select an instance.
3. Click **Perform** , then select an action.
4. On the resulting window, review the information, and provide input as required.
    Tips are available for some fields.
    Tips provide task-oriented information so that you can quickly complete your task. Task information
    can include, for example, syntax rules or instructions for how to modify the data in a table cell. To
    display the tips for a field, click the tips icon ( ).
5. Click **OK**.

**74**   Software Services task


## Index

**A**

actions
instances 70
actions definition file
modifying 42
adding
templates 15
approving
templates 52
archiving
templates 62

**C**

Cloud Provisioning tasks
Software Services 1
composite templates 2
consumers
making templates available 58
creating
templates
new versions 22
templates based on other templates 21

**F**

files
templates 20

**I**

instances
actions 70
creating from templates 55
introduction 1
viewing properties 65

**M**

modifying
actions definition file 42
templates 39

**P**

problems
provisioning 58
provisioning
troubleshooting 58
publishing
templates 58

**S**

Software Services 1

```
software services for Cloud Provisioning
managing 5
provisioning 9
software services instances 1
Software Services task
procedure for using 5, 9
software services templates
composite 2
```
**T**

```
templates
adding 15
approving 52
archiving 62
associating with tenants 51
composite 2
creating based on other templates 21
creating new versions 22
files 20
introduction 1
making available to consumers 58
modifying 39
modifying actions definitions file 42
publishing 58
test running 55
viewing properties of 26
tenants
associating with templates 51
test running
templates 55
troubleshooting
provisioning 58
```
**V**

```
versions
of templates 22
viewing
instances 65
properties of templates 26
```
```
Index   75
```

IBM®


## AI Control Interface

# IBM


## Contents

```
AI Control Interface...............................................................................................1
Terms you should know............................................................................................................................... 1
AI-enabled tools.......................................................................................................................................... 1
Training a system......................................................................................................................................... 2
Getting started in AI Control Interface........................................................................................................3
Managing intelligent operations.................................................................................................................. 3
Managing components in a system........................................................................................................5
```
**Index.................................................................................................................... 7**

**ii**


**AI Control Interface**

```
The AI Control Interface for IBM® z/OS® automates and enhances z/OS system management tasks with
prebuilt AI models.
With AI Control Interface, you can perform management actions to train models, update model settings,
view the status of AI enablement, and check the health of the z/OS AI Framework.
Reference the following links to learn how to use AI Control Interface:
AI-enabled tools
The system functions that are available to be configured for AI Control Interface. For more
information, see “AI-enabled tools” on page 1.
Training a system
Basic concepts to consider when training systems in AI Control Interface. For more information, see
“Training a system” on page 2.
Get started
Learn how to get started for the first time using AI Control Interface. For more information, see
“Getting started in AI Control Interface” on page 3.
Manage intelligent operations
Select an AI-enabled tool and being working with the available use cases for your configured z/OS
systems. For more information, see “Managing intelligent operations” on page 3.
Manage components in a system
View the available components that AI can manage for a selected AI-enabled tool in your z/OS
systems, begin training, and edit AI mode for available components. For more information, see
“Managing components in a system” on page 5.
```
### Terms you should know

```
Understand terminology in AI Control Interface.
Administrator
A z/OS system programmer who is an administrator for z/OS AI Control Interface. Administrators have
access to the IZUADMIN security group.
AI-enabled tool
System functions configured for use with AI Control Interface. These providers contain prebuilt AI
models to automate and enhance z/OS system management.
Component
Individual z/OSMF objects in a system that can be configured for management by the AI model. The
type of z/OSMF object is dependent on the associated use case for that system.
Use case
An AI-enhanced task that can be performed on a selected system.
```
### AI-enabled tools

```
The system functions available to be configured for AI Control Interface for IBM z/OS.
With AI-enabled tools in AI Control Interface, you can monitor the AI use cases that are configured on
your systems and take action on affected system components. The following providers are the available
tools that you can get started with today.
```
```
AI Control Interface   1
```

```
Note: For the initial release of AI Control Interface, Workload Management is the only AI-enabled tool
available for use. Additional tools are planned for future releases, check back for updates.
```
```
z/OS Workload Management (WLM)
Workload Management (WLM) monitors a z/OS system and dynamically provides resource to incoming
items of work based on predefined goals.
Use case: AI-powered WLM batch initiator management
Using sophisticated workload trends, you can proactively initiate resource assignment so that a
workload can start right away.
Component: Batch service classes
A service class is a group of work with similar performance goals, resource requirements, and
business importance. z/OS Workload Management manages each group of work according to the
performance goal assigned to the service class, and the business importance assigned to that
performance goal.
The batch service classes that are displayed in AI Control Interface are a subset of the total service
classes on a given system. These available batch service classes have usable SMF data that qualifies
them to be enhanced by AI-powered WLM batch initiator management.
```
### Training a system

```
Basic concepts for training systems in AI Control Interface for IBM z/OS.
Model training is a long-running operation, so there are some factors to potentially consider before you
decide to initiate the training process.
```
**Initiating training**

```
To start training a selected system, at least one component must be configured and discovered by AI
Control Interface. Model training runs on a system level, and includes all components that are discovered
in that system and are listed in the components table. For more information, see “Managing components
in a system” on page 5.
You cannot train multiple systems concurrently. One system must complete the training process before
you are able to start another in either a different system or a different AI-enabled tool. The Train system
button is disabled across all table instances while a training process is running.
The Train system button is also disabled if any rows are selected in the components table. Deselect all
components by individual row or by using the Cancel batch action in the table to proceed.
```
```
During training
You do not need to keep AI Control Interface open while training is running. Training proceeds in the
background while your z/OSMF server is running.
You are able to switch the AI-mode of a successfully trained component while another training process
is running. Only components that were previously successfully trained can be put into Enable mode. For
more information, see “Managing components in a system” on page 5.
```
**When training completes**

```
When a training process completes, messages are briefly displayed as notifications, and also persist in the
notification center until they are dismissed.
If a component fails during training, it is automatically switched to Disabled since the model is not able to
make prediction results on a failed component.
```
**2**   AI Control Interface


```
Retraining
To ensure that you are working with current and accurate system data, the recommended time period to
retrain a system is thirty days. If a system is not retrained within that time, a Needs attention status tag is
displayed in the AI mode column.
Related concepts
“Managing intelligent operations” on page 3
Use the Manage tab of AI Control Interface to select an AI-enabled tool and view the available use cases
that are configured for your z/OS systems.
```
### Getting started in AI Control Interface

```
How to get started with AI Control Interface for IBM z/OS.
To begin using AI Control Interface for the first time, select an AI-enabled tool from the list of available
system functions on the Get started tab.
If there are no system functions configured yet, a tile displays that there are no AI-enabled tools
available. The tools must be enabled by a z/OS System Programmer outside of AI Control Interface using
a z/OSMF configuration workflow. Once your z/OS System Programmer has configured the tool that you
are looking for, you can click can click the Refresh button on the tile to check tool configuration.
When a function is enabled for your system, a tile displays with the name of the AI-enabled tool and a
brief description of what use cases you can control with it. Click anywhere on the tile to proceed to the
Manage tab and activate AI support on a system.
```
**Connection status**

```
You can view the connection status of AI Control Interface by clicking the icon in the main navigation
bar.
If either the AI Base Component for IBM z/OS or the AI model server are not connected, the icon displays
as crossed as an indicator ( ). Clicking the icon displays a detailed connection error.
```
**Notifications**

```
A notification is a notice of some occurrence in the system that requires your awareness or response. A
notification can be informational in nature, or it can be a request for action.
```
```
To access your notifications, click the Notifications icon ( ) in the main navigation bar. When you have
unread notifications, the icon is shown with a circle for emphasis ( ).
For some notifications, a hyperlink is provided to a message that gives additional details and actions.
Related concepts
“Managing intelligent operations” on page 3
Use the Manage tab of AI Control Interface to select an AI-enabled tool and view the available use cases
that are configured for your z/OS systems.
```
### Managing intelligent operations

```
Use the Manage tab of AI Control Interface to select an AI-enabled tool and view the available use cases
that are configured for your z/OS systems.
Manage tab is composed of the AI-enabled tools selection list and the current enablement table of the
tool.
```
```
AI Control Interface   3
```

```
AI-enabled tools panel
The AI-enabled tools panel displays all available providers that you can enable AI on. The panel can be
collapsed by using the chevron icon.
For more information about the tools that are available for AI-enablement in AI Control Interface, see
“AI-enabled tools” on page 1.
```
**Systems table**

```
The systems table name reflects the selected AI-enabled tool. The latest timestamp that the table
contents were refreshed is displayed.
The table is populated with the configured systems that have z/OS 3.1 installed and the selected AI-
enabled tool enabled. The local system is always listed at the beginning of the table.
If no AI-enabled tools are configured yet, the table displays an empty state. You can click the Refresh
button to check whether the tool configuration is completed. The refresh timestamp updates to reflect
that the table contents were refreshed.
You can use the Search and Filter functions to locate a specific system within the table. You can filter and
sort the table by AI status.
After training, any systems with a status of Needs attention are sorted to the beginning of the table, until a
user applies an AI status of their choosing. This AI status selection persists for each user that is logged in.
You can hover over each tag in the AI status column for a detailed explanation.
Click anywhere on a row to view more details about a component. Table 1 on page 4 provides more
context about each column.
```
```
Table 1. Columns in the Systems table. These columns appear in the Systems table regardless of which option is
selected from the AI-enabled tools panel.
```
```
Column Description
```
```
System The name of the system that can be configured for management by the AI model.
```
```
Use case AI-enhanced tasks that are available to perform on the selected system.
```
```
AI status The current condition of the AI model used to perform the use case.
Ready
The system is newly available and can be trained with AI Control Interface.
Needs attention
It is recommended that you retrain the model for the system. The
recommended time period for retraining is within thirty days.
Inactive
The system was trained, but none of the system's components are being
managed by AI.
Active
The system has been trained and at least one of the system's components is
being managed by AI.
```
```
Components The current count and type of z/OSMF objects in the system that can be configured
for management by the AI model. The type of z/OSMF object is dependent on the
associated use case for that system.
The value of this column is Searching... while AI Control Interface searches a
selected system for enabled components when it is first added.
For more information, see “AI-enabled tools” on page 1.
```
**4**   AI Control Interface


#### Managing components in a system

```
The components table reflects the specific components of a system that AI can manage for a selected
AI-enabled tool in AI Control Interface.
The table name reflects the selected system that is configured to use AI-enhanced use cases for the
selected AI-enabled tool. A description of the use cases and components for the selected AI-enabled tool
is provided, along with the latest timestamp that the table contents were refreshed. The latest timestamp
that the training process was trained is also displayed if the system was previously trained.
If the system is searching for instances of the component, or no components are found after the search
has completed, the table displays an empty state. You cannot initiate training until at least one of the
component type is configured for AI Control Interface.
You can use the Search and Filter functions to locate a specific component within the table. You can filter
and sort the table by training status and AI mode.
If another component is added after the system was trained, that component appears at the beginning of
the table with a training status of Not yet trained and AI mode Disabled.
After training completes, any components that have a training status of Failed are automatically sorted to
the beginning of the table. You can hover over the status to see a detailed reason as to why training failed.
```
**Columns in the components table**

```
Some columns are persistent across all available use cases, while others are dynamically generated
depending on the components of the system that AI can manage in the selected use case. The Table 2 on
page 5 and Table 3 on page 6 provide more context about each column.
```
```
Table 2. Persistent columns in the components table
```
```
Column Description
```
```
Training status A record of AI performance against actual values from simulating.
Not trained yet
The AI model for this component's system is not trained yet.
Training
An AI model is training to perform a use case for this component.
Trained
The component was successfully trained.
Failed
Training failed for this component. Hover over the status for a detailed
message that explains why training failed. The AI mode for this component
is automatically switched to Disabled , since the model is not able to make
predictions for a failed component.
```
```
AI mode The current state of AI operations on the component.
Disabled
The AI model is not operating a use case for this component. Simulation-based
AI performance metrics are not available.
Simulating
The AI model is not operating a use case for this component, but it is
generating predictions.
Enabled
The AI model is operating a use case for this component.
```
```
AI Control Interface   5
```

```
Table 3. Dependent columns in the components table. The content of this column is dynamically generated
based on the option that was selected in the AI-enabled tools panel.
```
```
Column name
```
```
Associated AI-
enabled tool Description
```
```
Batch service
classes
```
```
Workload
Management
```
```
A group of work with similar performance goals, resource
requirements, and business importance. Enhance batch service
classes with an AI model for AI-powered WLM batch initiator
management. For more information, see “AI-enabled tools” on
page 1.
```
```
Table 4. Targeted actions for the components table
```
```
Action Description
```
```
Enable Allows the AI model to operate the use case for the selected AI-enabled tool on
the selected system. For more information, see “AI-enabled tools” on page 1.
```
```
Simulate Allows the AI model to make predictions about the use case for the selected
AI-enabled tool on the selected system, but the model does not operate the use
case. The selected AI-enabled tool continues to function without AI.
```
```
Disable Stops the AI model from operating the use case on the selected system. The
selected AI-enabled tool continues to function without AI.
Note: The AI-enabled tool continues to function as usual with no gaps in
processing if you choose to disable the AI model.
```
```
Table 5. Untargeted actions for the components table
```
```
Action Description
```
```
Train system Trains the model for the selected system. For more information, see “Training a
system” on page 2.
```
**6**   AI Control Interface


## Index

**A**

AI Control Interface task 1

**O**

overview 1

```
Index   7
```

IBM®


## IBM zERT Network Analyzer Task

## Summary

# IBM


## Contents

```
IBM zERT Network Analyzer Task Summary........................................................... 1
Welcome.......................................................................................................................................................1
What's new in IBM zERT Network Analyzer................................................................................................ 1
Data Management........................................................................................................................................2
Importing SMF dump data sets..............................................................................................................2
Working with Data Management History panel..................................................................................... 4
Working with Manage Database panel...................................................................................................8
Queries....................................................................................................................................................... 10
Working with Manage Queries panel................................................................................................... 10
Creating or editing a new query........................................................................................................... 23
Report.........................................................................................................................................................33
Working with Report panel...................................................................................................................33
Settings...................................................................................................................................................... 61
Configuring application settings.......................................................................................................... 61
Working with Database Settings panel................................................................................................65
Tutorial introduction.................................................................................................................................. 68
Defining database setting.................................................................................................................... 71
Obtaining SMF dump data sets............................................................................................................72
Module 1: Populating the IBM zERT Network Analyzer database...................................................... 72
Module 2: Querying records in the IBM zERT Network Analyzer database........................................80
Module 3: Viewing IBM zERT Network Analyzer query results...........................................................87
Module 4: Exporting query results to a CSV format file...................................................................... 95
Messages: IZUET0000 - IZUET9999......................................................................................................101
```
**Index................................................................................................................ 114**

**ii**


**IBM zERT Network Analyzer Task Summary**

```
The IBM® z/OS® Encryption Readiness Technology (zERT) Network Analyzer task helps you quickly identify
the cryptographic protection characteristics of TCP and Enterprise Extender (EE) connections with local
endpoints on your z/OS system. With the IBM zERT Network Analyzer task, you can:
```
- Import cryptographic protection data into the IBM zERT Network Analyzer database.
- Create and run queries that filter the security sessions in the database.
- Export the results of your queries to a comma-separated values (csv) format file.
For functional enhancements or other updates in IBM zERT Network Analyzer, see What's new in IBM
zERT Network Analyzer.

### Welcome

```
Welcome to IBM z/OS Encryption Readiness Technology (zERT) Network Analyzer.
This panel serves as the home page or welcome page for IBM zERT Network Analyzer. You can use
IBM zERT Network Analyzer to better understand the cryptographic protection characteristics of your Z
systems. You can also monitor whether that cryptographic protection meets your requirements. You can
perform the following operations with IBM zERT Network Analyzer:
```
- Configure global settings for IBM zERT Network Analyzer.
- Add SMF data to the IBM zERT Network Analyzer database.
- View the status of database management operations.
- Create, manage, or execute queries against imported SMF data.
You can also use the tutorial available on the welcome page to experience IBM zERT Network Analyzer.
For more details of the tutorial, see IBM zERT Network Analyzer tutorial introduction.

**Options**

- To configure global settings, click **Configure IBM zERT Network Analyzer** to access the **Settings** page.
- To add SMF data, click **Import SMF dump data sets** to access the **Import SMF Data** page.
- To view the status of database management operations, click **Manage operation history** to access the
    **Data Management History** page.
- To create, manage, or execute queries, click **Create, manage, and run queries** to access the **Queries**
    page.

### What's new in IBM zERT Network Analyzer

```
Find out functional enhancements or other updates in IBM z/OS Encryption Readiness Technology (zERT)
Network Analyzer.
Check out the following updates to IBM zERT Network Analyzer.
```
**New in z/OS 3.1**

```
IBM zERT Network Analyzer enhanced upgrade support - z/OS Management Facility (z/OSMF) with the
IBM zERT Network Analyzer for z/OS 3.1 introduces enhancements for users upgrading from a previous
release to z/OS 3.1:
```
- The sample database schema tooling now includes additional templates to upgrade an existing
    database from a previous release to the 3.1 schema.

```
IBM zERT Network Analyzer Task Summary   1
```

- The **Application Settings** panel is updated to add new function to import application settings from a
    previous release or reset to default values.
- The **Database Settings** panel is updated to add new function to import database connection settings
    from a previous release.
The IBM zERT Network Analyzer user interface has been refreshed with a new color scheme and icons.

```
New in APAR PH43118 for z/OS V2R3 and APAR PH43119 for z/OS V2R4 and z/OS
V2R5
```
```
IBM zERT Network Analyzer passphrase and password management support - z/OS Management
Facility (z/OSMF) with the IBM zERT Network Analyzer APAR PH43118 for z/OS V2R3 and APAR PH43119
for z/OS V2R4 and z/OS V2R5, supports the use of passphrases up to 100 characters to connect to the
Db2 for z/OS database. IBM zERT Network Analyzer includes additional enhancements in the Database
Settings panel to clear existing database credentials to allow for easier switching to a different database
user ID.
```
**New in APAR PH24492 for z/OS V2R3 and APAR PH24494 for z/OS V2R4**

```
IBM zERT Network Analyzer database administration enhancements - z/OS Management Facility (z/
OSMF) with the IBM zERT Network Analyzer APAR PH24492 for z/OS V2R3 and APAR PH24494 for z/OS
V2R4, introduces a configurable report timeout and limits to the maximum number of open reports per
user. The sample database schema tooling now includes additional templates to change the number of
partitions in the partition-by-range query result tables.
```
```
New in APAR PH16222 for z/OS V2R3 and APAR PH16223 for z/OS V2R4
IBM zERT Network Analyzer database administration enhancements - z/OS Management Facility (z/
OSMF) with the IBM zERT Network Analyzer APAR PH16222 for z/OS V2R3 and APAR PH16223 for
z/OS V2R4, provides additional flexibility in IBM zERT Network Analyzer's Db2 for z/OS database schema
definitions and reduces the access privileges required by the IBM zERT Network Analyzer's database user
ID. The supplied database schema tooling now supports customized values for the database schema
name, index names and even table names along with many other operational parameters that were
already configurable.
Dependencies: No new dependencies are introduced. The IBM zERT Network Analyzer requires z/OSMF
to be installed and a type 4 JDBC connection to Db2 for z/OS 11 or higher.
```
### Data Management

```
References to the Data Management panel of IBM z/OS Encryption Readiness Technology (zERT)
Network Analyzer.
In this topic, you can find references to help you work with the Data Management panel of IBM zERT
Network Analyzer.
```
#### Importing SMF dump data sets

**Before you begin**

```
Before you begin, decide which SMF dump data sets containing SMF 119 Subtype 12 records are to be
imported into IBM z/OS Encryption Readiness Technology (zERT) Network Analyzer. If SMF dump data
set names were saved in a previous session, those data sets are displayed in the SMF DUMP DATA SETS
table.
```
**2**   IBM zERT Network Analyzer Task Summary


**About this task**

Data management operations encompass both prune and import operations. You can add SMF dump
data set information to the IBM zERT Network Analyzer database with an import operation. IBM zERT
Network Analyzer consumes only SMF dump data sets that were dumped into MVS™ sequential data sets
by the IFASMFDP program for SMF data sets or IFASMFDL program for SMF log streams. The SMF dump
data sets can contain any SMF records, but only SMF 119 Subtype 12 records are imported into IBM
zERT Network Analyzer. SMF 119 subtype 12 records that have already been imported into the IBM zERT
Network Analyzer database are ignored.

Before you can import an SMF dump data set into IBM zERT Network Analyzer, you must add the data
set name to the **SMF DUMP DATA SETS** table. Adding a data set name to the table does not mean the
data set is imported - it only makes that data set eligible for importing. Likewise, if a data set is already
imported, removing the data set name from the table does not affect any data that was already imported
into IBM zERT Network Analyzer or pending import events that are listed in the **Data Management
History** panel. You can save the data set names in the table for future reuse.

**Restriction:**

- IBM zERT Network Analyzer only supports running a single data management operation at a time. If you
    initiate an import operation when another data management operation is active, the execution of the
    import operation is placed in a pending state. The execution of pending data management operations is
    performed in a first-in, first-out (FIFO) manner.
- IBM zERT Network Analyzer only supports running a data management operation when there are no
    active query operations. If you initiate an import operation while there are active query operations,
    the execution of the import operation is placed in a pending state. The execution of pending data
    management operations is performed once there are no more active query operations.
- IBM zERT Network Analyer supports importing SMF dump data sets into a database that was designed
    for a newer version of the IBM zERT Network Analyer. However, if you import this data, the imported
    data format will not support any new features of the newer release. You can verify what IBM zERT
    Network Analyzer release the database is designed for by viewing the **Database Information** section in
    the **Database Settings** panel.
- IBM zERT Network Analyzer does not support importing SMF dump data sets into a database that was
    designed for an older version of the IBM zERT Network Analyzer.

**Tip:** Use the **Data Management History** panel to track the progress of an initiated import operation.

**Procedure**

1. If the **SMF DUMP DATA SETS** table does not contain the data set that you want to import, complete
    the following steps:
       a. Click **Refresh import list** to retrieve the latest set of data sets stored in IBM zERT Network
          Analyzer. Click **Confirm** to refresh or **Cancel** to return to the current page. If you have unsaved
          changes to the list, the changes are lost as part of the refresh operation.
       b. Click **Add data set** to add a row to the table.
          c. In the new row, specify the data set name and optionally the comment. The data set name and
             comment that you specify must meet the following requirements:
             - A data set name must be a valid MVS data set name that meets the following requirements:
                - A data set name must consist of 2 - 22 segments that are separated by a period (.).
                - A data set name cannot exceed 44 characters, including all segments and periods that serve as
                   separators.
                - Each segment cannot exceed 8 characters.
                - The first character of a segment must be any of the following characters: A-Z # $ @.
                - The remaining seven characters of a segment can contain any of the following characters: 0-9
                   A-Z # $ - @.

```
IBM zERT Network Analyzer Task Summary   3
```

- A data set comment cannot exceed 50 characters.
2. If you want to add more data sets to the table, repeat step 1.
3. Optional: Save the data sets details in the table for future use:
- To save the whole **SMF DUMP DATA SETS** table, click **Save Import List**.
- To save a single data set, click the **save icon** on the right side of the row.
4. For each data set that you want to import, select the check box on the left side of the row.
5. Click **Import selected** in the upper right corner of the panel. Click **Confirm** to import or **Cancel** to go
back to the **SMF DUMP DATA SETS** table.
6. Optional: To remove unwanted data sets from the table, complete the following action:
- To remove multiple data sets, select the check box to the left of the data set names in the **SMF
DUMP DATA SETS** table, and click **Remove selected**.
- To remove an individual data, click the **minus sign** on the right side of the row.

#### Working with Data Management History panel

```
Data management operations encompass both import and prune operations. You can use the Data
Management History panel to view data management operations within IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer.
The Data Management History panel displays a tabular summary view of all the operation results. By
default, the results are displayed in chronological order, with the most recent operation listed first in the
table. Each row displays either an import or a prune data management operation. Click on a row to view
more details about the operation.
```
- For import operations, each row represents an attempt to import a specific data set containing SMF
    records into the IBM zERT Network Analyzer database.
- For prune operations, each row represents an attempt to prune SMF records from the IBM zERT
    Network Analyzer database.
See Table 1 on page 6 in “Appendix. Fields on the Data Management History panel” on page 6 for
description of operation summary fields.

```
Viewing import operation details
To view details about an import operation, click on the summary row of the import operation, and it
expands to show the details. The import operation detail view always includes the name of the SMF dump
data set that was used for the import operation, and the name of the user who submitted the operation.
The status of the import operation determines additional detail information displayed for the operation.
There are five possible values for an import operation status: Active, Canceled, Complete, Failed and
Pending.
See the following table for detailed information provided for each status.
```
```
Status Detail information provided
```
```
Active The name of the data set currently being used to import SMF records.
```
```
Canceled The name of the data set that was scheduled to be used to import SMF
records before the operation was canceled.
```
**4**   IBM zERT Network Analyzer Task Summary


```
Status Detail information provided
```
```
Complete • The name of the data set that was successfully used to import SMF
records.
```
- Statistics about the import operation.

```
Failed • The name of the data set associated with the failed import operation.
```
- The error message associated with the failed attempt.

```
Pending The name of the data set that is scheduled to be imported but has not yet
executed.
```
See Table 2 on page 7 in “Appendix. Fields on the Data Management History panel” on page 6 for
description of import operation detail fields.

**Viewing prune operation details**

There are three types of prune operations in IBM zERT Network Analyzer. The type is one the following:

- Prune all SMF records
- Prune a subset of SMF records associated with a customized time interval
- Prune a subset of SMF records associated with a time interval relative to when the operation is
    executed.

The prune operation detail view always includes the type of prune operation that was performed, and
the name of the user who submitted the operation. To view details about a prune operation, click on
the summary row of the prune operation, and it expands to show the details. The status of the prune
operation determines the detail information displayed for the operation. There are five possible values for
a prune operation status: Active, Canceled, Complete, Failed and Pending.

See the following table for detailed information provided for each status.

```
Status Detail information provided
```
```
Active The type of prune operation currently being performed to remove SMF
records.
```
```
Canceled The type of prune operation that was scheduled to be performed before the
operation was canceled.
```
```
Complete • The type of prune operation that was successfully performed to remove
SMF records.
```
- Statistics about the prune operation.

```
Failed • The type of prune operation that was attempted but failed.
```
- The error message associated with the failure attempt.

```
Pending The type of prune operation that is scheduled but has not yet executed.
```
See Table 3 on page 8 in “Appendix. Fields on the Data Management History panel” on page 6 for
description of prune operation detail fields.

**Sorting a table by column**

To sort a table by column, click on the column header, and that table is sorted by that column in ascending
order. To sort the column in descending order, click on the column header again.

```
IBM zERT Network Analyzer Task Summary   5
```

```
Updating the list of data management operations
Click Refresh history in the upper right corner of the panel to get the latest results of import and prune
operations in the IBM zERT Network Analyzer database.
```
**Appendix**

- “Appendix. Fields on the Data Management History panel” on page 6 describes different fields of
    operation summary, import operation details, and prune operation details on the **Data Management**
    **History** panel.

**Appendix. Fields on the Data Management History panel**

```
This appendix describes different fields in operation summary, import operation, and prune operation on
the Data Management History panel.
Operation summary fields shows the operation summary fields for views on the Data Management
History panel.
```
```
Table 1. Operation summary fields
```
```
Field name Description
```
```
Submitted The date and time when the operation was submitted for execution.
```
```
Operation Type of operation performed.
```
```
Possible operation values are Import and Prune.
When the value is Import , the Operation field also contains the name of the data
set of SMF records that was used for the import operation.
When the value is Prune , the Operation field also contains the type of prune
operation performed. Possible values are:
```
- **All Data** , when the prune operation removed all SMF records from the database.
- **Relative prune** , when the prune operation removes a subset of SMF records
    with creation dates older than an interval relative to the date when the
    operation is submitted.
- **Custom date range** , when the prune operation removes a subset of SMF
    records associated with a custom time interval.

```
Status The status of the data management operation. Possible values are:
```
- **Active** , when the operation is currently executing.
- **Canceled** , when the operation was stopped before completion by the user.
- **Complete** , when the operation finished successfully.
- **Failed** , when the operation did not complete successfully.
- **Pending** , when the operation has been submitted but is awaiting execution.

```
Start time One of the following:
```
- If the operation has started execution, has completed execution, or has failed
    execution, this field indicates the date and time when the operation started.
- If the operation was canceled prior to execution, this field indicates **Canceled**.
- If the job is still awaiting execution, this field indicates **Pending**.

**6**   IBM zERT Network Analyzer Task Summary


```
Table 1. Operation summary fields (continued)
```
```
Field name Description
```
```
End time One of the following:
```
- If the operation completed successfully, the date and time when the operation
    completed.
- If the operation is still executing, this field indicates **Active**.
- If the operation was canceled prior to starting execution, this field indicates
    **Canceled**.
- If the operation failed execution, this field indicates **Failed**.
- If the operation has been submitted but is awaiting execution, this field
    indicates **Pending**.

```
Import operation details shows the import operation detail fields for views on the Data Management
History panel.
```
_Table 2. Import operation details._

The table includes two columns of Field name and Description. This table shows the import operation detail for
views on the Data Management History panel in IBM zERT Network Analyzer.

```
Field name Description
```
```
Error message Error message generated when the import operation was unsuccessful.
```
```
Note: This information is only displayed when Status value is Failed or Canceled.
```
```
Data set name Name of the data set containing SMF records that was used in the import
operation, plus any comment that the user included when submitting the import
operation.
```
```
User Name of the IBM zERT Network Analyzer user that initiated the import operation.
```
```
Number of records added Count of the number of zERT aggregation summary interval SMF records
successfully added to the database. zERT aggregation summary interval records
are SMF type 119, subtype 12 records with an event type value equal to 'summary
interval'.
```
```
Number of duplicate
records
```
```
Count of the number of imported SMF records that were duplicates of existing
records in the database
```
```
Number of records ignored Count of the number of SMF records that were present in the data set but
which were not added to the database because they were not zERT aggregation
summary interval SMF records. zERT aggregation summary interval records are
SMF type 119, subtype 12 records with an event type value equal to 'summary
interval'.
```
```
Earliest record imported SMF record timestamp associated with the oldest SMF record added to the
database by this operation, or "N/A" if no records were imported as part of this
operation.
```
```
Latest record imported SMF record timestamp associated with the youngest SMF record added to the
database by this operation, or "N/A" if no records were imported as part of this
operation.
```
```
Prune operation details shows the prune operation detail fields for views on the Data Management
History panel.
```
```
IBM zERT Network Analyzer Task Summary   7
```

```
Table 3. Prune operation details.
The table includes two columns of Field name and Description. This table shows the prune operation detail for
views on the Data Management History panel in IBM zERT Network Analyzer.
```
```
Field name Description
```
```
Error message Error message generated when the prune operation was unsuccessful.
```
```
Note: This information is only displayed when Status value is Failed or Canceled.
```
```
Operation type The type of prune operation performed, plus any comment that the user included
when submitting the prune operation. Possible values are:
```
- **All imported data removed from zERT** , when the prune operation removed all
    SMF records from the database.
- **Relative prune: Older than** **_number_** **days** , when the prune operation removes
    a subset of SMF records with creation dates older than an interval relative to
    the date when the operation is submitted. The value for _number_ indicates the
    number of days in the relative interval.
- **Custom date range:** **_start date_** **to** **_end date_** , when the prune operation removes
    a subset of SMF records associated with a custom time interval. The displayed
    as _start date_ represents the oldest date for the custom interval, and the date
    displayed as _end date_ represents the youngest date for the custom interval.

```
User Name of the IBM zERT Network Analyzer user that initiated the prune operation.
```
```
Number of session records
pruned
```
```
Count of the number of session records successfully removed from the IBM zERT
Network Analyzer database by this operation.
Note: Session records contain the endpoint and cryptographic details about
security sessions. There is one set of session records for each individual security
session. Session statistics records contain the per-SMF interval statistics (counts
of connections, bytes in/out, segments in/out, etc.) for each security session.
There are typically many session statistics records (one per represented SMF
interval) for an individual security session.
```
```
Number of session
statistics records pruned
```
```
Count of the number of session statistics records successfully removed from the
IBM zERT Network Analyzer database by this operation.
```
```
Earliest record pruned SMF record timestamp associated with the oldest SMF record pruned by this
operation, or "N/A" if no records were pruned as part of this operation.
```
```
Latest record pruned SMF record timestamp associated with the newest SMF record pruned by this
operation, or "N/A" if no records were pruned as part of this operation.
```
#### Working with Manage Database panel

```
You can use the Manage Database panel to perform two operations to manage the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer database:
```
- to view the latest summary of the database
- to prune imported data from the database

**Viewing database summary**

```
You can view summary information from the DATABASE SUMMARY section. The summary information
contains:
```
- The current number of SMF 119 Subtype 12 records imported into the database.

**8**   IBM zERT Network Analyzer Task Summary


- The current number of security sessions represented in the database.
- The date of the earliest record in the database based on the time (SMFHDR_Time) and date
    (SMFHDR_Date) fields of the SMF record header. The earliest record identifies the oldest SMF record
       stored in the database.
- The date of the latest record in the database based on the time (SMFHDR_Time) and date
    (SMFHDR_Date) fields of the SMF record header. The latest record identifies the newest SMF record
    stored in the database.

To view the latest summary of the database click **Refresh database statistics.**

**Pruning data from the database**

Data management operations encompass both prune and import operations. You can prune data from
the IBM zERT Network Analyzer database with a prune operation. There are three options to prune data:
remove all records from the database, remove a subset of records by relative date, or remove a subset of
records by custom date.

- A relative date specification removes records older than a specified number of days (for example, older
    than 30 days).
- A custom date specification removes records within an explicit date range that is inclusive (for example,
    June 1, 2017 to June 30, 2017). When selecting a custom date range, the oldest date implicitly starts at
    00:00:00 hours and the newest date implicitly ends at 23:59:59 hours.

The date (SMFHDR_Date) field of the SMF record header is used to determine whether a record in the
database matches a date specification.

Before you initiate a prune operation, decide if you want to remove a subset of records based on a date
specification, or all records.

**Restriction:**

- IBM zERT Network Analyzer only supports running a single data management operation at a time. If
    you initiate a prune operation when another data management operation is active, the execution of the
    prune operation is placed in a pending state. The execution of pending data management operations is
    performed in a first-in, first-out (FIFO) manner.
- IBM zERT Network Analyzer only supports running a data management operation when there are no
    active query operations. If you initiate a prune operation while there are active query operations,
    the execution of the prune operation is placed in a pending state. The execution of pending data
    management operations is performed once there are no more active query operations.
- Once a prune operation completes, it cannot be undone. Be careful when specifying which SMF 119
    Subtype 12 records are to be removed. Any SMF 119 Subtype 12 records that are accidentally removed
    need to be reimported.

**Tip:** Use the **Data Management History** panel to track the progress of an initiated prune operation.

**Procedure**

1. In the **PRUNE DATABASE** section, select whether you want to remove all records, a subset of records
    by relative date, or a subset of records by custom date.
       a. To remove all records, click **Remove all data**.
       b. To remove a subset of records relative to the current date, click **Older than <x> days** and specify a
          non-zero number for **<x>** in the selection box. The default value is 30 days.
c. To remove a subset of records associated with a custom date, click **Custom range** and specify
the oldest and newest dates for the records to be removed. To specify a date, use one of these
methods:
- Select dates using the calendar icon. The current selected date is identified by a solid circle over
the date. The current calendar date is identified by a clear circle over the date.
- Manually enter the oldest and newest dates.

```
IBM zERT Network Analyzer Task Summary   9
```

```
Requirements:
```
- Manually entered dates must be a valid date using the format MM/DD/YYYY.
- When selecting a custom date, specify both the oldest date and youngest date. The oldest date
    must be earlier than, or equal to, the youngest date. In the **PRUNE DATABASE** section, the
    custom date on the left represents the oldest date, and the custom date on the right represents
    the youngest date.
2. Click **Prune imported data** in the upper right corner of the panel, and you are prompted to confirm to
proceed the action. Click **Confirm** to prune or **Cancel** to go back to **Data Management**.

### Queries

```
References to the Queries panel of IBM z/OS Encryption Readiness Technology (zERT) Network Analyzer.
In this topic, you can find references to help you work with the Queries panel of IBM zERT Network
Analyzer.
```
#### Working with Manage Queries panel

```
You can use the Manage Queries panel to create, edit, delete, run, or export the results of queries defined
by any user of IBM zERT Network Analyzer.
The Manage Queries panel displays a tabular summary view of all existing queries. Each row displays the
name of the query and if defined, the user-specified description of the query.
```
```
Table 4. Query fields description
```
```
Field name Description
```
```
Query name The name of the query
```
```
Description One of the following:
```
- The user-specified description of the query function, if one was
    specified for the query.
- The value _"No description provided"_.

```
Viewing query details
The query detail view always includes the name of the query and the user-specified description of the
query if defined. To view additional details about a query row, click on the query, and it expands to show
the details.
Table 4 on page 10 shows the query summary fields on the Manage Queries panel. These fields are also
displayed as query detail fields.
```
- See “Appendix A. Query filter matching rules” on page 12 for an explanation of how multiple filters are
    interpreted when the query is run.
- See “Appendix B. Filter value descriptions” on page 14 for descriptions of the query details.
- See “Appendix C. Matching query filter options to Report fields” on page 18 for a mapping of individual
    filter contents to the corresponding **Report** view fields that are matched against the filter contents.

**Creating a query**

```
Click New Query in the upper right corner of the panel to switch to the New/Edit Query tab. See
“Creating or editing a new query” on page 23 for more information.
Note: You can have only one create or edit query tab active at a time. If you select New Query and there
is a New/Edit Query tab already active, click Confirm to override the active query with a new query, or
```
**10**   IBM zERT Network Analyzer Task Summary


click **Cancel** to leave the existing query tab in place. If you override the active query with a new query, you
lose any unsaved changes for the previous query.

**Editing a query**

You can take the following steps to edit a query.

1. Select the row of the query that you want to edit.
2. Click **Edit query** in the selected row. The **Edit query** function is available in either the query summary
    or query detail view.
3. Select the **New/Edit query** tab to edit the query contents.

See “Creating or editing a new query” on page 23 for more information.

**Note:** You can have only one create or edit query tab active at a time. If you select **Edit query** and there is
a create or edit query tab already active, click **Confirm** to override the active query with this query, or click
**Cancel** to leave the existing query tab in place. If you override the active query with this query, you lose
any unsaved changes for the previous query.

**Deleting a query**

You can take the following steps to delete a query.

1. Select the row of the query that you want to delete.
2. Click **Delete query** in the selected row. The **Delete query** function is available in either the query
    summary or query detail view.
3. Click **Confirm** to delete the query, or click **Cancel** to return to the panel view.

**Running a query**

You can take the following steps to run a query.

1. Select the row representing the query you want to run.
2. Click **Run query** in the selected row. The **Run query** function is available in either the query summary
    or query detail view.
3. Click **Confirm** to start the query, or click **Cancel** to return to the panel view.
4. To see the results of the query, select the **Report** panel.

**Note:** Running a query uses an available database resource to store the query results. The database
information section in the **Database Settings** panel shows the maximum number of open reports
allowed. In addition, you can set the per-user limit in **Maximum open reports per user** field under
the **REPORTS SETTINGS** section in the **Application Settings** panel. If the maximum number is reached
by running multiple queries (either in different browser sessions or by different users), the IBM zERT
Network Analyzer is not able to run a new query in another browser session until a database partition is
made available by closing an active report.

**Exporting query results**

You can take the following steps to export query results to a comma-separated values (CSV) format file.

1. Select the row representing the query you want to export.
2. Click **Export query** in the selected row, and the **Export to CSV** panel is displayed.
    **Note:** The **Export query** function is available in either the query summary or query detail view.
3. Enter the requested information in the **EXPORT OPTIONS** section.
    - To identify the path and name of the export file that can be used for the query results, specify the
       path and name in the **Export Location** field. You must specify a path and name for the export file, or
       the export cannot be performed.

```
IBM zERT Network Analyzer Task Summary   11
```

```
Note: The value for the Export Location field must be a z/OS UNIX path and name on the z/OS
system where z/OSMF is running, and to which the logged-in user ID has permission to write.
```
- To specify the delimiter to use to separate columns of information in the exported data, select one of
    the delimiter options:
    - To use a comma, select **Comma**.
    - To use a vertical bar, select **Pipe**.
    - To use a semicolon, select **Semicolon**.
    - To use a tab character, select **Tab**.
    - To specify some other character, select **Custom** and enter the delimiter character to be used.
    **Note:** The default delimiter setting is the value most recently saved from the **EXPORT SETTINGS**
    section of the **Application Settings** panel.
- If you enter the name of an existing file, you must select **Replace existing file located at the Export**
    **Location**. If you specify an existing file in **Export Location** but do not perform this step, the export
    operation fails with the message " **Message from server: File exists:** **_filename_** ".
4. Click **Export** to export the query results, or click **Close** to return to the **Manage Query** panel.
**Note:** Once the export completes successfully, you can download the CSV file from the export location
to your workstation or device using binary file transfer. The generated CSV files are written in ASCII.

**Sorting table by column**

```
To sort the table by column, click on the column header and the table is sorted by that column in
ascending order. To sort in descending order, click on the column header again.
```
```
Updating the list of queries
Click Refresh queries list in the upper right corner of the panel to get the latest list of queries in the IBM
zERT Network Analyzer database.
```
**Appendix**

- “Appendix A. Query filter matching rules” on page 12 explains how IBM zERT Network Analyzer
    interprets the interaction of the different filters that are defined for a query.
- “Appendix B. Filter value descriptions” on page 14 describes possible filter values shown when a
    query is expanded on the **Manage Queries** panel of IBM zERT Network Analyzer.
- “Appendix C. Matching query filter options to Report fields” on page 18 describes the relationship
    between query detailed view filter descriptions displayed on the **Manage Queries** panel and the **Report**
    panel fields that are used when running the query.

**Appendix A. Query filter matching rules**

```
This appendix describes how IBM zERT Network Analyzer interprets the interaction of the different filters
that are defined for a query.
When you run a query, IBM zERT Network Analyzer interprets the specified filters as follows:
```
- If a security filter specifies one or more values in a list, only security sessions that have one of the
    specified values are eligible to be included in the query report.
    For example, QueryA has a single filter, IPSec Symmetric Encryption Algorithm, and DES and 3DES
    are the only algorithms selected for the filter. When QueryA is run, only IPSec security sessions that
    use either DES or 3DES as the symmetric encryption algorithm are eligible to be included in the query
    report.

**12**   IBM zERT Network Analyzer Task Summary


- If more than one security filter is specified for a specific protocol, only security sessions that match
    each individual filter’s criteria are eligible to be included in the query report.
    For example, QueryB has two IPSec filters defined:
    - IPSec symmetric encryption algorithm, with DES and 3DES selected as the algorithms to be included.
    - IPSec message authentication algorithm, with HMAC_MD5 and HMAC_SHA1 selected as the
       algorithms to be included.
When QueryB is run, IPSec security sessions that match both of the following two criteria are eligible to
be included in the query report.
- The IPSec security session must use either DES or 3DES as the symmetric encryption algorithm.
- The IPSec security sessions must use either HMAC_MD5 or HMAC_SHA1 as the message
authentication algorithm.
- If security filters are specified for multiple protocols, security sessions that match the criteria for either
    protocol are eligible to be included in the query report. In addition, security sessions that use protocols
    that do not have security filters included in the query are not eligible for the report.
    For example, QueryC has three filters defined:
    - IPSec symmetric encryption algorithm, with DES and 3DES selected as the algorithms to be included.
    - TLS symmetric encryption algorithm, with 3DES selected as the algorithm to be included.
    - SSH symmetric encryption algorithm, with DES selected as the algorithm to be included.
    When QueryC is run, any of the following security sessions are eligible to be included in the query
    report:
    - IPSec security sessions that use either DES or 3DES as the symmetric encryption algorithm.
    - TLS security sessions that use 3DES as the symmetric encryption algorithm.
    - SSH security sessions, that use DES as the symmetric encryption algorithm.
    **Note:** Security sessions with no recognized cryptographic protection are not eligible for this query
    because the **All traffic with no recognized cryptographic protection** filter was not selected.
- If a scope filter specifies more than one value for a given filter combination, only security sessions that
    match each of the specified values are eligible to be included in the query report.
    For example, QueryD has a single EE Endpoint filter combination with a local IP address of 10.81.1.0/24
    and local port range of 12000-12004 defined for the filter combination. When QueryD is run, only EE
    security sessions with a local IP address in the 10.81.1.0 subnet that use one or more EE ports in the
    range 12000-12004 are eligible to be included in the query report.
- If more than one filter combinations are specified for a scope filter, security sessions that match all the
    criteria of any individual filter combination are eligible to be included in the query report.
    For example, QueryE has two filter combinations for the TCP Endpoint filter:
    - One filter combination specifies a client IP address of 10.85.5.5 and server port range of 22.
    - One filter combination specifies a client IP address of 10.86.6.6 and server port range of 21-22.
    When QueryE is run, any security session that matches one of the following criteria is eligible to be
    included in the query report.
    - TCP/IP security session with a client IP address of 10.85.5.5 and port 22.
    - TCP/IP security session with a client IP address of 10.86.6.6 and a port number of either 21 or 22.
- If both TCP and EE endpoint scope filters are coded, security sessions that match either of the endpoint
    filter criteria are eligible to be included in the query report.
    For example, QueryF has two endpoint filters:
    - The TCP endpoint filter specifies a server IP address of 10.87.8.8 and a server port of 21.
    - The EE endpoint filter specifies a local IP address of 10.85.7.7 and an EE port range of 12000-12004.

```
IBM zERT Network Analyzer Task Summary   13
```

```
When QueryF is run, any security session that matches one of the following criteria is eligible to be
included in the query report.
```
- TCP/IP security session with a server IP address of 10.87.8.8 and port 21.
    - EE security session with a local IP address of 10.85.7.7 and a port number between 12000 and
       12004, inclusive.
- If more than type one scope filter is coded, only security sessions that match all the scope filter criteria
for the coded types are eligible to be included in the query report.
For example, QueryG has these four scope filters:
- Date range filter with a relative date of the past 15 days.
- The TCP endpoint filter specifies a server IP address of 10.87.8.8 and a server port of 21.
    - The EE endpoint filter specifies a local IP address of 10.85.7.7 and an EE port range of 12000-12004.
    - System filter with sysplex value of PLEX1 and wildcarded system and stack values.
    When QueryG is run, only security session with the following characteristics are eligible to be included
    in the query report:
- TCP/IP security session with a server IP address of 10.87.8.8 and port 21, provided they have a local
    endpoint in PLEX1 and were reported in the past 15 days.
    - EE security session with a local IP address of 10.85.7.7 and a port number between 12000 and
       12004, inclusive, provided they have a local endpoint in PLEX1 and were reported in the past 15
       days.
- If both scope and security filters are specified, security sessions must match the criteria for both the
scope filters and the security filters to be eligible to be included in the query report.
For example, QueryH has four filters defined:
- IPSec symmetric encryption algorithm, with DES and 3DES selected as the algorithms to be included.
- TLS symmetric encryption algorithm, with 3DES selected as the algorithm to be included.
- Date range filter with a relative date of the past 30 days.
- TCP endpoint filter with a client IP address of 10.91.5.5.
When QueryH is run, only the following security sessions are eligible to be included in the query report:
- IPSec security sessions reported within the past 30 days with a client at IP address 10.91.5.5 that
use either DES or 3DES as the symmetric encryption algorithm.
- TLS security sessions reported within the past 30 days with a client at IP address 10.91.5.5 that use
3DES as the symmetric encryption algorithm.

**Appendix B. Filter value descriptions**

```
This appendix describes possible filter values shown when a query is expanded on the Manage Queries
panel of IBM zERT Network Analyzer.
```
**Possible scope filters for a query**

```
Scope filter value descriptions shows the possible filters that can be listed under SCOPE FILTERS header
for an individual query on the Manage Queries panel.
```
- The query display includes only scope filters that are defined for the individual query.
- When no scope filters are defined for an individual query, the value shows that _"No scope filters specified_
    _for this query"_.

**14**   IBM zERT Network Analyzer Task Summary


_Table 5. Scope filter value descriptions_

**Filter name Description**

Date range The defined date range to be used in the query.

```
One of the following values is displayed:
```
- If the date range filter represents a relative date, then **Last** **_n_** **days** is
    displayed, where **_n_** is the number of relative days defined for the filter.
- If the date range filter represents a range of dates, then **_start_date_** **to**
    **_end_date_** is displayed. The format for both **_start_date_** and **_end_date_** is
    **yyyy-mm-dd**.

Systems The list of system filter combinations to be used in the query report.

- An individual system filter combination is displayed in the form
    **_sysplex_** **/** **_system_** **/** **_stack_**. A value of ***** is displayed for **_sysplex_** , **_system_**
    or **_stack_** if the wildcard was selected for the field in this systems
    combination.
- When multiple combinations are defined for a systems filter, the
    individual combinations are listed on separate lines.

TCP Endpoint The list of TCP endpoint filter combinations to be used in the query
report.

- An individual TCP endpoint filter combination is displayed in the form
    ( **_role_** ) **Server:** **_server_ip@:port_list_** **, Client:** **_client ip@_****.**
    - Possible values for **_role_** are **Client** , **Server** , or **Both**.
    - The format for **_server_ip@_** and **_client_ip@_** can be an IPv4 address
       or an IPv6 address. The value can be either a single IP address or
       an IP address/subnet notation.
       **Note:** If **_server_ip@_** is an IPv6 address, the address is enclosed in
       brackets.
    - Possible values for **_port_list_** are an individual port number or
       a range of port numbers in the format **_start_port_** - **_end_port_**. If
       multiple ports were specified in the query definition, the ports are
       all listed in **_port_list_** , and the values are separated by commas.
    - A value of ***** is displayed for **_server_ip@_** , **_port_list_** , or **_client_ip@_** if
       the wildcard was selected for the field in this TCP endpoint filter
       combination.
- When multiple combinations are defined for a TCP endpoint filter, the
    individual combinations are listed on separate lines.

```
IBM zERT Network Analyzer Task Summary   15
```

```
Table 5. Scope filter value descriptions (continued)
```
```
Filter name Description
```
```
EE Endpoint The list of Enterprise Extender (EE) endpoint filter combinations to be
used in the query report.
```
- An individual EE endpoint filter combination is displayed in the form
    **Local:** **_local_ip@:port_list_** **, Remote:** **_remote ip@_****.**
    - The format for **_local_ip@_** and **_remote_ip@_** can be an IPv4 address
       or an IPv6 address. The value can be either a single IP address or
       an IP address/subnet notation.
       **Note:** If **_local_ip@_** is an IPv6 address, the address is enclosed in
       brackets.
    - Possible values for **_port_list_** are an individual port number or
       a range of port numbers in the format **_start_port_** - **_end_port_**. If
       multiple ports were specified in the query definition, the ports are
       all listed in **_port_list_** , and the values are separated by commas.
    - A value of ***** is displayed for **_local_ip@_** , **_port_list_** , or **_remote_ip@_**
       if the wildcard was selected for the field in this EE endpoint filter
       combination.
- When multiple combinations are defined for an EE endpoint filter, the
    individual combinations are listed on separate lines.

```
Possible security filters for a query
Security filter value descriptions shows the possible filters that can be listed under SECURITY FILTERS
header for an individual query on the Manage Queries panel.
```
- The query display includes only security filters that are defined for the individual query.
- When no security filters are defined for an individual query, the value shows that _"No security filters_
    _specified for this query"_.
Unless noted in the table, the value displayed for a given filter is a list of selected options separated by
commas.

```
Table 6. Security filter value descriptions
```
```
Filter name Description
```
```
All traffic with no recognized
cryptographic protection
```
```
Traffic that does not have any recognized cryptographic protection
should be included in the query report.
```
```
All IPSec protected traffic Security sessions using IPSec to protect traffic should be included in the
query report.
```
```
IPSec symmetric encryption
algorithm
```
```
The list of IPSec symmetric encryption algorithm options to be included
in this query.
```
```
IPSec message authentication
algorithm
```
```
The list of IPSec message authentication algorithm options to be
included in this query.
```
```
IPSec certificate digital
signature algorithm
```
```
The list of IPSec certificate digital signature algorithm options to be
included in this query.
```
**16**   IBM zERT Network Analyzer Task Summary


```
Table 6. Security filter value descriptions (continued)
```
**Filter name Description**

IPSec certificate asymmetric
key length

```
The range of IPSec certificate asymmetric key lengths to be included
in this query. The range is expressed as a mathematical expression
<operand><length> , where
```
- **_operand_** can be "=" (equal to), "<" (less than), ">" (greater than), "<="
    (less than or equal to) or ">=" (greater than or equal to).
- **_length_** is the acceptable length of the asymmetric key.

```
IPSec key exchange algorithm The list of IPSec symmetric encryption algorithm options to be included
in this query.
```
```
All TLS protected traffic Security sessions using TLS to protect traffic should be included in the
query report.
```
```
TLS protocol version The list of TLS protocol versions to be included in this query.
```
```
TLS symmetric encryption
algorithm
```
```
The list of TLS symmetric encryption algorithm options to be included in
this query.
```
```
TLS message authentication
algorithm
```
```
The list of TLS message authentication algorithm options to be included
in this query.
```
```
TLS digital signature algorithm The list of TLS digital signature algorithm options to be included in this
query.
```
```
TLS certificate asymmetric
key length
```
```
The range of TLS certificate asymmetric key lengths to be included
in this query. The range is expressed as a mathemetical expression
operandlength , where
```
- **_operand_** can be “=” (equal to), “<” (less than), “>” (greater than), “<=”
    (less than or equal to) or “>=” (greater than or equal to).
- **_length_** is the acceptable length of the asymmetric key.

```
TLS key exchange algorithm The list of TLS symmetric encryption algorithm options to be included in
this query.
```
```
All SSH protected traffic Security sessions using SSH to protect traffic to be included in the query
report.
```
```
SSH protocol version The list of SSH protocol versions to be included in this query.
```
```
SSH symmetric encryption
algorithm
```
```
The list of SSH symmetric encryption algorithm options to be included in
this query.
```
```
SSH message authentication
algorithm
```
```
The list of SSH message authentication algorithm options to be included
in this query.
```
```
SSH key type The list of SSH key type options to be included in this query.
```
```
SSH key length The range of SSH certificate key lengths to be included in this query. The
range is expressed as a mathemetical expression operandlength , where
```
- **_operand_** can be “=” (equal to), “<” (less than), “>” (greater than), “<=”
    (less than or equal to) or “>=” (greater than or equal to).
- **_length_** is the acceptable length of the asymmetric key.

```
SSH key exchange algorithm The list of SSH key exchange algorithm options to be included in this
query.
```
```
IBM zERT Network Analyzer Task Summary   17
```

**Appendix C. Matching query filter options to Report fields**

```
This appendix describes the relationship between query detailed view filter descriptions displayed on the
Manage Queries panel and the Report panel fields that are used when running the query.
```
**Data Range filter**

```
The date when a security session was reported is not displayed in any Report table view, but it is saved
as an attribute of the security session in the IBM zERT Network Analyzer database. This saved attribute is
used for matching a security session against the Date Range filter setting.
```
```
Systems filter
The Report view fields used for matching a security session against a Systems filter setting include
multiple fields across different Report table views.
```
```
Filter value Report visibility Report field
```
```
Sysplex TCP Server
Summary
EE Peer
Summary
```
```
Sysplex
```
```
TCP Client
Summary
```
```
Client Sysplex
```
```
System TCP Server
Summary
EE Peer
Summary
```
```
System
```
```
TCP Client
Summary
```
```
Client System
```
```
Stack TCP Server
Summary
EE Peer
Summary
```
```
Stack
```
```
TCP Client
Summary
```
```
Client Stack
```
**TCP Endpoint filter**

```
The Report view fields used for matching a security session against a TCP Endpoint filter setting include
multiple fields across different Report table views, and depend on the role of the local z/OS CS in the TCP
connections using the security session.
The role ( role ) played by the local z/OS CS is not explicitly displayed in any Report table view, but can be
inferred from the table in which the security session appears in the Report view.
```
- If the security session appears in the **TCP Server Traffic** table view, then the local z/OS CS acted as the
    server for TCP connections using the security session.
    This **Server Role** table is used for matching security sessions against a **TCP Endpoint** that represents a
    z/OS CS Server role:

**18**   IBM zERT Network Analyzer Task Summary


```
Filter value Report visibility Report field
```
```
Server IP
address
```
```
TCP Server
Summary
```
```
Server IP
```
Server port
range

```
TCP Server
Summary
```
```
Server Port
```
Client IP
address

```
TCP Server
Client
```
```
Client IP
```
- If the security session appears in the **TCP Client Traffic** table view, then the local z/OS CS acted as the
    client for the TCP connections using the security session.
    This **Client Role** table is used for matching security sessions against a **TCP Endpoint** that represents a
    z/OS CS Server role:

**Filter value Report visibility Report field**

Server IP
address

```
TCP Client
Summary
```
```
Foreign Server IP
```
Server port
range

```
TCP Client
Summary
```
```
Foreign Server Port
```
Client IP
address

```
TCP Client
Client
```
```
Client IP
```
- If **_role_** is set to “ **Both”** in the **TCP Endpoint** filter, all security sessions are compared against the
    additional filter values. A security session with values that matches the **Report** fields in either the
    **Server Role** or **Client Role** tables is considered a match for the **TCP Endpoint** filter.

```
EE Endpoint filter
The Report view fields used for matching a security session against an EE Endpoint filter setting appear
in the EE Peer Traffic table.
```
**Filter value Report visibility Report field**

Local IP address **EE Peer**

```
Summary
```
```
Local EE Peer
```
Local port range **EE Peer**

```
Summary
```
```
UDP Port
```
Remote IP
address

```
EE Peer
Peer
```
```
Remote EE Peer
```
```
All traffic with no recognized cryptographic protection, All IPSec protected filter, All
TLS protected filter, and All SSH protected filter
```
```
The security protocol for an individual security session is not explicitly displayed in any Report table view.
You determine the protocol for a security session based on the cryptographic option selected for the
Security Sessions Details table view that contains the session.
```
- Security sessions with no recognized cryptographic protection are displayed when you select
    **Unprotected* Session Details** as the cryptographic option.
- IPSec protected security sessions are displayed when you select **IPSec Session Details** as the
    cryptographic option.

```
IBM zERT Network Analyzer Task Summary   19
```

- TLS protected security sessions are displayed when you select **TLS Session Details** as the
    cryptographic option.
- SSH protected security sessions are displayed when you select **SSH Session Details** as the
    cryptographic option.

```
IPSec symmetric encryption algorithm
The Report view fields used for matching a security session against the set of symmetric encryption
algorithms specified for the IPSec security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
IPSec
symmetric
encryption
algorithm
```
```
IPSec Session Details
Cryptographic Details
```
```
Symmetric Encryption Algorithm
```
```
IPsec Session Details
Peer Authentication Detail
```
```
IKE Tunnel Encryption Algorithm
```
**IPSec message authentication algorithm**

```
The Report view fields used for matching a security session against the set of message authentication
algorithms specified for the IPSec security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
IPSec message
authentication
algorithm
```
```
IPSec Session Details
Cryptographic Details
```
```
Message Authentication Algorithm
```
```
IPsec Session Details
Peer Authentication Detail
```
```
IKE Tunnel Authentication Algorithm
```
**IPSec certificate digital signature algorithm**

```
The Report view fields used for matching a security session against the set of certificate digital signature
algorithms specified for the IPSec security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
IPSec certificate
digital signature
algorithm
```
```
IPSec Session Details
Certificate Details
```
- Local Certificate Signature Method
- Remote Certificate Signature Method

```
IPSec certificate asymmetric key length
The Report view fields used for matching a security session against the length of the certificate
asymmetric key specified for the IPSec security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
IPSec certificate
asymmetric key
length
```
```
IPSec Session Details
Certificate Details
```
- Local Certificate Key Length
- Remote Certificate Key Length

**IPSec key exchange algorithm**

```
The Report view fields used for matching a security session against the set of key exchange algorithms
specified for the IPSec security filter appear in the Security Session Details table.
```
**20**   IBM zERT Network Analyzer Task Summary


```
Filter Report visibility Report field
```
```
IPSec key
exchange
algorithm
```
```
IPSec Session Details
Peer Authentication Details
```
- IKE Local Authentication Algorithm
- IKE Remote Authentication Algorithm

```
TLS protocol version
The Report view fields used for matching a security session against the set of protocols specified for the
TLS security filter appear in the Security Session Details table.
```
**Filter Report visibility Report field**

TLS protocol **TLS Session Details**

```
Cryptographic Details
```
```
Protocol Version
```
**TLS symmetric encryption algorithm**

```
The Report view fields used for matching a security session against the set of symmetric encryption
algorithms specified for the TLS security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
TLS symmetric
encryption
algorithm
```
```
TLS Session Details
Cryptographic Details
```
```
Symmetric Encryption Algorithm
```
**TLS message authentication algorithm**

```
The Report view fields used for matching a security session against the set of message authentication
algorithms specified for the TLS security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
TLS message
authentication
algorithm
```
```
TLS Session Details
Cryptographic Details
```
```
Message Authentication Algorithm
```
```
TLS digital signature algorithm
The Report view fields used for matching a security session against the set of digital signature algorithms
specified for the TLS security filter appear in the Security Session Details table.
```
**Filter Report visibility Report field**

TLS digital
signature
algorithm

```
TLS Session Details
Certificate Details
```
- Server Certificate Signature Method
- Client Certificate Signature Method

```
TLS Session Details
Cryptographic Details
```
- Server Handshake Signature Method
- Client Handshake Signature Method

**TLS certificate asymmetric key length**

```
The Report view fields used for matching a security session against the length of the certificate
asymmetric key specified for the TLS security filter appear in the Security Session Details table.
```
```
IBM zERT Network Analyzer Task Summary   21
```

```
Filter Report visibility Report field
```
```
TLS certificate
asymmetric key
length
```
```
TLS Session Details
Certificate Details
```
- Server Certificate Key Length
- Client Certificate Key Length

```
TLS key exchange algorithm
The Report view fields used for matching a security session against the set of key exchange algorithms
specified for the TLS security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
TLS key
exchange
algorithm
```
```
TLS Session Details
Cryptographic Details
```
```
Key Exchange Algorithm
```
**SSH protocol version**

```
The Report view fields used for matching a security session against the set of protocols specified for the
SSH security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
SSH protocol SSH Session Details
Cryptographic Details
```
```
Protocol Version
```
**SSH symmetric encryption algorithm**

```
The Report view fields used for matching a security session against the set of symmetric encryption
algorithms specified for the SSH security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
SSH symmetric
encryption
algorithm
```
```
SSH Session Details
Cryptographic Details
```
- Symmetric Encryption Algorithm In
- Symmetric Encryption Algorithm Out

```
SSH message authentication algorithm
The Report view fields used for matching a security session against the set of message authentication
algorithms specified for the SSH security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
SSH message
authentication
algorithm
```
```
SSH Session Details
Cryptographic Details
```
- Message Authentication Algorithm In
- Message Authentication Algorithm Out

**SSH key type**

```
The Report view fields used for matching a security session against the set of key types specified for the
SSH security filter appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
SSH key type SSH Session Details
Cryptographic Details
```
- Server Key Type
- Client Key Type

**22**   IBM zERT Network Analyzer Task Summary


```
SSH key length
The Report view fields used for matching a security session against the key length specified for the SSH
security filters appear in the Security Session Details table
```
```
Filter Report visibility Report field
```
```
SSH key length SSH Session Details
Cryptographic Details
```
- Server Key Length
- Client Key Length

**SSH key exchange algorithm**

```
The Report view fields used for matching a security session against the set of key exchange algorithms
specified for the SSH security filters appear in the Security Session Details table.
```
```
Filter Report visibility Report field
```
```
SSH key
exchange
algorithm
```
```
SSH Session Details
Cryptographic Details
```
```
Key Exchange Algorithm
```
#### Creating or editing a new query

```
You can use the New/Edit Query panel to create, edit, and run a query against the IBM zERT Network
Analyzer database.
Note: The name displayed for the New/Edit Query tab differs depending on the function being
performed.
```
- If you are creating a new query, the name of the tab is **New Query**. In addition, the first line of the panel
    is **"New Query"**. For example:
- If you are editing a query, or if you save the contents of a new query without closing the **New/Edit**
    **Query** tab, the name of the tab is **_query_name_** , where **_query_name_** is the name of the query being
       edited. In addition, the first line of the panel is “ **Edit Query:** **_query_name_** ”. For example:

```
Note: You can have only one New/Edit Query tab active at a time. If you have a New/Edit Query tab
active, and you replace that query by starting a new create-or-edit query session, you lose any unsaved
changes to the existing create-or-edit query activity.
```
**Creating a new query**

```
You can take the following steps to create a new query.
```
```
IBM zERT Network Analyzer Task Summary   23
```

1. Select the **Query Details** tab.
2. Enter the name of the query in the **Query Name** field. This field is required and can be a maximum of
    50 characters, including blanks.
3. **Optional:** Enter a description for the query in the **Query Description** field, using a maximum of 50
    characters.
4. **Optional:** Add one or more scope or security filters to the query. See “Appendix. Adding scope or
    security filters to a query” on page 25 for details.
    **Important:** If you don't select any scope or security filters, the query displays everything in the IBM
    zERT Network Analyzer database.
5. **Optional:** To remove a filter from the query, either
    - Click **Remove filter** in the filter section that you want to remove;
    - Unselect the filter in the list of filters on the left side of the **Scope Filters** or **Security Filters** tab.
    **Important:** If you remove a filter, the information you entered is not saved. If you subsequently add
    the filter again to the query, the filter is primed with default values.
6. Click **Save and run query** to run the query and save it to the IBM zERT Network Analyzer database.
    Click **Confirm** to save the query and run it, or click **Cancel** to return to the create query session.
    **Note:** You can also perform alternative actions in this step.
    - If you want to save the query to the IBM zERT Network Analyzer database without also running the
       query, click **Save query**. Click **Confirm** to save the query, or click **Cancel** to return to the create
       query session.
    - If you want to close the query tab without saving any information, click **Close query** or the
       beside the **New Query** tab. Click **Confirm** to exit the query, or click **Cancel** to return to the create
       query session.
          **Warning:** If you end your session with IBM zERT Network Analyzer without saving the query to the
          database, you lose the query data.

```
Editing an existing query
You can take the following steps to edit an existing query.
```
1. To change the name or description of the query, select the **Query Details** tab.
    - To change the name of the query, enter the new name of the query in the **Query Name** field. This
       field is required and can be a maximum of 50 characters, including blanks.
    - To change the description for the query, enter the new description in the **Query Description** field,
       using a maximum of 50 characters.
2. To change, add, or delete one or more scope filters, select the **Scope Filters** tab.
    - To change an existing filter definition, modify the contents of the filter to the new values.
       - To add a new filter row combination to an existing **Systems** , **TCP Endpoint** or **EE Endpoint** filter
          definition, click **Add system** , **Add TCP endpoint** or **Add EE endpoint** , respectively.
       - To delete a filter row combination from an existing **Systems** , **TCP Endpoint** , or **EE Endpoint** filter

```
definition, click the minus sign for the filter row combination to be removed.
See the description of the filter being changed in “Appendix. Adding scope or security filters to a
query” on page 25 for help on specifying new values.
```
- To add a completely new filter, select the desired filter in the table of filters on the left side of
    the **Scope Filters** tab. See the description of the filter being added in “Appendix. Adding scope or
    security filters to a query” on page 25 for help on creating the new filter.
- To delete a filter, click **Remove filter** in the filter section you want to remove.

**24**   IBM zERT Network Analyzer Task Summary


3. To change, add, or delete one or more security filters, select the **Security Filters** tab.
    - To change an existing filter definition, modify the contents of the filter to the new values. See the
       description of the filter being changed in “Appendix. Adding scope or security filters to a query” on
       page 25 for help on specifying the new values.
    - To add a completely new filter, select the desired filter in the table of filters on the left side of the
       **Security Filters** tab. See the description of the filter being added in “Appendix. Adding scope or
       security filters to a query” on page 25 for help on creating the new filter.
    - To delete a filter, click **Remove filter** in the filter section you want to remove.
4. Click **Save and run query** to run the query and save the modifications to the IBM zERT Network
    Analyzer database. Click **Confirm** to save the query and run it, or click **Cancel** to return to the edit
    query session.
    **Note:** You can also perform alternative actions:
    - If you want to save the query to the IBM zERT Network Analyzer database without also running the
       query, click **Save query**. Click **Confirm** to save the query, or click **Cancel** to return to the edit query
       session.
    - If you want to close the **_query_name_** tab without saving any information, click **Close query** or the

```
beside the query_name tab. Click Confirm to exit the query, or click Cancel to return to the edit
query session.
```
- If you want to undo your unsaved changes without closing the **_query_name_** tab, click **Refresh query**.
    Click **Confirm** to undo the changes, or click **Cancel** to return to the edit query session with the
    modifications still in place.

```
Warning: If you end your session with IBM zERT Network Analyzer without saving the modified
query to the database, you lose the modifications to the query.
```
**Appendix.**

- “Appendix. Adding scope or security filters to a query” on page 25 describes how to add one or more
    scope or security filters on the **New Query** panel.

**Appendix. Adding scope or security filters to a query**

This appendix describes how to add one or more scope or security filters to a query.

You can find a list of available filters on the left side of the **Scope Filters** or **Security Filters** tab. Select
one or more filters that you want to apply to the query. See “Appendix A. Query filter matching rules” on
page 12 in “Working with Manage Queries panel” on page 10 for detailed explanation of the interaction of
the filters that you can select.

**Selecting scope filter**
Select the **Scope Filters** tab if you want to add scope filters for this query. Scope filters relate to the dates
the security sessions were reported, the systems on which the security sessions were reported, and the
local or remote endpoints for the security sessions.

- If you want the query to include security sessions that were reported during a specific period of time,
    select **Date Range**.

```
Security sessions to be
included
```
```
Action
```
```
All security sessions that
were reported relative to
today's date
```
1. Select **Within the last <n> days** in the **DATE RANGE** filter.
2. Specify a non-zero integer as the value for **<n>** in the **Within the**
    **last <n> days** field in the **DATE RANGE** filter. The default value is
    30 days.

```
IBM zERT Network Analyzer Task Summary   25
```

```
Security sessions to be
included
```
```
Action
```
```
All security sessions that
were reported within a
specific range of dates
```
1. Select **Custom range** in the **DATE RANGE** filter.
2. Specify the first date in the custom range. Either:
    - Specify the date in the form mm/dd/yyyy in the first field in the
       **Custom range** field in the **DATE RANGE** filter.
    - Use the calendar icon associated with the first field in the
       **Custom range** field in the **DATE RANGE** filter to set the date.
3. Specify the last date in the custom range. Either:
    - Specify the date in the form mm/dd/yyyy in the second field in
       the **Custom range** field in the **DATE RANGE** filter.
    - Use the calendar icon associated with the second field in the
       **Custom range** field in the **DATE RANGE** filter to set the date.
    **Note:** The date specified in the second field must be equal to or
    later than the date specified in the first field.
- If you want the query to include security sessions with endpoints at one or more specific sysplexes,
systems, or TCP/IP stacks, select **Systems**.

```
System filter setting Action
```
```
Security sessions with an
endpoint associated with a
specific sysplex
```
- To use a specific sysplex name, select the name from the **Sysplex**
    drop-down list in the **SYSTEMS** filter.
- To specify a custom sysplex name:
    1. Select **Custom sysplex** from the **Sysplex** drop-down list in the
       **SYSTEMS** filter.
    2. Enter the name in the input field under **Sysplex**.
- To use any sysplex name, select the wildcard value (*) from the
    drop-down list. This is the default setting.

```
Security sessions with an
endpoint associated with a
specific system
```
- To use a specific system name, select the name from the **System**
    drop-down list in the **SYSTEMS** filter.
- To specify a custom system name:
    1. Select **Custom system** from the **System** drop-down list in the
       **SYSTEMS** filter.
    2. Enter the name in the input field under **System**.
- To use any system name, select the wildcard value (*) from the
    drop-down list. This is the default setting.

```
Security sessions with an
endpoint associated with a
specific TCP/IP stack
```
- To use a specific TCP/IP stack name, select the name from the
    **TCP/IP stack** drop-down list in the **SYSTEMS** filter.
- To specify a custom TCP/IP stack name:
    1. Select **Custom TCP/IP stack** from the **TCP/IP stack** drop-down
       list in the **SYSTEMS** filter.
    2. Enter the name in the input field under **TCP/IP stack**.
- To use any TCP/IP stack name, select the wildcard value (*) from the
    drop-down list. This is the default setting.

**26**   IBM zERT Network Analyzer Task Summary


```
System filter setting Action
```
```
Security sessions with an
endpoint associated with
a combination of sysplex,
system, or TCP/IP stack
```
- To include a sysplex name in the filter row, follow the previous
    instructions for adding a sysplex name.
- To include a systems name in the filter row, follow the previous
    instructions for adding a system name.
- To include a TCP/IP stack name in the filter row, follow the previous
    instructions for adding a TCP/IP stack name.

```
Multiple system filter settings – Click Add system in the SYSTEMS filter to create an additional row
in the filter box.
```
- Follow the previous instructions for adding the sysplex, systems, or
    TCP/IP stack value to the filter.

```
Note: To delete an individual filter row, click the minus icon at the end of the row.
```
- If you want the query to include security sessions associated with one or more specific local or remote
    IP addresses, server port range, or connection role, select **TCP Endpoints**.

```
TCP Endpoints filter setting Action
```
```
All security sessions where
z/OS at the local endpoint
performs a specific role
```
- To include security sessions where the local z/OS is the server,
    select **Server** in the **Endpoint role** field in the **TCP ENDPOINTS**
    filter.
- To include security sessions where the local z/OS is the client, select
    **Client** in the **Endpoint role** field.
- To include security sessions regardless of the role played by the
    local z/OS, select **Both** in the **Endpoint role** field. This is the default
    setting.

```
All security sessions with an
endpoint associated with a
specific server IP address,
or IP address and subnet
combination
```
- To specify a single IP address, enter the IP address in the **Server IP**
    **address** field in the **TCP ENDPOINTS** filter. The address can be IPv4
    or IPv6.
- To specify a range of IP addresses, enter the IP address and subnet
    value in the **Server IP address** field. The address/subnet value must
    be a valid IPv4 or IPv6 subnet expression.
- To specify all server IP addresses, enter * as a wildcard value. This is
    the default value.

```
All security sessions
associated with one or more
server ports
```
- To specify a single port, enter the port in the **Server port range** field
    in the **TCP ENDPOINTS** filter.
- To specify a range of server ports, enter the range in the **Server**
    **port range** field, using the format **_start_port-end_port_**. The value
    for **_start_port_** must be less than the value of **_end_port_**.
- To specify a list of port or port ranges values, enter the comma-
    separated list of values in the **Server port range** field.
- To specify all server ports, enter * as a wildcard value. This is the
    default setting.

```
IBM zERT Network Analyzer Task Summary   27
```

```
TCP Endpoints filter setting Action
```
```
All security sessions with an
endpoint associated with a
client IP address
```
- To specify a single client IP address, enter the IP address in the
    **Client IP address** field in the **TCP ENDPOINTS** filter. The address
    can be IPv4 or IPv6.
- To specify a range of IP addresses, enter the IP address and subnet
    value in the **Client IP address** field. The address/subnet value must
    be a valid IPv4 or IPv6 subnet expression.
- To specify all client IP addresses, enter * as a wildcard value. This is
    the default value.

```
Security sessions associated
with a combination of z/OS
role, server IP address,
server port range, or client IP
address
```
- To include a value for the local z/OS role, follow the instructions
    above for defining the z/OS role.
- To include a server IP address or IP address and subnet
    combination in the filter row, follow the previous instructions for
    adding a server IP address.
- To include a server port or port range in the filter row, follow the
    previous instructions for adding a server port value.
- To include a client IP address, or IP address and subnet
    combination in the filter row, follow the previous instructions for
    adding a client IP address.
**Note:** If your filter row includes both local and remote IP addresses,
the addresses must both be IPv4 addresses or both IPv6 addresses.

```
Multiple TCP endpoint filter
settings
```
- Click **Add TCP endpoint** in the **TCP ENDPOINTS** filter to create an
    additional row in the filter box.
- Follow the previous instructions for adding the local z/OS role,
    server IP address, server port or client IP address value to the filter.

```
Note:
```
- To delete an individual filter row, click the **minus icon** at the end of the row.
- If you specify a server port range in the **Server Port Range** field, security sessions that have a server
    port or server port range that is included in any portion of the filter value are eligible for the query
    report.
    For example, if you specify a server port range of 250-300 in the Server Port Range field:
    - Security sessions with single server ports between 250 and 300 match the query.
    - Security sessions with a server port range that overlaps any portion of the range 250-300 also
       match the query. This includes security sessions with a server port range of 200-275, or with a
       server port range of 280-500.
- If you want the query to include security sessions associated with one or more specific local or remote
Enterprise Extender (EE) endpoints or ports, select **EE Endpoints**.

**28**   IBM zERT Network Analyzer Task Summary


```
EE Endpoints filter setting Action
```
```
All security sessions with
an EE endpoint associated
with a local IP address,
or IP address and subnet
combination
```
- To specify a single IP address, enter the IP address in the **Local EE**
    **peer address** field in the **EE ENDPOINTS** filter. The address can be
    IPv4 or IPv6.
- To specify a range of IP addresses, enter the IP address and subnet
    value in the **Local EE peer address** field. The address/subnet value
    must be a valid IPv4 or IPv6 subnet expression.
- To specify all local IP addresses, enter * as a wildcard value. This is
    the default value.

```
All security sessions
associated with one or more
EE ports
```
- To specify a single EE port, enter the port in the **Local UDP port**
    **range** field in the **EE ENDPOINTS** filter.
- To specify a range of EE ports, enter the range in the **Local UDP**
    **port range** field, using the format **_start_port-end_port_**. The value
    for **_start port_** must be less than the value of **_end_port_**.
- To specify a list of port or port ranges values, enter the comma-
    separated list of values in the **Local UDP port range** field.
- To specify all EE ports, enter * as a wildcard value. This is the default
    value.

```
All security sessions with an
EE endpoint associated with
a remote IP address
```
- To specify a single remote IP address, enter the IP address in the
    **Remote EE peer address** field in the **EE ENDPOINTS** filter. The
    address can be IPv4 or IPv6.
- To specify a range of IP address, enter the IP address and subnet
    value in the **Remote EE peer address** field. The address/subset
    value must be a valid IPv4 or IPv6 subnet expression.
- To specify all remote IP addresses, enter * as a wildcard value. This
    is the default value.

```
Security sessions associated
with an EE endpoint defined
by a combination of local IP
address, server port range, or
remote IP address
```
- To include a local IP address or IP address and subnet combination
    in the filter row, follow the previous instructions for adding a local IP
    address.
- To include a server port or port range in the filter row, follow the
    previous instructions for adding a server port value.
- To include a remote IP address, or IP address and subnet
    combination in the filter row, follow the previous instructions for
    adding a remote IP address.
**Note:** If your filter row includes both local and remote IP addresses,
the addresses must both be IPv4 addresses or both IPv6 addresses.

```
Multiple EE endpoint filter
settings
```
- Click **Add EE endpoint** in the **EE ENDPOINTS** filter to create an
    additional row in the filter box.
- Follow the previous instructions for adding the local IP address, EE
    port or remote IP address value you want to the filter.

**Note:** To delete an individual filter row, click the **minus icon** at the end of the row.

```
IBM zERT Network Analyzer Task Summary   29
```

```
Selecting security filter
Select the Security Filters tab if you want to add security filters for this query. Security filters relate
to security sessions that use different security protocols as well as security sessions that use certain
protocol-specific attributes.
```
1. If you want the query to include all unprotected security sessions, select **All traffic with no**
    **recognized cryptographic protection** under the **Unprotected* traffic** heading.
    **Guideline:**
    Wherever the IBM zERT Network Analyzer reports traffic as being "unprotected," this means that zERT
    does not recognize any TLS, SSL, IPsec or SSH cryptographic protection for the traffic. There are a few
    conditions that cause this:
    - The traffic truly is unprotected and flows as cleartext. This is the most common case.
    - Some form of cryptographic protection applies, but in a manner that zERT does not recognize. The
       most common reasons for this behavior are:
       - A cryptographic protocol other than TLS, SSL, IPsec or SSH is used to protect the traffic.
       - TLS, SSL or SSH protection is applied using a cryptographic protocol provider that is not zERT-
          enabled, and the protocol handshake occurs at some point after cleartext data flows over
          the application connection. In this case, zERT does not recognize the protocol handshake and
          does not recognize that the cryptographic protection is in effect. IBM z/OS System SSL, IBM
          z/OS OpenSSH, IBM z/OS JSSE for Java™ 8 and IBM z/OS IPsec are the current zERT-enabled
          cryptographic protocol providers.
       - TLS or SSL protection is applied using IBM z/OS System SSL through direct calls from the
          application or middleware layer (i.e., not through AT-TLS), but the TLS/SSL handshake is initiated
          at some point after cleartext data flows over the application connection, and the application or
          middleware program does not use the SIOCHSNOTIFY ioctl to notify zERT that the handshake
          is about to begin. In this case, zERT does not recognize the protocol handshake and does not
          recognize that the cryptographic protection is in effect.
2. If you want the query to include some or all security sessions using IPSec, select one or more filters
    under the **IPSec** heading. See detailed instructions in the following table.

```
IPSec traffic to include Action
```
```
All security sessions using
IPSec
```
```
Select All IPSec protected traffic.
```
```
IPSec traffic that uses one
or more specific symmetric
encryption algorithms
```
```
a. Select the IPSec symmetric encryption algorithm.
b. Select the specific algorithms you want to use in the IPSEC
SYMMETRIC ENCRYPTION ALGORITHM filter.
```
```
IPSec traffic that uses one
or more specific message
authentication algorithms
```
```
a. Select the IPSec message authentication algorithm.
b. Select the specific algorithms you want to use in the IPSEC
MESSAGE AUTHENTICATION ALGORITHM filter.
```
```
IPSec traffic that uses one
or more specific certificate
digital signature algorithms
```
```
a. Select the IPSec certificate digital signature algorithm.
b. Select the specific algorithms you want to use in the IPSEC
CERTIFICATE DIGITAL SIGNATURE ALGORITHM filter.
```
**30**   IBM zERT Network Analyzer Task Summary


```
IPSec traffic to include Action
```
```
IPSec traffic that uses
certificates with asymmetric
keys within a range of
acceptable sizes
```
```
a. Select the IPSec certificate asymmetric key length.
b. Select the arithmetic operand that defines the acceptable size
range using the drop-down list in the IPSEC CERTIFICATE
ASYMMETRIC KEY LENGTH filter. The arithmetic operand is
" >=(Greater than or equal to) " by default.
c. Specify a non-negative integer as the key size. The size is 0 by
default.
```
```
IPSec traffic that uses one or
more specific key exchange
algorithms
```
```
a. Select the IPSec key exchange algorithm.
b. Select the specific algorithms you want to use in the IPSEC KEY
EXCHANGE ALGORITHM filter.
```
```
Note:
```
- Selecting **All IPSec protected traffic** automatically removes all the other IPSec filters from the
    query.
- Selecting an IPSec filter other than **All IPSec protected traffic** automatically removes the **All IPSec**
    **protected traffic** filter from the query.
- Select a value of _Unknown_ in a filter selection list if you want security sessions that reported an
    algorithm that is not recognized by IBM zERT Network Analyzer.
- Select a value of _None_ in a filter selection list if you want security sessions that did not use any
    algorithm for this function.
3. If you want the query to include some or all security sessions using TLS, select one or more filters
under the **TLS** heading. See detailed instructions in the following table.

```
TLS traffic to include Action
```
```
All security sessions using
TLS
```
```
Select All TLS protected traffic.
```
```
TLS traffic that uses one or
more specific TLS protocol
versions
```
```
a. Select the TLS protocol version.
b. Select the specific protocol versions you want to use in the TLS
PROTOCOL VERSION filter.
```
```
TLS traffic that uses one
or more specific symmetric
encryption algorithms
```
```
a. Select the TLS symmetric encryption algorithm.
b. Select the specific algorithms you want to use in the TLS
SYMMETRIC ENCRYPTION ALGORITHM filter.
```
```
TLS traffic that uses one
or more specific message
authentication algorithms
```
```
a. Select the TLS message authentication algorithm.
b. Select the specific algorithms you want to use in the TLS
MESSAGE AUTHENTICATION ALGORITHM filter.
```
```
TLS traffic that uses one
or more specific digital
signature algorithms
```
```
a. Select the TLS digital signature algorithm.
b. Select the specific algorithms you want to use in the TLS DIGITAL
SIGNATURE ALGORITHM filter.
```
```
IBM zERT Network Analyzer Task Summary   31
```

```
TLS traffic to include Action
```
```
TLS traffic that uses
certificates with asymmetric
keys within a range of
acceptable sizes
```
```
a. Select the TLS certificate asymmetric key length.
b. Select the arithmetic operand that defines the acceptable
size range using the drop-down list in the TLS CERTIFICATE
ASYMMETRIC KEY LENGTH filter. The arithmetic operand is
" >=(Greater than or equal to) " by default.
c. Specify a non-negative integer as the key size. The size is 0 by
default.
```
```
TLS traffic that uses one or
more specific key exchange
algorithms
```
```
a. Select the TLS key exchange algorithm.
b. Select the specific algorithms you want to use in the TLS KEY
EXCHANGE ALGORITHM filter.
```
```
Note:
```
- Selecting **All TLS protected traffic** automatically removes all the other TLS filters from the query.
- Selecting a TLS filter other than **All TLS protected traffic** automatically removes the **All TLS**
    **protected traffic** filter from the query.
- Select a value of _Unknown_ in a filter selection list if you want security sessions that reported an
    algorithm that is not recognized by IBM zERT Network Analyzer.
- Select a value of _None_ in a filter selection list if you want security sessions that did not use any
    algorithm for this filter.
4. If you want the query to include some or all security sessions using SSH, select one or more filters
under the **SSH** heading. See detailed instructions in the following table.

```
SSH traffic to include Action
```
```
All security sessions using
SSH
```
```
Select All SSH protected traffic.
```
```
SSH traffic that uses one or
more specific SSH protocol
versions
```
```
a. Select the SSH protocol version.
b. Select the specific protocol versions you want to use in the SSH
PROTOCOL VERSION filter.
```
```
SSH traffic that uses one
or more specific symmetric
encryption algorithms
```
```
a. Select the SSH symmetric encryption algorithm.
b. Select the specific algorithms you want to use in the SSH
SYMMETRIC ENCRYPTION ALGORITHM filter.
```
```
SSH traffic that uses one
or more specific message
authentication algorithms
```
```
a. Select the SSH message authentication algorithm.
b. Select the specific algorithms you want to use in the SSH
MESSAGE AUTHENTICATION ALGORITHM filter.
```
```
SSH traffic that uses one or
more specific key types
```
```
a. Select the SSH key type.
b. Select the specific key types you want to use in the SSH KEY TYPE
filter.
```
```
SSH traffic that uses keys
within a certain size range for
key length
```
```
a. Select the SSH key length.
b. Select the arithmetic operand that defines the acceptable size
range using the drop-down list in the SSH KEY LENGTH filter. The
arithmetic operand is " >=(Greater than or equal to) " by default.
c. Specify a non-negative integer as the key size. The size is 0 by
default.
```
**32**   IBM zERT Network Analyzer Task Summary


```
SSH traffic to include Action
```
```
SSH traffic that uses one or
more specific key exchange
algorithms
```
```
a. Select the SSH key exchange algorithm.
b. Select the specific algorithms you want to use in the SSH KEY
EXCHANGE ALGORITHM filter.
```
```
Note:
```
- Selecting **All SSH protected traffic** automatically removes all the other SSH filters from the query.
- Selecting an SSH filter other than **All SSH protected traffic** automatically removes the **All SSH**
    **protected traffic** filter from the query.
- Select a value of _Unknown_ in a filter selection list if you want security sessions that reported an
    algorithm that is not recognized by IBM zERT Network Analyzer.
- Select a value of _None_ in a filter selection list if you want security sessions that did not use any
    algorithm for this filter.

### Report

```
References to the Report panel of IBM z/OS Encryption Readiness Technology (zERT) Network Analyzer.
In this topic, you can find references to help you work with the Report panel of IBM zERT Network
Analyzer.
```
#### Working with Report panel

```
The Report panel shows the results of a query that is made over z/OS Encryption Readiness Technology
(zERT) data. Use the Report panel to view or export the report.
The Report panel displays a tabular summary view of query results that are organized by endpoint role of
the local z/OS system: TCP Server, TCP Client, or Enterprise Extender (EE) peer.
```
**Viewing summaries**

- If viewing TCP Server traffic, then each row contains information about an endpoint running on the local
    z/OS Sysplex, System, and Stack that is acting as a server where clients are connecting inbound.
- If viewing TCP Client traffic, then each row contains information about the foreign server IP and foreign
    server port to which clients that run on the local z/OS Sysplex, System, and Stack are connecting
    outbound. The foreign server IP and server port typically reside on a remote system, but might also
    reside on the local z/OS system.
- If viewing EE Peer traffic, then each row contains information about an EE endpoint running on the local
    z/OS Sysplex, System, and Stack.
See Table 7 on page 37 in “Appendix A. Report panel information” on page 37 for description of
summary fields.

**Viewing client details**

```
To view details about TCP clients or foreign EE peers associated with the summary row, click on the
summary row and it expands to show the details.
```
- If viewing TCP Server traffic, then each row of the details report contains information about a single
    foreign client that connected inbound to the local TCP server (listening on the local z/OS TCP/IP stack)
    in the associated summary row. The foreign TCP client might be connecting from a remote system or
    from the local TCP/IP stack.
- If viewing TCP Client traffic, then each row of the details report contains information about a single
    local client (connected through the local z/OS TCP/IP stack) that connected outbound to the foreign TCP

```
IBM zERT Network Analyzer Task Summary   33
```

```
server in the associated summary row. The foreign TCP server might be listening on a remote system or
on the local TCP/IP stack.
```
- If viewing EE Peer traffic, then each row of the details report contains information about a single foreign
    EE peer that is communicating with the local EE endpoint (connected through the local z/OS TCP/IP
    stack) in the associated summary row.
See Table 7 on page 37 in “Appendix A. Report panel information” on page 37 for description of client
detail fields.

```
Viewing security session details
The Security Session Details view summarizes the cryptographic details about the security sessions that
are used by the application connections. To view the cryptographic details, select one or more clients, and
click View security session details. To return to Client Details view, click View client details.
There are two drop-down lists in Security Session Details view which allow you to choose the details
to view. The left drop-down lists the available cryptographic protocol options which are "Unprotected*
Session Details", "IPsec Session Details", "SSH Session Details", and "TLS Session Details". Each one of
these options breaks down further into more specific detail options which can be selected from the right
drop-down list. These more detailed options are "Cryptographic Details", "Peer Authentication Details",
"Certificate Details", "Distinguished Name Details", and "Traffic Details". Both drop down menus show
options that apply for the security sessions that are reported. See the following tree view of security
session detail options:
Unprotected* Session Details
Traffic Details
IPsec Session Details
Cryptographic Details
Peer Authentication Details
Certificate Details
Distinguished Name Details
Traffic Details
SSH Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
TLS Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
See Table 8 on page 44 in “Appendix A. Report panel information” on page 37 for description of
security session detail fields.
```
**Sorting a table by column**

```
To sort a table by column, click on the column header. This sorts the table, in ascending order, by the
values in the column. Click the column a second time to sort the table in descending order. When you sort
the table by column, the entire result set is sorted and the information is displayed based on the order of
the selected column.
Note: When sorting columns with IP addresses, the following rules apply:
```
- IP addresses are always sorted according to octet values.

**34**   IBM zERT Network Analyzer Task Summary


- If the column is sorted in ascending order, IPv4 addresses appear before IPv6 addresses.
- If the column is sorted in descending order, IPv6 addresses appear before IPv4 addresses.

**Navigating the table**

To identify which rows in the table are currently being displayed, you can use the **Displaying
records <current_range> out of <max_records>** field on the top right corner of the table, where
**<current_range>** indicates the range of records currently being displayed and **<max_records>** indicates
the total number of rows that exist in the table. The first 100 rows in the table are shown when the query
results are first displayed.

To identify the number of pages that comprise the full table being displayed, you can use the
**<current_page>/<last_page>** field, where **<current_page>** is the current page being displayed and
**<last_page>** is the total number of pages available to display.

To request that a different page of rows be displayed on the **Report** panel, you can use one of these
methods:

- To display the next page of rows in the table, click **Next Page**.
- To display the previous page of rows in the table, click **Previous Page**.
- To display a specific page of rows, either:
    - Specify a value in the **<current_page>** field, then hit **Enter**.
       **Restriction:** You must specify a value for **<current_page>** that is greater than or equal to 1, and less
       than or equal to **<last_page>**.
    - Use the up and down arrows in the **<current_page>** field to increment or decrement
       **<current_page>** to the desired value, then hit **Enter**.

**Customizing which report fields to view**

You can customize what is shown in each row of any table in any view (Summaries, Client Details, and
Security Session Details). To select which report fields to display, perform the following actions:

1. Click the **Configure Icon** on the top-right corner of a table to open its column options panel.
2. Click the check boxes or the field names next to check boxes to choose the columns to display.
3. Click the **Configure Icon** again to hide the column options panel.

**Closing the report**

To close an active report, click **Close Report.**. Click **Confirm** to close the report or **Cancel** to go back to
the report. Closing a report discards any data (summary, client detail, security session details) and frees
the database partition associated with it. If you need to save the data from the report before closing it,
you can use the export function to export the results to a comma separated value (CSV) format file. Once
you close a report, you are redirected to the **Manage Queries** panel.

**Note:** The DATABASE INFORMATION section in the **Database Settings** panel shows the maximum
number of open reports allowed. If the maximum is reached by viewing multiple reports (in different
browser sessions or by different users), the IBM zERT Network Analyzer is not able to run a new query in
another browser session until a database partition is made available by closing an active report.

**Report timeout value**

```
IBM zERT Network Analyzer Task Summary   35
```

```
The REPORT SETTINGS section in the Application Settings panel allows configuring a report timeout
value in minutes. If a report timeout value is configured to a valid value other than 0, a warning prompt is
displayed 15 minutes before the report timeout happens.
```
- If you have finished viewing the report, click **Close report**. Closing a report discards any data (summary,
    client detail, security session details) and frees the database partition associated with it.
- If you would like to continue viewing the report, click **Continue report**. The report timeout interval will
    be reset.
If no action is taken or if the browser session is closed, the IBM zERT Network Analyzer will automatically
close the report after the report timeout happens.

```
Exporting report information from IBM zERT Network Analyzer
IBM zERT Network Analyzer provides a detail report that contains a row for each security session that
applies to the report. Each row contains server and client level information for that security session.
To export the report information to a comma-separated values (CSV) format file, click Export to CSV.
You can provide additional information for the export operation in the Export to CSV panel. Enter the
requested information in the EXPORT PANEL section.
```
1. To specify the z/OS UNIX file system path name, type the path and name in the **Export Location** field.
    You must specify a path and name for the export file, or the export cannot be performed.
    **Note:**
    - The value for the **Export Location** field must be a z/OS UNIX path and name on the z/OS system
       where z/OSMF is running, and to which the logged-in user ID has permission to write.
    - If you enter the name of an existing file, select **Replace existing file located at the Export Location**
       under **Additional Options**. If you do not perform this step, the export operation fails with the
       message **"Message from server: File exists:** **_filename_** **"**.
2. To specify the delimiter to use to separate columns of information in the exported data, select one of
    the delimiter options:
    - To use a comma, select **Comma**.
    - To use a vertical bar, select **Pipe**.
    - To use a semicolon, select **Semicolon**.
    - To use a tab character, select **Tab**.
    - To specify some other character, select **Custom** and enter the delimiter character to be used.
    **Note:** The default delimiter setting is the value most recently saved from the **Applications Settings**
    panel.
3. To start the export operation, click **Export**. Otherwise, to exit the **Export to CSV** panel without starting
    the export operation, click **Close**.
The export operation output file contents are stored as ASCII characters. If you download the file to your
workstation, you need to transfer the file in binary mode.
See “Appendix B. Export operation output file results” on page 51 for description of the fields in the
export operation output file.

**Appendix**

- “Appendix A. Report panel information” on page 37 describes detailed panel information in **Report**
    panel.

**36**   IBM zERT Network Analyzer Task Summary


- “Appendix B. Export operation output file results” on page 51 describes export operation output file
    results in **Report** panel.

**Appendix A. Report panel information**

```
This appendix describes detailed panel information in Report panel.
Table 7 on page 37 shows the possible report fields for Summary and Client Details views in Report
panel.
```
_Table 7. Report fields for Summary and Client Details views_

**Field name Visibility Description**

Sysplex **TCP Server**

```
Summary
EE Peer
Summary
```
```
Name of the Sysplex from which the SMF data
originated.
```
Client Sysplex **TCP Client**

```
Summary
```
```
Name of the Sysplex from which the SMF data
originated. This is a sysplex that clients are
connecting outbound from.
```
System **TCP Server**

```
Summary
EE Peer
Summary
```
```
Name of the System from which the SMF data
originated.
```
Client System **TCP Client**

```
Summary
```
```
Name of the System from which the SMF data
originated. This is a system that clients are
connecting outbound from.
```
Stack **TCP Server**

```
Summary
EE Peer
Summary
```
```
Name of the TCP/IP stack from which the SMF
data originated.
```
Client Stack **TCP Client**

```
Summary
```
```
Name of the TCP/IP stack from which the SMF
data originated. This is a stack that clients are
connecting outbound from.
```
Server IP **TCP Server**

```
Summary
```
```
IP address of a server running on the local stack
(that is, the z/OS stack that is identified by the
Sysplex, System, and Stack attributes).
```
Foreign Server
IP

```
TCP Client
Summary
```
```
IP address of a foreign server (that is, a server that
is connected to by a client running on the local
stack). The foreign server might or might not be
running on the local stack - typically the foreign
server runs on a different stack.
```
Local EE Peer **EE Peer**

```
Summary
```
```
The IP address of the Enterprise Extender peer
running on the local z/OS system.
```
```
IBM zERT Network Analyzer Task Summary   37
```

```
Table 7. Report fields for Summary and Client Details views (continued)
```
```
Field name Visibility Description
```
```
Server Port TCP Server
Summary
```
```
Port number of the server running on the local
stack.
```
- In most cases, this field contains one value.
- If the row contains data for FTP passive data
    connections and the FTP server is configured
    with a value for PASSIVEDATAPORTS, this field
    contains the port range specification from the
    PASSIVEDATAPORTS statement in the FTPD
    configuration file.

```
Foreign Server
Port
```
```
TCP Client
Summary
```
```
Port number of the foreign server that the local
client is connected to.
```
- In most cases, this field contains a single port
    value.
- If the row contains data for FTP passive data
    connections, this field contains the value range
    1024-65535.

```
UDP Port EE
Summary
```
```
UDP port for the local EE Peer.
```
```
Client IP TCP Server
Client
TCP Client
Client
```
```
IP address of the TCP client.
```
```
Remote EE Peer EE Peer
Peer
```
```
IP address of the remote EE peer.
```
```
User ID TCP Server
Summary
TCP Client
Client
EE Peer
Summary
```
```
z/OS user ID that opened the local socket.
```
```
Job Name TCP Server
Summary
TCP Client
Client
EE Peer
Summary
```
```
Job name under which the local socket was
opened
```
**38**   IBM zERT Network Analyzer Task Summary


```
Table 7. Report fields for Summary and Client Details views (continued)
```
```
Field name Visibility Description
```
```
Unprotected*
Total
Connections
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Total number of connections that had no
recognized cryptographic protection.
```
```
IPSec Total
Connections
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Total number of connections that were protected
by IPsec.
```
SSH Total
Connections

```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Total number of connections that were protected
by SSH.
```
TLS Total
Connections

```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Total number of connections that were protected
by TLS/SSL.
```
Unprotected*
Partial
Connections

```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Total number of connections with no recognized
cryptographic coverage. These connections had no
recognized coverage for only part of their lifetime.
```
```
IBM zERT Network Analyzer Task Summary   39
```

```
Table 7. Report fields for Summary and Client Details views (continued)
```
```
Field name Visibility Description
```
```
IPsec Partial
Connections
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Total number of connections that were protected
by IPsec for only part of their lifetime.
```
```
SSH Partial
Connections
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Total number of connections that were protected
by SSH for only part of their lifetime.
```
```
TLS Partial
Connections
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Total number of connections that were protected
by TLS/SSL for only part of their lifetime.
```
```
Unprotected*
Bytes In
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Number of inbound bytes that had no recognized
cryptographic protection.
```
```
IPsec Bytes In TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Number of inbound bytes that were protected by
IPSec.
```
**40**   IBM zERT Network Analyzer Task Summary


```
Table 7. Report fields for Summary and Client Details views (continued)
```
```
Field name Visibility Description
```
```
SSH Bytes In TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound bytes that were protected by
SSH.
```
TLS Bytes In **TCP Server**

```
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound bytes that were protected by
TLS/SSL.
```
Unprotected*
Bytes Out

```
TCP Server
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Number of outbound bytes that had no recognized
cryptographic protection.
```
IPsec Bytes Out **TCP Server**

```
Summary
Client
TCP Client
Summary
Client
EE Peer
Summary
Peer
```
```
Number of outbound bytes that were protected by
IPsec.
```
SSH Bytes Out **TCP Server**

```
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound bytes that were protected by
SSH.
```
```
IBM zERT Network Analyzer Task Summary   41
```

```
Table 7. Report fields for Summary and Client Details views (continued)
```
```
Field name Visibility Description
```
```
TLS Bytes Out TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound bytes that were protected by
TLS/SSL.
```
```
Unprotected*
Segments In
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound TCP segments that had no
recognized cryptographic protection.
```
```
IPsec Segments
In
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound TCP segments that were
protected by IPsec.
```
```
SSH Segments
In
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound TCP segments that were
protected by SSH.
```
```
TLS Segments
In
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of inbound TCP segments that were
protected by TLS/SSL.
```
```
Unprotected*
Segments Out
```
```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound TCP segments that had no
recognized cryptographic protection.
```
**42**   IBM zERT Network Analyzer Task Summary


_Table 7. Report fields for Summary and Client Details views (continued)_

**Field name Visibility Description**

IPsec Segments
Out

```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound TCP segments that were
protected by IPsec.
```
SSH Segments
Out

```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound TCP segments that were
protected by SSH.
```
TLS Segments
Out

```
TCP Server
Summary
Client
TCP Client
Summary
Client
```
```
Number of outbound TCP segments that were
protected by TLS/SSL.
```
Unprotected*
Datagrams In

```
EE Peer
Summary
Peer
```
```
Number of inbound UDP datagrams that had no
recognized cryptographic protection.
```
IPsec
Datagrams In

```
EE Peer
Summary
Peer
```
```
Number of inbound UDP datagrams that were
protected by IPsec.
```
Unprotected*
Datagrams Out

```
EE Peer
Summary
Peer
```
```
Number of outbound UDP datagrams that had no
recognized cryptographic protection.
```
IPsec
Datagrams Out

```
EE Peer
Summary
Peer
```
```
Number of outbound UDP datagrams that were
protected by IPsec.
```
```
Table 8 on page 44 shows the possible report fields for Security Session Details views in Report panel.
```
```
IBM zERT Network Analyzer Task Summary   43
```

```
Table 8. Report fields for Security Session Details views
```
```
Field name Visibility Description
```
```
Session ID Unprotected* Session Details
Traffic Details
IPsec Session Details
Cryptographic Details
Peer Authentication Details
Certificate Details
Distinguished Name Details
Traffic Details
SSH Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
TLS Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
```
```
A string that uniquely identifies a security session.
This value is generated by the TCP/IP stack and is
unique within the scope of that stack.
```
```
Client IP Unprotected* Session Details
Traffic Details
IPsec Session Details
Cryptographic Details
Peer Authentication Details
Certificate Details
Distinguished Name Details
Traffic Details
SSH Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
TLS Session Details
Cryptographic Details
Certificate Details
Distinguished Name Details
Traffic Details
```
```
IP address of the TCP client.
```
**44**   IBM zERT Network Analyzer Task Summary


_Table 8. Report fields for Security Session Details views (continued)_

**Field name Visibility Description**

Remote EE Peer **Unprotected* Session Details**

```
Traffic Details
IPsec Session Details
Cryptographic Details
Peer Authentication Details
Certificate Details
Distinguished Name Details
Traffic Details
```
```
IP address of the remote EE Peer.
```
Total
Connections

```
Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Total number of connections
```
Partial
Connections

```
Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Total number of connections that were protected
by this cryptographic protocol for only part of their
lifetime.
```
Bytes In **Unprotected* Session Details**

```
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Number of inbound bytes protected by the
specified cryptographic protocol.
```
Bytes Out **Unprotected* Session Details**

```
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Number of outbound bytes protected by the
specified cryptographic protocol.
```
```
IBM zERT Network Analyzer Task Summary   45
```

```
Table 8. Report fields for Security Session Details views (continued)
```
```
Field name Visibility Description
```
```
Segments In Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Number of inbound TCP segments protected by
the specified cryptographic protocol.
```
```
Segments Out Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
SSH Session Details
Traffic Details
TLS Session Details
Traffic Details
```
```
Number of inbound TCP segments protected by
the specified cryptographic protocol.
```
```
Datagrams In Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
```
```
Number of inbound TCP segments protected by
the specified cryptographic protocol.
```
```
Datagrams Out Unprotected* Session Details
Traffic Details
IPsec Session Details
Traffic Details
```
```
Number of inbound TCP segments protected by
the specified cryptographic protocol.
```
```
Symmetric
Encryption
Algorithm
```
```
IPsec Session Details
Cryptographic Details
TLS Session Details
Cryptographic Details
```
```
The algorithm used to encrypt/decrypt inbound
and outbound application connection data.
```
```
Message
Authentication
Algorithm
```
```
IPsec Session Details
Cryptographic Details
TLS Session Details
Cryptographic Details
```
```
The message authentication algorithm (MAC) used
to authenticate inbound and outbound application
connection data.
```
```
IPSec Protocol IPsec Session Details
Cryptographic Details
```
```
The IPsec protocol used to authenticate
application connection data.
```
```
Encapsulation
Mode
```
```
IPsec Session Details
Cryptographic Details
```
```
The mode used to encapsulate (i.e. construct)
application connection data into IPsec packets.
```
```
PFS Group IPsec Session Details
Cryptographic Details
```
```
The Diffie-Hellman group used to achieve perfect
forward secrecy during a dynamic key exchange to
derive keys to protect application connection data.
```
**46**   IBM zERT Network Analyzer Task Summary


_Table 8. Report fields for Security Session Details views (continued)_

**Field name Visibility Description**

Protocol Version **SSH Session Details**

```
Cryptographic Details
TLS Session Details
Cryptographic Details
```
```
The version of the security protocol used to
protect application connection data.
```
Key Exchange
Algorithm

```
SSH Session Details
Cryptographic Details
TLS Session Details
Cryptographic Details
```
```
The algorithm used to generate the keys used for
protecting application connection data.
```
Symmetric
Encryption
Algorithm In

```
SSH Session Details
Cryptographic Details
```
```
The algorithm used to decrypt inbound application
connection data.
```
Symmetric
Encryption
Algorithm Out

```
SSH Session Details
Cryptographic Details
```
```
The algorithm used to encrypt outbound
application connection data.
```
Message
Authentication
Algorithm In

```
SSH Session Details
Cryptographic Details
```
```
The message authentication algorithm (MAC) used
to authenticate inbound application connection
data.
```
Message
Authentication
Algorithm Out

```
SSH Session Details
Cryptographic Details
```
```
The message authentication algorithm (MAC) used
to authenticate outbound application connection
data.
```
Authentication
Method

```
SSH Session Details
Cryptographic Details
```
```
The first authentication method used to
authenticate the client of an application data
connection.
```
Authentication
Method 2

```
SSH Session Details
Cryptographic Details
```
```
The last of multiple authentication methods
used to authenticate the client of an application
data connection. Only meaningful when multiple
authentication methods were used.
```
Server Key
Length

```
SSH Session Details
Cryptographic Details
```
```
The length of the key used to authenticate the
server associated with an application connection.
```
Server Key Type **SSH Session Details**

```
Cryptographic Details
```
```
The type of the key used to authenticate the server
associated with an application connection.
```
Client Key
Length

```
SSH Session Details
Cryptographic Details
```
```
The length of the key used to authenticate the
client associated with an application connection.
```
Client Key Type **SSH Session Details**

```
Cryptographic Details
```
```
The type of the key used to authenticate the client
associated with an application connection.
```
ETM In **SSH Session Details**

```
Cryptographic Details
```
```
Indicates whether Encrypt-Then-MAC order was
used for inbound data. If so, then the inbound
data was encrypted before applying the message
authentication algorithm.
```
ETM Out **SSH Session Details**

```
Cryptographic Details
```
```
Indicates whether Encrypt-Then-MAC order was
used for outbound data. If so, then the outbound
data was encrypted before applying the message
authentication algorithm.
```
```
IBM zERT Network Analyzer Task Summary   47
```

```
Table 8. Report fields for Security Session Details views (continued)
```
```
Field name Visibility Description
```
```
Source SSH Session Details
Cryptographic Details
TLS Session Details
Cryptographic Details
```
```
The source of the information contained in the
security session (i.e. stream observation or a
cryptographic protocol provider).
```
```
Negotiated
Cipher
```
```
TLS Session Details
Cryptographic Details
```
```
Identifies the TLS/SSL cipher suite that was
negotiated for a TLS/SSL security session. If the
TLS version is SSLv3 or higher, this is a four
character value. For a complete list of the four-
character values, see details at the TLS Cipher
Suite registry. If the TLS version is SSLv2, this is
a six-character value. For more details, see SSLv2
specification.
```
```
ETM TLS Session Details
Cryptographic Details
```
```
Indicates whether Encrypt-Then-MAC order was
used. If so, then the data was encrypted before
applying the message authentication algorithm.
```
```
Negotiated Key
Share
```
```
TLS Session Details
Cryptographic Details
```
```
The negotiated key share used to facilitate the
encryption of TLSv1.3 handshake messages. If the
TLS version is 1.2 or lower, this field is shown as
"N/A".
```
```
Server
Handshake
Signature
Method
```
```
TLS Session Details
Cryptographic Details
```
```
The signature method used by the server to
sign the TLSv1.3 handshake message. If the TLS
version is 1.2 or lower, this field is shown as "N/A".
```
```
Client
Handshake
Signature
Method
```
```
TLS Session Details
Cryptographic Details
```
```
The signature method used by the server to
sign the TLSv1.3 handshake message. If the TLS
version is 1.2 or lower, this field is shown as "N/A".
```
```
Raw Public Key
Authentication
```
```
TLS Session Details
Cryptographic Details
```
```
If the TLS version is TLSv1.3 or higher, this value
indicates whether raw public key authentication
was used. If the TLS version is 1.2 or lower, this
field is shown as "N/A".
```
```
Pre-shared Key
Authentication
```
```
TLS Session Details
Cryptographic Details
```
```
If the TLS version is TLSv1.3 or higher, this value
indicates whether pre-shared key authentication
was used. If the TLS version is 1.2 or lower, this
field is shown as "N/A".
```
```
IKE Tunnel
Authentication
Algorithm
```
```
IPsec Session Details
Peer Authentication Details
```
```
The message authentication algorithm (MAC) used
to authenticate messages sent in an Internet Key
Exchange (IKE) key exchange.
```
```
IKE Tunnel
Encryption
Algorithm
```
```
IPsec Session Details
Peer Authentication Details
```
```
The algorithm used to encrypt/decrypt messages
sent in an IKE key exchange.
```
```
IKE Local
Authentication
Algorithm
```
```
IPsec Session Details
Peer Authentication Details
```
```
The authentication method used to authenticate
the local security endpoint of an IKE key exchange.
```
```
IKE Remote
Authentication
Algorithm
```
```
IPsec Session Details
Peer Authentication Details
```
```
The authentication method used to authenticate
the remote security endpoint of an IKE key
exchange.
```
**48**   IBM zERT Network Analyzer Task Summary


```
Table 8. Report fields for Security Session Details views (continued)
```
```
Field name Visibility Description
```
```
IKE Diffie
Hellman Group
```
```
IPsec Session Details
Peer Authentication Details
```
```
The Diffie-Hellman group used when generating
keying material used during IKE key exchanges.
```
```
IKE Pseudo
Random
Function
```
```
IPsec Session Details
Peer Authentication Details
```
```
The pseudo random function used when
generating keying material used during IKE key
exchanges.
```
```
IKE Local IP IPsec Session Details
Peer Authentication Details
```
```
The IP address of the local security endpoint
associated with IKE key exchanges.
```
```
IKE Remote IP IPsec Session Details
Peer Authentication Details
```
```
The IP address of the remote security endpoint
associated with IKE key exchanges.
```
```
IKE Version IPsec Session Details
Peer Authentication Details
```
```
The version of the IKE protocol used in dynamic
key exchanges.
```
Local Certificate
Signature
Method

```
IPsec Session Details
Certificate Details
```
```
The signature method used to sign the local
security endpoint's certificate.
```
Local Certificate
Asymmetric
Encryption
Algorithm

```
IPsec Session Details
Certificate Details
```
```
The asymmetric encryption algorithm used by the
signature method of the local security endpoint's
certificate.
```
Local Certificate
Digest
Algorithm

```
IPsec Session Details
Certificate Details
```
```
The authentication algorithm used by the
signature method of the local security endpoint's
certificate.
```
Local Certificate
Key Length

```
IPsec Session Details
Certificate Details
```
```
The length of the asymmetric key associated with
the local security endpoint's certificate.
```
```
Local Certificate
Key Type
```
```
IPsec Session Details
Certificate Details
```
```
The type of asymmetric key associated with the
local security endpoint's certificate.
```
```
Remote
Certificate
Signature
Method
```
```
IPsec Session Details
Certificate Details
```
```
The signature method used to sign the remote
security endpoint's certificate.
```
```
Remote
Certificate
Asymmetric
Encryption
Algorithm
```
```
IPsec Session Details
Certificate Details
```
```
The asymmetric encryption algorithm used by
the signature method of the remote security
endpoint's certificate.
```
```
Remote
Certificate
Digest
Algorithm
```
```
IPsec Session Details
Certificate Details
```
```
The authentication algorithm used by the
signature method of the remote security
endpoint's certificate.
```
```
Remote
Certificate Key
Length
```
```
IPsec Session Details
Certificate Details
```
```
The length of the asymmetric key associated with
the remote security endpoint's certificate.
```
```
Remote
Certificate Key
Type
```
```
IPsec Session Details
Certificate Details
```
```
The type of asymmetric key associated with the
remote security endpoint's certificate.
```
```
IBM zERT Network Analyzer Task Summary   49
```

```
Table 8. Report fields for Security Session Details views (continued)
```
```
Field name Visibility Description
```
```
Server
Certificate
Signature
Method
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The signature method used to sign the server's
certificate.
```
```
Server
Certificate
Asymmetric
Encryption
Algorithm
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The asymmetric encryption algorithm used by the
signature method of the server's certificate.
```
```
Server
Certificate
Digest
Algorithm
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The authentication algorithm used by the
signature method of the server's certificate.
```
```
Server
Certificate Key
Length
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The length of the asymmetric key associated with
the server's certificate.
```
```
Server
Certificate Key
Type
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The type of asymmetric key associated with the
server's certificate.
```
```
Client
Certificate
Signature
Method
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The signature method used to sign the client's
certificate.
```
```
Client
Certificate
Asymmetric
Encryption
Algorithm
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The asymmetric encryption algorithm used by the
signature method of the client's certificate.
```
```
Client
Certificate
Digest
Algorithm
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The authentication algorithm used by the
signature method of the client's certificate.
```
```
Client
Certificate Key
Length
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The length of the asymmetric key associated with
the client's certificate.
```
```
Client
Certificate Key
Type
```
```
SSH Session Details
Certificate Details
TLS Session Details
Certificate Details
```
```
The type of asymmetric key associated with the
client's certificate.
```
**50**   IBM zERT Network Analyzer Task Summary


_Table 8. Report fields for Security Session Details views (continued)_

**Field name Visibility Description**

Server
Certificate
Issuer
Distinguished
Name

```
SSH Session Details
Distinguished Name Details
TLS Session Details
Distinguished Name Details
```
```
The distinguished name of the issuer that issued
the server's certificate.
```
Server
Certificate
Subject
Distinguished
Name

```
SSH Session Details
Distinguished Name Details
TLS Session Details
Distinguished Name Details
```
```
The distinguished name of the subject associated
with the server's certificate.
```
Client
Certificate
Issuer
Distinguished
Name

```
SSH Session Details
Distinguished Name Details
TLS Session Details
Distinguished Name Details
```
```
The distinguished name of the issuer associated
with the client's certificate.
```
Client
Certificate
Subject
Distinguished
Name

```
SSH Session Details
Distinguished Name Details
TLS Session Details
Distinguished Name Details
```
```
The distinguished name of the subject that issued
the client's certificate.
```
Local Certificate
Issuer
Distinguished
Name

```
IPsec Session Details
Distinguished Name Details
```
```
The distinguished name of the issuer that issued
the local security endpoint's certificate.
```
Local Certificate
Subject
Distinguished
Name

```
IPsec Session Details
Distinguished Name Details
```
```
The distinguished name of the subject associated
with the local security endpoint's certificate.
```
Remote
Certificate
Issuer
Distinguished
Name

```
IPsec Session Details
Distinguished Name Details
```
```
The distinguished name of the issuer that issued
the remote security endpoint's certificate.
```
Remote
Certificate
Subject
Distinguished
Name

```
IPsec Session Details
Distinguished Name Details
```
```
The distinguished name of the subject associated
with the remote security endpoint's certificate.
```
**Appendix B. Export operation output file results**

```
This appendix describes export operation output file results in Report panel.
The format of the export operation output file is a series of rows of delimiter separated values, where:
```
- The first row contains the column headings ( **Column Name** ) for the delimited information.
- Each remaining row represents information about a specific security session in the IBM zERT Network
    Analyzer database. There is one row for every security session in the database.
By default, the values are separated by a comma delimiter, but you can specify a different delimiter value
when you submit the export operation.

```
IBM zERT Network Analyzer Task Summary   51
```

```
Each column represents a unique field in the IBM zERT Network Analyzer database representation of a
security session. Each row reports the same number of columns, and columns that represent fields that
have no value for the security session are represented with a blank character. For instance, columns
representing TLS/SSL or SSH fields have no meaning for security sessions that use IPSec security
coverage, so the columns representing those fields contain blanks in a row for an IPSec security session.
The columns are described in four different tables:
```
- Table 9 on page 52 describes the common fields that apply to all security sessions.
- Table 10 on page 54 describes the fields that apply only when the security session protocol is IPSec.
- Table 11 on page 56 describes the fields that apply only when the security session protocol is TLS/SSL.
- Table 12 on page 59 describes the fields that apply only when the security session protocol is SSH.
**Note:** All references to SMF 119 field names in Appendix B refer to information provided in the zERT
Summary record (subtype 12) section of _z/OS Communications Server: IP Programmer's Guide and
Reference_.
Table 9 on page 52 shows the fields that apply to all security sessions.

```
Table 9. Common fields for an export operation
```
```
Column Name Description of contents
```
```
SECSESS_SYSPLEX Name of the sysplex from which the security association originated.
```
```
SECSESS_SYSTEM Name of the system from which the security association originated.
```
```
SECSESS_STACK Name of the stack from which the security association originated.
```
```
SECSESS_SESSIONID A string that uniquely identifies the security session. This value is generated
by the TCP/IP stack when the SMF 12 record is created and it is unique
within the scope of that stack.
```
```
SECSESS_LOCALROLE The role of the endpoint that caused the generation of the SMF 119 subtype
12 records for this security association.
```
- 1 - TCP server
- 2 - TCP client
- 3 - Enterprise Extender (EE) peer

```
SECSESS_TRANSPROT The IP protocol value of the traffic using the security session.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SAIPProto field.
```
```
SECSESS_SECPROT An indication of the security protocol used by the security session.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SASecProtos field.
```
```
SECSESS_SRVIP • When SECSESS_LOCALROLE indicates "server" this column contains the IP
address of a server connected to the local stack.
```
- When SECSESS_LOCALROLE indicates "client" this column contains the
    IP address of a foreign server (i.e. a server that is connected to a client
    running on the local stack).
    **Guideline:** The foreign server might or might not be running on the local
    stack. Typically the foreign server runs on a different stack or TCP/IP node.
- When SECSESS_LOCALROLE indicates "EE peer" this column contains the
    IP address of the Enterprise Extender endpoint connected to the local
    stack.

**52**   IBM zERT Network Analyzer Task Summary


```
Table 9. Common fields for an export operation (continued)
```
```
Column Name Description of contents
```
SECSESS_SRVPORTSTART • When SECSESS_LOCALROLE indicates "server" this column contains the

```
port number of the server running on the local stack.
If the row contains data for FTP passive data connections and the
FTP server is configured with a value for PASSIVEDATAPORTS, this
column contains the low port specification from the PASSIVEDATAPORTS
statement in the FTPD configuration file.
```
- When SECSESS_LOCALROLE indicates "client" this column contains the
    port number of the foreign server that the local client is connected to.
    If the row contains data for FTP passive data connections, this column
    contains the value 1024.
- When SECSESS_LOCALROLE indicates "EE peer" this column contains the
    UDP port a local Enterprise Extender endpoint.

```
SECSESS_SRVPORTEND • When SECSESS_LOCALROLE indicates "server" this column usually
contains the same value as SECSESS_SRVPORTSTART.
If the row contains data for FTP passive data connections and the
FTP server is configured with a value for PASSIVEDATAPORTS, then this
column contains the high port specification from the PASSIVEDATAPORTS
statement in the FTPD configuration file.
```
- When SECSESS_LOCALROLE indicates "client" this column usually contains
    the same value as SECSESS_SRVPORTSTART.
    If the row contains data for FTP passive data connections, then this
    column contains the value 65535.
- When SECSESS_LOCALROLE indicates "EE peer" this column contains the
    same value as SECSESS_SRVPORTSTART.

```
SECSESS_SRVJOBNAME Job name under which local sockets using the security session were opened.
```
```
SECSESS_SRVUSERID z/OS user ID that opened local sockets using the security session.
```
```
SECSESS_CLNTIP • When SECSESS_LOCALROLE indicates "server" this column contains the IP
address of foreign clients using the security session (i.e. clients that are
connected to a server connected to the local stack).
Guideline: The foreign client might or might not connect from the local
stack. Typically the foreign client connects from a different stack or TCP/IP
node.
```
- When SECSESS_LOCALROLE indicates "client" this column contains the IP
    address of a client connected to the local stack.
- When SECSESS_LOCALROLE indicates "EE peer" this column contains the
    IP address of an Enterprise Extender endpoint connected to a foreign local
    stack.

```
SECSESS_TOTAL_CONNECTION
S
```
```
Total number of connections that used the security session.
```
##### SECSESS_PARTIAL_CONNECTI

##### ONS

```
Total number of connections that were used by the security session for only
part of their lifetime.
```
```
SECSESS_BYTES_IN Number of inbound bytes that used the security session.
```
```
SECSESS_BYTES_OUT Number of outbound bytes that used the security session.
```
```
IBM zERT Network Analyzer Task Summary   53
```

```
Table 9. Common fields for an export operation (continued)
```
```
Column Name Description of contents
```
```
SECSESS_SEGMENTS_IN Number of inbound TCP or EE/UDP segments that used the security session.
```
```
SECSESS_SEGMENTS_OUT Number of outbound TCP or EE/UDP segments that used the security
session.
```
```
Table 10 on page 54 shows the fields that are applicable when the security session protocol is IPSec
(SECSESS_SECPROT indicates "IPSEC"). These fields are blank for any other security session protocol
value.
```
```
Table 10. IPSec specific fields reported in an export operation
```
```
Column Name Description of contents
```
```
IPSEC_SYMMENCALG The symmetric encryption algorithm used by IPsec to encrypt/decrypt
inbound and outbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunEncAlg field.
```
```
IPSEC_MSGAUTHALG The message authentication algorithm (MAC) used by IPsec to authenticate
inbound and outbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunAuthAlg field.
```
```
IPSEC_PFSGROUP The Diffie-Hellman group used by IPsec to achieve perfect forward secrecy
during a dynamic key exchange to derive keys to protect application
connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_PFSGroup field.
```
```
IPSEC_ENCAPMODE The mode used to encapsulate application connection data into IPsec
packets.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_EncapMode field.
```
```
IPSEC_AUTHPROT The IPsec protocol used to authenticate application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_AuthProto field.
```
```
IPSEC_IKEMAJVER The major version of the IKE protocol used in dynamic key exchanges.
```
```
IPSEC_IKEMINVER The minor version of the IKE protocol used in dynamic key exchanges.
```
```
IPSEC_IKELCLIP The IP address of the local security endpoint associated with IKE key
exchanges.
```
```
IPSEC_IKERMTIP The IP address of the remote security endpoint associated with IKE key
exchanges.
```
```
IPSEC_IKELCLAUTHMETH The authentication method used to authenticate the local security endpoint
of an IKE key exchange.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunLclAuthMeth field.
```
**54**   IBM zERT Network Analyzer Task Summary


```
Table 10. IPSec specific fields reported in an export operation (continued)
```
```
Column Name Description of contents
```
IPSEC_IKERMTAUTHMETH The authentication method used to authenticate the remote security
endpoint of an IKE key exchange.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_IPSec_IKETunRmtAuthMeth** field.

```
IPSEC_IKETUNAUTHALG The message authentication algorithm used to authenticate messages sent
in an IKE key exchange.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunAuthAlg field.
```
```
IPSEC_IKETUNENCALG The symmetric encryption algorithm used to encrypt/decrypt messages sent
in an IKE key exchange.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunEncAlg field.
```
```
IPSEC_IKEDHGROUP The Diffie-Hellman group used when generating keying material during IKE
key exchanges.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunDHGroup field.
```
```
IPSEC_IKEPSEUDORANDFUNC The pseudo random function used when generating keying material during
IKE key exchanges.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_IKETunPseudoRandFunc field.
```
```
IPSEC_LCLCERTSIGMETH The signature method used to sign the local IPsec security endpoint's
certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_LclCert_Sign_Meth field.
```
```
IPSEC_LCLCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
local IPsec security endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_LclCert_Enc_Meth field.
```
```
IPSEC_LCLCERTDIGESTALG The digest algorithm used by the signature method of the local IPsec
security endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_LclCert_Digest_Alg field.
```
```
IPSEC_LCLCERTKEYTYPE The type of asymmetric key associated with the local IPsec security
endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_LclCert_Key_Type field.
```
```
IPSEC_LCLCERTKEYLEN The length, in bits, of the asymmetric key associated with the local IPsec
security endpoint's certificate.
```
```
IPSEC_LCLCERTSUBJDN The distinguished name of the subject associated with the local IPsec
security endpoint's certificate.
```
```
IBM zERT Network Analyzer Task Summary   55
```

```
Table 10. IPSec specific fields reported in an export operation (continued)
```
```
Column Name Description of contents
```
```
IPSEC_LCLCERTISSDN The distinguished name of the issuer that issued the local IPsec security
endpoint's certificate.
```
```
IPSEC_RMTCERTSIGMETH The signature method used to sign the remote IPsec security endpoint's
certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_RmtCert_Sign_Meth field.
```
```
IPSEC_RMTCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
remote IPsec security endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_RmtCert_Enc_Meth field.
```
```
IPSEC_RMTCERTDIGESTALG The digest algorithm used by the signature method of the remote IPsec
security endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_RmtCert_Digest_Alg field.
```
```
IPSEC_RMTCERTKEYTYPE The type of asymmetric key associated with the remote IPsec security
endpoint's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_IPSec_RmtCert_Key_Type field.
```
```
IPSEC_RMTCERTKEYLEN The length, in bits, of the asymmetric key associated with the remote IPsec
security endpoint's certificate.
```
```
IPSEC_RMTCERTSUBJDN The distinguished name of the subject associated with the remote IPsec
security endpoint's certificate.
```
```
IPSEC_RMTCERTISSDN The distinguished name of the issuer that issued the remote IPsec security
endpoint's certificate.
```
```
Table 11 on page 56 shows the fields that are applicable when the security session protocol is TLS/SSL
(SECSESS_SECPROT indicates "TLS/SSL"). These fields are blank for any other security session protocol
value.
```
```
Table 11. TLS/SSL specific fields reported in an export operation
```
```
Column Name Description of contents
```
```
TLS_SYMMENCALG The symmetric encryption algorithm used by TLS to encrypt/decrypt inbound
and outbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CS_Enc_Alg field.
```
```
TLS_MSGAUTHALG The message authentication algorithm (MAC) used by TLS to authenticate
inbound and outbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CS_Msg_Auth field.
```
**56**   IBM zERT Network Analyzer Task Summary


_Table 11. TLS/SSL specific fields reported in an export operation (continued)_

**Column Name Description of contents**

TLS_KEXALG The algorithm used to generate the TLS keys used for protecting application
connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_TLS_CS_Kex_Alg** field.

TLS_ETM Indicates whether Encrypt-Then-MAC order was used by TLS. If so, then the
data was encrypted before applying the message authentication algorithm.

- A value of 1 indicates that Encrypt-Then-MAC order was used.
- A value of 0 indicates that MAC-Then-Encrypt order was used.

TLS_SOURCE The source of the information contained in the security session. The source
can be either stream observation or a cryptographic protocol provider.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_TLS_Source** field.

TLS_PROTVER The version of the TLS or SSL security protocol used to protect application
connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_TLS_Prot_Ver** field.

TLS_NEGCIPHER Identifies the TLS/SSL cipher suite that was negotiated for a TLS/SSL
security session.

- If **TLS_PROTVER** is SSLv3 or higher, this is a four character value. For a
    complete list of the four-character values, see details at the TLS Cipher
    Suite registry.
- If **TLS_PROTVER** is SSLv2, this is a six-character value. For more details,
    see SSLv2 specification.

TLS_SRVCERTSIGMETH The signature method used to sign the TLS server's certificate.

```
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_SCert_Signature_Method field.
```
TLS_SRVCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
TLS server's certificate.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_TLS_SCert_Enc_Method** field.

TLS_SRVCERTDIGESTALG The authentication algorithm used by the signature method of the TLS
server's certificate.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_TLS_SCert_Digest_Alg** field.

TLS_SRVCERTKEYTYPE The type of asymmetric key associated with the TLS server's certificate.

```
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_SCert_Key_Type field.
```
TLS_SRVCERTKEYLEN The length, in bits, of the asymmetric key associated with the TLS server's
certificate.

TLS_SRVCERTSUBJDN The distinguished name of the subject associated with the TLS server's
certificate.

```
IBM zERT Network Analyzer Task Summary   57
```

```
Table 11. TLS/SSL specific fields reported in an export operation (continued)
```
```
Column Name Description of contents
```
```
TLS_SRVCERTISSDN The distinguished name of the issuer that issued the TLS server's certificate.
```
```
TLS_CLNTCERTSIGMETH The signature method used to sign the TLS client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CCert_Signature_Method field.
```
```
TLS_CLNTCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
TLS client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CCert_Enc_Method field.
```
```
TLS_CLNTCERTDIGESTALG The authentication algorithm used by the signature method of the TLS
client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CCert_Digest_Alg field.
```
```
TLS_CLNTCERTKEYTYPE The type of asymmetric key associated with the TLS client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_CCert_Key_Type field.
```
```
TLS_CLNTCERTKEYLEN The length, in bits, of the asymmetric key associated with the TLS client's
certificate.
```
```
TLS_CLNTCERTSUBJDN The distinguished name of the subject that issued the TLS client's certificate.
```
```
TLS_CLNTCERTISSDN The distinguished name of the issuer associated with the TLS client's
certificate.
```
```
TLS_NEGKEYSHARE The negotiated key share used to facilitate the encryption of TLSv1.3
handshake messages.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_TLS_Neg_Key_Share field.
```
```
TLS_SRVHSSIGMETH The signature method used for the server certificate used for a TLSv1.3
handshake.
See zERT Summary record (subtype 12) for possible values of the
SMF119SC_TLS_SCert_Signature_Method field.
```
```
TLS_CLNTHSSIGMETH The signature method used for the client certificate used for a TLSv1.3
handshake.
See zERT Summary record (subtype 12) for possible values of the
SMF119SC_TLS_SCert_Signature_Method field.
```
```
TLS_RAWPUBLICKEYAUTH Indicates whether raw public key authentication was used by TLS.
```
- A value of 1 indicates that raw public key authentication is used.
- A value of 0 indicates that raw public key authentication was not used.

```
TLS_PRESHAREDKEYAUTH Indicates whether pre-shared key authentication was used by TLS.
```
- A value of 1 indicates that pre-shared key authentication is used.
- A value of 0 indicates that pre-shared key authentication was not used.

**58**   IBM zERT Network Analyzer Task Summary


```
Table 12 on page 59 shows the fields that are applicable when the security session protocol is SSH
(SECSESS_SECPROT indicates "SSH"). These fields are blank for any other security session protocol value.
```
_Table 12. SSH specific fields reported in an export operation_

**Column Name Description of contents**

SSH_SYMMENCALGIN The symmetric encryption algorithm used by SSH to decrypt inbound

```
application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_In_Enc_Alg field.
```
SSH_SYMMENCALGOUT The symmetric encryption algorithm used by SSH to encrypt outbound

```
application connection data.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_Out_Enc_Alg field.
```
SSH_MSGAUTHALGIN The message authentication algorithm (MAC) used by SSH to authenticate
inbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_SSH_In_Msg_Auth** field.

SSH_MSGAUTHALGOUT The message authentication algorithm used by SSH to authenticate
outbound application connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_SSH_Out_Msg_Auth** field.

SSH_ETMIN Indicates whether Encrypt-Then-MAC order was used by SSH for inbound
data. If so, then the inbound data was encrypted before applying the
message authentication algorithm.

- A value of 1 indicates that Encrypt-Then-MAC order was used.
- A value of 0 indicates that MAC-Then-Encrypt order was used.

SSH_ETMOUT Indicates whether Encrypt-Then-MAC order was used by SSH for outbound
data. If so, then the outbound data was encrypted before applying the
message authentication algorithm.

- A value of 1 indicates that Encrypt-Then-MAC order was used.
- A value of 0 indicates that MAC-Then-Encrypt order was used.

SSH_SOURCE The source of the information contained in the security session.

```
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_Source field.
```
SSH_PROTVER The version of the SSH security protocol used to protect application
connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_SSH_Prot_Ver** field.

SSH_KEXALG The algorithm used by SSH to generate the keys used for protecting
application connection data.
See zERT Summary record (subtype 12) for possible values of the
**SMF119SS_SSH_Kex_Method** field.

```
IBM zERT Network Analyzer Task Summary   59
```

```
Table 12. SSH specific fields reported in an export operation (continued)
```
```
Column Name Description of contents
```
```
SSH_AUTHMETH The first authentication method used to authenticate the SSH client of an
application data connection.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_Auth_Method field.
```
```
SSH_AUTHMETH2 The last of multiple authentication methods used to authenticate the SSH
client of an application data connection.
Note: This field is only meaningful when multiple authentication methods
were used.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_Auth_Method2 field.
```
```
SSH_SRVKEYTYPE The type of the key used to authenticate the SSH server associated with an
application connection.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_SKey_Type field.
```
```
SSH_SRVKEYLEN The length of the key, in bits, used to authenticate the SSH server associated
with an application connection.
```
```
SSH_CLNTKEYTYPE The type of the key used to authenticate the SSH client associated with an
application connection.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_CKey_Type field.
```
```
SSH_CLNTKEYLEN The length of the key, in bits, used to authenticate the SSH client associated
with an application connection.
```
```
SSH_SRVCERTSIGMETH The signature method used to sign the SSH server's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_SCert_Signature_Method field.
```
```
SSH_SRVCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
SSH server's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_SCert_Enc_Method field.
```
```
SSH_SRVCERTDIGESTALG The digest algorithm used by the signature method of the SSH server's
certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_SCert_Digest_Alg field.
```
```
SSH_SRVCERTKEYTYPE The type of asymmetric key associated with the SSH server's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_SCert_Key_Type field.
```
```
SSH_SRVCERTKEYLEN The length, in bits, of the asymmetric key associated with the SSH server's
certificate.
```
```
SSH_SRVCERTSUBJDN The distinguished name of the subject associated with the SSH server's
certificate.
```
**60**   IBM zERT Network Analyzer Task Summary


```
Table 12. SSH specific fields reported in an export operation (continued)
```
```
Column Name Description of contents
```
```
SSH_SRVCERTISSDN The distinguished name of the issuer that issued the SSH server's certificate.
```
```
SSH_CLNTCERTSIGMETH The signature method used to sign the SSH client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_CCert_Signature_Method field.
```
```
SSH_CLNTCERTASYMENCALG The asymmetric encryption algorithm used by the signature method of the
SSH client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_CCert_Enc_Method field.
```
```
SSH_CLNTCERTDIGESTALG The digest algorithm used by the signature method of the SSH client's
certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_CCert_Digest_Alg field.
```
```
SSH_CLNTCERTKEYTYPE The type of asymmetric key associated with the SSH client's certificate.
See zERT Summary record (subtype 12) for possible values of the
SMF119SS_SSH_CCert_Key_Type field.
```
```
SSH_CLNTCERTKEYLEN The length, in bits, of the asymmetric key associated with the SSH client's
certificate.
```
```
SSH_CLNTCERTSUBJDN The distinguished name of the subject that issued the SSH client's
certificate.
```
```
SSH_CLNTCERTISSDN The distinguished name of the issuer associated with the SSH client's
certificate.
```
### Settings

```
References to the Settings panel of IBM z/OS Encryption Readiness Technology (zERT) Network Analyzer.
In this topic, you can find references to help you work with the Settings panel of IBM zERT Network
Analyzer.
```
#### Configuring application settings

```
You can use the Application Settings panel to configure the following settings that are used by IBM zERT
Network Analyzer.
```
- Log settings
    - Logging information levels for IBM zERT Network Analyzer messages.
- Report settings
    - Maximum number limit of open reports allowed for each user.
    - Report inactivity timeout value.
- Export settings
    - Default delimiter for the comma-separated values (CSV) output file that is created by using the
       **Export** function.

```
IBM zERT Network Analyzer Task Summary   61
```

```
You can also reset settings to their default values or import settings from an earlier release of the IBM
zERT Network Analyzer using the Import or reset application settings panel within the Application
Settings panel.
```
```
Log Settings
The fields in the Log Settings control the level of log information collected by IBM zERT Network Analyzer.
IBM zERT Network Analyzer can log debug information into z/OSMF log files or IBM zERT Network
Analyzer specific log files, or both.
```
- z/OSMF log files are located in the /data/logs folder of the z/OSMF user file system.
- IBM zERT Network Analyzer log files are located in the /data/app/ **<release>** /debug folder of the z/
    OSMF user file system. The format of **<release>** is **ZNAxxxx** , where **xxxx** identifies the release level of
    IBM zERT Network Analyzer.
**Note:** The USERDIR setting in the z/OSMF configuration identifies the mount point of the z/OSMF user file
system. By default the mount point is /global/zosmf/.
The fields in the **Log Settings** section are initially set to the default configuration settings:
- The default setting of **Log level** field is **INFO**.
- The default setting of **Debug log level** field is **OFF**.
- The default setting of **Number of debug log files** field is **10**.
- The default setting of **Maximum debug log file size** field is **1048576** bytes.
To change the logging information level for IBM zERT Network Analyzer, use the **Log Settings** section:
    1. Specify the following fields in the **Log Settings** section.
       - **Log level:** to set the level for IBM zERT Network Analyzer debug information written to the z/OSMF
          log files, select one of the following values from the **Log level** drop-down list.

```
Value Detail information provided
```
```
INFO Collect informational, warning and severe level messages
```
```
WARNING Collect warning and severe level messages
```
```
SEVERE Collect severe level messages
```
```
OFF Collect no messages
```
- **Debug log level:** to set the level for IBM zERT Network Analyzer debug information written to the
    IBM zERT Network Analyzer log files, select one of the following values from the **Debug log level**
    drop-down list.

```
Value Detail information provided
```
```
FINEST Collect finest, finer, fine, informational, warning and severe level
messages
```
```
FINER Collect finer, fine, informational, warning and severe level messages
```
```
FINE Collect fine, informational, warning and severe level messages
```
```
INFO Collect informational, warning and severe level messages
```
```
WARNING Collect warning and severe level messages
```
```
SEVERE Collect severe level messages
```
```
OFF Collect no messages
```
- **Number of debug log files:** to set the number of IBM zERT Network Analyzer debug log files to be
    used for IBM zERT Network Analyzer debug information, specify an integer value in the range of 1 -
    25 in the **Number of debug log files** field.

**62**   IBM zERT Network Analyzer Task Summary


- **Maximum debug log file size:** to set the maximum size in bytes of an IBM zERT Network Analyzer
    debug log file, specify an integer value in the range of 1024 - 10485760 using the **Maximum debug**
    **log file size** field.
2. Click **Save settings** after you specify the settings you want. You can see the updated settings in the
**Log Settings** section the next time you use the **Application Settings** panel.

**Report Settings**

The fields in the **Report Settings** provide options for managing query results across concurrent IBM zERT
Network Analyzer sessions.

The fields in the **Report Settings** section are initially configured to the default settings:

- The default setting of **Report timeout value (in minutes)** field is **60**.
- The default setting of **Maximum open reports per user** field is **0**.

To change the report options for IBM zERT Network Analyzer, use the **Report Settings** section:

1. Specify the following fields in the **Report Settings** section.
    - **Report timeout value (in minutes):** to set the report timeout value in minutes for when the IBM
       zERT Network Analyzer closes an inactive report, specify 0 or an integer number in the range of
       30 - 999999. A value of 0 indicates that the report inactivity timer will be disabled, allowing a
       report to be available for the life of the users z/OSMF session. If the z/OSMF session timeout (i.e.
       SESSION_EXPIRE parameter in the IZUPRMxx parmlib) is less than the configured report timeout
       value then the z/OSMF session timeout overrides this setting.
    - **Maximum open reports per user:** to set the maximum number of open reports allowed for each IBM
       zERT Network Analyzer user, specify an integer number in the range of 0 - 999. A value of 0 indicates
       that there is no open report limit for the user. The value must be less than the number of query result
       set partitions that was configured for the IBM zERT Network Analyzer database in order for the limit
       to be enforced.
2. Click **Save settings** after you configure the settings. You can see the updated settings in the **Report**
    **Settings** section the next time when you use the **Application Settings** panel.

**Note:**

- The modified report timeout value takes effect the next time when you run a new query. If a report is
    currently open when the field is changed, the previous report timeout continues to be valid for the life of
    the report.
- The modified maximum number of open reports per user takes effect immediately after you save the
    modified field.

**Restriction:** If the default value (0) is specified for the maximum number of open reports, the current
number of available partitions restricts the IBM zERT Network Analyzer from running reports. You can
find the maximum number of open reports allowed in the **Database Information** section in the **Database
Settings** panel.

**Export Settings**

The fields in the **Export Settings** control the default delimiter used when exporting a CSV file.

The **Default delimiter for exported CSV files** field in the **Export Settings** section is initially set to the
value of **Comma**. To change the delimiter for exported CSV files, use the **Default delimiter for exported
CSV files** field in the **Export Settings** section.

1. Specify a delimiter in the **Export Settings** section.
    - To use a comma, select **Comma**.
    - To use a vertical bar, select **Pipe**.

```
IBM zERT Network Analyzer Task Summary   63
```

- To use a semicolon, select **Semicolon**.
- To use a tab character, select **Tab**.
- To specify some other character, select **Custom** and enter the delimiter character to be used.
2. Click **Save settings** after you specify the setting you want. You can see the updated setting in the
**Export Settings** section the next time you use the **Application Settings** panel.

**Import or reset application settings**

```
You can take the following steps to import or reset application settings to their defaults values or import
settings from an earlier release of the IBM zERT Network Analyzer. Application settings are saved in an
izu.zdf file within a directory unique to the current release of the IBM zERT Network Analyzer as part of
the z/OSMF data directory.
To reset application settings to their default values:
```
1. Click on **Import or reset application settings** , and the **Import or reset application settings** panel is
    displayed.
       a. To cancel this operation, click the top-right "X" button to close the panel and return back to the
          **Application Settings** panel.
2. If unique application settings have been set, the **Preview application settings** section automatically
    displays a comparison view of the currently saved settings against the default values.
3. Click **Reset to default settings** , which closes the **Import or reset application settings** panel and
    returns back to the **Application Settings** panel.
4. The **Log Settings** , **Report Settings** , and **Export Settings** fields are automatically updated to be set to
    the default values.
5. Click **Save settings** to confirm these settings.
To import application settings from a previous release of the IBM zERT Network Analyzer:
1. Click on **Import or reset application settings** , and the **Import or reset application settings** panel is
displayed.
a. To cancel this operation, click the **"X"** button to close the panel and return back to the **Application
Settings** panel.
2. By default, the IBM zERT Network Analyzer attempts to search for an application settings file from the
previous release (" _n_ - 1") or the penultimate release (" _n_ - 2") as a fallback. The search is limited to
within the z/OSMF data directory of the _current_ IBM zERT Network Analyzer release (i.e. the USER_DIR
parameter in the IZUPRMxx parmlib).
a. If the desired application settings file and release are found, the **Preview application settings**
section is updated to display the release and location of the IBM zERT Network Analyzer application
settings file.
b. If the desired application settings file and release are not found, click on the **Select application
settings file** button to open the **Data Set and File Search** dialog.
i) Enter a z/OS UNIX® file path or use the dialog to navigate to the (izu.zdf) file or its parent
directory.
ii) Select the izu.zdf file or its parent directory and click **OK** to close the **Data Set and File Search**
dialog.
iii) The **Import or reset application settings** panel verifies and previews the application settings
within the **Preview application settings** section.
3. If unique application settings have been set, the **Preview application settings** section automatically
displays a comparison view of the currently saved settings, the loaded previous release, and the
default values.

**64**   IBM zERT Network Analyzer Task Summary


4. Click **Import settings** from previous release, which closes the **Import or reset application settings**
    panel and returns back to the **Application Settings** panel.
5. The **Log Settings** , **Report Settings** , and **Export Settings** fields are automatically updated to be set to
    the previous release's values.
6. Click **Save settings** to confirm these settings.
**Note:**
You can click **Refresh application settings** to restore the fields in the **Log Settings** , **Report Settings** , and
**Export Settings** sections to the last saved value.
**Restrictions:**
- When updating the **Application Settings** panel, you must change the value of at least one field from its
current saved value in either the **Log Settings** , **Report Settings** , or **Export Settings** section before you
can click **Save settings**.
- This restriction also applies when using the **Import or reset application settings** panel. If the result
of importing application settings from a previous release of IBM zERT Network Analyzer or resetting
application settings to their defaults yields no changes to any field within the **Application Settings** ,
no additional action is needed.
- When selecting the IBM zERT Network Analyzer application settings file (e.g., izu.zdf), the file must
be located within a z/OS UNIX path on the z/OS system where z/OSMF is running, and to which the
logged-in user ID has permission to read.

#### Working with Database Settings panel

```
You can use the Database Settings panel to perform two operations related to the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer database:
```
- to view schema information about the IBM zERT Network Analyzer database
- to configure the database connection for the Db2® for z/OS subsystem used for the IBM zERT Network
    Analyzer database
- to import database connection configuration from a previous release of the IBM zERT Network Analyzer
    using the **Import database settings** panel
IBM zERT Network Analyzer only supports Db2 11 for z/OS and Db2 12 for z/OS.

**Viewing database information**

```
You can view database schema information from the Database Information section. The schema
information includes:
```
- The current IBM zERT Network Analyzer database schema version.
- The current IBM zERT Network Analyzer database schema release.
- The current IBM zERT Network Analyzer maximum number of open reports allowed.
When you first start IBM zERT Network Analyzer, or IBM zERT Network Analyzer is unable to retrieve the
schema information using the specified database connection settings, the schema information is set to
_Unknown_.

```
Editing database settings
You can edit the database connection from the Database Settings section. The fields on the Database
Settings panel are empty the first time you start IBM zERT Network Analyzer. When you start the IBM
zERT Network Analyzer the first time, you are immediately directed to the Database Settings panel to
provide these values. You cannot navigate to any other portion of the IBM zERT Network Analyzer except
for the help and tutorial pages until you finish configuration of the database settings.
Procedure
```
```
IBM zERT Network Analyzer Task Summary   65
```

1. To set Db2 values for IBM zERT Network Analyzer, configure the settings with the following fields in the
    **Database Settings** section:
    - **Host name:** to set the IP address where the Db2 for z/OS subsystem resides, specify either the IP
       address or the host name of the Db2 for z/OS subsystem in the **Host name** field. The value must be
       no longer than 255 characters. You can specify either an IPv4 or an IPv6 address.
    - **Port number:** to set the port number on which the Db2 for z/OS subsystem is listening, specify the
       port number as an integer in the range 1–65535 in the **Port number** field.
    - **Location name:** to set the Db2 for z/OS subsystem name, specify the name in the **Location name**
       field. The instance name must be no longer than 16 characters.
    - **JDBC classpath:** to set the path for the Java Database Connectivity (JDBC) driver required for Db2
       processing, specify the path in the **JDBC classpath** field. The path must represent a valid Unix path,
       and must be no longer than 4096 characters.
       **Note:** For a typical installation of Db2 11 for z/OS, the classpath is /usr/lpp/db2b10/jdbc/classes/.
       For a typical installation of Db2 12 for z/OS, the classpath is /usr/lpp/db2c10/jdbc/classes/.
    - **User ID:** to set the user ID that can be used by IBM zERT Network Analyzer to connect to the Db2 for
       z/OS subsystem, specify the z/OS user ID in the User ID field. The user ID must be no longer than 8
       characters.
    - **Password:** to set the password or passphrase associated with the user ID that connects to the Db2
       for z/OS subsystem, specify the password or passphrase in the **Password** field. The passphrase
       must be no longer than 100 characters. The visibility of the password can be toggled using the **View**
       icon on the right side of the field.
       **Note:** The User ID and Password fields can be cleared using the **Clear User ID and Password**
       button.
2. Click **Save settings** after you set all the values, and click **Confirm** to update the database settings or
    **Cancel** to continue editing the database settings.
**Important:** Changing database settings causes the IBM zERT Network Analyzer to restart all current user
sessions and unsaved data to be lost. You must close and reopen your browser session to reconnect to
IBM zERT Network Analyzer. No action is taken if database settings are not modified.
You can see the updated settings values displayed in the **Database Settings** section the next time you
use the **Database Settings** panel.
You can also click **Refresh database settings** to restore the fields in the **Database Settings** section to the
last saved value.

```
Import database connection settings
You can take the following steps to import database connection settings to their defaults values or import
settings from an earlier release of the IBM zERT Network Analyzer. Application settings are saved within
a izuznagui.*.xml file unique to the current release of the IBM zERT Network Analyzer within the z/OSMF
configuration directory.
To import database settings from a previous release of the IBM zERT Network Analyzer:
```
1. Click on **Import database connection settings** , and the **Import database settings** panel is displayed.
    a. To cancel this operation, click the "X" button to close the panel and return back to the **Database**
       **Settings** panel.
2. By default, the IBM zERT Network Analyzer attempts to search for a database connection settings file
    from the current release's backup file, then the previous release (" _n_ - 1") or the penultimate release (" _n_
    - 2") as fallbacks. The search is limited to within the z/OSMF configuration directory of the _current_ IBM
    zERT Network Analyzer release.
       a. If the desired database connection settings file and release is found, the **Preview database**
          **connection settings** section is updated to display the release and location of the IBM zERT
          Network Analyzer database connection settings file.

**66**   IBM zERT Network Analyzer Task Summary


```
b. If the desired database connection settings file and release are not found in the Preview database
connection settings section, click on the Select database settings file button to open the Data
Set and File Search dialog.
i) Enter a z/OS UNIX® file path or use the dialog to navigate to the (izuznagui.*.xml) file or its parent
directory.
ii) Select the izuznagui.*.xml file or its parent directory and click OK to close the Data Set and File
Search dialog.
iii) The Import database connection settings panel verifies and previews the database connection
settings within the Preview database connection settings section.
```
3. If unique database settings have been set, the **Preview database connection settings** section
    automatically displays a comparison view of the currently saved settings against the loaded previous
    release.
4. Click **Import settings from previous release**. It closes the Import database settings panel and returns
    back to the **Database Settings** panel.
5. The **Database Settings** fields are automatically updated to be set to the previous release's values.
6. Click **Save settings** after you set all the values and click **Confirm** to update the database settings or
    **Cancel** to continue editing the database settings.

**Important:**

- The **User ID** and **Password** fields must be reentered in the **Database Settings** panel when previous
    database connection settings are imported. The **Database Settings** panel can still be saved, but the
    IBM zERT Network Analyzer remains in a limited mode and does not connect to the database until those
    fields are set.
- Changing database settings causes the IBM zERT Network Analyzer to restart and all current user
    sessions and unsaved data to be lost. You must close and reopen your browser session to reconnect to
    IBM zERT Network Analyzer. No action is taken if database settings are not modified.
- You can also click **Refresh database settings** to restore the fields in the **Database Settings** section to
    the last saved value.

**Restrictions:**

- When using the **Database Settings** panel for the first time, you must specify valid values for the **Host**
    **name** , **Port number** , **Location name** , and **JDBC classpath** fields before you can click **Save settings**.
    The **User ID** and **Password** are optional fields, but the IBM zERT Network Analyzer will remain in a
    limited mode and will not connect to the database until those fields are set.
- When updating the **Database Settings** panel, you must change the value of at least one field from its
    current saved value before you can click **Save settings**. If the same password is reentered, the IBM
    zERT Network Analyzer takes no action if no other fields are changed in the **Database Settings** panel.
    - This restriction also applies when using the **Import database connection settings** panel. If the result
       of importing database connection settings from a previous release of IBM® zERT Network Analyzer
       yields no changes to any field within the **Database Settings** , no additional action is needed.
- When using the Database Settings panel to save a database password or passphrase, the IBM zERT
    Network Analyzer encrypts the field using an AES encryption key provided by the WebSphere Liberty
    profile. Any function toggled from the z/OS Management Facility (z/OSMF) or WebSphere Liberty profile
    that updates the AES encryption key could result in the IBM zERT Network Analyzer not being able
    to connect to the database. If the AES encryption key is modified and database user authentication
    subsequently fails, you must reenter the password or passphrase in the **Database Settings** panel.
- When selecting the IBM zERT Network Analyzer database connection settings file (izuznagui.*.xml), the
    file must be located within a z/OS UNIX path on the z/OS system where z/OSMF is running, and to which
    the logged-in user ID has permission to read.

```
IBM zERT Network Analyzer Task Summary   67
```

### Tutorial introduction

```
This tutorial demonstrates some of the features of IBM z/OS Encryption Readiness Technology (zERT)
Network Analyzer and includes exercises to help you to become familiar with generating IBM zERT
Network Analyzer reports.
IBM zERT Network Analyzer is a web-based tool that provides z/OS network security administrators with
the ability to import, query and analyze data recorded in SMF 119 zERT Summary (subtype 12) records
by the z/OS Communications Server zERT aggregation function. IBM zERT Network Analyzer helps you
answer the following questions:
```
- _What_ TCP and Enterprise Extender (EE) traffic is being protected, and what traffic is not?
- _How_ is that traffic being protected? For example, what cryptographic protocols are being used, which
    cryptographic algorithms are being used, and what are the key lengths?
- _Who_ on my z/OS system is consuming or producing the network traffic, whether it is protected or not?
- _Where_ is the remote endpoint of that traffic?
This tutorial covers the basic steps for using IBM zERT Network Analyzer. The tutorial scenario is based on
a fictional company that uses different types of cryptographic protocols for TCP and EE connection traffic.
The scenario is simplified for ease of reference and learning.

```
Learning Objectives
The tutorial does not cover all features of IBM zERT Network Analyzer, but demonstrates an overall
approach that you can apply when analyzing your own business cryptographic coverage.
By completing the tutorial, you learn about the following aspects of IBM zERT Network Analyzer:
```
- Importing SMF data into the IBM zERT Network Analyzer database
- Creating and running queries to identify security sessions with specific cryptographic protection
    characteristics
- Examining the results of a query
- Exporting query results to an external comma-separated values (CSV) format file

**Tutorial scenario**

```
Prepare for the tutorial by reviewing the scenario.
The tutorial scenario is based on a fictitious company Example.com that uses different types of
cryptographic protocols for TCP traffic. Example.com is looking to increase its usage of TLS 1.2 protocols,
particularly connections to server applications operating in two specific subnets. To do this, Example.com
wants to identify existing traffic that uses either TLS 1.0 or TLS 1.1 protocols, as well as traffic that
does not use any recognized cryptographic protocols. Only traffic that occurred after 2017 needs to be
considered.
In this scenario you will:
```
- Import Example.com's SMF records into IBM zERT Network Analyzer.
- Prune security session information that does not need to be examined.
- Create a query to identify specific TCP connection traffic involving the local server applications of
    interest, provided that traffic also uses the cryptographic protection of interest.
- Run the query, and examine the results of the query processing on the database contents.
- Export a report of the query results to a comma-separated values (CSV) format file and use a
    spreadsheet to examine the results.
The following diagram shows a simplified view of the scenario:

**68**   IBM zERT Network Analyzer Task Summary


Example.com has multiple server applications, but for this exercise it is just concerned with its server
applications with IP addresses in two different subnets:

- IPv4 subnet 10.11.0.0/16
- IPv6 subnet FD00:197::0/32

Example.com wants to use IBM zERT Network Analyzer to identify TCP traffic to the server applications
in those subnets that use no recognized cryptographic protection, or that still use TLS 1.0 or TLS 1.1
protection.

**Time Required**

The tutorial takes about 60 minutes.

**Audience**

This tutorial is for z/OS network security administrators who want to explore features of IBM zERT
Network Analyzer task and gain an understanding on how to use the task to identify cryptographic
characteristics of their z/OS TCP traffic.

**How to use this tutorial?**

There are multiple ways you can use the tutorial:

- You can read the tutorial without first customizing your z/OS system to use IBM zERT Network Analyzer.

```
This approach allows you to gain understanding of IBM zERT Network Analyzer concepts, but you are
unable to perform similar actions on your system as you take the tutorial. You also cannot perform any
of the optional steps in the tutorial.
```
- You can follow along with the tutorial interactively as an introductory exercise for using the IBM zERT
    Network Analyzer task after you have customized your z/OS systems to use IBM zERT Network Analyzer.
    This approach requires more setup work before taking the tutorial, but you are able to perform each
    step using your own SMF dump data sets while you learn IBM zERT Network Analyzer concepts. You are
    also able to perform any optional additional steps in the tutorial for further exploration of the IBM zERT
    Network Analyzer task. Using this approach, you gain real-time experience with the IBM zERT Network
    Analyzer task.
    **Note:** If you are using your own SMF dump data sets, you will want to tailor the query to your own
    network IP addresses, and your results will differ from the screen shots included in this tutorial. You

```
IBM zERT Network Analyzer Task Summary   69
```

```
can still use the tutorial process as a guide for analyzing the cryptographic protection attributes of your
network.
```
```
Prerequisites
Before getting started with the tutorial, you need familiarity with basic zERT concepts. For more
information about zERT concepts, see z/OS Encryption Readiness Technology (zERT) Concepts in z/OS
Communications Server: IP Configuration Guide for more information.
If you are going to just read the tutorial, click on “Module 1: Populating the IBM zERT Network Analyzer
database” on page 72 to begin.
If you are going to follow the tutorial interactively with your own SMF dump data sets, take the following
actions before you start with the tutorial:
```
1. If you haven't customized your z/OS system for IBM zERT Network Analyzer yet, complete the
    following steps:
       a. Authorize the user IDs that will be using the tutorial and accessing IBM zERT Network Analyzer
          to the necessary SAF resources. See _Authorize users to the IBM zERT Network Analyzer task_ in the
          _z/OSMF Configuration Guide_ for instructions.
       b. Work with your Db2 for z/OS database administrator (DBA) to complete the following steps:
          i)Define and create the required Db2 database objects for the IBM zERT Network Analyzer to
             operate. See _Db2 for z/OS customization for the IBM zERT Network Analyzer task_ in the _z/OSMF_
             _Configuration Guide_ for instructions.
ii) Connect IBM zERT Network Analyzer to the Db2 for z/OS database. See “Defining database
setting” on page 71 for more information.
2. Create or identify the SMF dump data sets you plan to use in the tutorial. See “Obtaining SMF dump
    data sets” on page 72 for more information.
3. **Optional** : Start IBM zERT Network Analyzer if you haven't started it yet.
    - Select and double-click the **IBM zERT Network Analyzer** task from the z/OSMF
       desktop. If the **IBM zERT Network Analyzer** task is not displayed on the desktop, select it from
       the App Center in the taskbar.

```
Modules in this tutorial
“Module 1: Populating the IBM zERT Network Analyzer database” on page 72
Populate the IBM zERT Network Analyzer database with zERT Summary (Type 119 subtype 12) SMF
records.
“Module 2: Querying records in the IBM zERT Network Analyzer database” on page 80
Create and run a query against the contents of the IBM zERT Network Analyzer database.
“Module 3: Viewing IBM zERT Network Analyzer query results” on page 87
Examine the results of running your query against the contents of the IBM zERT Network Analyzer
database.
“Module 4: Exporting query results to a CSV format file” on page 95
Export the results of a query run against the IBM zERT Network Analyzer database to a comma-separated
values (CSV) format file.
```
**70**   IBM zERT Network Analyzer Task Summary


#### Defining database setting

**About this task**

```
This task describes the procedure of how you define the database settings of IBM zERT Network Analyzer.
```
**Procedure**

1. Start z/OSMF.
2. When using the z/OSMF traditional view, expand the **Analysis** category in the navigation area, and
    select **IBM zERT Network Analyzer** ; when using the z/OSMF desktop view, click the **IBM zERT**

```
Network Analyzer icon.
```
3. Select **IBM zERT Network Analyzer**.
4. Select the **Setting** tab.
5. Select the **Database Settings** sub-tab.
6. Specify the information required to connect IBM zERT Network Analyzer to the Db2 for z/OS database.
    a. Fill in the necessary fields.
       - Specify the IP address, or the host name associated with the IP address, where the Db2 for z/OS
          subsystem resides in the **Host name** field.
       - Specify the z/OS user ID to be used to connect to the Db2 for z/OS subsystem in the **User ID** field.
       - Specify the port number on which the Db2 for z/OS subsystem is listening in the **Port number**
          field.
       - Specify the password associated with the user ID that connects to the Db2 for z/OS subsystem in
          the **Password** field.
       - Specify the Db2 for z/OS subsystem name in the **Location name** field.
       - Specify the path for the Java Database Connectivity (JDBC) driver required for Db2 for z/OS
          processing in the **JDBC classpath** field. The path must represent a valid z/OS UNIX path.
          **Note:** For a typical installation of Db2 11 for z/OS, the classpath is /usr/lpp/db2b10/jdbc/
          classes/. For a typical installation of Db2 12 for z/OS, the classpath is /usr/lpp/db2c10/jdbc/
          classes/.

```
IBM zERT Network Analyzer Task Summary   71
```

```
b. Click Save settings.
c. Click Confirm to update the database settings.
```
```
Note: IBM zERT Network Analyzer restarts automatically to use new settings. You must close and
reopen your browser session to reconnect to IBM zERT Network Analyzer.
```
#### Obtaining SMF dump data sets

```
In order to use this tutorial in an interactive manner, you will need access to at least one, but preferably
more than one, SMF dump data set containing zERT Summary (type 119, subtype 12) SMF records.
If you do not already have SMF dump data sets with zERT Summary records, take the following steps to
obtain the necessary SMF dump data sets:
```
- If you have not already enabled zERT aggregation, enable the function. You must also enable collection
    of zERT Summary (SMF 119 subtype 12) SMF records to the System Management Facility (SMF).
    For more details, see Enabling zERT aggregation and zERT Summary record (subtype 12) in IBM
    Documentation.
- After zERT aggregation and zERT Summary SMF record collection has been enabled, collect one or more
    SMF intervals of record data.
    **Note:** You can collect the records into more than one SMF dump data set in order to get the most out of
    using the tutorial interactively.
- Format the collected SMF records to an SMF dump data set or SMF dump stream.
    - If you are dumping the SMF records to an SMF data set, the records must be dumped to the data set
       using the IFASMFDP program.
    - If you are dumping the SMF records to an SMF log stream, the records must be dumped to the data
       stream using the IFASMFDL program.
**Note:** The SMF dump data sets you plan to use must be cataloged and accessible to z/OSMF, and the user
ID under which z/OSMF runs must have permission to read the data sets.

#### Module 1: Populating the IBM zERT Network Analyzer database

```
Populate the IBM zERT Network Analyzer database with zERT Summary (Type 119 subtype 12) SMF
records.
In this module, you can define a list of SMF dump data sets to be imported. You can use the list to
import SMF records into the IBM zERT Network Analyzer database, then prune unwanted records from the
database.
```
```
Lessons in this module
“Task 1-1: Define a list of SMF dump data sets to use” on page 73
```
**72**   IBM zERT Network Analyzer Task Summary


Create a list of SMF dump data sets that include zERT Summary SMF records to be imported into the IBM
zERT Network Analyzer database.

**“Task 1-2: Import SMF records into the database” on page 74**

Add security session information in the IBM zERT Network Analyzer database by importing SMF records
from multiple SMF dump data sets.

**“Task 1-3: Prune unwanted records from the database” on page 78**

Prune security sessions that were reported during a specific date range from the IBM zERT Network
Analyzer database.

**Task 1-1: Define a list of SMF dump data sets to use**

**About this task**

In this lesson, you can use the IBM zERT Network Analyzer Data Management panel to create a list of SMF
dump data sets to be used in import operations.

**Procedure**

1. Select the **Data Management** tab.
2. Select the **Import SMF Data** sub-tab.
3. Add a SMF dump data set to the list of **SMF DUMP DATA SETS** table.
    a. Click **Add data set**.
    b. Enter data set name (IPCS.TUTORIAL.SMFDAT01) and optionally a description of the data set.

```
c. Click Save icon to save this data set name to the list, and Confirm to save the data set.
d. Verify operation was successful.
```
4. Add four additional SMF dump data sets to the import list.
    a. Click **Add data set**.
    b. Enter data set name (IPCS.TUTORIAL.SMFDAT02) and optionally a description of the data set.
       c. Repeat for the next data set (IPCS.TUTORIAL.SMFDAT03).
    d. Repeat for the next data set (IPCS.TUTORIAL.SMFDAT04).
       e. Repeat for the last data set (IPCS.TUTORIAL.SMFDAT05). There should be a total of five data sets
          listed at the end of this step.

```
IBM zERT Network Analyzer Task Summary   73
```

5. Click **Save import list** and **Confirm** to save the import list.
    **Note:** If you do not save the data set list before you close the IBM zERT Network Analyzer session, the
    data set names you entered are lost.
6. Verify that the operation was successful.

```
What to do next
In the next step, you use the list of SMF dump data sets to initiate an import operation.
```
**Task 1-2: Import SMF records into the database**

```
About this task
In this lesson, you can initiate import operations using one or more SMF dump data sets in the list, and
then check the status of the import operation on the Data Management History panel.
```
**Procedure**

1. Select the **Data Management** tab.
2. Select the **Import SMF Data** sub-tab.
3. Initiate the import operation.
    a. Select the SMF dump data sets that you want to import from the list of data sets. For this exercise,
       select IPCS.TUTORIAL.SMFDAT01.

**74**   IBM zERT Network Analyzer Task Summary


```
b. Click Import selected to start the import operation.
```
```
Note: The number of files to be imported (1) is displayed in the Import selected button.
c. Click Confirm to start the import operation.
```
```
d. Verify import operation was scheduled successfully.
```
4. View the results of the import operation.

```
a. Select the Data Management History sub-tab.
```
```
b. If the import operations you just initiated do not appear in the operations table, click Refresh
history.
Depending on the size of the SMF dump data set, the import operation may take some time to
complete. The Status field in the Data Management History display indicates the current state of
the import operation.
```
- **Pending** indicates that the import of the data set has been scheduled but not started.
- **Active** indicates that the import of the data set is currently being performed.
- **Failed** indicates that the import of the data set did not work.
- **Complete** indicates that the import of the data set was successful.
c. When the **Status** field indicates **Complete** for the selected SMF dump data set, the import is
completed and the database is populated with the zERT Summary records from that data set.

```
IBM zERT Network Analyzer Task Summary   75
```

```
d. Click on the selected SMF dump data set (IPCS.TUTORIAL.SMFDAT01) to expand the detailed view
of the import operation of that SMF dump data set.
```
- The number of zERT Summary SMF records added to the database is shown in the **Number of**
    **records added** field.
- The number of zERT Summary SMF records that have already been imported in a previous import
    operation is shown in the **Number of duplicate records** field.
- The number of SMF records that were not zERT Summary SMF records is shown in the **Number of**
    **records ignored** field.
- The SMF reporting times of the earliest SMF record and the latest SMF record in the data set are
    shown in the **Earliest record imported** and **Latest record imported** fields, respectively.
5. Initiate an import of the other data sets in the import list.
a. Select the **Import SMF Data** sub-tab.

```
b. Select all five data sets to add them to the import list.
```
```
c. Click Import selected to start the import operation.
```
```
Note: The number of files to be imported (5), is displayed in the Import selected button.
d. Click Confirm to proceed with the import operation.
```
**76**   IBM zERT Network Analyzer Task Summary


```
e. Verify import operation was scheduled successfully.
```
6. View the results of the import operation.

```
a. Select the Data Management History sub-tab.
```
```
b. Depending on the size of the SMF dump data sets, you may see the various SMF dump data sets in
different states. For example, this view shows one data set in the process of being imported, and
the remaining four data sets are pending.
```
```
c. Click Refresh history to view updated status for the import operation.
d. When the status changes to Complete for all SMF dump data sets, the database is populated.
```
```
e. Expand the most recent import operation of the previously imported SMF dump data set
(IPCS.TUTORIAL.SMFDAT01) to view the details of the second import operation.
```
- Because we already imported this data set into the database, no new records were added. This is
    highlighted by the **Number of records added** and the **Number of duplicate records** fields.

```
IBM zERT Network Analyzer Task Summary   77
```

- The same SMF records ignored previously were ignored again in this import operation, as shown
    in the **Number of records ignored** field.
- No new records were added, so the **Earliest record imported** and **Latest record imported** fields
    have nothing to report.
f. ( **Optional** ) Repeat the previous step for the four data sets imported for the first time to see the
details of those import operations.

```
What to do next
In the next task, you prune the contents of the database.
```
**Task 1-3: Prune unwanted records from the database**

```
About this task
In this lesson, you can remove or prune SMF data records from the zERT Network Analyzer database.
Pruning allows you to manage the size of your database and to eliminate security session information that
is no longer of interest. You can always import the SMF records again later, assuming the SMF dump data
set still exists, if you determine that you want to re-examine the pruned information.
```
**Procedure**

1. Select the **Data Management** tab.
2. Select the **Manage Database** sub-tab.
3. View database statistics
    a. Click **Refresh database statistics** to ensure you see the current information.
    b. Examine the **DATABASE SUMMARY** information.
       - The total number of zERT Summary records imported is shown in the **Total number of SMF 119**
          **subtype 12 records** field. This represents the number of unique SMF records imported to create
          the current contents of the database.

**78**   IBM zERT Network Analyzer Task Summary


- The total number of security sessions created from the imported SMF records is shown in the
    **Total security sessions** field. When security sessions exist over multiple SMF intervals, multiple
    SMF records describing those session are collected (one record per session per SMF interval). The
    data from those records are combined in the database, allowing you to see how connections were
    protected by those security sessions over time.
- The SMF reporting times of the earliest SMF record and the latest SMF record in the database are
    shown in the **Earliest record date** and **Latest record date** fields, respectively.
4. Initiate a prune operation. The dates that you will be selecting for the prune operation represent the
dates that the SMF records were reported, not the dates when the SMF records were loaded into the
IBM zERT Network Analyzer database.
a. Use the date specified on the **Earliest record date** field as the date to use for the prune operation.
You only need the calendar date for the prune operation.

```
b. Enter the selected start and end dates as a Custom range value in the PRUNE DATABASE section.
Select values to delete any records from the year 2017. Enter the dates in the form mm/dd/yyyy.
```
```
c. Click Prune imported data and Confirm to prune.
d. Verify that the prune operation was scheduled successfully.
```
5. View the results of the prune operation.

```
a. Select the Data Management History sub-tab.
```
```
b. Click Refresh history to find the scheduled prune operation.
When the status is Complete , it indicates that the prune operation has finished.
```
```
c. Click on Prune - Custom data range to expand the detailed view of the prune operation in the IBM
zERT Network Analyzer database.
```
```
IBM zERT Network Analyzer Task Summary   79
```

- The number of unique security sessions that are no longer represented in the database is shown
    in the **Number of session records pruned** field.
- The number of unique SMF records that were removed from the database because they
    represented SMF 119 subtype 12 records written within the specified custom date range is
    shown in the **Number of session statistic records pruned** field.
- The dates of the earliest and latest SMF records to be pruned is shown in the **Earliest record**
    **pruned** and **Latest record pruned** fields, respectively.
d. Select **Manage Database** sub-tab.

```
e. Click Refresh database statistics to obtain updated statistics.
f. Compare the new statistics with the previous statistics. The Earliest record date now reflects that
there are no records from 2017.
```
**Results**

```
The IBM zERT Network Analyzer database is populated. The module is complete.
```
#### Module 2: Querying records in the IBM zERT Network Analyzer database

```
Create and run a query against the contents of the IBM zERT Network Analyzer database.
In this module, you can create a query to be run against the security session information in the IBM
zERT Network Analyzer database. You can edit the saved query to change the attributes, and then run the
modified query against the IBM zERT Network Analyzer database.
```
```
Lessons in this module
“Task 2-1: Create a new query” on page 81
```
**80**   IBM zERT Network Analyzer Task Summary


Create, save, and view a query to be run against the security session information in the IBM zERT Network
Analyzer database.

**“Task 2-2: Edit a saved query” on page 84**

Edit the query and change the filters defined for the query..

**“Task 2-3: Run a saved query” on page 86**

Run the modified query against the IBM zERT Network Analyzer database.

**Task 2-1: Create a new query**

**About this task**

In this lesson, you can use the IBM zERT Network Analyzer Queries panel to create and save a new query
that displays security sessions that use either no recognized cryptographic protections or TLS protection,
provided the server IP address matches the correct subnet value. You can use the **Manage Query** panel to
verify the creation of the query.

**Procedure**

1. Select the **Queries** tab.
2. Click **New Query**.
3. Select the **New Query** sub-tab that was just created.
4. In the **QUERY DETAILS** view, provide a name for the query (TUTORIALQUERY-1). Optionally you can
    add a description of the query characteristics.

```
5.Define the query characteristics.
a. Select the Scope Filters sub-tab to filter the database contents by date, system characteristics, or
connection endpoint values. For this exercise, filter data based on the server IP address used for
the security session.
```
```
b. Select the TCP Endpoints filter option.
```
```
IBM zERT Network Analyzer Task Summary   81
```

```
The TCP Endpoints section now appears to the right of the filter selection box, with a warning that
the filter definition currently does not actually filter any data.
```
```
c. Specify an IPv4 subnet range (10.11.0.0/16) in the Server IP address field. Note that the warning
message is cleared when you enter a value in the filter.
```
```
d. Click Add TCP endpoint to add an IPv6 address to the filter.
e. Specify an IPv6 subnet range (FD00:197::0/32) in the Server IP address field in the second row
in the filter.
```
```
f. Select the Security Filters sub-tab to filter database contents based on cryptographic protection
characteristics for the security session. For this exercise, filter data based on the security session
using TLS or no recognized cryptographic protection.
```
```
Note: The Scope Filters sub-tab shows the number of defined scope filters for this query ((1) for
the TCP Endpoints that was added in the above steps).
```
**82**   IBM zERT Network Analyzer Task Summary


g. Click **All TLS protected traffic**.

```
The ALL TLS PROTECTED TRAFFIC filter appears to the right of the filter selection box.
```
h. Click **All traffic with no recognized cryptographic protection**.

```
The ALL TRAFFIC WITH NO RECOGNIZED CRYPTOGRAPHIC PROTECTION filter appears to the
right of the filter box. Even though you selected this filter second, it appears above the ALL TLS
PROTECTED TRAFFIC filter. The display order of the filters corresponds to the order of the filters
in the filter selection box.
```
```
i. Click Save query and Confirm to save the query.
j. Verify that the query was saved successfully.
```
```
Note:
```
- After the query is saved, the name on the original **New Query** sub-tab and the title on the panel
    are changed to the name of the query. The query is in edit mode after you save the query.

```
IBM zERT Network Analyzer Task Summary   83
```

- After the query is created, the **Security Filters** sub-tab shows the number of defined security
    filters for this query (currently 2).
6. View the attributes of the new query.
a. Select the **Manage Queries** sub-tab.

```
b. Find the query you created (TUTORIALQUERY-1) and expand the row by clicking on it, to view the
query details.
```
- The two server IP addresses specified for the **TCP Endpoints** filter are listed on separate rows
    under **SCOPE FILTERS**. Since you did not specify any value for the server port or client IP
    address, portions of the filter are represented by ***** , meaning any port value or client IP address
    matches. Since you did not specify either server or client as the TCP endpoint filter role, a value of
    (Both) is displayed.
- The selection of the **All traffic with no recognized cryptographic protection** and **All TLS**
    **protected traffic** filters are shown under **SECURITY FILTERS**.

**What to do next**

```
In the next task, you edit the query you just created and change the security filter being used.
```
**Task 2-2: Edit a saved query**

**About this task**

```
In this lesson, you can change your saved query to include only TLS security sessions that use either of
two specific TLS protocol versions, while still including security sessions with no recognized cryptographic
protection. You can verify the results of the edit operation.
```
**Procedure**

1. Select the **Queries** tab and go to the **Manage Queries** sub-tab.

**84**   IBM zERT Network Analyzer Task Summary


2. Click **Edit query** in the row representing the TUTORIALQUERY-1 query that you created earlier.
3. Select the **_TUTORIALQUERY-1_** sub-tab.
4. Modify the query characteristics

```
a. Select the Security Filters sub-tab.
```
```
b. Verify the current Security Filter contents. The ALL TRAFFIC WITH NO RECOGNIZED
CRYPTOGRAPHIC PROTECTION and ALL TLS PROTECTED TRAFFIC filter should be included in
the filter display, and the corresponding filters should be checked.
```
```
c. Click TLS protocol version.
```
```
The All TLS protected traffic filter is no longer selected because you selected a different TLS filter.
The ALL TLS PROTECTED TRAFFIC filter has been replaced with the TLS PROTOCOL VERSION
filter. The new filter includes a warning message that no options are currently selected.
```
```
IBM zERT Network Analyzer Task Summary   85
```

```
d. Select TLS 1.0 and TLS 1.1 from the TLS PROTOCOL VERSION list.
```
```
The warning message was removed once you made a selection from the list.
e. Click Save query and Confirm to save the query.
f. Verify that the query was saved successfully.
```
5. View the attributes of the updated query.
    a. Select the **Manage Queries** sub-tab.

```
b. Find the query you modified and expand the row to show the new query details.
```
```
The SECURITY FILTERS filter now includes TLS protocol version , with the two values you selected
listed underneath.
```
**What to do next**

```
In the next task, you run your query.
```
**Task 2-3: Run a saved query**

**About this task**

```
In this lesson, you can run the query you just modified to generate a report, and verify that the query ran
successfully.
```
**86**   IBM zERT Network Analyzer Task Summary


**Procedure**

1. Select the **Queries** tab and go to the **Manage Queries** sub-tab.
2. Find the TUTORIALQUERY-1 that you modified in the previous task.
3. Click **Run Query** in the row representing the TUTORIALQUERY-1 query, and **Confirm** to run the query.
4. Verify that the operation has completed. This may take some time.

```
The Report tab is updated with a checkmark icon once the query operation has completed.
```
```
Results
The query has been created, edited, and run. The module is complete.
```
#### Module 3: Viewing IBM zERT Network Analyzer query results

```
Examine the results of running your query against the contents of the IBM zERT Network Analyzer
database.
In this module, you can examine summary and detailed views of the results of running your query against
the security session information in the IBM zERT Network Analyzer database. You can also add and
remove columns in the default reports.
```
```
Lessons in this module
“Task 3-1: View summary information” on page 87
View the summary reports of the results of running your query against the security session information in
the IBM zERT Network Analyzer database.
“Task 3-2: View detailed information” on page 89
Select one security session from the summary report and view detailed information about that security
session.
“Task 3-3: View additional information” on page 91
```
- Add additional columns to the detailed and summary views.
- Switch between views of TLS and no recognized cryptographic protection security session information.
- Remove columns from the detailed view.

**Task 3-1: View summary information**

```
About this task
In this lesson, you can
```
- use the IBM zERT Network Analyzer **Report** panel to examine the results of running the
    TUTORIALQUERY-1 query;

```
IBM zERT Network Analyzer Task Summary   87
```

- examine the **TCP Server Traffic** sub-tab and optionally the **TCP Client Traffic** sub-tabs;
- use the navigation options to view additional security sessions in the current view;
- sort the information.

**Procedure**

1. Select the **Report** tab. The name of the query that was run to generate this report is listed at the top of
    the report.
2. Select the **TCP Server Traffic** column header and view TCP Server Traffic summary information.

```
Each row in the summary view of this table represents a unique server IP address and server port
range, and the server for the security session is local to the sysplex, system and TCP/IP stack.
```
- The **Displaying records** value shows the total number of rows.

```
This display indicates that the first 100, out of 2291, records are currently being displayed (the
screen shots in this example only show the first 5 rows being displayed).
```
- The connection counts for each security protocol are shown by default for each server in the list.
3. Sort the table by clicking on the **TLS Total Conns** column header. This sorts the table, in ascending
order, by the values in the TLS total connections column. Click **TLS Total Conns** a second time to sort
the table in descending order.
4. Specify a different value (for example, 3) from the value in the **Displaying records** field to navigate to
additional pages of security session information.

```
Hit Enter to retrieve the different page of results.
```
5. Click **back** twice to return to the first row in the sorted table.

**88**   IBM zERT Network Analyzer Task Summary


```
Note: When you are at the first page in the table, the back button grays out and is disabled.
```
6. **(Optional)** Repeat by selecting the **TCP Client Traffic** column header.

**What to do next**

In the next task, select different security sessions and examine the detailed information available for that
session.

**Task 3-2: View detailed information**

**About this task**

In this lesson, you can use the IBM zERT Network Analyzer **Report** panel to examine the detailed
information about one security session at a time, and switch between views of TLS security session
information and information about security sessions that use no recognized cryptographic protection.

**Procedure**

1. Select the **Report** tab. The **TCP Server Traffic** column is selected by default.
2. Sort the **TCP Server Traffic** table by clicking twice on the **TLS Total Conns** column. These should be
    the first five rows in the sorted table:
3. Click the summary row for server IP address 10.11.105.6 and server port 923 (the first row in the
    table) to view client information for that security session.

```
This particular server/port combination has one client, and that client only had connections that used
TLS protected traffic.
```
4. Click the summary row for server IP address 10.11.105.1 and server port 2220 (the fourth row in
    the table) to view client information for that security session. The client information of the previous
    security session is no longer displayed.

```
IBM zERT Network Analyzer Task Summary   89
```

```
This particular server/port combination has three clients, some of which have both traffic with no
recognized cryptographic protection and TLS protection to server 10.11.105.1. The sum of the client
information is equal to the values displayed for the server in the summary view.
```
5. View security session details for the clients.
    a. Select the clients from the list to be displayed. For our example, select the last two clients in the
       list.

```
b. Click View security session details.
```
```
The button shows the number of selected clients (2) to be displayed.
c. By default, the Unprotected* Session Details view is displayed, since these clients had security
sessions that did not use a recognized type of cryptographic protection.
```
```
d.Select TLS Session Details from the first drop-down
selection to view details about the security sessions that used TLS protection.
```
- The **Protocol Version** for each security session indicates **_TLSv1.1_** , which is one of the filter
    options we selected for this query.

**90**   IBM zERT Network Analyzer Task Summary


- There are two entries for **Client IP** 10.26.126.1, which indicates that different TLS protection
    characteristics were used for the TCP connections involving this client.

```
e. Select Distinguished Name Details from the second
drop-down selection to change the display to show TLS security session characteristics related
to distinguished name values.
```
```
Note: Values under the Client Cert Subject Distinguished Name column are different for the
second and third rows. These are the values that caused two different security sessions to be
created for this combination of server IP address, server port, and client IP address.
f. (Optional) : Explore different displays by selecting Certificate Details and Traffic Details from the
second drop-down list.
```
6. Click **View client details** to toggle back to client view.
7. Click the server summary row to collapse the client view.

**What to do next**

In the step, you display additional information in the summary and detailed views.

**Task 3-3: View additional information**

**About this task**

In this lesson, you can select additional information to be displayed for the summary and detailed view,
and remove information from the displays.

**Procedure**

1. Select the **Report** tab. The **TCP Server Traffic** column is selected by default.
2. Add additional security session attributes to the display.

```
a. Click Column Options at the end of the column header row next to the TLS Total Conns
column. The set of Endpoint Attributes and Total Connections per security protocol is selected for
you by default.
```
```
IBM zERT Network Analyzer Task Summary   91
```

```
b. Select additional TLS-related options from the list. There is one TLS-related option in each column,
for example TLS Partial Connections under the Partial Connections column.
```
```
As you click each option the tabular display shows the added column. When you have selected each
option, the table looks like follows:
```
```
From the tabular display you see the volume of TLS protected traffic associated with each of the
security sessions.
```
3. Click the summary row for server IP address 10.11.105.1 and server port 2220 (the fourth row in the
    table) to view client information for that security session.
4. View security session details for the clients.
    a. Select the first two clients in this list.

**92**   IBM zERT Network Analyzer Task Summary


b. Click **View security session details**. By default, security sessions with no recognized cryptographic
protection are displayed. The following security session details table is displayed.

```
c. Select TLS Session Details from the first drop-down
selection to view details about the security sessions that used TLS encryption.
```
- The entry for Client IP 10.2.107.1 is no longer displayed because there were no TLS security
    sessions involving that client.
- The **Protocol Version** field indicates that this security session used **_TLSv1.1_** protocols.

d. Click the **Column Options** next to the **Message Auth Alg** column to display the selection list
for the columns that can be displayed for the current view, which is a combination of **TLS Session
Details** and **Cryptographic Details**.

```
IBM zERT Network Analyzer Task Summary   93
```

```
e. Select Source to add that column.
```
**94**   IBM zERT Network Analyzer Task Summary


```
The display changes as you select options. The Source column is additional to the display.
```
```
f. Deselect Source and Message Authentication Algorithm from COLUMN OPTIONS. Those columns
no longer appear in the view.
```
```
g. (Optional) : Explore different display possibilities by selecting Traffic Details , Certificate Details
and Distinguished Name Details from the second drop-down list.
```
```
Results
You have examined the results of your query. The module is complete.
```
#### Module 4: Exporting query results to a CSV format file

```
Export the results of a query run against the IBM zERT Network Analyzer database to a comma-separated
values (CSV) file.
In this module, you can generate a CSV format export file containing the results of your new query and
examine the output export file using a spreadsheet application.
```
```
IBM zERT Network Analyzer Task Summary   95
```

```
Lessons in this module
“Task 4-1: Export report information” on page 96
Export the current detail contents from the IBM zERT Network Analyzer Report panel.
“Task 4-2: Interpret export file contents” on page 98
Use a spreadsheet application of your choice to create a readable version of the CSV export file, and
examine the spreadsheet information.
```
**Task 4-1: Export report information**

```
About this task
In this lesson, you can use the IBM zERT Network Analyzer Report panel to export the current query
results to a comma-separated values (CSV) file.
```
**Procedure**

1. Select the **Queries** tab and go to the **Manage Queries** sub-tab.
2. Select the row for TUTORIALQUERY-1 in the list of queries. Click on the selected row to display the
    contents of the query.
3. Click **Run Query** and **Confirm** to run the query.
4. Select the **Report** tab.
5. Click **Export to CSV**.

**96**   IBM zERT Network Analyzer Task Summary


6.Define export file characteristics.

```
a. Provide a target z/OS Unix file system path name to be used for the output. If you specify an
existing file, click Replace existing file located at the Export Location.
b. ( Optional ) Click on the desired delimiter to use for the CSV file. The default delimiter is a comma.
When you have entered the information, the panel should look something like the following:
```
```
IBM zERT Network Analyzer Task Summary   97
```

7. Click **Export** and verify that the operation has completed.
8. ( **Optional** ) Export the results of TUTORIALQUERY-1 from the **Manage Queries** sub-tab.

**What to do next**

```
In the next step, examine the contents of an export file using a spreadsheet of your choice.
```
**Task 4-2: Interpret export file contents**

**About this task**

```
In this lesson, you can use a spreadsheet of your choice to examine the contents of one of the export files.
```
**Procedure**

1. Download the exported CSV files from the z/OS UNIX file system to your client device. Make sure to
    transfer the file as character data as the exported data is written in ASCII.

**98**   IBM zERT Network Analyzer Task Summary


2. Open the exported file with a spreadsheet application of your choice (The following screen captures
    are from Microsoft Excel user interface). In this tutorial example, the file to examine is **/tmp/**
    **tutorial.report.csv**.
3. Each row in the spreadsheet represents an individual security session. The tutorial does not cover
    every field in the report, but highlights certain values.
    - The **SECSESS_SYSPLEX, SECSESS_SYSTEM and SECSESS_STACK** columns display the Sysplex,
       System, and TCP/IP stack name for that individual security session, respectively. You can use the
       **Systems** scope filter to further refine your query search based on the contents of these columns.
    - The **SECSESS_LOCALROLE** column indicates the role of the local TCP/IP stack:
       - For TCP connections, a value of "1" represents a server, while a value of "2" represents a client.
       - For EE connections, the value is always "3".
       You can use the **Endpoint role** value in the **TCP Endpoints** scope filter, or use the **EE Endpoints**
       scope filter, to further refine your query based on the contents of this column.
    - The **SECSESS_TRANSPROT** column identifies whether the connection is a TCP connection or a
       UDP/EE connection. A value of "6" indicates these are TCP connections.
    - The **SECSESS_SRVIP, SECSESS_CLNTIP** , **SECSESS_SRVPORTSTART** and **SECSESS_SRVPORTEND**
       columns identify the server IP address, client IP address, and server port range start and end
       values, respectively. You included the **TCP Endpoints** filter in the TUTORIALQUERY-1 query to use
       the contents of the SECSESS_SRVIP field to limit the output to server IP addresses in one of two
       subnets. You can also use the **EE Endpoints** scope filter to refine your query based on the contents
       of these columns.
    - The **SECSESS_TOTAL_CONNECTION** S column contains the total number of connections that have
       associated with this security session. In our example, based on the value of SECSESS_TRANSPROT,
       these are TCP connections. If this was a UDP/EE connection, the value would be the number of EE
       connections for this security session.
4. The export file contains every possible column for every security session included in the report. If a
    given column doesn’t apply, the column is blank. For instance, since we included security sessions
    with either no recognized cryptographic protection or certain levels of TLS protection, the IPSec
    columns all contain blanks.

```
IBM zERT Network Analyzer Task Summary   99
```

```
The same applies for SSH related information.
```
5. The TLS related columns have non-zero information for security sessions that used TLS protection, as
    evidenced by this sample of the spreadsheet. There are many additional TLS fields, but we will discuss
    just a few.

**100**   IBM zERT Network Analyzer Task Summary


- The **TLS_SYMMENCALG** column indicates the symmetric algorithm used by the security session,
    where "8" = RC4_40 and "14" = AES_CBC_256. You can use the **TLS symmetric encryption**
    **algorithm** filter to further refine your query search based on the contents of this column.
- The **TLS_MSGAUTHALG** column indicates the message authentication algorithm used by the
    security session, where "3" = HMAC-MD5 and "4" = HMAC-SHA1. You can use the **TLS message**
    **authentication encryption algorithm** filter to further refine your query search based on the contents
    of this column.
- The **TLS_KEXALG** column indicates the key exchange algorithm used by the security session, when
    "2" = RSA and "3" = RSA_EXPORT. You can use the **TLS key exchange algorithm** filter to further
    refine your query search based on the contents of this column.
- The **TLS_PROTVER** column represents the TLS protocol version used for the security session, where
    "769" = TLS 1.0. You included the **TLS protocol version** filter to use the contents of this field as part
    of the TUTORIALQUERY-1 query.
6. ( **Optional** ) Manipulate the spreadsheet information as you choose to learn more about the report
content and structure.

**Results**

```
A report has been exported and reviewed. The module is complete. Congratulations, you have completed
the tutorial!
```
### Messages: IZUET0000 - IZUET9999

This topic describes the z/OSMF messages that have a message ID between IZUET0000-IZUET9999.
**IZUET0001W Multiple startup servlets of the
IBM zERT Network Analyzer
attempted**

**Explanation:**
An attempt was made to start the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer while
it was already started. The attempt to start the

```
IBM zERT Network Analyzer is ignored. The existing
instance of the IBM zERT Network Analyzer is
unaffected.
```
```
System programmer response
No action is required.
```
```
IBM zERT Network Analyzer Task Summary   101
```

**User response**

No action is required.

**IZUET0002E Failed to create application
properties for** **_application-id_**

**Explanation**
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not load
its application properties. The IBM zERT Network
Analyzer terminates.

In the message text:

**_application-id_**
Application identifier of the IBM zERT Network
Analyzer.

**System programmer response**

Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0003E Failed to unregister the IBM
zERT Network Analyzer during
shutdown**

**Explanation:**
During shutdown, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not be
unregistered. Shutdown of the IBM zERT Network
Analyzer continues.

**System programmer response:**
Contact the IBM Support Center if this condition
persists.

**User response:**
No action is required.

**IZUET0004I Starting the IBM zERT Network
Analyzer, version** **_version-id_**

**Explanation**
Startup of the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer begins.

In the message text:

**_version-id_**
Version identifier of the IBM zERT Network
Analyzer.

**System programmer response:**
No action is required.

**User response:**
No action is required.

```
IZUET0005E Failed to obtain registration
manager instance for plugin ID
plugin-id
```
```
Explanation
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not register
with z/OSMF. The IBM zERT Network Analyzer
terminates.
In the message text:
plugin-id
Plug-in identifier of the IBM zERT Network
Analyzer.
System programmer response:
Contact the IBM Support Center.
User response:
No action is required.
IZUET0006E Invalid z/OSMF context while
registering task ID task-id
```
**Explanation**

```
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not register
with z/OSMF. The IBM zERT Network Analyzer
terminates.
In the message text:
task-id
Task identifier of the IBM zERT Network Analyzer.
System programmer response:
Contact the IBM Support Center.
User response:
No action is required.
IZUET0007I Shutdown started for IBM zERT
Network Analyzer, version version-
id
```
**Explanation**

```
Termination of the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer begins.
In the message text:
version-id
Version identifier of the IBM zERT Network
Analyzer.
System programmer response:
No action is required.
User response:
No action is required.
```
**102**   IBM zERT Network Analyzer Task Summary


**IZUET0008W Multiple startup attempts of
servlet** **_application-id_** **outstanding,
attempt to destroy servlet ignored**

**Explanation**

An attempt was made to stop the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer while
there were still outstanding startup requests to be
processed. The attempt to stop the IBM zERT Network
Analyzer is ignored. The existing instance of the IBM
zERT Network Analyzer is unaffected.

In the message text:

**_application-id_**
Application identifier of the IBM zERT Network
Analyzer.

**System programmer response:**
No action is required.

**User response:**
No action is required.

**IZUET0009I Shutdown complete for IBM zERT
Network Analyzer, version** **_version-
id_**

**Explanation**

Shutdown of the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer has completed.

In the message text:

**_version-id_**
Version identifier of the IBM zERT Network
Analyzer.

**System programmer response:**
No action is required.

**User response:**
No action is required.

**IZUET0010I Start up complete for IBM zERT
Network Analyzer, version** **_version-
id_**

**Explanation**

Startup of the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer has completed.

In the message text:

**_version-id_**
Version identifier of the IBM zERT Network
Analyzer.

**System programmer response:**
No action is required.

**User response:**

```
No action is required.
IZUET0011I Import operation for request
request-id , data set data-set
completed successfully
```
```
Explanation
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer import
an SMF dump data set, and the import operation
completed successfully.
In the message text:
request-id
An internally generated identifier associated with
the import operation.
data-set
The name of the SMF dump data set that was
imported.
System programmer response:
No action is required.
User response:
No action is required.
IZUET0012E Import operation for request
request-id , data set data-set failed
[ embedded-message ]
```
**Explanation**

```
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer import
an SMF dump data set, but the import operation was
not successful.
In the message text:
request-id
An internally generated identifier associated with
the import operation.
data-set
The name of the SMF dump data set that IBM zERT
Network Analyzer attempted to import.
embedded-message
An embedded message providing additional details
about the cause of the failure.
System programmer response:
Refer to the embedded message to determine if any
actions are required.
User response:
No action is required.
```
```
IBM zERT Network Analyzer Task Summary   103
```

**IZUET0013E Error connecting to database –**
**_exception-info_**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an error
attempting to access its internal database. The
attempt fails.

In the message text:

**_exception-info_**

```
Diagnostic information about the error condition
encountered.
```
**System programmer response:**
Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0014W The property** **_property_** **contains an
invalid value and is ignored**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer property file contained an
application property with an invalid value. The value
is ignored and the application property's default value
is used.

In the message text:

**_property_**

```
The name of the application property.
```
**System programmer response:**
Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0015I Import operation pending for
request** **_request-id_** **, data set** **_data-
set_**

**Explanation**

A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer import
an SMF dump data set. The import operation has been
queued.

In the message text:

**_request-id_**

```
An internally generated identifier associated with
the import operation.
```
```
data-set
The name of the SMF dump data set that is in
pending state waiting to be imported.
System programmer response:
No action is required.
User response:
No action is required.
IZUET0016I Import operation active for
request request-id , data set data-
set
```
```
Explanation
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer import
an SMF dump data set, and the import operation has
been started.
In the message text:
request-id
An internally generated identifier associated with
the import operation.
data-set
The name of the SMF dump data set that has
started being imported.
System programmer response:
No action is required.
User response:
No action is required.
IZUET0017I Unexpected import operation at
startup - set to FAILED
```
**Explanation**

```
The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an import
operation in an active state during startup processing.
The import operation is marked as failed.
```
**System programmer response**

```
Use the associated IZUET0012E message to identify
the import operation that was marked as failed. Retry
the import operation if applicable.
```
```
User response
Use the IBM zERT Network Analyzer Data
Management History panel to identify the import
operation that was marked as failed. Retry the import
operation if applicable.
```
**104**   IBM zERT Network Analyzer Task Summary


**IZUET0018I Prune operation pending for
request** **_request-id_**

**Explanation**

A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer prune
security session information from the database. The
prune operation has been queued.

In the message text:

**_request-id_**

```
An internally generated identifier associated with
the import operation.
```
**System programmer response:**
No action is required.

**User response:**
No action is required.

**IZUET0019I Prune operation active for request**
**_request-id_**

**Explanation**

A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer prune
security session information from the database. The
prune operation has been started.

In the message text:

**_request-id_**

```
An internally generated identifier associated with
the import operation.
```
**System programmer response:**
No action is required.

**User response:**
No action is required.

**IZUET0020I Unexpected prune operation at
startup - set to FAILED**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered a prune
operation in an active state during startup processing.
The prune operation is marked as failed.

**System programmer response**

Use the associated IZUET0022E message to identify
the prune operation that was marked as failed. Retry
the prune operation if applicable.

```
User response
Use the IBM zERT Network Analyzer Data
Management History panel to identify the prune
operation that was marked as failed. Retry the prune
operation if applicable.
```
```
IZUET0021I Prune operation for request
request-id completed successfully
```
**Explanation**

```
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer prune
security session information from the database, and
the prune operation completed successfully.
In the message text:
request-id
An internally generated identifier associated with
the prune operation.
System programmer response:
No action is required.
User response:
No action is required.
IZUET0022E Prune operation for request
request-id failed [ embedded-
message ]
```
**Explanation**

```
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer prune
security session information from the database, but
the prune operation was unsuccessful.
In the message text:
request-id
An internally generated identifier associated with
the prune operation.
embedded-message
An embedded message providing additional details
about the cause of the failure.
```
```
System programmer response
Refer to the embedded message to determine if any
actions are required.
User response:
No action is required.
IZUET0023I Cannot import a migrated data set
```
```
IBM zERT Network Analyzer Task Summary   105
```

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered a migrated SMF
dump data set during an import operation. The import
operation fails. The IBM zERT Network Analyzer will
not recall a migrated SMF dump data set.

**System programmer response**

Use the associated IZUET0012E message to identify
the import operation that failed. Recall the migrated
SMF dump data set and retry the import operation.

**User response**

Use the IBM zERT Network Analyzer **Data
Management History** panel to identify the import
operation that failed. Recall the migrated SMF dump
data set and retry the import operation.

**IZUET0024I Error opening data set - errno**
**_errno-val_** **errno2** **_errno2-val_**

**Explanation**

The IBM z/OS® Encryption Readiness Technology
(zERT) Network Analyzer encountered an error
attempting to open an SMF dump data set during an
import operation. The import operation fails.

In the message text:

**_errno-val_**

```
The errno information captured at the time of the
failure. This value is displayed in decimal.
```
**_errno2-val_**

```
The errno2 information captured at the time of the
failure. This value is displayed in hexadecimal.
```
**System programmer response**

Use the associated IZUET0012E message to identify
the failed import operation.

**User response**

Use the IBM zERT Network Analyzer **Data
Management History** panel to identify the failed
import operation.

**IZUET0025I Error allocating data set - S99
error** **_error-val_**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an error

```
attempting to allocate an SMF dump data set during
an import operation. The import operation fails.
In the message text:
error-val
An SVC 99 error code. This value is displayed in
hexadecimal.
```
```
System programmer response
Use the associated IZUET0012E message to identify
the failed import operation.
```
**User response**

```
Use the IBM zERT Network Analyzer Data
Management History panel to identify the failed
import operation.
```
```
IZUET0026I Security exception accessing data
set
```
**Explanation**

```
The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered a security
exception attempting to allocate an SMF dump data
set during an import operation. The import operation
fails.
```
```
System programmer response
Use the associated IZUET0012E message to identify
the failed import operation. Ensure the user id running
the z/OSMF server has access to the data set being
allocated.
```
**User response**

```
Use the IBM zERT Network Analyzer Data
Management History panel to identify the failed
import operation. Ensure the user id running the
z/OSMF server has access to the data set being
allocated.
```
```
IZUET0027I Exception encounter while
processing data management
operation – exception-info
```
```
Explanation
The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an exception
attempting an import or prune operation. The
operation fails.
In the message text:
```
**106**   IBM zERT Network Analyzer Task Summary


**_exception-info_**

```
Information about the exception.
```
**System programmer response**

Use the associated IZUET0012E or IZUET0022E
message to identify the failed import or prune
operation.

**User response**

Use the IBM zERT Network Analyzer **Data
Management History** panel to identify the failed
import or prune operation.

**IZUET0030I Database error – unexpected
value** **_value_** **in column** **_column_**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an unexpected
value in a database column while attempting a prune
operation. The operation fails.

In the message text:

**_value_**

```
The value detected in the database column.
```
**_column_**

```
The name of the database column.
```
**System programmer response**

Use the associated IZUET0022E message to identify
the failed prune operation.

**User response**

Use the IBM zERT Network Analyzer **Data
Management History** panel to identify the failed prune
operation.

**IZUET0031I Could not connect to database**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer encountered an error
attempting to access its internal database while
attempting an import or prune operation. The
operation fails.

**System programmer response**

Use the associated IZUET0012E or IZUET0022E
message to identify the failed import or prune
operation.

```
User response
Use the IBM zERT Network Analyzer Data
Management History panel to identify the failed
import or prune operation.
```
```
IZUET0032E Could not identify schema
information for database
```
**Explanation**

```
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not obtain
the schema information associated with the internal
database tables. The schema information includes the
schema release and version. The IBM zERT Network
Analyzer will not continue initialization until the issue
is corrected.
```
**System programmer response**

```
Contact the database administrator to verify that the
IBM zERT Network Analyzer installation steps for Db2
for z/OS were completed successfully.
```
```
User response
No action is required.
```
```
IZUET0033E Unsupported Db2 version
detected: database-version
```
**Explanation**

```
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer connected to an
unsupported version of Db2. The IBM zERT Network
Analyzer supports Db2 11 for z/OS and above.
The IBM zERT Network Analyzer will not continue
initialization until the issue is corrected.
In the message text:
database-version
The unsupported database version detected.
```
```
System programmer response
Contact the database administrator to verify that the
IBM zERT Network Analyzer installation steps for Db2
for z/OS were completed successfully.
User response:
No action is required.
IZUET0034E Exception encountered: exception-
info
```
```
IBM zERT Network Analyzer Task Summary   107
```

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer has detected an exception
during execution.

In the message text:

**_exception-info_**

```
Diagnostic information about the error condition
encountered.
```
**System programmer response:**
Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0035E Data management thread could
not be created**

**Explanation**

During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not create
the thread used to perform data management
operations. The IBM zERT Network Analyzer
continues, but is unable to import SMF dump data sets
or prune data from its database.

**System programmer response:**
Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0036E Error encountered initializing
context for the IBM zERT Network
Analyzer servlet**

**Explanation**

During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not
initialize context for its servlet. The IBM zERT Network
Analyzer terminates.

**System programmer response:**
Contact the IBM Support Center.

**User response:**
No action is required.

**IZUET0037W Error encountered destroying
context for the IBM zERT Network
Analyzer servlet**

**Explanation**

During termination, the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer could
not destroy context for its servlet. The IBM zERT
Network Analyzer continues with termination.

```
System programmer response:
Contact the IBM Support Center.
User response:
No action is required.
IZUET0038I Pending import operation at
startup – set to CANCELED
```
```
Explanation
During the initialization of the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer, an
import operation in the pending state was detected
and was set to the canceled state. The import
operation does not execute and the IBM zERT Network
Analyzer continues to process new data management
operations.
System programmer response:
No action is required.
```
**User response**

```
Use the IBM zERT Network Analyzer Data
Management History panel to identify the failed
import operation. Schedule a new import operation for
the SMF dump data set if necessary.
```
```
IZUET0039I Pending prune operation at
startup – set to CANCELED
```
**Explanation**

```
During the initialization of the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer, a
prune operation in the pending state was detected
and was set to the canceled state. The prune
operation does not execute and the IBM zERT Network
Analyzer continues to process new data management
operations.
System programmer response:
No action is required.
```
```
User response
Use the IBM zERT Network Analyzer Data
Management History panel to identify the failed
prune operation. Schedule a new prune operation if
necessary.
```
```
IZUET0040I Import operation for request
request-id , data set data-set
canceled [ embedded-message ]
```
**Explanation**

```
A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer import
```
**108**   IBM zERT Network Analyzer Task Summary


an SMF dump data set, but the operation was canceled
before it was started.

In the message text:

**_request-id_**
An internally generated identifier associated with
the import operation.

**_data-set_**
The name of the SMF dump data set that the user
requested to be imported

**_embedded-message_**
An embedded message providing additional details
about the cause of the cancellation.

**System programmer response**

Refer to the embedded message to determine if any
actions are required.

**User response:**
No action is required.

**IZUET0041I Prune operation for request**
**_request-id_** **canceled [** **_embedded-
message_** **]**

**Explanation**

A user requested that the IBM z/OS Encryption
Readiness Technology (zERT) Network Analyzer prune
security session information from the database, but
the operation was canceled before it was started.

In the message text:

**_request-id_**
An internally generated identifier associated with
the prune operation.

**_embedded-message_**
An embedded message providing additional details
about the cause of the cancellation.

**System programmer response**

Refer to the embedded message to determine if any
actions are required.

**User response**

No action is required.

**IZUET0042E Missing required database table**
**_table-name_**

**Explanation**

During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer could not locate
a necessary table in the internal database. The IBM

```
zERT Network Analyzer will not continue initialization
until the issue is corrected.
In the message text:
table-name
Name of the missing database table.
```
```
System programmer response
Contact the database administrator to verify that the
IBM zERT Network Analyzer installation steps for Db2
for z/OS were completed successfully.
```
**User response**

```
No action is required.
```
```
IZUET0043E Database connection not set up.
Please specify and save your
database settings.
```
**Explanation**

```
The information required to connect the IBM z/OS
Encryption Readiness Technology (zERT) Network
Analyzer to the Db2 for z/OS database has not been
specified. The IBM zERT Network Analyzer will not
continue initialization until the issue is corrected.
```
```
System programmer response
No action is required.
```
**User response**

```
Navigate to the Settings -> Database Settings panel
in the IBM zERT Network Analyzer browser session.
Supply the necessary database connection information
and click Save settings. If the information is accepted,
the IBM zERT Network Analyzer plug-in recycles. You
must close and reopen the browser session for IBM
zERT Network Analyzer to resume.
```
```
IZUET0044E Could not connect to database to
verify database schema. Please
close and reopen IBM zERT
Network Analyzer once database
connection can be established.
```
```
Explanation
During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer was unable to
connect to the internal database using the current
connection information. The IBM zERT Network
Analyzer will not continue initialization until the issue
is corrected.
```
```
IBM zERT Network Analyzer Task Summary   109
```

**System programmer response**

Contact the database administrator to verify that Db2
for z/OS is active and listening on the expected port.

**User response**

Navigate to the **Settings -> Database Settings**
panel in the IBM zERT Network Analyzer browser
session. Verify that the supplied database connection
information is correct. If the information needs to be
updated, make the necessary changes and click **Save
settings.** If the information is accepted, the IBM zERT
Network Analyzer plug-in recycles. You must close and
reopen the browser session for IBM zERT Network
Analyzer to resume.

**IZUET0045E Database schema not valid. Please
contact database administrator
to correct issue. Please close
and reopen IBM zERT Network
Analyzer once issue is resolved.**

**Explanation**

During startup, the IBM z/OS Encryption Readiness
Technology (zERT) Network Analyzer was able to
connect to the internal database using the current
connection information but detected an invalid
database schema version. The IBM zERT Network
Analyzer will not continue initialization until the issue
is corrected.

**System programmer response**

Contact the database administrator to verify that the
IBM zERT Network Analyzer installation steps for Db2
for z/OS were completed successfully.

**User response**

See system programmer response.

**IZUET0046E Error encountered during start up
for IBM zERT Network Analyzer:**
**_error-info_**

**Explanation**

The IBM z/OS Encryption Readiness Technology
(zERT) Network Analyzer has detected an error during
start up of the plug-in.

In the message text:

**_error-info_**

```
Diagnostic information about the error condition
encountered.
```
```
System programmer response
Contact the IBM Support Center.
```
**User response**

```
No action is required.
```
```
IZUET0047W The maximum number of open
reports has been reached for
the IBM® zERT Network Analyzer.
Please try again after one or more
reports are closed.
```
**Explanation**

```
During execution of a query, the IBM z/OS® Encryption
Readiness Technology (zERT) Network Analyzer was
unable to obtain an available database partition to
store query results. The IBM zERT Network Analyzer
is not able to execute a new query until an open report
partition is available.
```
```
System programmer response
None
```
**User response**

```
You or another user must close an open report to free
up a database partition by clicking Close Report on
the Reports tab.
Note: Closing a report discards any data (summary,
client detail, security session details) associated with
it. If you need to save the data from the report before
closing it, you can use the Export function to export
the results to a comma separated value (CSV) format
file.
If this message is a common occurrence with multiple
users of the IBM zERT Network Analyzer, contact
your Db2 for z/OS database administrator to increase
the number of partitions available to the IBM zERT
Network Analyzer.
Note: It is necessary to restart the IBM zERT Network
Analyzer after modifying the number of available
partitions.
```
```
IZUET0048E Report failed to close
```
```
Explanation
The report failed to close because the IBM z/OS®
Encryption Readiness Technology (zERT) Network
Analyzer detected an error while freeing up the
database partition associated with the report.
```
**110**   IBM zERT Network Analyzer Task Summary


**System programmer response**

Contact the IBM Support Center.

**User response**

Contact the IBM Support Center.

**IZUET0049E Error freeing up partition** **_partition-
id_** **during IBM zERT Network
Analyzer startup**

**Explanation**

When the IBM z/OS® Encryption Readiness Technology
(zERT) Network Analyzer starts up, all actively used
database partitions are released. The IBM zERT
Network Analyzer detected an error when freeing one
of the database partitions. The database partition
might be in an unavailable state.

In the message text:

**_partition-id_**

```
An IBM zERT Network Analyzer database partition
identifier
```
**System programmer response**

See _Recover unavailable partitions_ under _Problems
when using IBM zERT Network Analyzer_ section of
_Chapter 15. Troubleshooting problems_ in _z/OSMF
Configuration Guide_.

**User response**

Contact the IBM Support Center.

**IZUET0050E Error freeing up partition** **_partition-
id_** **during IBM zERT Network
Analyzer session timeout**

**Explanation**

When the IBM z/OS® Encryption Readiness Technology
(zERT) Network Analyzer session times out, all actively
used database partitions are released. The IBM zERT
Network Analyzer detected an error when freeing one
of the database partitions.

In the message text:

**_partition-id_**

```
An IBM zERT Network Analyzer database partition
identifier
```
**System programmer response**

Contact the IBM Support Center.

```
User response
Contact the IBM Support Center.
```
```
IZUET0051W Cannot close report while a query
is running
```
**Explanation**

```
A user requested that the IBM z/OS® Encryption
Readiness Technology (zERT) Network Analyzer close
an open report, but the operation was canceled as
another query was being executed within the same
browser session.
```
**System programmer response**

```
None
```
```
User response
You must wait for the query to complete within the
same browser session that the report being closed is
located. Once the query execution is completed, the
report panel is refreshed with the results from the last
query, and you are able to close the open report by
clicking Close Report on the Reports panel.
```
```
IZUET0052W Cannot free up partition partition-
id while a query is running
```
**Explanation**

```
When the IBM z/OS® Encryption Readiness Technology
(zERT) Network Analyzer session times out or z/OSMF
is shutting down, all actively used database partitions
are released. If a query is in progress while the
database partitions are being freed, then the IBM zERT
Network Analyzer cannot free the partition.
In the message text:
partition-id
An IBM zERT Network Analyzer database partition
identifier
```
```
System programmer response
Contact the IBM Support Center.
```
**User response**

```
Contact the IBM Support Center.
```
```
IZUET0053W IBM zERT Network Analyzer is
connected to a database that is
designed for a newer version of
the IBM zERT Network Analyzer.
```
```
IBM zERT Network Analyzer Task Summary   111
```

**Explanation**

During startup, the IBM® z/OS® Encryption Readiness
Technology (zERT) Network Analyzer identified the
schema information associated with the internal
database tables as belonging to a newer release
of the IBM zERT Network Analyzer. The IBM zERT
Network Analyzer will continue to operate but certain
restrictions may apply when using an older release of
the IBM zERT Network Analyzer.

**Restriction:**

Any imported/exported zERT data does not support
any new features of the newer release.

**System programmer response**

Contact the database administrator to verify that the
IBM zERT Network Analyzer installation steps for Db2
for z/OS were completed successfully.

**User response**

No action is required.

**IZUET0054W The maximum number of open
reports per user has been reached
for the IBM® zERT Network
Analyzer. Please try again after
one or more reports are closed.**

**Explanation**

During execution of a query, the IBM z/OS®
Encryption Readiness Technology (zERT) Network
Analyzer detected that you have reached the allocated
maximum number of active reports per user. The IBM
zERT Network Analyzer will not be able to execute a
new query until you close one of your active reports.

**System programmer response**

None.

**User response**

You must close an open report to free up a database
partition by clicking **Close Report** on the **Reports** tab.

**Note:** Closing a report discards any data (summary,
client detail, and security session details) associated
with it. Use the export function to export the results to
a comma separated value (CSV) format file if you need
to save the data before closing it.

If this message is a common occurrence with multiple
users of the IBM zERT Network Analyzer, consider
changing it through the **Application Settings** panel
under the **Settings** tab.

```
Note: The newly configured value applies to all
IBM zERT Network Analyzer users. Be careful when
changing this value.
```
```
IZUET0055E User not authorized. Contact your
security administrator to gain
access. Please close and reopen
IBM® zERT Network Analyzer once
issue is resolved.
```
```
Explanation
The IBM z/OS® Encryption Readiness Technology
(zERT) Network Analyzer detected an insufficient
resource authorization for the current user. The
current user session for IBM zERT Network Analyzer
will not continue.
```
**System programmer response**

```
Review the z/OSMF server joblog for message
CWWKS9104A to identify the missing role associated
with the resource authorization for the current user.
Contact the security administrator to grant the user
sufficient resource authorizations for the IBM zERT
Network Analyzer. The z/OSMF server needs to be
recycled once the user is granted sufficient resource
authorization.
```
**User response**

```
After the security administrator has granted the
missing resource authorization, close the current
browser session and open a new browser session for
IBM zERT Network Analyzer to establish a new user
session.
```
```
IZUET0056E Database User ID or Password not
accepted. Please reenter and save
your database settings.
```
```
Explanation
During startup or in a session where initialization
was successful, the IBM z/OS® Encryption Readiness
Technology (zERT) Network Analyzer failed to connect
to the database using the saved IBM zERT Network
Analyzer user ID and password.
```
- If this error is encountered during initialization,
    the IBM zERT Network Analyzer will not continue
    initialization until the issue is corrected.
- If this error is encountered in a session where
    initialization was successful, the current database
    user credentials are no longer valid for this session.
    The IBM zERT Network Analyzer will not continue
    normal operation until the issue is corrected.

**112**   IBM zERT Network Analyzer Task Summary


**System programmer response**

None.

```
User response
Ensure that the proper database user credentials are
entered and saved in the Database Settings panel
under the Settings tab.
```
```
IBM zERT Network Analyzer Task Summary   113
```

## Index

**I**

IBM zERT Network Analyzer 1, 68

**P**

Pervasive Encryption 68

**W**

What's New 1

**114**   IBM zERT Network Analyzer Task Summary



IBM®


## z/OS Operator Consoles

# IBM


## Contents

```
z/OS Operator Consoles.........................................................................................1
Completing console setup .......................................................................................................................... 1
Setting up a console.....................................................................................................................................1
Settings for a console............................................................................................................................. 2
Specifying OPERPARM settings for a console........................................................................................2
View a console..............................................................................................................................................5
Overview ......................................................................................................................................................5
Console summary view.......................................................................................................................... 8
Console ........................................................................................................................................................8
System command reference ............................................................................................................... 10
```
**Index.................................................................................................................. 11**

**ii**


**z/OS Operator Consoles**

```
The z/OS® Operator Consoles task lets you work with z/OS consoles. You can view system messages
and issue system commands. The systems that you can work with are defined with the Systems task in
z/OSMF Settings.
You can see a graphic summary of the message activity. If an available IBM Docs server URL is provided,
the z/OS Operator Consoles task lets you quickly see documentation for a message by hovering the
mouse pointer on a message that is displayed on the Console view.
To get started, select the z/OS Operator Consoles task in the z/OSMF desktop.
```
### Completing console setup

```
Some setup is required before you can use a z/OS console with the z/OS Operator Consoles task.
```
- “Settings for a console” on page 2
- “Configuring message help ” on page 4

### Setting up a console

```
Before you begin
Select the z/OS Operator Consoles task in the Consoles category. The Console Summary table shows the
consoles for the systems that are available.
```
```
About this task
The setup described in this task applies to systems in the Console Summary table that have a status of
Setup required. If the status is some other value, the setup is already complete or is not appropriate. The
setup consists of the following:
```
- Establishing an extended MCS console for a specific system, then granting permission to a user to use
    that console. This is typically performed by a security administrator outside of z/OSMF.
- Indicating to z/OSMF that the setup has been performed. This is performed by the user in z/OSMF.

**Procedure**

1. Select a system with the status of Setup required.
2. Click **Actions** , then select **Complete Setup**. The **Complete Setup** window is displayed.
3. Contact the security administrator to ensure that the setup is performed for the system that you
    selected. You might choose to close the window while the setup is being performed.
    Sample job SYS1.SAMPLIB(IZUGCSEC) provides a sample for the required setup.
    The setup establishes an extended MCS console and gives you access to that console. With RACF, you
    use ADDUSER commands with the OPERPARM parameter. The syntax is

```
ADDUSER useur-id OPERPARM(MSCOPE( system-names ))
```
```
The MSCOPE parameter specifies the systems from which a console can receive messages that are not
directed to a specific console.
The following example establishes a console for SYS1 and gives user JSMITH access to it.
```
```
ADDUSER JSMITH OPERPARM(MSCOPE(SYS1))
```
```
The following example establishes consoles for all systems and gives user BJONES access to it.
```
```
z/OS Operator Consoles   1
```

```
ADDUSER BJONES OPERPARM(MSCOPE(*ALL))
```
4. Return to the **Complete Setup** window.
    If you closed the window, display it again using the same steps that you originally used. If the EMCS
    console name that is used in the setup is a customized name supplied by your installation, rather than
    the default name that is generated by z/OSMF, update the EMCS console name field on the **Complete**
    **Setup** page.
5. It is recommended that you specify OPERPARM information for the console.
    You can select one or all console items in the table on the Complete Setup page and click **Settings**. For
    more information, see “Settings for a console” on page 2.
6. After the setup is complete, click **Setup Complete**.

**Results**

```
The console status changes to Setup Complete.
```
**What to do next**

```
To begin using the console, click Start console. When the console status changes to Connected, click the
system name to open a tab for the console. You see system messages and can issue system commands.
```
#### Settings for a console

#### Specifying OPERPARM settings for a console

**Before you begin**

```
You are required to have at least READ access for resource profile CONOPER in the TSOAUTH class to
specify the OPERPARM fields.
The values that you specify for the OPERPARM keywords take effect after a command is entered from the
console for the first time.
```
**Procedure**

1. Select the z/OS Operator Consoles task in the Consoles category.
    The Console Summary table shows the consoles for the systems that are available.
2. Click **Actions** , then select **Complete Setup**.
    The **Complete Setup** page is displayed.
3. Select one or all console items in the table on the **Complete Setup** page and click **Settings**.
    The **Settings** window is displayed.
4. In the **Settings** window, specify values for the OPERPARM fields.
    To use the following recommended values, select **Show recommended values** :
    - auth=MASTER
    - mscope=ALL
    - storage=1
    - auto=NO
    For more information about the OPERPARM values, see Table 1 on page 3.

**2**   z/OS Operator Consoles


_Table 1. OPERPARM fields_

**Field name Description**

auth Command authority for the console. The first time the user issues a command from the console, this
value takes effect.
You can select one of the following values:
**MASTER**
Allows this console to act as a master console, which can issue all MVS operator commands.
**ALL**
Allows this console to issue system control commands, input/output commands, console control
commands, and informational commands.
**INFO**
Allows this console to issue informational commands. This value is the default.
**CONS**
Allows this console to issue console control and informational commands.
**IO**
Allows this console to issue input/output and informational commands.
**SYS**
Allows this console to issue system control commands and informational commands.
If you omit this value, the console uses INFO by default.

routcode Routing codes of messages that the console receives. Customize **routcode** to its proper value. The
value of this field only takes effect when the user issues a command from the console for the first time.
You can select one of the following values:
**ALL**
All routing codes.
**NONE**
No routing codes.
**_(routing code, routing code... )_**
List of one or more routing codes, which are enclosed in parentheses. Each routing code is an
integer in the range 1 - 128. To specify multiple routing codes, separate the entries with commas.
**Note:** Setting the **routcode** to ALL, 1-10,12-128, or mscope=*ALL may trigger the system health
check warning.
If you omit this value, the console uses NONE by default.

mscope The systems from which this console can receive messages that are not directed to a specific console.
The value of this field takes effect only when the user issues a command from the console for the first
time.
You can select one of the following values:
**(system-name)**
List of one or more system names, where system-name can be any combination of A - Z, 0 - 9, #
(X'7B'), $ (X'5B'), or @ (X'7C'). The system name can be any combination of A - Z, 0 - 9, # (X'7B'),
$ (X'5B'), or @ (X'7C'), and cannot start with number 0-9. To specify multiple systems, separate the
entries with commas.
Up to 32 systems can be specified, if the couple data set is configured for that many. If more than 32
systems are specified, the first 32 systems are used and the remaining specifications are ignored.
**LOCAL**
System on which the console is active.
**ALL**
All systems.
Usually, a sysplex console is configured to receive console messages from all systems in the sysplex. To
enable this capability, set the mscope value to ALL.
If you omit this value, the console uses ALL by default.

```
z/OS Operator Consoles   3
```

```
Table 1. OPERPARM fields (continued)
Field name Description
storage Amount of storage in kilobytes in the TSO/E user's address space, which can be used for message
queuing to this console. The value of this field takes effect only after the user issues a command from the
console for the first time. If specified, the storage value must be a number in the range 1 - 2000.
If the expected console message size is large, it is recommended that you increase this parameter to a
larger value. For example, if the expected response size is 10 megabytes, consider setting the storage to
15M, based on the following formula: 10M+5M=15M.
If you omit this value, the console uses STORAGE(1) when a session is established. Also, a value of 0 is
listed in the OPERPARM segment of the user's profile to indicate that no storage value was specified.
auto Specifies whether the console receives messages that are eligible for automation. The value of this field
takes effect only when the user issues a command from the console for the first time.
You can select one of the following values:
YES
The console receives messages that are eligible for automation.
NO
The console does not receive messages that are eligible for automation.
If you omit this value, the console uses NO by default.
```
5. After the setup is complete, click **OK** to return to the **Complete Setup** window. Then, click **Setup**
    **Complete**.

**Results**

```
The console status changes to Setup Complete.
```
```
What to do next
To begin using the console, click Start console. When the console status changes to Connected , click the
system name to open a tab for the console. You see system messages and can enter system commands.
To view the OPERPARM settings for the console, click the console name.
```
```
Configuring message help
To display information for system messages in z/OS product from the IBM Documentation, you must
perform some configuration.
```
```
Before you begin
The z/OS Operator Consoles task can retrieve message help in z/OS product from IBM Documentation
with an internet connection. This message help is displayed when a user hovers the mouse pointer over a
message ID in the Console view.
To enable this feature, you must provide an available IBM Docs server URL, by default, https://
http://www.ibm.com/docs/api/v1 is used. If another server is provided, you also need to ensure the certificate
of the IBM Docs server is trusted by your web browser.
For more information about IBM Documentation, see About IBM Documentation.
```
**Procedure**

1. Select the z/OS Operator Consoles task in the z/OSMF desktop.
    In the z/OS Operator Consoles, the Console Summary table shows the available consoles for your
    systems.
2. Click **Actions** , then select **Configure message help**.
    The **Configure message help** window is displayed.

**4**   z/OS Operator Consoles


3. In the **Configure message help** window, supply an available IBM Docs server URL. **Parent topic:**
    Completing console setup.

### View a console

```
This topic describes how to view a z/OS console using the z/OS Operator Consoles task.
```
**Procedure**

1. In the z/OSMF desktop, select z/OS Operator Consoles.
2. Select a console with the action that is appropriate for the status:
    - **Connected** : Click the system name to display the console.
    - **Setup complete** : Use the **Start Console** action. When the status changes to Connected, click the
       system name.
    - **Setup required** : To continue, you need to ensure that console setup is complete, and click **Setup**
       **Complete** on the **Complete Setup** window.
          a. Select the system.
b. Click **Actions** , then select **Complete Setup**. The **Complete Setup** window is displayed.
c. Perform the setup that is required. For information, click **Help** on the **Complete Setup** window.
You might choose to close the window while the setup is being performed.
d. Once the setup is complete, click **Setup Complete** on the **Complete Setup** window. (If you
closed the window, display it again using the same steps that you originally used.)
e. Use the **Start Console** action. When the status changes to Connected, click the system name.
    - **Locked** : Use the **Resume** action. When the status changes to Connected, click the system name.
    - **Unavailable** : You cannot display the console for this system.

### Overview

```
Use the Overview tab to see the sysplexes and systems that are available for the z/OS Operator Consoles
function. You can also use this tab to display a console for a system.
The systems that you can work with are defined with the Systems task of the z/OSMF Settings category.
The z/OS Operator Consoles task shows them in the Console Summary table. To see current information
in the Console Summary table, click Refresh.
```
**Columns in the Console Summary table**

```
Table 2. Columns in the Console Summary table
```
```
Column Description
```
```
Sysplex or System Name of the sysplex or system.
```
```
Console Name Name of the console.
```
```
z/OS Operator Consoles   5
```

```
Table 2. Columns in the Console Summary table (continued)
```
```
Column Description
```
```
Status Status of the console:
Connected
A connection is made to a z/OS console. Click the sysplex or system name
to open a tab for the console. You can enter commands and see system
messages.
Error
An error was encountered. Try the Start action. If the status does not change
to Connected, an error exists that must be resolved.
Invalid
The selected system is no longer valid, based on the information that was
retrieved from the systems table. You might want to remove the system from
the Console Summary table with the Remove action.
Locked
The connection is locked. System messages are no longer retrieved. Use the
Resume action to begin retrieving messages again.
Setup complete
The console setup is complete. You can start the console with the Start
console action.
Setup required
The console setup is not complete. Use the Complete setup action to ensure
that the setup is complete and to indicate that the setup is complete.
Unavailable
This system is not available for the z/OS Operator Consoles task. You cannot
display the console for this system.
```
```
Console Summary View Summary view of the console, if it is connected. For more information, see
“Console summary view” on page 8.
```
```
Actions for the Console Summary table
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 3 on page 6.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 4
    on page 7.

```
Table 3. Targeted actions for the Console Summary table
```
```
Action Description
```
```
Open console Open the console. This opens a tab for the console to view system messages and
issue system commands. This action is available when the status is Connected.
```
```
Start Console Activate the console. When a connection is made to a z/OS console, the status
changes to Connected. This action is available when the status is Setup Complete.
```
```
Complete Setup Learn about console setup, and indicate that the console setup is complete.
Complete Setup displays the Complete Setup window. On the window, click Help
to display information about console setup. When the setup is complete, click
Setup Complete to indicate that the console is ready for use.
```
```
Stop Console Stop the console. It will stop retrieving messages. This action is available when the
status is Connected.
```
**6**   z/OS Operator Consoles


_Table 3. Targeted actions for the Console Summary table (continued)_

**Action Description**

**Resume Console** Resume a console. This action is available when the status is Locked. The status
returns to Connected.

**Delete** Delete a console from the table.

**Change Setup** Display a window that allows you to change the console name and OPERPARM
information. Supply the new name, then click **Setup Complete**. This action is
available when the status is Setup Complete.

**Lock Console** Lock a console so that messages are no longer retrieved. This action is available
when the status is Connected.

**Configure message help** Display a window for supplying an available IBM Docs server URL. With an avaliable
IBM Docs server URL, the z/OS Operator Consoles task can retrieve message help
information from IBM Documentation when users hover the mouse pointer over a
message ID on the Console view.

_Table 4. Table actions for the Console Summary table_

**Action Description**

**Select All** Select all of the items in the table.

**Deselect All** Clear all of the items in the table.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Show Filter Row** Display the filter row.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Clear Sorts** Clear the sort from all of the columns in the table. When you use this action, the
column defaults to a descending sort.

```
Inactive console
If there is no activity for 30 minutes, the status of the console is changed so that the console does not
continue to receive messages – similar to when a Stop action is used.
All interaction with the system is disabled. For example:
```
- The actions **Submit** and **Retrieve Historic Messages Up/Down** are not available. If you hover the
    mouse pointer over either action, the following message is displayed: Console is not active.
- **Delete** is not available. If you hover the mouse pointer over a message, the **Delete** button is not
    displayed.
To resume using the console, close the console tab, then start the console by using the **Start** action.

```
z/OS Operator Consoles   7
```

#### Console summary view

```
The console summary view provides a graphic view of system message activity.
```
**Console Summary View**

```
The Console Summary Viewer provides a graphical view of activity. Each bar in the graph represents a
unit of time; taller bars represent more activity. The colors of the bars reflect the colors of the messages
that are displayed in the console. Hover the mouse pointer over the summary view to display additional
information for that unit of time.
Select a bar in the console summary to show detail for that interval.
The console summary view is available from both the Console Summary table and the Console tab.
```
### Console

```
Use the Console tab to view system messages and to enter system commands.
```
**Console Summary Viewer**

```
The Console Summary Viewer provides a graphical view of activity. Each bar in the graph represents a
unit of time; taller bars represent more activity. The colors of the bars reflect the colors of the messages
that are displayed in the console. Hover the mouse pointer over the summary view to display additional
information for that unit of time.
```
```
Use the console summary icon, , in the control bar to show or hide the summary view. Hover
the mouse pointer over the icon to display a description of the associated function.
```
**WTOR and HOLD view**

```
The WTOR and HOLD view displays the WTOR and HOLD messages that were received by the console, in
the time since the console was started. HOLD messages are messages with descriptor codes 1, 2, 3 and
11.
To manually delete WTOR and HOLD messages from the WTOR and HOLD view, hover the mouse pointer
over the message content to display a Delete button, then click the button. WTOR messages might be
automatically removed from the WTOR and HOLD view if they have been replied to.
```
```
Use the WTOR and HOLD icon in the control bar to show or hide the WTOR and HOLD view. Hover
the mouse pointer over the icon to display a description of the associated function.
In the WTOR and HOLD view, notice that you can display the messages vertically or horizontally by using
```
```
the icons or in the control bar, as follows:
```
- When you select the horizontal layout, a horizontal line separates the **WTOR and HOLD** view from
    the **Console** view. Hover the mouse pointer over the horizontal line to display a description of the
    associated function. To increase the size of the **WTOR and HOLD** view so that you can see more
    messages, use the mouse pointer to drag the horizontal line vertically.
- When you select the vertical layout, a vertical line separates the **WTOR and HOLD** view from the
    **Console** view. Hover the mouse pointer over the vertical line to display a description of the associated
    function. To increase the size of the **WTOR and HOLD** view so that you can see more messages, use the
    mouse pointer to drag the vertical line horizontally.

**8**   z/OS Operator Consoles


**Console view**

The **Console** view shows system messages in this format: timestamp, system name, job name, reply ID,
and message, beginning with the message ID. It also shows any commands that you issued from the
command line.

Use the icons in the control bar above the **Console** view to search, filter, and lock the console. Hover the
mouse pointer over an icon to display a description of the associated function.

You can filter by time and date, system, job name, or message color.

Messages are shown in colors that are consistent with the colors that are shown on traditional z/OS
consoles. To control message colors, use PARMLIB member MPFLST _xx_.

Initially, the **Console** view shows only messages that were issued after you started the console. To view

messages that were issued prior to your starting the console, click above the first message in the
console window. This action retrieves messages from the log, as follows:

- OPERLOG, if it is enabled.
- SYSLOG, if OPERLOG is not enabled. Messages that are retrieved from the SYSLOG do not include the
    color attributes of the messages.

If clicking does not retrieve any messages, it might be because the console is not yet ready. Try

clicking again.

A horizontal line separates messages that were retrieved from the log and the messages that were
retrieved with the z/OS Operator Consoles task. Hover the mouse pointer over the horizontal line to
display a description of the function.

Each time that you click , approximately 200 messages are retrieved from the log (if the messages are

present). When no more messages are available to be retrieved, the is disabled.

The **Console** view keeps a history of up to 5,000 messages that were retrieved from the log. You can
view this history by scrolling up and down. When 5,000 messages have been retrieved, retrieving more
log messages causes the oldest of the log messages to be dropped from the view. You can no longer see

them by scrolling down on the **Console** view. If so, is displayed immediately above the horizontal line.

Click to retrieve the log messages again.

The **Console** view keeps up to 10,000 real-time messages that are retrieved with the z/OS Operator
Consoles task after the console is started. When 10,000 messages have been retrieved, retrieving more
real-time messages causes the oldest 5,000 real-time messages to be automatically dropped from the

view to make room for upcoming messages. At that point, is displayed immediately above the

horizontal line. Click to retrieve the log messages again.

**Sysplex scope:** If OPERLOG is enabled, all systems in the sysplex in which z/OSMF is running support
retrieving log messages. If OPERLOG is not enabled, only the system on which z/OSMF is running supports

retrieving log messages (from SYSLOG), and the icon is disabled for other systems in the sysplex.

**Command line**

From the Command line, you can enter system commands. You can enter MVS commands and other
system commands. You can type the command text in the command line, or select a command from the
list of previously entered commands. When necessary, include the appropriate command character, such
as a dollar sign ($) for JES2. To enter the command, click **Submit**.

```
z/OS Operator Consoles   9
```

```
Message help
With an available IBM Docs server URL is provided, you can quickly see documentation for a message by
hovering the mouse pointer on a message that is displayed on the Console view. You must first use the
Configure Message Help action on the Consoles table on the Overview tab to specify an available IBM
Docs server URL.
```
**Inactive console**

```
If there is no activity for 30 minutes, the status of the console is changed so that the console does not
continue to receive messages – similar to when a Stop action is used.
All interaction with the system is disabled. For example:
```
- The actions **Submit** and **Retrieve Historic Messages Up/Down** are not available. If you hover the
    mouse pointer over either action, the following message is displayed: Console is not active.
- **Delete** is not available. If you hover the mouse pointer over a message, the **Delete** button is not
    displayed.
To resume using the console, close the console tab, then start the console by using the **Start** action.

#### System command reference

```
This topic lists some sources in IBM Documentation for command reference information.
See Table 5 on page 10 for links to command syntax and related reference information. Complete
information for z/OS system commands is available at the IBM Documentation: IBM Documentation
(www.ibm.com/docs/en/zos).
```
```
Table 5. Commands Reference
```
```
Element General Reference
```
```
JES2 z/OS JES2 Commands
```
```
JES3 z/OS JES3 Commands
```
```
MVS z/OS MVS System Commands
```
```
RMF z/OS RMF User's Guide
```
```
SDSF z/OS SDSF Operation and Customization
```
**10**   z/OS Operator Consoles


## Index

**O**

Operator Consoles task 1

```
Index   11
```

IBM®


## Security Configuration Assistant task

# IBM


## Contents

```
Security Configuration Assistant task.....................................................................1
Security Configuration Assistant tab........................................................................................................... 4
Nucleus tab.................................................................................................................................................. 5
Services tab..................................................................................................................................................5
Advanced Configuration tab........................................................................................................................ 7
Imported Products view.............................................................................................................................. 9
```
**ii**


**Security Configuration Assistant task**

```
You can use the Security Configuration Assistant task to verify that security is configured properly for
the z/OSMF host system and its users. You can check the authorizations for z/OSMF itself, including the
nucleus, core and optional services, and advanced configuration options. You can also check the security
setup for other products on your system for which you have security descriptor files.
If you are a security administrator, you can fix missing authorizations for failed validations. In the Security
Configuration Assistant task, you can verify the following areas of the security configuration on your
system:
z/OSMF
Each of the following areas of z/OSMF security configuration is presented in a report format:
```
- Security Configuration Assistant task
- z/OSMF nucleus
- z/OSMF services
- z/OSMF advanced configuration options.
**Imported products**
You can check the security configuration for external products on your z/OS system. This option
requires that you obtain and install a security descriptor file from the product vendor. For more
information, see “Imported Products view” on page 9.
To get started with the Security Configuration Assistant task, click the **Security Configuration Assistant**
icon on the z/OSMF desktop.

**Key features**

```
The Security Configuration Assistant task:
```
- Displays the security setup details in a graphical user interface (GUI).
- Performs security checks on your setup and provides the results in an easy-to-read table format.
- Enables fixing missing authorizations for failed validations.
As you progress through the security checks, you can rerun the Security Configuration Assistant to refresh
the results.

```
Understanding the Security Configuration Assistant layout
The Security Configuration Assistant provides a visual framework for examining particular areas of your
security configuration. The Security Configuration Assistant layout consists of tabbed sections and tabular
reports that can be expanded or compressed, as needed. This framework provides a comprehensive
perspective on your security setup.
With the addition of one or more security descriptor files, you can expand the coverage of the Security
Configuration Assistant to include other products on your system. To do so, you require the product
security descriptor file, which is typically provided by the product vendor.
Figure 1 on page 2 depicts the layout of the Security Configuration Assistant interface, when it is used
to inspect the z/OSMF security configuration.
```
```
Security Configuration Assistant task   1
```

```
Figure 1. Security Configuration Assistant interface layout
```
```
The following areas of the Security Configuration Assistant are highlighted in Figure 1 on page 2:
```
1. User ID or group ID for which security validation will be performed. Specify either a z/OS user ID
    or a RACF group ID. If you specify a group ID, the Security Configuration Assistant checks the RACF
    profiles that are defined to the group. Also, in the row of each validated security resource, an icon
    indicates whether the result is for a user ID or group ID.
2. Select the verification view: z/OSMF or an external product. By default, the z/OSMF view is selected.
    To verify an external product, click the **Imported Products** view. To run the Security Configuration
    Assistant for an external product, you must first import the product security descriptor file into the
    Security Configuration Assistant. Typically, this file is provided by the product vendor.
3. Click **Validate all** to run all possible validation checks for the specified user ID or group ID. This
    action refreshes the Security Configuration Assistant display to show the updated validation results.
4. When it is used to inspect the z/OSMF security configuration, the Security Configuration Assistant
    organizes the validation results for the selected user or group into a set of tabbed areas: **Security**
    **Configuration Assistant** , **Nucleus** , **Services** , and **Advanced Configuration**. Click the tab for the

**2**   Security Configuration Assistant task


```
area that you want to explore. When it is used to inspect the security configuration for an external
product, the Security Configuration Assistant displays the validation results in a scrollable page with
expandable areas.
```
5. You can filter the display to show the enabled z/OSMF services only. This option is available only for
    the Services tab.
6. To filter the display for the currently selected area to a particular type of validation result, select one
    or more of the following filters:
    **Failed**
       Shows only the failed authorizations.
    **Manual**
       Shows only the authorizations that must be created manually by your security administrator.
    **Unknown**
       Shows only the authorizations that cannot be checked by the Security Configuration Assistant.
7. Detailed view of each resource that requires user authorization.

```
If you selected the z/OSMF view, you can view the authorizations for a selected area of z/OSMF
security, as follows:
```
- In the **Security Configuration Assistant** tab, you can check the user's authorizations for
    the Security Configuration Assistant. To view the individual SAF resources that require user
    authorization, select and expand **z/OSMF Security Configuration Assistant**. The required
    authorizations are provided in the secondary tabbed area _Automated_.
- In the **Nucleus** tab, you can check the user's authorizations to the z/OSMF base functions or
    _nucleus_. To view the individual SAF resources that require user authorization, select and expand
    **z/OSMF Nucleus**. The required authorizations are organized into the secondary tabbed areas
    _Automated_ and _Manual_.
- In the **Services** tab, you can check the user's authorizations to the z/OSMF services. To view the
    individual SAF resources that require user authorization, select and expand the service name. The
    required authorizations are provided in the secondary tabbed area _Automated_. To further limit the
    view to just the services that are enabled on the host system, select the option **Show enabled**
    **services only**.
- In the **Advanced Configuration** tab, you can view details about the security structures that are
    needed for a multi-system or multi-sysplex environment. For example, this area shows the status
    for authorizations that are needed for establishing an auto-started server on your system.
If you selected the **Imported Products** view, you can view the authorizations for one or more
external products. To do so, you must first import the product security descriptor file into the Security
Configuration Assistant. In the **Imported Products** tab, import the security descriptor file by using
the **Import** action. Then, select and expand the product name to view the authorizations for the
product.
8. The validation status for the selected view as summarized in a bar chart (in Figure 1 on page 2, the
Services view is shown). Counts of each type of validation check are summarized in the bar chart.
From left to right, the statistics are shown for the automated, configurable, and manual security setup
steps.
The following status values are possible:
**Passed**
Authorization that was created correctly.
**Failed**
Authorization that is missing or in error. Correcting such errors requires you to determine why the
automated security was not performed.
**Unknown**
Authorization that cannot be checked by the Security Configuration Assistant. Check with your
security administrator to determine whether this authorization was created on your system.

```
Security Configuration Assistant task   3
```

```
Manual
Authorization that must be created manually by your security administrator.
A status of Unknown means that the Security Configuration Assistant cannot verify that the
authorization is created. In such cases, your security administrator must verify that the authorization
is created.
```
9. Status of the validation checks for each authorization type: _Automated_ , _Configurable_ , and _Manual_.
    For information about resource profile names that include variable text, see “Configurable resource
    names” on page 6.
10. Click the validate icon or select **Action** > **Validate** to run or repeat the validation checks for the
selected resource. You might use this action iteratively as you resolve any authorization issues that
are indicated by the Security Configuration Assistant.
If a resource profile returns with a status value of _Failed_ after validation, select **Action** > **Review &
Fix** to correct the authorization issue. The **Command** tab displays the commands that are set to be
run to define the specified resource profile and permit required access. Confirm the commands by
clicking **Submit**.
Working with the Security Configuration Assistant task in multiple browsers or browser tabs concurrently
might cause data inconsistencies. It is recommended to work in only one session at a time. Reopen the
task if any data inconsistencies occur.

### Security Configuration Assistant tab

```
You can use the Security Configuration Assistant tab to check the security setup for the Security
Configuration Assistant task.
On the Security Configuration Assistant tab, you can check the validation status of the z/OSMF core
functions.
```
**Columns in the Security Configuration Assistant table**

```
Table 1. Columns in the Security Configuration Assistant table
```
```
Column Description
```
```
Resource Resource profile name.
```
```
Description Explains why the authorization is needed.
```
```
Class SAF resource class.
```
```
Who needs access Users (security groups) who require access to this resource. These groups are
defined on the SEC_GROUPS statement of the IZUPRMxx parmlib member.
Only the current user ID is validated. The Security Configuration Assistant does not
verify that security groups are defined for your z/OSMF configuration; your security
administrator must verify that the groups exist.
For more information about the IZUPRMxx parmlib member, see z/OSMF
Configuration Guide.
```
```
Required access Level of access that is required, such as READ, UPDATE, ALTER, or CONTROL.
```
```
Validated ID The currently validated user ID or group ID.
```
```
Validation result Validation result: Pass , Failed , or Unknown.
```
```
Action After you create or update a security authorization, you can rerun the Security
Configuration Assistant to verify that your change was successful. To do so, click
the Refresh icon in this column. The Security Configuration Assistant task runs
validation again to determine whether the user has the required level of access to
the selected resource name.
```
**4**   Security Configuration Assistant task


### Nucleus tab

```
You can use the Nucleus tab in the Security Configuration Assistant task to check the validation status of
the z/OSMF nucleus functions.
The most basic configuration of z/OSMF is referred to as the nucleus. This type of configuration requires
only a minimal amount of z/OS customization, but provides several key z/OSMF functions that are
required by many z/OS installations.
The z/OSMF nucleus includes the following functions, which are enabled when the z/OSMF server is
started.
```
- WebSphere Liberty profile runtime
- z/OSMF desktop user interface (UI)
- z/OSMF online help system.
The **Nucleus** tab shows which authorizations are required for the z/OSMF nucleus. These authorizations
are used to protect the resources that are used by the z/OSMF server, and to grant users access to the
z/OSMF nucleus functions.
**Tip:** The security job IZUNUSEC contains a set of sample RACF® commands for creating security profiles
for the z/OSMF nucleus. IBM provides this job in SYS1.SAMPLIB.

**Columns in the Nucleus table**

```
Table 2. Columns in the Nucleus table
```
```
Column Description
```
```
Resource Resource profile name.
```
```
Description Explains why the authorization is needed.
```
```
Class SAF resource class.
```
```
Who needs access Users (security groups) who require access to this resource. These groups are
defined on the SEC_GROUPS statement of the IZUPRMxx parmlib member.
Only the current user ID is validated. The Security Configuration Assistant does not
verify that security groups are defined for your z/OSMF configuration; your security
administrator must verify that the groups exist.
For more information about the IZUPRMxx parmlib member, see z/OSMF
Configuration Guide.
```
```
Validated ID The currently validated user ID or group ID.
```
```
Validation result Validation result: Pass , Failed , or Unknown.
```
```
Action After you create or update a security authorization, you can rerun the Security
Configuration Assistant to verify that your change was successful. To do so, click
the Refresh icon in this column. The Security Configuration Assistant task runs
validation again to determine whether the user has the required level of access to
the selected resource name.
```
### Services tab

```
You can use the Services tab in the Security Configuration Assistant task to check the security setup for
the z/OSMF core services and optional services.
In z/OSMF, you can further extend the functions of the nucleus by adding core services and optional
services. These services include the z/OSMF system management tasks and the z/OSMF REST API
interfaces.
```
```
Security Configuration Assistant task   5
```

```
The security validation status for each service is listed in the Services tab.
In general, enabling a z/OSMF service involves the following activities:
```
- Configuring any prerequisite services that might be required by the service.
- Creating security profiles for the z/OSMF tasks and REST services that are associated with the service.
    IBM provides a set of IZU _nn_ SEC jobs in SYS1.SAMPLIB with RACF commands to help with performing
    these changes. Each IZU _nn_ SEC job is associated with a service, as described in _z/OSMF Configuration_
    _Guide_.
- Performing the various z/OS system customization updates, if any, that are associated with each
    service.
**Tip:** Because some services require other services to be enabled, you might need to configure more
services than the ones you plan to use. If so, these dependencies are noted in each service description in
_z/OSMF Configuration Guide_.

**Columns in the Services table**

```
Table 3. Columns in the Services table
```
```
Column Description
```
```
Resource Resource profile name.
```
```
Description Explains why the authorization is needed.
```
```
Class SAF resource class.
```
```
Who needs access Users (security groups) who require access to this resource. These groups are
defined on the SEC_GROUPS statement of the IZUPRMxx parmlib member.
Only the current user ID is validated. The Security Configuration Assistant does not
verify that security groups are defined for your z/OSMF configuration; your security
administrator must verify that the groups exist.
For more information about the IZUPRMxx parmlib member, see z/OSMF
Configuration Guide.
```
```
Required access Level of access that is required, such as READ, UPDATE, ALTER, or CONTROL.
```
```
Validated ID The currently validated user ID or group ID.
```
```
Validation result Validation result: Pass , Failed , or Unknown.
```
```
Action After you create or update a security authorization, you can rerun the Security
Configuration Assistant to verify that your change was successful. To do so, click
the Refresh icon in this column. The Security Configuration Assistant task runs
validation again to determine whether the user has the required level of access to
the selected resource name.
```
**Configurable resource names**

```
Your z/OSMF security authorizations might include RACF resource profile names that include one or
more variables. Such RACF resource profile names are considered to be configurable ; they can be set to
variables that meet the requirements of your installation.
For example, the following resource profile includes a variable segment to allow for the specification of a
unique console name:
```
```
MVS.MCSOPER. <console_name>
```
```
With the Security Configuration Assistant task, you can substitute actual values for these variables and
run validation on the resource profiles.
```
**6**   Security Configuration Assistant task


```
On the Services tab, locate the resource profiles that are configurable (contain variable values). To reveal
an action menu (a vertical ellipsis), hover the mouse pointer over particular resource profiles.
In the action menu, the available actions are as follows:
Add
Input values for the resource profile variables.
Edit
Edit the existing values for the resource profile variables.
Remove
Remove values for resource profile variables. Because this action cannot be undone, you are
prompted to confirm your decision.
When you add values to the resource profile, you are replacing the variable portion with an actual value.
You must ensure that the resource profile is correct for your system.
When you add values to the resource profile, if the toggle option Apply this value to all the resource
names that contain same variables is set to On , all of the resource profiles that exactly match the
variables in the current service are set with the same value. Resource profiles that contain more or fewer
variables are not affected.
When you remove values from the resource profile, if the toggle option Remove all the same value for
resource names that contain same variables is set to On , all of the resource profiles that exactly match
the variables with the same values in the current service are removed. Resource profiles that contain
more or fewer variables or have different values are not affected.
The Security Configuration Assistant task retains the resource profile names that you save — you can
access them again on subsequent uses. Also, the saved resource profile names are visible and usable by
other users of the Security Configuration Assistant task.
The Security Configuration Assistant task cannot validate a resource profile that contains variable
values. Therefore, if you remove an actual value from a profile, it cannot be validated with the Security
Configuration Assistant task.
```
### Advanced Configuration tab

```
You can use the Advanced Configuration tab in the Security Configuration Assistant task to check the
status of advanced configuration options on your system. For example, this area shows the status for
authorizations that are needed for a multi-system or multiple sysplex environments, or for establishing an
auto-started z/OSMF server on your system.
On the Advanced Configuration tab, you can check the validation status of the z/OSMF advanced
configuration options.
```
**Columns in the Advanced Configuration table**

```
Table 4. Columns in the Advanced Configuration table
```
```
Column Description
```
```
Resource Resource profile name.
```
```
Description Explains why the authorization is needed.
```
```
Class SAF resource class.
```
```
Security Configuration Assistant task   7
```

```
Table 4. Columns in the Advanced Configuration table (continued)
```
```
Column Description
```
```
Who needs access Users (security groups) who require access to this resource. These groups are
defined on the SEC_GROUPS statement of the IZUPRMxx parmlib member.
Only the current user ID is validated. The Security Configuration Assistant does not
verify that security groups are defined for your z/OSMF configuration; your security
administrator must verify that the groups exist.
For more information about the IZUPRMxx parmlib member, see z/OSMF
Configuration Guide.
```
```
Required access Level of access that is required, such as READ, UPDATE, ALTER, or CONTROL.
```
```
Validated ID The currently validated user ID or group ID.
```
```
Validation result Validation result: Pass , Failed , or Unknown.
```
```
Action After you create or update a security authorization, you can rerun the Security
Configuration Assistant to verify that your change was successful. To do so, click
the Refresh icon in this column. The Security Configuration Assistant task runs
validation again to determine whether the user has the required level of access to
the selected resource name.
```
```
Configurable resource names
Your z/OSMF security authorizations might include RACF resource profile names that include one or
more variables. Such RACF resource profile names are considered to be configurable ; they can be set to
variables that meet the requirements of your installation.
For example, the following resource profile includes a variable segment to allow for the specification of a
unique console name:
```
```
MVS.MCSOPER. <console_name>
```
```
With the Security Configuration Assistant task, you can substitute actual values for these variables and
run validation on the resource profiles.
On the Advanced Configuration tab, locate the resource profiles that are configurable (contain variable
values). To reveal an action menu (a vertical ellipsis), hover the mouse pointer over particular resource
profiles.
In the action menu, the available actions are as follows:
Add
Input values for the resource profile variables.
Edit
Edit the existing values for the resource profile variables.
Remove
Remove values for resource profile variables. Because this action cannot be undone, you are
prompted to confirm your decision.
When you add values to the resource profile, you are replacing the variable portion with an actual value.
You must ensure that the resource profile is correct for your system.
When you add values to the resource profile, if the toggle option Apply this value to all the resource
names that contain same variables is set to On , all of the resource profiles that exactly match the
variables in the current service are set with the same value. Resource profiles that contain more or fewer
variables are not affected.
When you remove values from the resource profile, if the toggle option Remove all the same value for
resource names that contain same variables is set to On , all of the resource profiles that exactly match
```
**8**   Security Configuration Assistant task


```
the variables with the same values in the current service are removed. Resource profiles that contain
more or fewer variables or have different values are not affected.
The Security Configuration Assistant task retains the resource profile names that you save — you can
access them again on subsequent uses. Also, the saved resource profile names are visible and usable by
other users of the Security Configuration Assistant task.
The Security Configuration Assistant task cannot validate a resource profile that contains variable
values. Therefore, if you remove an actual value from a profile, it cannot be validated with the Security
Configuration Assistant task.
```
### Imported Products view

```
In the Imported Products view, you can check the security configuration for external products on your
z/OS system. This option requires a security descriptor file, which is typically provided by the product
vendor.
In general, configuring the security for a product involves the following activities:
```
- Creating security profiles for the product.
- Performing the various z/OS system customization updates, if any, that are required by the product.

**Before you begin**

1. Obtain the security descriptor file from the product vendor. The file format is JSON.
2. Ask your system programmer to install the security descriptor file in a USS directory. Make sure
    the server has READ access to the file and its directory. The default directory for loading security
    descriptor files is the following z/OSMF directory: <IZU_CONFIG_DIR>/configuration/security.
    By default, this directory is named /global/zosmf/configuration/security.
3. Ask your system programmer to restart the z/OSMF server to make this change effective.
4. In the **Imported Products** view, click **Import**. Specify the USS directory to import from. This action
    displays a list of the available security descriptor files in your specified directory.
5. Select the files for the products that you want to verify and click **Load**. If the file contains an error that
    prevents it from being loaded, an error message is displayed. For more details, such as the line number
    of the error, click the information icon for the file name.

**Columns in the Imported Products table**

```
The security validation status for each product is listed in the Imported Products table.
```
```
Table 5. Columns in the Imported Products table
```
```
Column Description
```
```
Resource Resource profile name.
```
```
Description Explains why the authorization is needed.
```
```
Class SAF resource class.
```
```
Who needs access Users (security groups) who require access to this resource.
Only the current user ID is validated. The Security Configuration Assistant does
not verify that security groups are defined for the external product; your security
administrator must verify that the groups exist.
```
```
Required access Level of access that is required, such as READ, UPDATE, ALTER, or CONTROL.
```
```
Validated ID The currently validated user ID or group ID.
```
```
Validation result Validation result: Pass , Failed , or Unknown.
```
```
Security Configuration Assistant task   9
```

```
Table 5. Columns in the Imported Products table (continued)
```
```
Column Description
```
```
Action After you create or update a security authorization, you can rerun the Security
Configuration Assistant to verify that your change was successful. To do so, click
the Validate action in this column. The Security Configuration Assistant task runs
validation again to indicate whether the user has the required level of access to the
selected resource name.
If you modify a security descriptor file and want to reload it, click Reload. This
action causes the Security Configuration Assistant to refresh the security data for
the product. You might use this action if you add variable values to the file, as
described in “Configurable resource names” on page 10.
To remove a security descriptor file from the Security Configuration Assistant task,
click Unload. This action removes the product from the Security Configuration
Assistant task. However, the security descriptor file is retained in z/OSMF. If you
added variable values to the security descriptor file (see “Configurable resource
names” on page 10), you can undo these changes in the file by selecting the
option Remove the variable values added. If you later decide to resume security
checking for the product, you must import the security descriptor file into the
Security Configuration Assistant task again.
```
```
Configurable resource names
The security authorizations for a product might include RACF resource profile names with one or more
variables. Such RACF resource profile names are considered to be configurable ; they can be set to
variables that meet the requirements of your installation.
For example, the following resource profile includes a variable segment to allow for the specification of a
unique user ID:
```
```
STGADMIN.EDG.OWNER. <userid>
```
```
With the Security Configuration Assistant task, you can substitute actual values for variables and run
validation on the resource profiles.
In the Imported Products table, locate the resource profiles that are configurable (contain variable
values). To reveal an action menu (a vertical ellipsis), hover the mouse pointer over particular resource
profiles.
In the action menu, the available actions are as follows:
Add
Input values for the resource profile variables.
Edit
Edit the existing values for the resource profile variables.
Remove
Remove values for resource profile variables. Because this action cannot be undone, you are
prompted to confirm your decision.
When you add values to the resource profile, you are replacing the variable portion with an actual value.
You must ensure that the resource profile is correct for your system.
When you add values to the resource profile, if the toggle option Apply this value to all the resource
names that contain same variables is set to On , all of the resource profiles that exactly match the
variables in the current service are set with the same value. Resource profiles that contain more or fewer
variables are not affected.
When you remove values from the resource profile, if the toggle option Remove all the same value for
resource names that contain same variables is set to On , all of the resource profiles that exactly match
```
**10**   Security Configuration Assistant task


the variables with the same values in the current service are removed. Resource profiles that contain
more or fewer variables or have different values are not affected.

The Security Configuration Assistant task retains the resource profile names that you save — you can
access them again on subsequent uses. Also, the saved resource profile names are visible and usable by
other users of the Security Configuration Assistant task.

The Security Configuration Assistant task cannot validate a resource profile that contains variable
values. Therefore, if you remove an actual value from a profile, it cannot be validated with the Security
Configuration Assistant task.

```
Security Configuration Assistant task   11
```

IBM®


## Links in the z/OSMF navigation area

# IBM


## Contents

**Launching links..................................................................................................... 1**

**Index.................................................................................................................... 2**

**ii**


**Links in the z/OSMF navigation area**

```
When you are performing system management tasks with z/OSMF, you might find it helpful to refer to
other tools and information on the web. The z/OSMF navigation area comes supplied with several useful
links in the Links category.
Your installation can customize the z/OSMF navigation area with its own links, as needed. Links can be
added to the Links category or to any other category in the z/OSMF navigation area. To define links for
z/OSMF, you must be authorized to do so. By default, only the z/OSMF Administrator can define links.
When you select a link, the link launches in either a separate browser window or tab, or as a tab in the
z/OSMF work area. This launch behavior is specified when the link is defined to z/OSMF.
```
**Launching links**

```
To launch a link, select the link from the appropriate category in the navigation area.
```
**Procedure**

1. Expand the category in the navigation area. If the link is not listed, the link is either not defined or you
    have not been authorized to access the link.
2. Select the link to be launched.

**Results**

```
The link launches in a separate browser window or tab, or as a tab in the work area. This launch behavior
was specified for the link when it was defined to z/OSMF.
```
```
Links in the z/OSMF navigation area   1
```

## Index

**L**

launching custom links 1
launching links 1
links 1

**S**

selecting links 1

**2**   Links in the z/OSMF navigation area



IBM®


## Performance

# IBM


## Contents

**Performance......................................................................................................... 1**

**Index.................................................................................................................... 2**

**ii**


**Performance**

```
This section, when the appropriate plugins are installed, describes the z/OSMF tasks that you can use
to query the status of the Capacity Provisioning Manager, monitor the performance of the z/OS®, AIX®,
Linux®, and Windows systems in your enterprise, administer and operate WLM, manage WLM service
definitions and policies, and define the systems to be monitored.
```
```
Performance   1
```

## Index

**P**

performance 1

**2**   Performance



IBM®


## Capacity Provisioning Task

# IBM


## Contents

```
Capacity Provisioning Task.................................................................................... 1
Provisioning manager...................................................................................................................................1
Managing connections............................................................................................................................2
Viewing status reports............................................................................................................................5
Managing domain configurations.............................................................................................................. 51
Managing a domain configuration........................................................................................................53
Installing domain configurations......................................................................................................... 60
Activating domain configurations........................................................................................................ 61
Exporting domain configurations to a file............................................................................................62
Importing domain configurations from a file.......................................................................................63
Importing domain configurations from a domain............................................................................... 64
Managing policies...................................................................................................................................... 65
Managing a policy.................................................................................................................................67
Installing policies............................................................................................................................... 114
Activating policies.............................................................................................................................. 115
Exporting policies to a file..................................................................................................................116
Importing policies from a file.............................................................................................................116
Importing policies from a domain..................................................................................................... 117
Settings.................................................................................................................................................... 118
Capacity Provisioning Basics...................................................................................................................118
Domain configuration.........................................................................................................................118
Provisioning Policy............................................................................................................................. 119
Repository.......................................................................................................................................... 121
Naming Conventions.......................................................................................................................... 124
Messages............................................................................................................................................125
Table actions...................................................................................................................................... 126
```
**ii**


**Capacity Provisioning Task**

```
The Capacity Provisioning task in z/OSMF provides a browser-based user interface for working with the
Capacity Provisioning Manager on your z/OS® system. Through this task, you can manage your domain
configurations and policies and request various reports of the status of the Capacity Provisioning Manager.
With the Capacity Provisioning task in z/OSMF you can:
```
- Manage domain configurations and policies:
    - Define new domain configurations and policies or display existing domain configurations or policies.
    - Install domain configurations and policies. You can transfer a domain configuration or policy from the
       z/OSMF repository to the domain configuration or policy repository of your domain.
    - Activate domain configurations and policies. You can change the domain configuration which the
       Provisioning Manager uses to control the domain by selecting a different one from the domain
       configuration repository. Policies can be activated from the policy repository. Optionally, you can also
       activate a domain configuration or a policy immediately after it has been installed.
    - Import and export domain configurations and policies. You can import a domain configuration from
       your local workstation or from the domain configuration repository of a domain to the z/OSMF
       repository. Export transfers the data in the reverse direction. The same can be done with policies, but
       they are stored in the policy repository on the domain.
- Manage connections to your Provisioning Manager. You can manage connections to the Provisioning
    Manager, and use them to transfer provisioning policies and domain configurations to the Provisioning
    Manager, or to query various status reports. The connection to the Provisioning Manager is established
    using a CIM server running on the same system as the Provisioning Manager. You can use the
    Provisioning Manager running on the same system on which z/OSMF is running or connect to a remote
    Provisioning Manager.
- View the status of your Provisioning Manager. The following status reports are available:
    - Domain status. This report contains information about the current setup of the domain that is
       managed by the Provisioning Manager.
    - Active configuration. This report contains information about the active domain configuration and
       its status. You can view a detailed status of the CPCs and systems that belong to the active
       configuration.
    - Active policy. This report contains information about the active policy and its status. You can view
       detailed information about each policy element.
**Note:** If an action is not listed in the **Overview** tab, the z/OSMF role to which your user ID is assigned is
not authorized to perform that action. To obtain authorization, contact your z/OSMF administrator.

### Provisioning manager

```
On the Provisioning Manager page you can manage connections to Provisioning Managers and use a
connection to access a domain. You can define and modify connections, and use a selected connection to
view the status of a Provisioning Manager.
The Provisioning Manager is the component of Capacity Provisioning which, based on your active policy
and domain configuration, monitors the domain and performs provisioning and deprovisioning requests
for additional capacity. The Provisioning Manager monitors the workload on a set of z/OS systems
and organizes the provisioning of additional capacity to these systems when required. You define the
systems to be observed in a domain configuration file. Details of additional capacity and the rules for its
provisioning are stored in a policy file. These files are managed using the Capacity Provisioning task.
You can manage connections to the Provisioning Manager, and use them to transfer provisioning policies
and domain configurations to the Provisioning Manager, or to query various status reports. You can use
```
```
Capacity Provisioning Task   1
```

```
the Provisioning Manager running on the same system on which z/OSMF is running or connect to a remote
Provisioning Manager.
Before connecting to a Provisioning Manager, the following prerequisites must be met:
```
- You must be a member of the Provisioning Manager query security group.
- You can only communicate with a Provisioning Manager which delivers report information, this is the
    case if it runs on a system with z/OS V1R12 or higher.
- If you want to install and activate policies or domain configurations, you must also be a member of the
    Provisioning Manager control security group.
The Provisioning Manager runs on a z/OS system and controls one domain at a time. To ensure availability,
you can install and set up the Provisioning Manager on more than one system. Only one instance of the
Provisioning Manager can be active at a time. You must create a connection definition for each system on
which the Provisioning Manager can run to be able to access the Provisioning Manager when it runs on
that system.
The connections that have been defined in z/OSMF are stored in the z/OSMF repository and are listed in
the “Connections table” on page 2 on the Provisioning Manager page.

#### Managing connections

```
The table on the Provisioning Manager page shows information about the defined connections. The
defined connections can be used to access a domain. You can define and modify connections, and use a
selected connection to view the status of a Provisioning Manager.
The Provisioning Manager is the component of Capacity Provisioning which monitors the domain and
performs provisioning requests, based on your active policy and domain configuration. Connections
describe how to connect z/OSMF to a Provisioning Manager which is responsible for a domain. If the
Provisioning Manager can be started on more than one system, you must create a connection definition
for each system.
The defined connections can be used to request status reports and they are used when provisioning
policies or domain configurations are installed and activated for a domain. Also when policies or domain
configurations are imported from a domain you have to select the connection to be used.
To connect z/OSMF to a Provisioning Manager, you need a CIM server running on the same system as the
Provisioning Manager.
The connections that have been defined in z/OSMF are stored in the z/OSMF repository and are listed in
the connections table on the Provisioning Manager page. The repository is shared across all users that are
authorized to access the Capacity Provisioning task; therefore, all users see the same list of connections.
To retrieve the latest information from the repository and refresh the connections table, click the Refresh
button.
For a description of the columns in the connections table, see Table 1 on page 2. For a description of
the actions that you can take against connections, see “Actions for connections” on page 3.
```
**Connections table**

```
Table 1. Columns in the connections table
```
```
Column name Description
```
```
Host Address Symbolic host name or IP address of the system on which the Provisioning
Manager and the CIM server are running. If a connection to the local
Provisioning Manager is used, "Same system as z/OSMF" is displayed as
host address.
```
```
Protocol Indicates if HTTP or HTTPS is used to establish a connection to the CIM
server.
```
**2**   Capacity Provisioning Task


_Table 1. Columns in the connections table (continued)_

**Column name Description**

**Port** Port number where the CIM server is listening for HTTP or HTTPS requests.
The port number is required, and it must be an integer between 1 and

65535. The default port number for HTTP is 5988 and for HTTPS 5989.

```
Actions for connections
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected connection. To use a targeted action, you must
    select one or more connections.
- **General actions:** Actions that apply to connections. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first connection.

_Table 2. Targeted actions_

**Action Description**

**View** View the status of the Provisioning Manager running on the system defined
in the selected connection. You may request a report of the status of the
domain, the active policy or the active domain configuration. A window
opens which shows a list of all possible domains that can be accessed
using the selected connection. The requested report is displayed in the
**Provisioning Manager** tab.

**Modify** Modify the selected connection. The selected connection is opened in edit
mode.

**Delete** Delete the selected connections.

_Table 3. General actions_

**Action Description**

**New** Define a new connection.

```
Defining connections
To define and add new connection entries, use the New action provided on the Provisioning Manager
page.
On the New Connection page you define the details of a connection. The connection can be used to
connect z/OSMF to a Provisioning Manager which is responsible for a domain.
Select Use same system as z/OSMF
to define a connection to a Provisioning Manager running on the same system as z/OSMF. When
selecting such a connection the following properties (host address, protocol, and port) are hidden as
they are determined automatically.
Select Use the following connection properties
and specify host address, protocol, and port.
```
```
Capacity Provisioning Task   3
```

```
Table 4. Connection entry fields
```
```
Field Description
```
```
Host address Symbolic host name or IP address of the system on which the Provisioning
Manager and the CIM server are running. The host name or IP address is
required. It can contain up to 255 characters.
```
```
Protocol Indicates if HTTP or HTTPS is used to establish a connection to the CIM
server.
```
```
Port Port number where the CIM server is listening for HTTP or HTTPS requests.
The port number is required, and it must be an integer between 1 and
```
65535. The default port number for HTTP is 5988 and for HTTPS 5989.

**Procedure**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. From the **Actions** menu, select **New**. The New Connection page is displayed.
4. Specify the appropriate settings.
5. Click **OK** to save your changes. The newly created connection is displayed in the connections table.

```
Modifying connections
To modify a connection definition, use the Modify action provided on the Provisioning Manager page.
Select Use same system as z/OSMF
to define a connection to a Provisioning Manager running on the same system as z/OSMF. When
selecting such a connection the following properties (host address, protocol, and port) are hidden as
they are determined automatically.
Select Use the following connection properties
and specify host address, protocol, and port.
```
```
Table 5. Connection entry fields
```
```
Field Description
```
```
Host address Symbolic host name or IP address of the system on which the Provisioning
Manager and the CIM server are running. The host name or IP address is
required. It can contain up to 255 characters.
```
```
Protocol Indicates if HTTP or HTTPS is used to establish a connection to the CIM
server.
```
```
Port Port number where the CIM server is listening for HTTP or HTTPS requests.
The port number is required, and it must be an integer between 1 and
```
65535. The default port number for HTTP is 5988 and for HTTPS 5989.

**Procedure**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to be modified. You can select only one connection.
4. From the **Actions** menu, select **Modify**. The Modify Connection page is displayed.
5. Modify the settings as needed.

**4**   Capacity Provisioning Task


6. Click **OK** to save your changes.

```
Deleting connections
To permanently remove connection entries, use the Delete action provided on the Provisioning Manager
page.
```
**Procedure**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection entries to be deleted. You can select one or more
    connection entries.
4. From the **Actions** menu, select **Delete**. A confirmation window displays the selected connections.
5. Click **OK** to delete the selected connection entries. You cannot undo this action.

#### Viewing status reports

```
To view the status of a Provisioning Manager, use the View > Domain Status, View > Active
Configuration or View > Active Policy actions provided on the Provisioning Manager page.
The status reports show information about the current setup of the domain that is managed by the
Provisioning Manager. Capacity Provisioning can maintain the configuration of more than one domain for
different purposes. A domain is identified by a unique name.
The domain consists of:
```
- Observed systems that can trigger provisioning, where the number of logical processors is monitored or
    where the defined capacity can be changed.
- Central Processor Complexes (CPCs) on which the temporary capacity and the Group Capacity can be
    changed.
To be able to view the status of a Provisioning Manager, you have to define how this Provisioning Manager
can be accessed, see “Managing connections” on page 2.

**Procedure to view a status report**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Domain Status** , **View > Active Configuration** or **View > Active**
    **Policy** depending on which of the three status reports you want to view. A window opens which shows
    a list of all possible domains that can be reached using the selected connection. For more details
    about each field, see help topics “Domain status” on page 5, “Active configuration” on page 7 or
    “Active policy” on page 17.
5. Select a domain and click **OK**. The Domain Status page, Active Configuration or Active Policy page is
    displayed in the **Provisioning Manager** tab.

```
Domain status
The Domain Status page shows information about the current status of the Provisioning Manager and the
domain that it manages.
All dates and times are displayed using the time zone displayed. The time zone can be changed using the
Settings link in the Overview tab.
```
```
Capacity Provisioning Task   5
```

```
Table 6. Reported domain status
```
```
Field Description
```
```
Domain name Name of the provisioning domain.
```
```
Provisioning Manager start time Time when the Provisioning Manager for the specified domain was started.
```
```
Processing mode The active processing mode. The possible values for the processing mode
are:
Manual
You can issue manual activation and deactivation commands to the
Provisioning Manager, but the Provisioning Manager does not activate
additional capacity or increase capacity by itself.
Analysis
You are informed through console messages if any additional capacity is
required.
Confirmation
You are informed of proposed capacity changes through console
messages, and you are asked to confirm the changes.
Autonomic
The Provisioning Manager autonomically adjusts the capacity settings of
the resources.
```
```
Processing mode activation
time
```
```
Time when the processing mode was activated.
```
```
Configuration name Name of the active domain configuration. A domain configuration name of
*none indicates that the default domain configuration is active as you have
never activated your own domain configuration.
```
```
Configuration activation time Time the active domain configuration was activated. In case of domain
configuration *none the reported time is the time when the Provisioning
Manager first ran.
```
```
Policy name Name of the active provisioning policy. A policy name of *none indicates
that the default policy is active as you have never activated your own policy.
```
```
Policy activation time Time the policy was activated. In case of policy *none the reported time is
the time when the Provisioning Manager first ran.
```
```
Code level Service information about the code level of the Provisioning Manager.
```
```
Note: The activation times for the processing mode, the domain configuration and the policy may have
occurred in a previous run of the Provisioning Manager and may be earlier than the current start time of
the Provisioning Manager.
To refresh the Domain Status click the Refresh button. The Last refresh field shows the time of the last
snapshot.
```
```
View another report for the same domain
To view a different report for the same domain, click the Report button and select one of the available
reports:
```
- Domain Status
- Active Configuration
- Active Policy
- Health

**6**   Capacity Provisioning Task


**Procedure to view the domain status**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Domain Status**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Domain Status page is displayed in the **Provisioning Manager** tab.

```
Active configuration
The Active Configuration page shows information about the active domain configuration and the status of
its CPCs and systems.
The information reported is:
```
- Name of the active domain configuration.
- Its current enabled/disabled status. A domain configuration is disabled if the Provisioning Manager is
    running in processing mode _Manual_. In all other processing modes the domain configuration is enabled.
- The **CPCs** tab shows information about the CPCs defined in the domain configuration.
- The **Systems** tab shows information about the systems in the domain configuration.
**Note:** If **Active configuration** is _*none_ , "There is no data to display" is displayed in the table area.

```
CPCs tab
To view information about the CPCs that are defined in the active domain configuration, select the CPCs
tab.
The CPCs tab shows the set of CPCs for which the Provisioning Manager manages capacity. These CPCs
must be defined at your HMC.
```
_Table 7. Columns in the CPCs table_

**Column Description**

**CPC** Name of the CPC.

**Correlation Status** Correlation status of the CPC at the support element (SE) or at the Hardware
Management Console (HMC). It can be one of the following values:
**Not correlated**
CPC has not yet been detected at the SE or HMC. It cannot be used to
activate temporary capacity.
**Correlated**
The CPC has been detected at the SE or HMC but detailed information
about it is not yet available to the Provisioning Manager. It cannot be
used at present to activate temporary capacity.
**Matched**
The CPC has been detected at the SE or HMC and detailed information
about it is available. Temporary capacity can be activated on it if a valid
record exists.

**Record ID** The record ID of the CPC.

**Active MSU** How many MSU are currently active for the record.

**Active zAAPs** How many zAAPs are currently active for the record.

```
Capacity Provisioning Task   7
```

```
Table 7. Columns in the CPCs table (continued)
```
```
Column Description
```
```
Active zIIPs How many zIIPs are currently active for the record.
```
```
Status Indicates whether the CPC is enabled or disabled.
```
```
Default status The default status indicates whether the CPC was enabled or disabled by
default when the domain configuration was activated.
```
```
Active IFLs How many IFLs are currently active for the record.
```
```
Active ICFs How many ICFs are currently active for the record.
```
```
Active SAPs How many SAPs are currently active for the record.
```
**Actions for CPC entries**

```
Table 8. Actions for CPC entries
```
```
Action Description
```
```
View CPC Details View details about the selected CPC.
```
**Systems tab**

```
To view information about the systems that are defined in the active domain configuration, select the
Systems tab.
The Systems tab shows the set of the systems to be monitored by the Provisioning Manager for capacity
shortages.
```
```
Table 9. Columns in the systems table
```
```
Column Description
```
```
System Name Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Connection Status The connection status of the system can be one of the following values:
```
```
Not connected
The connection to the system has not yet been established successfully.
The Provisioning Manager is trying to connect to the system at the
related host address.
Available
The connection to the system has been successfully established.
Temporarily unavailable
The connection to the system has been suspended after successfully
establishing a connection. The Provisioning Manager tries to connect to
the system again.
Unavailable
The connection to the system has been broken. The Provisioning
Manager tries to connect to the system again.
```
**8**   Capacity Provisioning Task


_Table 9. Columns in the systems table (continued)_

**Column Description**

**System Status** The system status can be one of the following values:

```
Unknown
The system is not identified. The name of the system or the name of the
sysplex has not yet been retrieved.
Found
The system is not correlated. The Provisioning Manager has not yet
detected if the name of the system and the name of the sysplex this
system belongs to match the names in the domain configuration.
Correct
The version of this system is not available. The version of the operating
system has not yet been retrieved.
Incorrect
This system is not the defined system. The name of the system or
the name of the sysplex this system belongs to does not match the
definition of these names in the domain configuration.
Unsupported version
The version of the system is not supported. The version of the system is
not supported by the Provisioning Manager.
CPC unknown
The CPC serial number is not available. The serial number of the CPC on
which the system is running has not yet been retrieved.
CPC unknown name
The CPC serial number is not correlated. The serial number of the CPC
has not yet been correlated with the name of the CPC.
CPC name matched
The CPC is not correlated. The CPC has not yet been correlated. The
Provisioning Manager has not detected if the CPC the system is running
on is defined in the domain configuration.
CPC not in domain
The CPC is not part of the domain. The CPC the system is running on is
not defined in the domain configuration.
Sysplex unknown mintime
Insufficient information for retrieving metric values. The information for
retrieving metric values has not yet been retrieved, or could not be
retrieved.
Sysplex unknown
The information about the WLM service definition is not available. Name
of the installed WLM service definition, the name of the active WLM
policy or the activation time of this policy has not yet been retrieved.
Sysplex unknown SCP
The information about WLM service class periods is not available. The
service class periods defined in the active WLM policy have not yet been
retrieved.
Sysplex valid
Detailed information about the system is available and is displayed in
the WLM section and in the Defined Capacity section of the System
Details page.
```
```
Capacity Provisioning Task   9
```

```
Table 9. Columns in the systems table (continued)
```
```
Column Description
```
```
Observation Status The observation status information. The system can be observed if the
domain configuration is enabled and the system is enabled. This status can
be:
Primary observed
The Provisioning Manager retrieves information from the system at the
primary host address.
Alternate observed
The Provisioning Manager retrieves information from the system at the
alternate host address.
Both observed
The Provisioning Manager retrieves information from the system at the
primary host address and from the system at the alternate host address.
This is the case if both systems are unavailable.
None observed
The Provisioning Manager does not retrieve information from the system
at the primary host address nor from the system at the alternate host
address. The system is not observed if the domain configuration is
disabled or the system is disabled.
```
```
Status Indicates whether the system is enabled or disabled.
```
```
Default status The default status indicates whether the system was enabled or disabled by
default when the domain configuration was activated.
```
**Actions for system entries**

```
Table 10. Actions for system entries
```
```
Action Description
```
```
View System Details View details about the selected system.
```
**Viewing CPC and system details**

```
For further details about CPCs, see help topic “CPC details” on page 11 and for more details about
systems, see help topic “System details” on page 14.
```
**View another report for the same domain**

```
To view a different report for the same domain, click the Report button and select one of the available
reports:
```
- Domain Status
- Active Configuration
- Active Policy
- Health

**Procedure to view the Active Configuration**

1. To show information about the Active configuration for a domain select the **Capacity Provisioning** task
    under the Performance category in the navigation area. The Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.

**10**   Capacity Provisioning Task


3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Configuration**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Active Configuration page is displayed in the **Provisioning Manager**
    tab.

```
CPC details
The CPC Details page shows detailed information about the selected CPC defined in the active domain
configuration of a Provisioning Manager.
```
**General**

```
This section shows runtime information about the selected CPC. All dates and times are displayed using
the time zone displayed. The time zone can be changed using the Settings link in the Overview tab.
```
_Table 11. CPC general fields_

**Field Description**

**Configuration** Name of the active configuration.

**CPC** Name of the CPC.

**Serial** The serial number of the CPC.

**Machine type - model** The CPC hardware type and model. If it is supported then detailed capacity
information about the CPC follows in the “Configuration” on page 12 and
optionally in the “On/Off CoD Status” on page 12 section.

**Correlation status** The correlation status of the CPC at the support element (SE) or at the
Hardware Management Console (HMC). This status can be:
**Not correlated**
The CPC has not yet been detected at the SE or HMC. It cannot be used
to activate temporary capacity.
**Correlated**
The CPC has been detected at the SE or HMC but detailed information
about it is not yet available to the Provisioning Manager. It cannot be
used at present to activate temporary capacity.
**Matched**
The CPC has been detected at the SE or HMC and detailed information
about it is available. Temporary capacity can be activated on it if a valid
record exists.

**Correlation status since** The time when the correlation status was reached.

**Status** The current enabled/disabled status of the CPC.

**Default status** The default status indicates whether the CPC was enabled or disabled by
default when the domain configuration was activated.

**Power® save mode** Optionally, if the CPC supports static power save function, this field shows
whether the function is enabled or disabled. In disabled state it is also
reported when it is not allowed to enable static power save mode.

```
Capacity Provisioning Task   11
```

```
Table 11. CPC general fields (continued)
```
```
Field Description
```
```
Error status The error status, which indicates whether the CPC is supported for capacity
management.
No Error
CPC is supported.
any other value
The reason, why it is not supported. For example: the record has expired
or the configuration of the CPC does not allow commands to perform the
temporary capacity change.
```
```
Configuration
If the CPC is at a supported hardware level then detailed information about the CPC is displayed in the
Configuration section:
```
```
Table 12. CPC configuration
```
```
Field Description
```
```
Model / Current The current CPC model.
```
```
Model / Permanent The permanent CPC model.
```
```
MSU / Current Capacity in MSU for the current model.
```
```
MSU / Permanent Capacity in MSU for the permanent model.
```
```
zAAPs The number of zAAPs for the current model.
```
```
zIIPs The number of zIIPs for the current model.
```
```
IFLs The number of IFLs for the current model.
```
```
ICFs The number of ICFs for the current model.
```
```
SAPs The number of SAPs for the current model.
```
```
Spares The number of spare processors for the current model.
```
**On/Off CoD Status**

```
This section displays the information about the record used by the Provisioning Manager for managing
temporary capacity.
```
```
Table 13. CPC On/Off CoD status
```
```
Field Description
```
```
Record ID The record ID used by the Provisioning Manager for managing temporary
capacity.
```
```
MSU The number of active MSU of the record.
```
```
Capacity level The number of increases in the capacity settings of the record.
```
```
CPs / Active The number of active general purpose processors of the record
```
```
zAAPs / Active The number of active zAAPs of the record.
```
```
zIIPs / Active The number of active zIIPs of the record.
```
```
IFLs / Active The number of active IFLs of the record.
```
**12**   Capacity Provisioning Task


_Table 13. CPC On/Off CoD status (continued)_

**Field Description**

**ICFs / Active** The number of active ICFs of the record.

**SAPs / Active** The number of active SAPs of the record.

**zAAPs / Limit** The number of zAAP processors allowed to be active for this record. If there
is no activation limit in the record a value of unlimited is reported.

**zIIPs / Limit** The number of zIIP processors allowed to be active for this record. If there
is no activation limit in the record a value of unlimited is reported.

**IFLs / Limit** The number of IFL processors allowed to be active for this record. If there is
no activation limit in the record a value of unlimited is reported.

**ICFs / Limit** The number of ICF processors allowed to be active for this record. If there is
no activation limit in the record a value of unlimited is reported.

**SAPs / Limit** The number of SAP processors allowed to be active for this record. If there
is no activation limit in the record a value of unlimited is reported.

**CPs / Remaining Capacity** The remaining number of MSU days for general purpose capacity. If there is
no limit for MSU days defined in the record a value of unlimited is reported.

**zAAPs / Remaining Capacity** The remaining number of processor days for zAAPs. If there is no limit for
processor days defined in the record a value of unlimited is reported.

**zIIPs / Remaining Capacity** The remaining number of processor days for zIIPs. If there is no limit for
processor days defined in the record a value of unlimited is reported.

**IFLs / Remaining Capacity** The remaining number of processor days for IFLs. If there is no limit for
processor days defined in the record a value of unlimited is reported.

**ICFs / Remaining Capacity** The remaining number of processor days for ICFs. If there is no limit for
processor days defined in the record a value of unlimited is reported.

**SAPs / Remaining Capacity** The remaining number of processor days for SAPs. If there is no limit for
processor days defined in the record a value of unlimited is reported.

**Procedure to display details about a CPC**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Configuration**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Active Configuration page is displayed in the **Provisioning Manager**
    tab.
6. Click the **CPCs** tab.
7. Select the CPC to be viewed and select **View CPC Details** from the **Actions** menu, or click the CPC
    name link. The CPC Details page is displayed in the **Provisioning Manager** tab.

```
Capacity Provisioning Task   13
```

```
System details
The System Details page shows detailed information about the selected system defined in the active
domain configuration of a Provisioning Manager.
```
**General**

```
This section shows runtime information about the selected system. All dates and times are displayed
using the time zone displayed. The time zone can be changed using the Settings link in the Overview tab.
```
```
Table 14. General information
```
```
Field Description
```
```
Configuration Name of the active configuration.
```
```
System Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Status The system's current enabled/disabled status.
```
```
Default status The default status indicates whether the system was enabled or disabled by
default when the domain configuration was activated.
```
**Connection**

```
Table 15. General connection information
```
```
Field Description
```
```
Protocol/Port The protocol and the port.
```
```
Primary and alternate host information for a selected system are shown.
```
```
Table 16. Primary and alternate host information
```
```
Field Description
```
```
Address The related host address.
```
```
Connection status The connection status of the system can be one of the following values:
```
```
Not connected
The connection to the system has not yet been established successfully.
The Provisioning Manager is trying to connect to the system at the
related host address.
Available
The connection to the system has been successfully established.
Temporarily unavailable
The connection to the system has been suspended after successfully
establishing a connection. The Provisioning Manager tries to connect to
the system again.
Unavailable
The connection to the system has been broken. The Provisioning
Manager tries to connect to the system again.
```
```
Status since The time when the connection changed into this status.
```
**14**   Capacity Provisioning Task


_Table 16. Primary and alternate host information (continued)_

**Field Description**

**System status** The system status can be one of the following values:

```
Unknown
The system is not identified. The name of the system or the name of the
sysplex has not yet been retrieved.
Found
The system is not correlated. The Provisioning Manager has not yet
detected if the name of the system and the name of the sysplex this
system belongs to match the names in the domain configuration.
Correct
The version of this system is not available. The version of the operating
system has not yet been retrieved.
Incorrect
This system is not the defined system. The name of the system or
the name of the sysplex this system belongs to does not match the
definition of these names in the domain configuration.
Unsupported version
The version of the system is not supported. The version of the system is
not supported by the Provisioning Manager.
CPC unknown
The CPC serial number is not available. The serial number of the CPC on
which the system is running has not yet been retrieved.
CPC unknown name
The CPC serial number is not correlated. The serial number of the CPC
has not yet been correlated with the name of the CPC.
CPC name matched
The CPC is not correlated. The CPC has not yet been correlated. The
Provisioning Manager has not detected if the CPC the system is running
on is defined in the domain configuration.
CPC not in domain
The CPC is not part of the domain. The CPC the system is running on is
not defined in the domain configuration.
Sysplex unknown mintime
Insufficient information for retrieving metric values. The information for
retrieving metric values has not yet been retrieved, or could not be
retrieved.
Sysplex unknown
The information about the WLM service definition is not available. Name
of the installed WLM service definition, the name of the active WLM
policy or the activation time of this policy has not yet been retrieved.
Sysplex unknown SCP
The information about WLM service class periods is not available. The
service class periods defined in the active WLM policy have not yet been
retrieved.
Sysplex valid
Detailed information about the system is available and is displayed in
the WLM section and in the Defined Capacity section of the System
Details page.
```
```
Capacity Provisioning Task   15
```

```
Table 16. Primary and alternate host information (continued)
```
```
Field Description
```
```
Observation status This status can be:
Observed
The Provisioning Manager retrieves information from the system at the
reported host address. The system can be observed if the domain
configuration is enabled and the system is enabled. If the alternate
host address is not defined the system at the primary host address is
observed. If both host addresses are defined at least one of the two
systems is observed. This depends on the runtime status of the system
at the other host address.
Not observed
The Provisioning Manager does not retrieve information from the system
at the reported host address. The system is not observed if the domain
configuration is disabled or if the system is disabled. If the domain
configuration is enabled and the system is enabled, and if both host
addresses are defined, the system may be not observed. This depends
on the runtime status of the system at the other host address.
```
```
Running on CPC The CPC where the system is running.
```
```
WLM
This section shows additional information about the system, if its system status is Sysplex valid :
```
```
Table 17. WLM details
```
```
Field Description
```
```
Service definition The installed WLM service definition.
```
```
Policy The active WLM policy.
```
**Defined Capacity**

```
This section shows additional information about the system, if its system status is Sysplex valid :
```
```
Table 18. Defined capacity information
```
```
Field Description
```
```
LPAR The name of the system's LPAR.
```
```
Defined Capacity (MSU) The current Defined Capacity.
```
```
Capacity Group Name Name of the capacity group to which the system's LPAR belongs.
```
```
Group Capacity (MSU) The current Group Capacity.
```
**LPAR Weight**

```
This section shows additional information about the system, if its system status is Sysplex valid :
```
**16**   Capacity Provisioning Task


_Table 19. LPAR weight information_

**Field Description**

**Weight management** Values are:

```
on
WLM weight management is enabled for the LPAR.
off
WLM weight management is not enabled for the LPAR.
```
**Weight (CP / zIIP / IFL)** The system's LPAR current weight for processor types CP (general purpose),
zIIP and IFL.
A value of 0 is displayed if the LPAR is defined with dedicated processors of
the corresponding type.
A value of - is displayed if the LPAR is defined without processors of the
corresponding type or the data is not available to the system's monitoring
product.

**CPC total** The sum of current weights of all active LPARs running in the same CPC for
processor types CP (general purpose), zIIP and IFL.
A value of 0 is displayed if the CPC is defined without any processors of the
corresponding type.
A value of - is displayed if the data is not available to the system's
monitoring product.

**Procedure to display details about a system**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Configuration**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Active Configuration page is displayed in the **Provisioning Manager**
    tab.
6. Click the **Systems** tab.
7. Select the system to be viewed and select **View System Details** from the **Actions** menu, or click the
    system name link. The System Details page is displayed in the **Provisioning Manager** tab.

```
Active policy
The Active Policy page shows information about the active policy. The table shows the elements of the
policy and their status.
The information reported is:
```
- Name of the active policy.
- Its current enabled/disabled status. A policy is disabled if the Provisioning Manager is running in
    processing mode _Manual_. In all other processing modes the policy is enabled.
- The table shows the elements of the policy and its status. Select an element in the table to show detail
    information.

```
Capacity Provisioning Task   17
```

**Columns in the policy element table**

```
Table 20. Columns in the policy element table
```
```
Column Description
```
```
Type The type of the element and its position in the hierarchy of the policy.
```
```
Name Name of the element.
```
**18**   Capacity Provisioning Task


_Table 20. Columns in the policy element table (continued)_

**Column Description**

**Status** The status of the element depends on the type of the policy element and
can be one of the following:
**Enabled**
Enabled policy elements are considered by the Provisioning Manager
**Disabled**
Disabled policy elements are not considered by the Provisioning
Manager.
**Pending**
The current time is before the start time of the time condition and no
observation of any system is necessary.
**Observing and Enabled**
The current time is after the observation start time and before the
start time of the time condition. The time condition is enabled, and
one or more workload conditions or utilization conditions are defined
that require systems to be observed. Systems that are referenced
by associated workload conditions are contacted to get performance
information for further processing.
**Observing and Disabled**
The current time is after the observation start time and before the start
time of the time condition. The policy is enabled but the time condition
is disabled.
**Active and Enabled**
The current time is after the start time and before the deadline of
the time condition, and the time condition is enabled. The Provisioning
Manager may change the managed capacity based on the provisioning
condition that contains the time condition.
**Active and Disabled**
The current time is after the start time and before the deadline of the
time condition. The policy is enabled but the time condition is disabled.
The managed capacity cannot be changed by the Provisioning Manager
based on the provisioning condition that contains the time condition.
**Drained and Enabled**
The current time is after the deadline and before the end time of the
time condition; the time condition is enabled. The Provisioning Manager
cannot change the managed capacity but can maintain the current
managed capacity based on the provisioning condition that contains the
time condition.
**Drained and Disabled**
The current time is after the deadline and before the end time of the
time condition. The policy is enabled but the time condition is disabled.
The managed capacity cannot be changed by the Provisioning Manager
based on the provisioning condition that contains the time condition.
**Inactive**
The current time is after the end time of the time condition; for recurring
time conditions the current time is after the end time of the last selected
day of the week between the start date and the end date. The managed
capacity cannot be changed by the Provisioning Manager based on the
provisioning condition that contains the time condition.

```
Capacity Provisioning Task   19
```

```
Table 20. Columns in the policy element table (continued)
```
```
Column Description
```
```
Details Details of the policy element are shown in short form. For more information
about the details of the policy element click on the corresponding section
name in Table 21 on page 20.
```
```
Click on a policy element in the table to show the complete detail information of the element. Depending
on the type of the policy element, the following details section is displayed on the Policy Element Details
page:
```
```
Table 21. Section names depending on policy element type
```
```
Policy element type Section name on the Policy Elements Details page
```
```
Policy “Policy details” on page 22
```
```
Maximum processor scope “Maximum processor scope details” on page 23
```
```
Processor limit “Maximum processor limit details” on page 23
```
```
Logical processor scope “Logical processor scope details” on page 24
```
```
Processor limit “Logical processor limit details” on page 25
```
```
Maximum defined capacity
scope
```
```
“Maximum defined capacity scope details” on page 26
```
```
Capacity limit “Maximum defined capacity limit details” on page 27
```
```
Maximum group capacity scope “Maximum group capacity scope details” on page 28
```
```
Capacity limit “Maximum group capacity limit details” on page 29
```
```
Rule “Rule details” on page 30
```
```
Processor scope “Processor scope details” on page 31
```
```
Processor limit “Processor limit details” on page 32
```
```
Defined capacity scope “Defined capacity scope details” on page 33
```
```
Capacity limit “Defined capacity limit details” on page 34
```
```
Group capacity scope “Group capacity scope details” on page 34
```
```
Capacity limit “Group capacity limit details” on page 35
```
```
Condition “Condition details” on page 36
```
```
Time condition “Nonrecurring time condition details” on page 37
```
```
Recurring time condition “Recurring time condition details” on page 39
```
```
Workload condition “Workload condition details” on page 41
```
```
Utilization condition “Utilization condition details” on page 42
```
```
Importance filter “Importance filter details” on page 44
```
```
Included service class “Included service class details” on page 45
```
```
Excluded service class “Excluded service class details” on page 47
```
**20**   Capacity Provisioning Task


**View another report for the same domain**

To view a different report for the same domain, click the **Report** button and select one of the available
reports:

- Domain Status
- Active Configuration
- Active Policy
- Health

**Procedure to view the Active Policy**

1. To show information about the Active Policy of a Provisioning Manager select the **Capacity**
    **Provisioning** task under the Performance category in the navigation area. The Capacity Provisioning
    page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Active Policy page is displayed in the **Provisioning Manager** tab.

**_Policy element details_**
The Policy Elements Details page shows details about an active policy element.

The page contains two sections: One showing the policy hierarchy where the policy element is positioned.
Depending on which policy element type is selected, the second section is labeled differently:

- Policy Details
- Maximum Processor Scope Details
- Maximum Processor Limit Details
- Logical Processor Scope Details
- Logical Processor Limit Details
- Maximum Defined Capacity Scope Details
- Maximum Defined Capacity Limit Details
- Maximum Group Capacity Scope Details
- Maximum Group Capacity Limit Details
- Rule Details
- Processor Scope Details
- Processor Limit Details
- Defined Capacity Scope Details
- Defined Capacity Limit Details
- Group Capacity Scope Details
- Group Capacity Limit Details
- Condition Details
- Nonrecurring Time Condition Details
- Recurring Time Condition Details
- Workload Condition Details
- “Utilization condition details” on page 42
- Importance Filter Details

```
Capacity Provisioning Task   21
```

- Included Service Class Details
- Excluded Service Class Details

**Procedure**

1. To show the detailed status of a policy you first have to show information about the Active Policy of
    a Provisioning Manager. Select the **Capacity Provisioning** task under the Performance category in the
    navigation area.
2. In the connections table of the Provisioning Manager page, select the connection you want to use to
    communicate with the Provisioning Manager. You can select only one connection.
3. From the **Actions** menu, select **View > Active Policy**. A window opens which shows a list of all
    possible domains that can be reached using the selected connection.
4. Select a domain and click **OK**. The Active Policy page is displayed in the **Provisioning Manager** tab.
5. Click on a policy element in the **Type** column in the policy element table. The Policy Element Details
    page is displayed.

```
Policy details
The Policy Details section shows the details of the active policy status.
```
**Policy hierarchy**

```
This table shows the policy hierarchy of the selected element.
```
```
Table 22. Policy hierarchy
```
```
Field (element type) Description
```
```
Policy Name of the active policy.
```
**Policy details**

```
Table 23. Policy details
```
```
Field Description
```
```
Name Name of the active policy.
```
```
Status The enabled/disabled status of the policy. A policy is disabled if the
Provisioning Manager is running in processing mode Manual. In all other
processing modes the policy is enabled.
```
**Procedure**

1. To show the detailed status of a policy you first have to show information about the Active Policy of a
    Provisioning Manager. To do so select the **Capacity Provisioning** task under the Performance category
    in the navigation area. The Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Policy** in the policy element table to show detail information. The Policy Element Details page
    is displayed.

**22**   Capacity Provisioning Task


```
Maximum processor scope details
The Maximum Processor Scope Details section shows the table of processor limits defined in the
maximum processor scope of the active policy.
For each processor limit the CPC name and the maximum and the minimum amount of temporary
processor resources that can be activated for the CPC by all provisioning rules are displayed.
```
```
Policy hierarchy
This field shows where the selected maximum processor scope is positioned in the policy hierarchy.
```
_Table 24. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

**The processor limit table**

```
For each processor limit in the maximum processor scope, the table shows the following information:
```
_Table 25. Columns of the Processor limit table_

**Column Description**

**CPC** Name of the CPC.

**Max. Activation (MSU)** Maximum amount of MSU to be activated.

**Max. zAAP Processors** Maximum number of zAAP processors to be activated.

**Max. zIIP Processors** Maximum number of zIIP processors to be activated.

**Primary Activation (MSU)** Minimum amount of MSU to be activated with the first activation.

**Secondary Activations (MSU)** Minimum amount of MSU to be activated with the second and all following
activations.

**Procedure**

```
To show details about the maximum processor scope you first have to show information about the Active
Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum processor scope** in the policy element table. The Policy Element Details page is
    displayed.

```
Maximum processor limit details
The Maximum Processor Limit Details section shows the details about the status of a processor limit in
the maximum processor scope of the active policy.
This contains the CPC name and the maximum and the minimum amount of temporary processor
resources which can be activated for the CPC by all provisioning rules.
```
```
Capacity Provisioning Task   23
```

```
Policy hierarchy
These fields show where the selected maximum processor limit is positioned in the policy hierarchy.
```
```
Table 26. Policy hierarchy
```
```
Field Description
```
```
Policy Name of the active policy.
```
```
Maximum Processor Scope
```
**Details of a maximum processor limit**

```
Table 27. Maximum Processor limit details
```
```
Field Description
```
```
CPC Name of the CPC.
```
```
Max. activation (MSU) Maximum amount of MSU to be activated.
```
```
Max. zAAP processors Maximum number of zAAP processors to be activated.
```
```
Max. zIIP processors Maximum number of zIIP processors to be activated.
```
```
Primary Activation (MSU) Minimum amount of MSU to be activated with the first activation.
```
```
Secondary Activations (MSU) Minimum amount of MSU to be activated with the second and all following
activations.
```
**Procedure**

```
To show details about the status of a maximum processor limit you first have to show information about
the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum processor limit** in the policy element table. The Policy Element Details page is
    displayed.

```
Logical processor scope details
The Logical Processor Scope Details section shows the table of processor limits defined in the logical
processor scope of the active policy.
For each processor limit the system and sysplex name, the maximum number of processors, and the
defined action are displayed. When a limit is reached the Provisioning Manager stops to recommend on
additional logical processors. The value Max. possible for CP limit, zAAP limit, and zIIP limit means the
value allowed by the z/OS and LPAR configuration.
```
```
Policy hierarchy
This field shows where the selected logical processor scope is positioned in the policy hierarchy.
```
**24**   Capacity Provisioning Task


_Table 28. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

```
The processor limit table
For each processor limit in the logical processor scope, the table shows the following information:
```
_Table 29. Columns in the processor limit table_

**Column Description**

**System** Name of the z/OS system for which recommendations to change the
number of logical processors are issued.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. CP Processors** Maximum number of logical general purpose processors.

**Max. zAAP Processors** Maximum number of logical zAAP processors.

**Max. zIIP Processors** Maximum number of logical zIIP processors.

**Action** The type of action to take, when required changes are detected.

**Procedure**

```
To show details about the logical processor scope you first have to show information about the active
policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Logical processor scope** in the policy element table. The Policy Element Details page is
    displayed.

```
Logical processor limit details
The Logical Processor Limit Details section shows details about the status of a processor limit in the
logical processor scope.
The value Max. possible for CP limit, zAAP limit, and zIIP limit means the value allowed by the z/OS and
LPAR configuration. When a limit is reached the Provisioning Manager stops to recommend on additional
logical processors.
```
**Policy hierarchy**

```
These fields show where the selected logical processor limit is positioned in the policy hierarchy.
```
_Table 30. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

```
Capacity Provisioning Task   25
```

```
Table 30. Policy hierarchy (continued)
```
```
Field Description
```
```
Logical Processor Scope
```
**Details of a logical processor limit**

```
Table 31. Logical processor limit details
```
```
Field Description
```
```
System Name of the z/OS system for which recommendations to change the
number of logical processors are issued.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Max. CP processors Maximum number of logical general purpose processors.
```
```
Max. zAAP processors Maximum number of logical zAAP processors.
```
```
Max. zIIP processors Maximum number of logical zIIP processors.
```
```
Action The type of action to take, when required changes are detected.
```
**Procedure**

```
To show details about the status of a logical processor limit you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Logical processor limit** in the policy element table. The Policy Element Details page is
    displayed.

```
Maximum defined capacity scope details
The Maximum Defined Capacity Scope Details section shows the table of capacity limits defined in the
maximum defined capacity scope of the active policy.
For each capacity limit the system and the sysplex name, and the maximum and the minimum amount of
MSU by which the Defined Capacity of the system can be increased by all provisioning rules are displayed.
```
**Policy hierarchy**

```
This field shows where the selected maximum defined capacity scope is positioned in the policy
hierarchy.
```
```
Table 32. Policy hierarchy
```
```
Field Description
```
```
Policy Name of the active policy.
```
**26**   Capacity Provisioning Task


```
The capacity limit table
For each capacity limit in the maximum defined capacity scope, the table shows the following
information:
```
_Table 33. Columns of the capacity limit table_

**Column Description**

**System** Name of the z/OS system.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. Increase (MSU)** Maximum amount of MSU by which the Defined Capacity of the system can
be increased by all the rules of the policy.

**Primary Increment (MSU)** Minimum amount of MSU by which the Defined Capacity of the system can
be increased with the first increment.

**Secondary Increments (MSU)** Minimum amount of MSU by which the Defined Capacity of the system can
be increased on the second increment and all subsequent increments.

**Procedure**

```
To show details about the maximum defined capacity scope you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum defined capacity scope** in the policy element table. The Policy Element Details
    page is displayed.

```
Maximum defined capacity limit details
The Maximum Defined Capacity Limit Details section shows the details about the status of a capacity
limit in the maximum defined capacity scope of the active policy.
This contains the system and the sysplex name and the maximum amount of MSU by which the Defined
Capacity for the z/OS system can be increased by all provisioning rules, and the capacity increments
defined for the system.
```
**Policy hierarchy**

```
These fields show where the selected maximum defined capacity limit is positioned in the policy
hierarchy.
```
_Table 34. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

**Maximum Defined Capacity
Scope**

```
Capacity Provisioning Task   27
```

**Details of a maximum defined capacity limit**

```
Table 35. Maximum defined capacity limit details
```
```
Field Description
```
```
System Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Defined Capacity of the system can
be increased by all the rules of the policy.
```
```
Primary increment (MSU) Minimum amount of MSU by which the Defined Capacity of the system can
be increased with the first increment.
```
```
Secondary increments (MSU) Minimum amount of MSU by which the Defined Capacity of the system can
be increased on the second increment and all subsequent increments.
```
**Procedure**

```
To show details about the status of a maximum defined capacity limit you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum defined capacity limit** in the policy element table. The Policy Element Details page
    is displayed.

```
Maximum group capacity scope details
The Maximum Group Capacity Scope Details section shows the table of capacity limits defined in the
maximum group capacity scope of the active policy.
For each capacity limit the capacity group and the CPC name, and the maximum and the minimum
amount of MSU by which the Group Capacity for a capacity group of a CPC can be increased by all
provisioning rules are displayed.
```
**Policy hierarchy**

```
This field shows where the selected maximum group capacity scope is positioned in the policy hierarchy.
```
```
Table 36. Policy hierarchy
```
```
Field Description
```
```
Policy Name of the active policy.
```
```
The capacity limit table
For each capacity limit in the maximum group capacity scope, the table shows the following information:
```
**28**   Capacity Provisioning Task


_Table 37. Columns of the capacity limit table_

**Column Description**

**Group** Name of the capacity group.

**CPC** Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.

**Max. Increase (MSU)** Maximum amount of MSU by which the Group Capacity can be increased by
all the rules of the policy.

**Primary Increment (MSU)** Minimum amount of MSU by which the Group Capacity can be increased
with the first increment.

**Secondary Increments (MSU)** Minimum amount of MSU by which the Group Capacity can be increased on
the second increment and all subsequent increments.

```
Procedure
To show details about the maximum group capacity scope you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum group capacity scope** in the policy element table. The Policy Element Details page
    is displayed.

```
Maximum group capacity limit details
The Maximum Group Capacity Limit Details section shows the details about the status of a capacity limit
in the maximum group capacity scope of the active policy.
This contains the capacity group, the CPC name, the maximum amount of MSU by which the Group
Capacity for a capacity group of a CPC can be increased by all provisioning rules, and the capacity
increments defined for the capacity group.
```
**Policy hierarchy**

```
These fields show where the selected maximum group capacity limit is positioned in the policy hierarchy.
```
_Table 38. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

**Maximum Group Capacity
Scope**

```
Capacity Provisioning Task   29
```

**Details of a maximum group capacity limit**

```
Table 39. Maximum group capacity limit details
```
```
Field Description
```
```
Group Name of the capacity group.
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased by
all rules of the policy.
```
```
Primary increment (MSU) Minimum amount of MSU by which the Group Capacity can be increased
with the first increment.
```
```
Secondary increments (MSU) Minimum amount of MSU by which the Group Capacity can be increased on
the second increment and all subsequent increments.
```
**Procedure**

```
To show details about the status of a maximum group capacity limit you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Maximum group capacity limit** in the policy element table. The Policy Element Details page is
    displayed.

```
Rule details
The Rule Details section shows details about the status of a selected rule in the active policy.
```
**Policy hierarchy**

```
This field shows where the selected rule is positioned in the policy hierarchy.
```
```
Table 40. Policy hierarchy
```
```
Field (element type) Description
```
```
Policy Name of the active policy.
```
**Rule details**

```
Table 41. Rule details
```
```
Field Description
```
```
Name Name of the selected rule.
```
```
Status The current enabled/disabled status of the rule.
```
**30**   Capacity Provisioning Task


_Table 41. Rule details (continued)_

**Field Description**

**Default status** Indicates if the rule is enabled or disabled by default when the policy was
activated.

```
Procedure
To show details about the status of a selected rule you first have to show information about the Active
Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manage** r
    tab.
6. Click on **Rule** in the policy element table. The Policy Element Details page is displayed.

```
Processor scope details
The Processor Scope Details section shows the table of processor limits defined in the processor scope
of a rule.
For each processor limit the CPC name and the temporary processor resources which can be activated for
the CPC by the selected rule are displayed.
```
**Policy hierarchy**

```
These fields show where the selected processor scope is positioned in the policy hierarchy.
```
_Table 42. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule to which the processor scope belongs

**The processor limit table**

```
For each processor limit the table shows the following information:
```
_Table 43. Columns of the processor limit table_

**Column Description**

**CPC Name** Name of the CPC.

**MSU Limit** Maximum amount of MSU to be activated.

**zAAP Limit** Maximum number of zAAP processors to be activated.

**zIIP Limit** Maximum number of zIIP processors to be activated.

```
Capacity Provisioning Task   31
```

```
Procedure
To show details about the processor scope of a rule you first have to show information about the Active
Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Processor scope** in the policy element table. The Policy Element Details page is displayed.

```
Processor limit details
The Processor Limit Details section shows the details about the status of a processor limit in the
processor scope of a rule.
This contains the CPC name and the temporary processor resources which can be activated for the CPC by
the selected rule.
```
**Policy hierarchy**

```
These fields show where the selected processor limit is positioned in the policy hierarchy.
```
```
Table 44. Policy hierarchy
```
```
Field Description
```
```
Policy Name of the active policy.
```
```
Rule Name of the rule to which the processor scope belongs
```
```
Processor Scope
```
**Details of a processor limit**

```
Table 45. Processor limit details
```
```
Field Description
```
```
CPC name Name of the CPC.
```
```
MSU limit Maximum amount of MSU to be activated.
```
```
zAAP limit Maximum number of zAAP processors to be activated.
```
```
zIIP limit Maximum number of zIIP processors to be activated.
```
```
Procedure
To show details about the status of a processor limit in the processor scope of a rule you first have to
show information about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.

**32**   Capacity Provisioning Task


4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Processor limit** in the policy element table. The Policy Element Details page is displayed.

```
Defined capacity scope details
The Defined Capacity Scope Details section shows the table of capacity limits defined in the defined
capacity scope of a rule.
For each capacity limit the system and the sysplex name and the maximum amount of MSU by which the
Defined Capacity of the system can be increased by the selected rule are displayed.
```
```
Policy hierarchy
These fields show where the selected defined capacity scope is positioned in the policy hierarchy.
```
_Table 46. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule to which the defined capacity scope belongs

**The capacity limit table**

```
For each capacity limit in the defined capacity scope, the table shows the following information:
```
_Table 47. Columns of the capacity limit table_

**Column Description**

**System** Name of the z/OS system.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. Increase (MSU)** Maximum amount of MSU by which the Defined Capacity of the system can
be increased by the selected rule.

**Procedure**

```
To show details about the defined capacity scope of a rule you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Defined capacity scope** in the policy element table. The Policy Element Details page is
    displayed.

```
Capacity Provisioning Task   33
```

```
Defined capacity limit details
The Defined Capacity Limit Details section shows the details about the status of a capacity limit in the
defined capacity scope of a rule.
This contains the system and the sysplex name and the maximum amount of MSU by which the Defined
Capacity for the z/OS system can be increased by the selected rule.
```
```
Policy hierarchy
These fields show where the selected capacity limit is positioned in the policy hierarchy.
```
```
Table 48. Policy hierarchy
```
```
Field Description
```
```
Policy Name of the active policy.
```
```
Rule Name of the rule to which the defined capacity scope belongs
```
```
Defined Capacity Scope
```
**Details of a defined capacity limit**

```
Table 49. Defined capacity limit details
```
```
Field Description
```
```
System Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Defined Capacity of the system can
be increased by the selected rule.
```
**Procedure**

```
To show details about the status of a capacity limit in the defined capacity scope of a rule you first have to
show information about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Defined capacity limit** in the policy element table. The Policy Element Details page is
    displayed.

```
Group capacity scope details
The Group Capacity Scope Details section shows the table of capacity limits defined in the group
capacity scope of a rule.
For each capacity limit the capacity group and the CPC name and the maximum amount of MSU by which
the Group Capacity for a capacity group of a CPC can be increased by the selected rule are displayed.
```
```
Policy hierarchy
These fields show where the selected group capacity scope is positioned in the policy hierarchy.
```
**34**   Capacity Provisioning Task


_Table 50. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule to which the group capacity scope belongs

```
The capacity limit table
For each capacity limit in the group capacity scope, the table shows the following information:
```
_Table 51. Columns of the capacity limit table_

**Column Description**

**Group** Name of the capacity group.

**CPC** Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.

**Max. Increase (MSU)** Maximum amount of MSU by which the Group Capacity can be increased by
the selected rule.

**Procedure**

```
To show details about the group capacity scope of a rule you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Group capacity scope** in the policy element table. The Policy Element Details page is
    displayed.

```
Group capacity limit details
The Group Capacity Limit Details section shows the details about the status of a capacity limit in the
group capacity scope of a rule.
This contains the capacity group and the CPC name and maximum amount of MSU by which the Group
Capacity for a capacity group of a CPC can be increased by the selected rule.
```
**Policy hierarchy**

```
These fields show where the selected capacity limit is positioned in the policy hierarchy.
```
_Table 52. Policy hierarchy_

**Field Description**

**Policy** Name of the active policy.

**Rule** Name of the rule to which the group capacity scope belongs

```
Capacity Provisioning Task   35
```

```
Table 52. Policy hierarchy (continued)
```
```
Field Description
```
```
Group Capacity Scope
```
**Details of a group capacity limit**

```
Table 53. Group capacity limit details
```
```
Field Description
```
```
Group Name of the capacity group.
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased by
the selected rule.
```
**Procedure**

```
To show details about the status of a capacity limit in the group capacity scope of a rule you first have to
show information about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Group capacity limit** in the policy element table. The Policy Element Details page is
    displayed.

```
Condition details
The Condition Details section shows details about the status of a selected condition in the active policy.
```
**Policy hierarchy**

```
These fields show where the selected condition is positioned in the policy hierarchy.
```
```
Table 54. Policy hierarchy
```
```
Field (element type) Description
```
```
Policy Name of the active policy.
```
```
Rule Name of the rule to which the condition belongs
```
**Condition details**

```
Table 55. Condition details
```
```
Field Description
```
```
Name Name of the selected condition.
```
**36**   Capacity Provisioning Task


_Table 55. Condition details (continued)_

**Field Description**

**Status** The current enabled/disabled status of the condition.

**Default status** Indicates if the condition is enabled or disabled by default when the policy
was activated.

```
Procedure
To show details about the status of a selected condition you first have to show information about the
Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Condition** in the policy element table. The Policy Element Details page is displayed.

```
Nonrecurring time condition details
The Nonrecurring Time Condition Details section shows details about the status of a selected
nonrecurring time condition in the active policy.
```
**Policy hierarchy**

```
These fields show where the selected time condition is positioned in the policy hierarchy.
```
_Table 56. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule

**Condition** Name of the condition to which the time condition belongs

**Nonrecurring time condition details**

```
All dates and times are displayed using the time zone displayed. The time zone can be changed using the
Settings link in the Overview tab.
```
_Table 57. Time condition details_

**Field Description**

**Name** Name of the selected time condition.

```
Capacity Provisioning Task   37
```

```
Table 57. Time condition details (continued)
```
```
Field Description
```
```
Status The current status, it can be one of:
Pending
The current time is before the start time of the condition and no
observation of any system is necessary.
Observing and enabled
The current time is after the observation start time and before the start
time of the condition, the time condition and policy are enabled, and
one or more workload conditions are defined which require systems
to be observed if possible. Systems that are referenced by associated
workload conditions may be contacted to get performance information
for further processing.
Observing and disabled
The current time is after the observation start time and before the start
time of the condition. The time condition is disabled.
Active and enabled
The current time is after the start time and before the deadline of the
condition, and the time condition is enabled. The Provisioning Manager
may change the managed capacity based on the provisioning condition
that contains the time condition.
Active and disabled
The current time is after the start time and before the deadline of the
condition. The managed capacity cannot be changed by the Provisioning
Manager based on the provisioning condition that contains the time
condition.
Drained and enabled
The current time is after the deadline and before the end time of the
condition; the time condition is enabled. The Provisioning Manager
cannot change the managed capacity but can maintain the current
managed capacity based on the provisioning condition that contains the
time condition.
Drained and disabled
The current time is after the deadline and before the end time of the
condition. The managed capacity cannot be changed by the Provisioning
Manager based on the provisioning condition that contains the time
condition.
Inactive
The current time is after the end time of the condition. The managed
capacity cannot be changed by the Provisioning Manager based on the
provisioning condition that contains the time condition.
```
```
Start time The start time at which the Provisioning Manager can start to provision
additional capacity if one of the associated workloads suffers.
```
```
Deadline The deadline, which is the latest time when provisioning of additional
capacity is allowed. Additional capacity that has already been provisioned
can remain active until the end time or until the capacity is no longer
needed.
```
```
End time The end time at which the Provisioning Manager starts to deprovision
additional capacity.
```
```
Note: All reported times are displayed using the time zone specified in the “Settings” on page 118 page.
```
**38**   Capacity Provisioning Task


```
Procedure
To show details about the status of a selected nonrecurring time condition you first have to show
information about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Nonrecurring time condition** in the policy element table. The Policy Element Details page is
    displayed.

```
Recurring time condition details
The Recurring Time Condition Details section shows details about the status of a selected recurring time
condition in the active policy.
```
**Policy hierarchy**

```
These fields show where the selected time condition is positioned in the policy hierarchy.
```
_Table 58. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule

**Condition** Name of the condition to which the time condition belongs

**Recurring time condition details**

```
All dates and times are displayed using the time zone displayed. The time zone can be changed using the
Settings link on the Overview page.
```
_Table 59. Recurring time condition details_

**Field Description**

**Name** Name of the selected recurring time condition.

```
Capacity Provisioning Task   39
```

```
Table 59. Recurring time condition details (continued)
```
```
Field Description
```
```
Status The current status, it can be one of:
Pending
The current time is before the start time of the condition and no
observation of any system is necessary.
Observing and enabled
The current time is after the observation start time and before the start
time of the condition, the time condition and policy are enabled, and
one or more workload conditions are defined which require systems
to be observed if possible. Systems that are referenced by associated
workload conditions may be contacted to get performance information
for further processing.
Observing and disabled
The current time is after the observation start time and before the start
time of the condition. The time condition is disabled.
Active and enabled
The current time is after the start time and before the deadline of the
condition, and the time condition is enabled. The Provisioning Manager
may change the managed capacity based on the provisioning condition
that contains the time condition.
Active and disabled
The current time is after the start time and before the deadline of the
condition. The managed capacity cannot be changed by the Provisioning
Manager based on the provisioning condition that contains the time
condition.
Drained and enabled
The current time is after the deadline and before the end time of the
condition; the time condition is enabled. The Provisioning Manager
cannot change the managed capacity but can maintain the current
managed capacity based on the provisioning condition that contains the
time condition.
Drained and disabled
The current time is after the deadline and before the end time of the
condition. The managed capacity cannot be changed by the Provisioning
Manager based on the provisioning condition that contains the time
condition.
Inactive
The current time is after the end time of the last selected day of
the week between the start date and the end date. The managed
capacity cannot be changed by the Provisioning Manager based on the
provisioning condition that contains the time condition.
```
```
Start date The date of the first day on which the Provisioning Manager may provision
additional capacity.
```
```
End date The date of the last day on which the Provisioning Manager may provision
additional capacity.
```
**40**   Capacity Provisioning Task


_Table 59. Recurring time condition details (continued)_

**Field Description**

**Days of the week** The days of week on which provisioning of additional capacity is allowed.
The time when additional capacity can be provisioned on the selected day is
displayed in the **Start time** field. The deadline and end time can be on the
following day if these times are before the start time.
In short form the days of the week are marked with "X" if the day of the
week is allowed and with a "-" if the day of the week is not allowed. The
days are reported from Monday to Sunday.

**Start time** The time of the selected day at which the Provisioning Manager can start to
provision additional capacity, if one of the associated workload suffers.

**Deadline** The time of the selected day when no further capacity will be provisioned.
Additional capacity which is already provisioned can remain active until the
end time or until the capacity is no longer needed. Be aware that Deadline
can be before Start Time.

**End time** The time of the selected day at which the Provisioning Manager starts to
deprovision additional capacity. Be aware that End Time can be before Start
Time.

```
Note: All reported dates and times are displayed using the time zone specified in the “Settings” on page
118 page. The selected days of the week are displayed based on the specified time zone. If local time is
selected and this is a time zone that uses daylight saving time, the actual date and time values used might
be one hour later or earlier than the time displayed.
```
```
Procedure
To show details about the status of a selected recurring time condition you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Recurring time condition** in the policy element table. The Policy Element Details page is
    displayed.

```
Workload condition details
The Workload Condition Details section shows details about the status of a selected workload condition
in the active policy.
```
**Policy hierarchy**

```
These fields show where the selected workload condition is positioned in the policy hierarchy.
```
```
Capacity Provisioning Task   41
```

```
Table 60. Policy hierarchy
```
```
Field (element type) Description
```
```
Policy Name of the active policy.
```
```
Rule Name of the rule.
```
```
Condition Name of the condition to which the workload condition belongs.
```
**Workload condition details**

```
Table 61. Workload condition details
```
```
Field Description
```
```
Name Name of the selected workload condition.
```
```
System Name of the z/OS system to which the workload condition applies.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Importance filters This table shows the details of all importance filters of the selected
workload condition. See “Importance filter details” on page 44 for a
detailed description of the fields.
```
```
Included service classes This table shows the details of all Included service classes of the selected
workload condition. See “Included service class details” on page 46 for a
detailed description of the fields.
```
```
Excluded service classes This table shows the details of all Excluded service classes of the selected
workload condition. See “Excluded service class details” on page 48 for a
detailed description of the fields.
```
**Procedure**

```
To show details about the status of a selected workload condition you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Workload condition** in the policy element table. The Policy Element page is displayed.

```
Utilization condition details
The Utilization Condition Details section shows details about the status of a selected utilization
condition in the active policy.
```
**Policy hierarchy**

```
These fields show where the selected utilization condition is positioned in the policy hierarchy.
```
**42**   Capacity Provisioning Task


_Table 62. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule.

**Condition** Name of the condition to which the utilization condition belongs.

**Utilization condition details**

_Table 63. Utilization condition details_

**Field Description**

**Name** Name of the selected utilization condition.

**CPC** Name of the CPC on which the utilization condition can trigger provisioning.
This name is the logical name by which it is identified at the support
element (SE) of that processor complex.

**Processor Type** Processor Type for which the CPC utilization is monitored.

**Provisioning Utilization (%)** Processor utilization threshold for provisioning. If the provisioning utilization
is equal or higher than the specified percentage value, the Provisioning
Manager triggers activation of additional temporary capacity.
It must be a number from 1-100.

**Provisioning Duration (Minutes)** Number of minutes the processor utilization threshold has to exceed the
specified value before the Provisioning Manager triggers the activation of
additional capacity.
It must be a number from 4-1440.

**Deprovisioning Utilization (%)** Processor utilization threshold for deprovisioning. If the deprovisioning
utilization is equal or lower than the specified percentage value, the
Provisioning Manager triggers deactivation of additional temporary capacity.
It must be a number from 0-99.

**Deprovisioning Duration
(Minutes)**

```
Number of minutes the processor utilization threshold has to be lower
than the specified value before the Provisioning Manager triggers the
deactivation of additional capacity.
It must be a number from 4-1440.
```
**Procedure**

```
To show details about the status of a selected utilization condition you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.

```
Capacity Provisioning Task   43
```

6. Click on **Utilization condition** in the policy element table. The Policy Element page is displayed.

```
Importance filter details
The Importance Filter Details section shows details about the status of an importance filter of a
workload condition.
```
```
Policy hierarchy
The specification of importance filters is optional, however there must be at least one importance filter
or one included service class filter for a valid workload condition defined. All service class periods with
an importance level equal to or higher than the specified value will be monitored by the Provisioning
Manager and can trigger provisioning. For each specified importance level additional provisioning criteria
are defined.
These fields show where the selected importance filter is positioned in the policy hierarchy.
```
```
Table 64. Policy hierarchy
```
```
Field (element type) Description
```
```
Policy Name of the active policy.
```
```
Rule Name of the rule
```
```
Condition Name of the condition
```
```
Workload condition Name of the workload condition
```
**Importance filter details**

```
Table 65. Importance filter details
```
```
Field Description
```
```
Importance Service class periods with the specified importance value less than or equal
to the specified importance value match the importance filter. It must
contain a number between 1 and 5.
```
```
Provisioning PI If the performance index of a service class period is equal or higher than the
specified value the Provisioning Manager considers the service class period
to be suffering.
```
```
Provisioning duration Number of minutes the performance index must exceed the specified
provisioning PI before the Provisioning Manager considers a service class
period to be suffering.
```
```
Deprovisioning PI If the performance index of a service class period is lower than the specified
value the Provisioning Manager considers the service class period not to be
suffering.
```
```
Deprovisioning duration Number of minutes the performance index must be lower than the
deprovisioning PI before the Provisioning Manager considers a service class
period to be no longer suffering.
```
**44**   Capacity Provisioning Task


_Table 65. Importance filter details (continued)_

**Field Description**

**PI Scope** Indicates if the provisioning PI and deprovisioning PI values refer to the
sysplex PI or the system PI of the service class period.
**System**
Indicates that the performance index of the service class period on
each system in the sysplex is used. The system PI is also referred to
as the local performance index (local PI). This is the default and the
recommended setting.
**Sysplex**
Indicates that the performance index of the service class period within
the sysplex is used. A sysplex PI should only be chosen if all systems
joining the sysplex are defined to the provisioning domain. If you choose
PI scope "Sysplex", the Provisioning Manager monitors in addition to
monitoring the sysplex PI also the system PI. Only if the monitored
system is actually suffering, the Provisioning Manager starts to take
actions.

```
Procedure
To show details about the status of a selected importance filter you first have to show information about
the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Importance filter** in the policy element table. The Policy Element Details page is displayed.

```
Included service class details
The Included Service Class Details section shows details about the status of an included service class of
a workload condition.
```
**Policy hierarchy**

```
The specification of included service classes filters is optional, however at least one importance filter or
one included service class filter must be specified for a valid workload condition. All service classes listed
in the Included Service Classes table can trigger provisioning when they are in the defined service class
period. For each specified service class period additional provisioning criteria are defined.
These fields show where the selected included service class filter is positioned in the policy hierarchy.
```
_Table 66. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule

**Condition** Name of the condition

```
Capacity Provisioning Task   45
```

```
Table 66. Policy hierarchy (continued)
```
```
Field (element type) Description
```
```
Workload condition Name of the workload condition
```
```
Included service class details
For the included service class the following information is given:
```
```
Table 67. Included service class details
```
```
Field Description
```
```
Service definition Name of the z/OS Workload Manager (WLM) service definition. The specified
service class periods are only considered if this WLM service definition is
installed.
Any service definition
Indicates that all WLM service definitions are considered.
A name specifies a particular WLM service definition.
```
```
Service policy Name of the service policy within the WLM service definition to which
the WLM service class belongs. The specified service class periods are
considered if a service policy with that name is activated.
Any service policy
Includes all service policies matching the other criteria.
A name specifies a particular WLM service policy.
```
```
Service class Name of the WLM service class to consider.
Any service class
Includes all service classes matching the other criteria.
A name specifies a particular WLM service class.
```
```
Period The period of the service class to be considered. This period and all periods
with a lower period number are considered eligible to trigger provisioning.
If a service class has fewer periods than this number, all periods are
considered.
```
```
Provisioning PI If the performance index of a service class period is equal to or higher than
the specified value the Provisioning Manager considers the service class
period to be suffering.
```
```
Provisioning duration Number of minutes the performance index must exceed the specified
provisioning PI before the Provisioning Manager considers a service class
period to be suffering.
```
```
Deprovisioning PI If the performance index of a service class period is lower than the specified
value the Provisioning Manager considers the service class period not to be
suffering.
```
```
Deprovisioning duration Number of minutes the performance index must be lower than the
deprovisioning PI before the Provisioning Manager considers a service class
period to be no longer suffering.
```
**46**   Capacity Provisioning Task


_Table 67. Included service class details (continued)_

**Field Description**

**PI scope** Indicates if the provisioning PI and deprovisioning PI values refer to the
sysplex PI or the system PI of the service class period.
**System**
Indicates that the performance index of the service class period on
each system in the sysplex is used. The system PI is also referred to
as the local performance index (local PI). This is the default and the
recommended setting.
**Sysplex**
Indicates that the performance index of the service class period within
the sysplex is used. A sysplex PI should only be chosen if all systems
joining the sysplex are defined to the provisioning domain. If you choose
PI scope "Sysplex", the Provisioning Manager monitors in addition to
monitoring the sysplex PI also the system PI. Only if the monitored
system is actually suffering, the Provisioning Manager starts to take
actions.

```
Procedure
To show details about the status of a selected included service class you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Included service class** in the policy element table. The Policy Element Details page is
    displayed.

```
Excluded service class details
The Excluded Service Class Details section shows details about the status of an excluded service class
of a workload condition.
The specification of excluded service classes filters is optional. It is used to exclude selected service
classes which would otherwise be included by an importance filter. The service classes listed in the
Excluded Service Classes table cannot trigger provisioning even if they match the importance filters or
the included service classes criteria.
```
**Policy hierarchy**

```
These fields show where the selected excluded service class filter is positioned in the policy hierarchy.
```
_Table 68. Policy hierarchy_

**Field (element type) Description**

**Policy** Name of the active policy.

**Rule** Name of the rule

```
Capacity Provisioning Task   47
```

```
Table 68. Policy hierarchy (continued)
```
```
Field (element type) Description
```
```
Condition Name of the condition
```
```
Workload condition Name of the workload condition
```
```
Excluded service class details
For the excluded service class the following information is given:
```
```
Table 69. Excluded service class details
```
```
Field Description
```
```
Service definition Name of the z/OS Workload Manager (WLM) service definition where the
service class is defined.
Any service definition
Specifies all service definitions.
A name specifies a particular WLM service definition.
```
```
Service policy Name of the service policy within the WLM service definition to which the
WLM service class belongs.
Any service policy
Specifies all service policies in the specified WLM service definition.
A name specifies a particular WLM service policy.
```
```
Service class Name of the WLM service class to consider.
Any service class
Specifies all service classes in the specified WLM service policies.
A name specifies a particular WLM service class.
```
```
Period The period of the service class to be considered. This period and all periods
with a higher period number are excluded from provisioning.
```
**Procedure**

```
To show details about the status of a selected included service class you first have to show information
about the Active Policy of a Provisioning Manager.
```
1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Active Policy**.
5. Select a domain in the window which shows a list of possible domains that can be reached using the
    selected connection and click **OK**. The Active Policy page is displayed in the **Provisioning Manager**
    tab.
6. Click on **Excluded service class** in the policy element table. The Policy Element Details page is
    displayed.

**48**   Capacity Provisioning Task


```
Health
The health report displays state information about the connectivity of the managed CPCs and systems.
All CPCs and systems that are defined in the active domain configuration and their current health states
are displayed.
```
_Table 70. Fields on the Health page_

**Field Description**

**Active configuration** The name of the currently active domain configuration.

**Overall health** The overall health, in percent.

```
Possible health states are as follows:
OK
There is no error or warning message relating to the CPC or system
availability.
ERROR
See the corresponding CPO messages that are displayed in the
Messages column.
WARNING
See the corresponding CPO messages that are displayed in the
Messages column.
UNAVAILABLE
No information is available. The connection to the system or CPC might
not yet have been established.
DISABLED
An element of the domain configuration is disabled.
```
**CPC tab**

```
Table 71. CPC health states
```
```
Field Description
```
```
CPC name Name of the CPC. This name is the logical name by which the CPC is
identified at the support element (SE) of that processor complex.
```
```
Health state Health state of the CPC.
```
```
Messages CPM message that describes the situation that lead to the given health
state.
```
**Systems tab**

```
Table 72. System health states
```
```
Field Description
```
```
System name Name of the z/OS system.
```
```
Health state Health state of the z/OS system.
```
```
Messages CPM message that describes the situation that lead to the given health
state.
```
```
To refresh the health states, click Refresh. The Last refresh field shows the time of the last snapshot.
```
```
Capacity Provisioning Task   49
```

```
View another report for the same domain
To view a different report for the same domain, click the Report button and select one of the available
reports:
```
- Domain Status
- Active Configuration
- Active Policy
- Health

**Procedure to view the Health**

1. To show information about the Health of an active configuration, select the **Capacity Provisioning** task
    under the Performance category in the navigation area. The Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Provisioning Manager** link. The Provisioning Manager page is displayed.
3. In the connections table, select the connection to the system where the Provisioning Manager whose
    status you want to inspect is running.
4. From the **Actions** menu, select **View > Health**. A window opens which shows a list of all possible
    domains that can be reached using the selected connection.
5. Select a domain and click **OK**. The Active Configuration Health page is displayed in the **Provisioning**
    **Manager** tab.

```
CPC details
The CPC Details page shows detailed information about the selected CPC.
```
```
Table 73. CPC details fields
```
```
Field Description
```
```
Active configuration Name of the active configuration.
```
```
CPC name Name of the CPC.
```
```
Health status The status of the CPC's health.
```
```
Messages CPM messages that explain the health status.
```
```
System details
The System Details page shows detailed information about the selected system.
```
```
Table 74. System details fields
```
```
Field Description
```
```
Active configuration Name of the active configuration.
```
```
System name Name of the z/OS system.
```
```
Sysplex status Name of the sysplex to which the z/OS system belongs.
```
```
Health status The health status of the system.
```
```
Messages CPM messages that explain the health status.
```
**50**   Capacity Provisioning Task


### Managing domain configurations

```
The Domain Configurations page shows information about the defined domain configurations. You can
define, modify, view, import, export, install, and activate domain configurations.
A domain configuration defines the scope of management within a provisioning domain. It lists a set of
z/OS systems which can be monitored by the Provisioning Manager and a set of CPCs for which capacity
can be managed. A complete domain configuration can be installed and activated.
The domain configurations that have been defined in z/OSMF are stored in the z/OSMF repository and are
listed in the table on the Domain Configurations page. The repository is shared across all users authorized
to access the Capacity Provisioning task; therefore, all users see the same list of domain configurations.
To retrieve the latest information from the repository and refresh the Domain Configurations table, click
the Refresh button.
For a description of the columns in the Domain Configurations table, see Table 75 on page 51.
For a description of the actions that you can take against domain configurations, see “Actions for domain
configurations” on page 52.
```
**Domain Configurations table**

```
Table 75. Columns in the Domain Configurations table
```
```
Column Description
```
```
Name Name of the domain configuration. The name is displayed as a hyperlink.
When clicked, the name link opens the domain configuration in a new tab in
view mode and displays the domain configuration details.
```
```
Description Description of the domain configuration. You can use this field, for example,
to indicate the version of a domain configuration.
```
```
Capacity Provisioning Task   51
```

```
Table 75. Columns in the Domain Configurations table (continued)
```
```
Column Description
```
```
Activity Indicates the state of the domain configuration. This column can have one
of the following values:
```
- Being viewed
- Being modified
- Changes pending
- Being viewed, changes pending
- Being modified, changes pending
- Temporary
The values and icons in the **Activity** column are displayed as a hyperlink.
Click the link to display the associated message. To display the messages
or help for the messages, you can also select the cell that contains the link
or icon and press **Ctrl+M** (message) or **Ctrl+Q** (message help). For more
details about each state, see help topic z/OSMF “Repository” on page 121.
**Note:** If your browser is busy and cannot communicate with the z/OSMF
server within three minutes, z/OSMF assumes that the domain configuration
is not in use and releases any locks. If this situation occurs, you might notice
one of the following:
- The state in the **Activity** column does not reflect the actual state of the
    domain configuration. For example, if you have the domain configuration
    open in view or edit mode, the activity might be blank even though you are
    modifying or viewing the domain configuration.
- Another user deleted the domain configuration while you were viewing or
    modifying it.
If these situations occur frequently, try working with fewer tabs, or consider
using a different browser. For a list of tested browsers, see the z/OSMF
Browser Compatibility Web page.

```
Message Indicates the highest severity of the messages that occurred for the domain
configuration. One of the following message indicators is displayed:
```
- **Blank.** No messages exist for the domain configuration.
- **Information.** Information messages exist for the domain configuration.
- **Warning.** Warning messages exist for the domain configuration.
    Information messages might also exist.
- **Error.** Error messages exist for the domain configuration. Information
    and warning messages might also exist.
To display the messages, you can click the link or status icon. The domain
configuration is either opened in view mode or the existing tab with the
domain configuration is focused and the message log is displayed.

```
Last Modified Date and time the domain configuration was last modified.
```
```
Modified By User ID of the person who last modified the domain configuration.
```
```
Actions for domain configurations
The actions are described in the following tables:
```
**52**   Capacity Provisioning Task


- **Targeted actions:** Actions that apply to the selected domain configurations. To use a targeted action,
    you must select one or more domain configurations. If you select more than one domain configuration,
       only the actions which can be applied to several domain configurations are enabled.
- **General actions:** Actions that apply to domain configurations. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first domain configuration.

```
Table 76. Targeted actions
```
```
Action Description
```
```
View View the selected domain configuration. The selected domain configuration
is opened in a new tab in view mode. When it is already open, the tab is
focussed.
```
```
Modify Modify the selected domain configuration. The selected domain
configuration is opened in a new tab in edit mode. When it is already open,
the tab is focussed.
```
```
Delete Delete the selected domain configurations.
```
```
Copy Create a copy of the selected domain configuration. The copied domain
configuration is opened in a new tab in edit mode.
```
```
Install Install the selected domain configuration on a domain. Optionally, the
domain configuration can be activated after the installation.
```
```
Export to File Export the selected domain configuration to a file.
```
```
Table 77. General actions
```
```
Action Description
```
```
New Define a new domain configuration.
```
```
Import Import a domain configuration.
Import from domain
In the Import submenu you can choose to import a domain
configuration from a domain configuration repository of a domain. ( From
Domain )
Import from file
In the Import submenu you can choose to import a domain
configuration from the local workstation. ( From File ).
```
```
Activate Activates an installed domain configuration for a domain.
```
#### Managing a domain configuration

```
To manage a domain configuration, you can use the Domain Configuration page. To define, view, or modify
a domain configuration, use the New , View , or Modify actions provided in the Domain Configurations
page.
A domain configuration lists a set of z/OS systems and a set of CPCs which can be monitored by the
Provisioning Manager and for which capacity can be managed.
In the Domain Configuration page you define the details of a domain configuration. A domain
configuration is identified by the name in the Domain configuration name field and is described in more
detail by the text in the Description field.
A complete domain configuration must contain at least one observed system and one managed CPC.
```
```
Capacity Provisioning Task   53
```

```
Table 78. Domain configuration fields
```
```
Field Description
```
```
Domain configuration name Domain configurations are identified by name. Domain configuration names
must be unique.
```
```
Description Description of the domain configuration. You can use this field, for example,
to indicate the version of a domain configuration.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for Domain
configuration name and Description.
```
```
CPCs tab
A domain configuration contains a list of managed CPCs. For a managed CPC temporary capacity can be
activated and the Group Capacity can be increased.
To manage the CPCs of a domain configuration, you can use the CPCs tab. To define, view, or modify
a CPC, use the New , View , or Modify actions or click on the CPC in the table to follow the link. When
clicked, the CPC page is opened and details of the selected CPC are displayed. See help topic “Managing
CPCs” on page 58.
```
```
Table 79. Columns in the CPCs table
```
```
Column Description
```
```
CPC Name of the processor complex. This name is the logical name by which it is
identified at the support element (SE) of that processor complex.
```
```
Default Status Indicates if the CPC is enabled or disabled by default, when the domain
configuration is activated.
```
```
Record ID ID of the On/Off CoD record describing temporary capacity that can be
managed on that CPC.
Any indicates that the Provisioning Manager will select an appropriate
record. Note that if there are multiple records, the identifier of the record
to be used should be specified.
None indicates that no temporary capacity shall be activated for the CPC.
```
```
Actions for CPCs
The actions for CPCs are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected CPCs. To use a targeted action, you must select
    one or more CPCs. If you select more than one CPC, only the actions which can be applied to several
    CPCs are enabled.
- **General actions:** Actions that apply to CPCs. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first CPC.

```
Table 80. Targeted actions for CPCs
```
```
Action Description
```
```
View View the selected CPC. The selected CPC is opened and details are
displayed.
```
**54**   Capacity Provisioning Task


_Table 80. Targeted actions for CPCs (continued)_

**Action Description**

**Modify** Modify the selected CPC. The selected CPC is opened and details can be
modified.

**Delete** Delete the selected CPCs.

**Copy** Copy the selected CPCs. The selected CPCs are copied into the clipboard.

_Table 81. General actions for CPCs_

**Action Description**

**New** Define a new CPC. A new CPC is opened and details can be specified.

**Paste** Paste the copied CPCs. To enable this action, invoke the **Copy** action for one
or more CPCs.

```
Systems tab
A domain configuration contains a list of observed systems. An observed system is monitored by the
Provisioning Manger and the Defined Capacity can be increased for this system.
To manage the systems of a domain configuration, you can use the Systems tab. To define, view, or modify
a system, use the New , View , or Modify actions or click on the system in the table to follow the link.
When clicked, the System page is opened and details of the selected system are displayed. See help topic
“Managing systems” on page 57.
```
_Table 82. Columns in the systems table_

**Column Description**

**System** Name of the z/OS system.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Default Status** Indicates if the system is enabled or disabled by default when the domain
configuration is activated.

**Primary Host Address** Symbolic host name or IP address of the system. A CIM server must be
running on the system to be available for the Provisioning Manager.

**Alternate Host Address** Symbolic host name or the IP address of the system to be used if the
primary address is not working.

**Protocol** Indicates if HTTP or HTTPS is used to establish a connection to the CIM
server.

**Port** Port number where the CIM server is listening for HTTP or HTTPS requests.
The port number is required, and it must be an integer between 1 and

65535. The default port number for HTTP is 5988 and for HTTPS 5989.

```
Actions for Systems
The actions for systems are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected systems. To use a targeted action, you must select
    one or more systems. If you select more than one system, only the actions which can be applied to
    several systems are enabled.
- **General actions:** Actions that apply to systems. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.

```
Capacity Provisioning Task   55
```

```
A limited set of actions is available until you create the first system.
```
```
Table 83. Targeted actions for systems
```
```
Action Description
```
```
View View the selected system. The selected system is opened and details are
displayed.
```
```
Modify Modify the selected system. The selected system is opened and details can
be modified.
```
```
Delete Delete the selected systems.
```
```
Copy Copy the selected systems. The selected systems are copied into the
clipboard.
```
```
Table 84. General actions for systems
```
```
Action Description
```
```
New Define a new system. A new system is opened and details can be specified.
```
```
Paste Paste the copied systems. The systems are pasted from the clipboard.
```
**Procedures to manage a domain configuration**

**Create a new domain configuration**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configuration page is
    displayed.
3. From the **Actions** menu, select **New**. The Domain Configuration page containing the new domain
    configuration is displayed.
4. Specify a name and description and add CPCs and systems.
5. Click **OK** to save the domain configuration. The newly created domain configuration is displayed in the
    **Domain Configurations** table.

**Modify an existing domain configuration**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Select the domain configuration you want to modify.
4. From the **Actions** menu, select **Modify**. The Domain Configuration page containing the selected
    domain configuration is displayed.
5. Modify the name and the description and define the CPCs and systems domain configurations.
6. Click **OK** to save the domain configuration. The modified domain configuration is displayed in the
    **Domain Configurations** table.

**View an existing domain configuration**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page opens.

**56**   Capacity Provisioning Task


2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Select the domain configuration to be viewed.
4. From the **Actions** menu, select **View**. The Domain Configuration page containing the selected domain
    configuration is displayed.

```
Managing systems
To manage a system for a domain configuration, you can use the System page. To define, view, or modify a
system, use the New , View , or Modify actions on the Systems tab of the Domain Configuration page.
On the System page you define the details of a system to be monitored by the Provisioning Manager and
for which the Provisioning Manager is allowed to manage capacity. A system is identified by a system
name and a sysplex name.
Note: To complete the domain configuration, you must specify at least one system.
```
_Table 85. Fields on the System page_

**Field Description**

**System** Name of the z/OS system. You may choose from already defined system
names.

**Sysplex** Name of the sysplex to which this z/OS system belongs. You may choose
from already defined sysplex names.

**Default status** Systems are enabled by default. If you want to disable the system by default
select **Disabled**.

**Primary host address** Symbolic host name or IP address of the system. A CIM server must be
running on the system to be available for the Provisioning Manager.

**Alternate host address** If this system has an alternate address to be used if the primary address
is not working, specify either the alternate host name or the alternate IP
address of the system.

**Protocol** You may choose between HTTP and HTTPS protocol to access the CIM
server on the system.

**Port** Port number where the CIM server is listening for HTTP or HTTPS requests.
The port number is required, and it must be an integer between 1 and

65535. The default port number for HTTP is 5988 and for HTTPS 5989.

```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for System and
Sysplex.
Open the Defined Systems section to see the table of already defined systems in this domain
configuration to have a quick reference.
```
**Procedures to manage systems**

**Add a new system**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open the domain configuration you want to modify in modify mode.
4. Select the **Systems** tab.

```
Capacity Provisioning Task   57
```

5. From the **Actions** menu, select **New**.
6. Specify the system, the sysplex, its default status, the primary and optionally the alternate host
    address, the protocol, and port as described in the table above.
7. Click **OK** to accept the changes. A “Messages” on page 125 window opens if the system is not
    complete or contains incompatible specifications. The newly created system is displayed in the
    **Systems** table.

**Modify an existing system**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open the domain configuration you want to modify in modify mode.
4. Select the **Systems** tab.
5. Open the System page by clicking the link to the system you want to edit.
6. Change the system, the sysplex name, its default status, the primary and optionally the alternate host
    address, the protocol, and port as described in the table above.
7. Click **OK** to accept the changes. A “Messages” on page 125 window opens if the system is not
    complete or contains incompatible specifications. The modified system is displayed in the **Systems**
    table.

**View an existing system**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open a domain configuration in view mode.
4. Select the **Systems** tab.
5. Open the System page by clicking the link to the system you want to display.

```
Managing CPCs
To manage a CPC for a domain configuration, you can use the CPC page. To define, view, or modify a CPC,
use the New , View , or Modify actions on the CPCs tab of the Domain Configuration page.
On the CPC page you define the details of a CPC to be monitored by the Provisioning Manager and for
which the Provisioning Manager is allowed to manage capacity.
Note: To complete the domain configuration, you must specify at least one CPC.
```
```
Table 86. Fields on the CPC page
```
```
Field Description
```
```
CPC name Name of the CPC. This name is the logical name by which it is identified at
the support element (SE) of that processor complex. Choose from already
defined CPC names, or choose RETRIEVE MORE to retrieve more CPCs that
are known to the HMC, then select one from the list.
```
```
Default status CPCs are enabled by default. If you want to disable the CPC by default
select Disabled.
```
**58**   Capacity Provisioning Task


_Table 86. Fields on the CPC page (continued)_

**Field Description**

**Record ID** There can be multiple On/Off CoD records describing temporary capacity
that can be activated on that CPC. Each record is identified by a record ID. If
there are multiple records, the identifier of the record to be used should be
specified. Select an option:
**Any**
If you have just one On/Off CoD record. The Provisioning Manager will
then find the record. Note, if you have multiple On/Off CoD records, the
Provisioning Manager will select an arbitrary one.
**None**
If no temporary capacity shall be activated for the CPC.
**Specify a value**
If you want the Provisioning Manager to use a specific On/Off CoD
record. Select or type the identifier of the record describing the
temporary capacity that can be activated on that CPC.

```
Refer to “Naming Conventions” on page 124 in order to find out which values are allowed for CPC name
and Record ID.
Open the Defined CPCs section to see the table of already defined CPCs in this domain configuration to
have a quick reference.
```
**Procedures to manage CPCs**

**Add a new CPC**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open the domain configuration you want to modify in modify mode.
4. Select the **CPCs** tab.
5. From the **Actions** menu, select **New**.
6. Specify the CPC name, its default status, and the record ID as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
7. Click **OK** to accept the changes. A “Messages” on page 125 window opens if the CPC is not complete
    or contains incompatible specifications. The newly created CPC is displayed in the **CPCs** table.

**Modify an existing CPC**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open the domain configuration you want to modify in modify mode.
4. Select the **CPCs** tab.
5. Open the CPC page by clicking on the name of the CPC you want to modify.
6. Change the CPC name, its default status, and the record ID as needed.

```
Capacity Provisioning Task   59
```

```
To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
the CPM domain that should be used to request a list of available CPCs. You can use any one
connection that is listed in the Connections table on the Provisioning Manager page.
```
7. Click **OK** to accept the changes. A “Messages” on page 125 window opens if the CPC is not complete
    or contains incompatible specifications. The modified CPC is displayed in the **CPCs** table.

**View an existing CPC**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Open a domain configuration in view mode.
4. Select the **CPCs** tab.
5. Open the CPC page by clicking the link to the CPC you want to display.

```
Retrieving CPCs
The Retrieve CPCs page lets you retrieve all known CPCs from a domain.
On the Retrieve CPCs page, you select a connection and a CPM domain to use in requesting a list of all
CPCs known by the HMC.
```
```
Table 87. Fields on the Retrieve CPCs page
```
```
Field Description
```
```
Connection The connection. You can use any connection that is listed in the Connections
table on the Provisioning Manager page.
```
```
Domain Name of the domain.
```
```
Retrieving Record IDs
The Retrieve Record IDs page lets you retrieve all OOCoD record IDs from a CPC.
On the Retrieve Record IDs page, you select a connection and a domain to define which OOCoD record
IDs to retrieve.
```
```
Table 88. Fields on the Retrieve Record IDs page
```
```
Field Description
```
```
Connection The connection. You can use any connection that is listed in the Connections
table on the Provisioning Manager page.
```
```
Domain Name of the domain.
```
```
CPC Name of the CPC.
```
#### Installing domain configurations

```
To install a domain configuration use the Install action provided in the Domain Configurations page.
Installing a domain configuration transfers a domain configuration from the z/OSMF repository to the
domain configuration repository of a domain. Optionally, you can activate the domain configuration after
successful installation.
The Provisioning Manager which is responsible for the domain owns a policy repository and a domain
configuration repository. You can store multiple domain configurations for different purposes in the
domain configuration repository of a domain, but only one domain configuration can be active in the
domain. To install a domain configuration, a connection to the Provisioning Manager must be established
and you must be a member of the Provisioning Manager control security group.
```
**60**   Capacity Provisioning Task


```
Before installing a domain configuration, verify that the domain configuration to be installed is correct and
does not contain any errors. Then select the domain, on which to install the domain configuration. Finally,
specify if you want to activate the domain configuration after installation. The domain configuration
is transferred to the domain configuration repository of the selected domain. If the transfer is not
successful, the domain configuration is also not activated.
```
```
Table 89. Fields in the Install Domain Configuration window
```
```
Field Description
```
```
Domain configuration name Name of the domain configuration to be installed.
```
```
Domain configuration
description
```
```
Description of the domain configuration to be installed.
```
```
Last modified Date and time the domain configuration was last modified.
```
```
Modified by User ID of the last user who modified the domain configuration.
```
```
Attention Hint whether there are warnings.
```
```
Connection Connection to the system where the Provisioning Manager for the domain is
running. Host address, port and protocol are displayed.
```
```
Domain Domain where the domain configuration is to be installed.
```
```
Activate domain configuration
immediately after successful
installation
```
```
Indicator of whether the domain configuration will be activated immediately
after it is installed in the domain. If selected, the domain configuration will
be activated. Otherwise, you can use the Activate action, which is provided
on the Domain Configurations tab, to activate the domain configuration
later.
```
**Procedure to install a domain configuration**

1. To install a domain configuration select the **Capacity Provisioning** task under the Performance
    category in the navigation area.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Select the domain configuration you want to install.
4. From the **Actions** menu, select **Install**
    **Note:** You cannot install domain configurations that contain messages with an error severity.
5. Select a connection and select a domain from the list of domains that can be reached using the
    selected connection.
6. Optionally, if you want to activate the domain configuration after installation, select the **Activate**
    **domain configuration immediately after successful installation** checkbox.
7. Click **OK**.

```
Result
If the installation completed successfully, you will see a message indicating the successful installation. If
you specified the optional step to also activate the domain configuration you will see a second message
about the successful activation.
```
#### Activating domain configurations

```
To activate an installed domain configuration, you can use the Activate action provided in the Domain
Configurations page.
Activating a domain configuration changes the global processing information of the domain to use the
selected domain configuration of the domain configuration repository.
```
```
Capacity Provisioning Task   61
```

```
When a domain configuration is activated for the domain, the Provisioning Manager starts to use this
domain configuration to control the domain. The domain configuration must be installed in the domain
configuration repository of the domain.
You can store multiple domain configurations for different purposes in the repository, but only one domain
configuration can be active in the domain. To be able to activate a domain configuration, a connection to
the Provisioning Manager must be established and you must be a member of the Provisioning Manager
control security group. The Provisioning Manager validates the content before the domain configuration is
activated.
```
```
Table 90. Fields in the Activate Installed Domain Configuration dialog.
```
```
Field Description
```
```
Connection Connection to the system where a Provisioning Manager for the domain is running.
Host address, port and protocol are displayed.
```
```
Domain Domain where the domain configuration shall be activated.
```
```
Domain configuration
name
```
```
Name of the domain configuration to be activated.
```
```
Procedure to activate a domain configuration
You can select from the installed domain configurations of the selected domain.
```
1. To activate an installed domain configuration select the **Capacity Provisioning** task under the
    Performance category in the navigation area.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. From the **Actions** menu, select **Activate**.
4. Select a connection.
5. Select a domain from the list of domains that can be reached using the selected connection.
6. Select the name of the domain configuration that you want to activate from the list of domain
    configurations which are installed in the repository of the domain. The domain configuration must
    be installed in the configuration repository of the domain.
7. Click **OK**.

```
Result
If the activation completes successfully, you see a message indicating the successful activation.
```
#### Exporting domain configurations to a file

```
To export a domain configuration from the z/OSMF repository to a file on your workstation, you can use
the Export To File action provided in the Domain Configurations page.
The domain configuration is transferred to the local workstation and is stored in the specified location.
```
**Before you begin**

```
If you are using Microsoft Internet Explorer, ensure that automatic prompting for file downloads is
enabled for the Web link (URL) to the active z/OSMF instance. If the feature is disabled, when you attempt
to display the File Download window, the browser window refreshes and all of your selections and
unsaved changes are discarded. To enable automatic prompting for file downloads, complete the steps
provided in help topic Enabling automatic prompting for file downloads.
```
**62**   Capacity Provisioning Task


**Procedure to export a domain configuration to a file**

1. To export a domain configuration, select the **Capacity Provisioning** task under the Performance
    category in the navigation area.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. Select the domain configuration you want to export. You can select only one domain configuration.
4. From the **Actions** menu, select **Export To File**.
5. Select a location to store the XML file or open it with a local XML viewer of your choice.
6. Click **OK**.

```
Result
If the file was exported, it is listed in your local download directory or displayed in the XML viewer
you selected. The domain configuration is exported as an XML file named domain-configration-name.xml
where domain-configuration-name is the name of the domain configuration you exported.
```
#### Importing domain configurations from a file

```
To import a domain configuration from a file on your local workstation to the z/OSMF repository, you can
use the Import > From File action provided in the Domain Configurations page.
```
```
Table 91. Fields of the Import Domain Configuration From File window
```
```
Field Description
```
```
File to import File containing the domain configuration to be imported.
```
```
Import Select this option to import the domain configuration with the name of the
domain configuration that is specified in the file to be imported.
```
```
Import with new name Select this option to import the domain configuration using a new name.
Then, in the Domain configuration name field, enter the name to be used.
```
```
Domain configuration name Enter the name to use for the domain configuration. The name must comply
with the syntax rules described in help topic “Naming Conventions” on page
124.
```
```
Replace existing domain
configuration with same name
```
```
If this domain configuration has the same name as a domain configuration
that already exists in z/OSMF, select this option to overwrite the existing
domain configuration.
```
**Procedure**

1. To import a domain configuration select the **Capacity Provisioning** task under the Performance
    category in the navigation area.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. From the **Actions** menu, select **Import > From File**.
4. Click **Browse** to select the file containing the domain configuration to be imported. The domain
    configuration must be in XML format.
5. Decide whether you want to save the imported domain configuration with the current name or with a
    new name.
6. Enter the new name if you decided to change the name.
7. Decide whether you want to overwrite an existing domain configuration.
8. Click **OK**.

```
Capacity Provisioning Task   63
```

```
Result
If the domain configuration was imported, it is listed in the Domain Configurations table using the domain
configuration name contained in the XML file or the name you specified.
Note: The domain configuration name contained in the file may differ from the file name.
```
#### Importing domain configurations from a domain

```
To import a domain configuration from a domain to the z/OSMF repository, you can use the Import > From
Domain action provided in the Domain Configurations page.
The domain configuration is transferred from the domain configuration repository of the selected domain
to the z/OSMF repository. To import a domain configuration from a domain, a connection to the
Provisioning Manager must be established and you must be a member of the Provisioning Manager control
security group.
```
```
Table 92. Fields of the Import Domain Configuration From Domain window
```
```
Field Description
```
```
Connection Connection to the system where the Provisioning Manager for the domain is
running. Host address, port and protocol are displayed.
```
```
Domain Domain owning the domain configuration repository.
```
```
Domain configuration The domain configuration to be imported.
```
```
Import Select this option to import the domain configuration with the name as in
the domain configuration repository.
```
```
Import with new name Select this option to import the domain configuration using a new name.
Then, in the Domain configuration name field, enter the name to be used.
```
```
Domain configuration name Enter the name to use for the domain configuration. The name must comply
with the syntax rules described in help topic “Naming Conventions” on page
124.
```
```
Replace existing domain
configuration with same name
```
```
If this domain configuration has the same name as a domain configuration
that already exists in z/OSMF, select this option to overwrite the existing
domain configuration.
```
**Procedure**

1. To import a domain configuration select the **Capacity Provisioning** task under the Performance
    category in the navigation area.
2. In the **Overview** tab, click the **Domain Configurations** link. The Domain Configurations page is
    displayed.
3. From the **Actions** menu, select **Import > From Domain**.
4. Select a connection and a domain.
5. Select the domain configuration that you want to import.
6. Decide whether you want to save the imported domain configuration with the current name or with a
    new name.
7. Enter the new name if you decided to change the name.
8. Decide whether you want to overwrite an existing domain configuration.
9. Click **OK**.

```
Result
If the import is successful, the imported domain configuration shows up in your Domain Configurations
table and is selected.
```
**64**   Capacity Provisioning Task


### Managing policies

```
The Policies page shows information about the defined policies. You can define, modify, view, import,
export, or install and activate provisioning policies.
A provisioning policy defines when provisioning is allowed, which work qualifies for provisioning, and how
much additional capacity can be provisioned. Provisioning scopes on the policy level restrict the capacity
that can be provisioned by the rules in the policy. A policy consists of the following elements:
Maximum Processor Scope
The total amount of temporary processor resources that can be activated for CPCs by the rules in the
policy.
Logical Processor Scope
The z/OS systems on which the number of logical processors is monitored.
Maximum Defined Capacity Scope
The maximum amount of MSU by which the Defined Capacity for a z/OS system can be increased by
the rules in the policy.
Maximum Group Capacity Scope
The maximum amount of MSU by which the Group Capacity for a capacity group of a CPC can be
increased by the rules in the policy.
Rules
A provisioning rule contains a set of provisioning conditions and scopes which define provisioning
limits for different types of capacity. The provisioning scopes restrict the capacity that can be
provisioned by the conditions in the rule
Processor Scope
The temporary processor resources that can be activated for CPCs by the conditions in the rule.
Defined Capacity Scope
The maximum amount of MSU by which the Defined Capacity for a z/OS system can be increased
by the conditions in the rule.
Group Capacity Scope
The maximum amount of MSU by which the Group Capacity for a capacity group of a CPC can be
increased by the conditions in the rule.
Provisioning Conditions
Set of time conditions and workload conditions.
Time Conditions
Time periods when additional capacity can be provisioned.
Utilization Conditions
Physical consumption level that can trigger provisioning of additional processor capacity.
Workload Conditions
Work that can trigger the provisioning of additional capacity.
The policies that have been defined in z/OSMF are stored in the z/OSMF repository and are listed in the
table on the Policies page. The repository is shared across all users authorized to access the Capacity
Provisioning task; therefore, all users see the same list of policies. To retrieve the latest information from
the repository and refresh the Policies table, click the Refresh button.
For a description of the columns in the Policies table, see Table 93 on page 66.
For a description of the actions that you can take against policies, see “Actions for policies” on page 67.
```
```
Capacity Provisioning Task   65
```

**Policies table**

```
Table 93. Columns in the Policies table
```
```
Column Description
```
```
Name Name of the policy. The name is displayed as a hyperlink. When clicked,
the name link opens the policy in a new tab in view mode and displays the
policy details.
```
```
Description Description of the policy. You can use this field, for example, to indicate the
version of a policy.
```
```
Activity Indicates the state of the policy. This column can have one of the following
values:
```
- Being viewed
- Being modified
- Changes pending
- Being viewed, changes pending
- Being modified, changes pending
- Temporary
The values and icons in the **Activity** column are displayed as a hyperlink.
Click the link to display the associated message. To display the messages
or help for the messages, you can also select the cell that contains the link
or icon and press **Ctrl+M** (message) or **Ctrl+Q** (message help). For more
details about each state, see help topic z/OSMF “Repository” on page 121.
**Note:** If your browser is busy and cannot communicate with the z/OSMF
server within three minutes, z/OSMF assumes that the policy is not in use
and releases any locks. If this situation occurs, you might notice one of the
following:
- The state in the **Activity** column does not reflect the actual state of the
    policy. For example, if you have the policy open in view or edit mode,
    the activity might be blank even though you are modifying or viewing the
    policy.
- Another user deleted the policy while you were viewing or modifying it.
If these situations occur frequently, try working with fewer tabs, or consider
using a different browser. For a list of tested browsers, see the z/OSMF
Browser Compatibility Web page.

```
Message Indicates the highest severity of the messages that occurred for the policy.
One of the following message indicators is displayed:
```
- **Blank.** No messages exist for the policy.
- **Information.** Information messages exist for the policy.
- **Warning.** Warning messages exist for the policy. Information
    messages might also exist.
- **Error.** Error messages exist for the policy. Information and warning
    messages might also exist.
To display the messages, click the link or status icon, or select the cell that
contains the link or icon and press **Ctrl+M**. The policy is either opened in
view mode or the existing tab with the policy is focused and the message log
is displayed.

**66**   Capacity Provisioning Task


```
Table 93. Columns in the Policies table (continued)
```
```
Column Description
```
```
Last Modified Date and time the policy was last modified.
```
```
Modified By User ID of the person who last modified the policy.
```
```
Actions for policies
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected policies. To use a targeted action, you must select
    one or more policies. If you select more than one policy, only the actions which can be applied to
    several policies are enabled.
- **General actions:** Actions that apply to policies. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first policy.

```
Table 94. Targeted actions
```
```
Action Description
```
```
View View the selected policy. The selected policy is opened in a new tab in view
mode. When it is already open, the tab is focussed.
```
```
Modify Modify the selected policy. The selected policy is opened in a new tab in edit
mode. When it is already open, the tab is focussed.
```
```
Delete Delete the selected policies.
```
```
Copy Create a copy of the selected policy. The copied policy is opened in a new
tab in edit mode.
```
```
Install Install the selected policy on a Provisioning Manager.
```
```
Export to File Export the selected policy to a file.
```
```
Table 95. General actions
```
```
Action Description
```
```
New Define a new policy.
```
```
Import Import a policy.
Import from domain
In the Import submenu you can choose to import a policy from the
policy repository of a domain ( From Domain ).
Import from file
In the Import submenu you can choose to import a policy from the local
workstation. ( From File ).
```
```
Activate Activate an installed policy for a domain.
```
#### Managing a policy

```
To manage a policy, you can use the Policy page. To define, view, or modify a policy, use the New , View , or
Modify actions provided in the Policies page.
A provisioning policy contains a set of provisioning rules and provisioning scopes which define
provisioning limits for different types of capacity. The provisioning rules define the time periods in which
```
```
Capacity Provisioning Task   67
```

```
additional capacity can be provisioned and the work which can trigger the provisioning of this capacity.
The provisioning scopes restrict the capacity that can be provisioned by the rules in the policy:
```
- The maximum processor scope restricts the temporary processor resources which can be activated for
    CPCs.
- The logical processor scope defines the z/OS systems on which Capacity Provisioning monitors the
    number of logical processors.
- The maximum defined capacity scope restricts the increase of the Defined Capacity of z/OS systems.
- The maximum group capacity scope restricts the capacity increase for capacity groups.
In the Policy page you define the details of a policy. A policy is identified by the name in the **Policy name**
field and is described in more detail by the text in the **Description** field.
A complete policy must contain at least one processor limit in the maximum processor scope, or one
capacity limit in the maximum defined capacity scope or one in the maximum group capacity scope, and
at least one rule. Optionally, you can define the logical processor scope.

```
Table 96. Policy entry fields
```
```
Field Description
```
```
Policy name Policies are identified by name. Policy names must be unique.
```
```
Description Description of the policy for your reference.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which values are allowed for Policy name
and Description.
```
```
Maximum Processor Scope tab
A policy contains a maximum processor scope element which defines the total amount of temporary
processor resources that can be activated for CPCs by all the rules contained in the policy.
Only resources that are activated through a Capacity Provisioning policy are considered in this limit.
Resources that are activated manually, by using either Provisioning Manager commands or the interfaces
available on the HMC, are not managed by the Provisioning Manager.
For each CPC in the table, the following resources are bound:
```
- The general purpose capacity in MSU.
- The number of Application Assist Processors (zAAPs).
- The number of Integrated Information Processors (zIIPs).
**Note:** At least one processor limit in the maximum processor scope or one capacity limit in the maximum
defined capacity scope or in the maximum group capacity scope must be specified.
To manage the maximum processor scope of a policy, you can use the **Maximum Processor Scope** tab.
To define, view, or modify a processor limit, use the **New** , **View** , or **Modify** actions or in the table click on
a CPC for which the processor limit is defined to follow the link. When clicked, the Maximum Processor
Limit page is opened for the CPC and processor limit details are displayed. See help topic “Managing the
maximum processor scope” on page 73.

```
Table 97. Columns in the Maximum Processor Scope table
```
```
Columns Description
```
```
CPC Name of the CPC. This name is the logical name by which it is identified at
the support element (SE) of that processor complex.
```
```
Max. Activation (MSU) Maximum amount of MSU to be activated.
```
```
Max. zAAP Processors Maximum number of zAAP processors to be activated.
```
**68**   Capacity Provisioning Task


_Table 97. Columns in the Maximum Processor Scope table (continued)_

**Columns Description**

**Max. zIIP Processors** Maximum number of zIIP processors to be activated.

**Primary Activation (MSU)** Minimum amount of MSU to be activated with the first activation.

**Secondary Activations (MSU)** Minimum amount of MSU to be activated with the second and all following
activations.

```
Logical Processor Scope tab
A policy contains a logical processor scope element, which defines the z/OS systems where the number of
logical processors is monitored. For each system you can either specify a maximum number of processors
or specify that the limit of the LPAR definition applies. Specifying a logical processor limit is optional. If a
limit is defined for a system the Provisioning Manager monitors the number of logical processors for this
system and informs you when changes are required. When a limit is reached the Provisioning Manager
stops to recommend on additional logical processors.
To manage the logical processor scope of a policy, you can use the Logical Processor Scope tab. To
define, view, or modify a processor limit, use the New , View , or Modify actions or in the table click on
the system for which the processor limit is defined to follow the link. When clicked, the Logical Processor
Limit page is opened for the system and processor limit details are displayed. See help topic “Managing
the logical processor scope” on page 74.
```
_Table 98. Columns in the Logical Processor Scope table_

**Columns Description**

**System** Name of the z/OS system for which recommendations to change the
number of logical processors are issued.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. CP Processors** Maximum number of logical general purpose processors.

**Max. zAAP Processors** Maximum number of logical zAAP processors.

**Max. zIIP Processors** Maximum number of logical zIIP processors

**Action** System where to send a message to when a need for more or less
processors is detected. Possible values:

- Message on runtime system.
- Message on managed system.

**Maximum Defined Capacity Scope tab**

```
A policy contains a maximum defined capacity scope element which restricts the increase of the Defined
Capacity of z/OS systems. For each system in the table, it defines the maximum amount of MSU by which
the Defined Capacity for the z/OS system can be increased by all the contained rules.
Only increases of Defined Capacity that are performed through a Capacity Provisioning policy are
considered in this limit. Increases that are performed manually, by using either Provisioning Manager
commands or the interfaces available on the HMC, are not managed by the Provisioning Manager.
Note: At least one processor limit in the maximum processor scope or one capacity limit in the maximum
defined capacity scope or in the maximum group capacity scope must be specified.
To manage the maximum defined capacity scope of a policy, you can use the Maximum Defined Capacity
Scope tab. To define, view, or modify a capacity limit, use the New , View , or Modify actions or in the table
click on the system for which the capacity limit is defined to follow the link. When clicked, the Maximum
```
```
Capacity Provisioning Task   69
```

```
Defined Capacity Limit page is opened for the system and capacity limit details are displayed. See help
topic “Managing the maximum defined capacity scope” on page 76.
```
```
Table 99. Columns in the Maximum Defined Capacity Scope table
```
```
Columns Description
```
```
System Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Max. Increase (MSU) Maximum amount of MSU by which the Defined Capacity of the system can
be increased.
```
```
Primary Increment (MSU) Minimum amount of MSU by which the Defined Capacity of the system can
be increased with the first increment.
```
```
Secondary Increments (MSU) Minimum amount of MSU by which the Defined Capacity of the system can
be increased on the second increment and all subsequent increments.
```
```
Maximum Group Capacity Scope tab
A policy contains a maximum group capacity scope element which restricts the capacity increase for
capacity groups. For each capacity group in the table, it defines the maximum amount of MSU by which
the Group Capacity can be increased by all the rules in the policy.
Only increases of the Group Capacity that are performed through a Capacity Provisioning policy are
considered in this limit. Increases that are performed manually, by using either Provisioning Manager
commands or the interfaces available on the HMC, are not managed by the Provisioning Manager.
Note: At least one processor limit in the maximum processor scope or one capacity limit in the maximum
defined capacity scope or in the maximum group capacity scope must be specified.
To manage the maximum group capacity scope of a policy, you can use the Maximum Group Capacity
Scope tab. To define, view, or modify a capacity limit, use the New , View , or Modify actions or in the table
or click on the group for which the capacity limit is defined to follow the link. When clicked, the Maximum
Group Capacity Limit page is opened for the capacity group and capacity limit details are displayed. See
help topic “Managing the maximum group capacity scope” on page 78.
```
```
Table 100. Columns in the Maximum Processor Scope table
```
```
Columns Description
```
```
Group Name of the capacity group
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. Increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased.
```
```
Primary Increment (MSU) Minimum amount of MSU by which the Group Capacity can be increased
with the first increment.
```
```
Secondary Increments (MSU) Minimum amount of MSU by which the Group Capacity can be increased on
the second increment and all subsequent increments.
```
```
Actions for processor limits and capacity limits
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected limits. To use a targeted action, you must select
    one or more limits. If you select more than one limit, only the actions which can be applied to several
    limits are enabled.
- **General actions:** Actions that apply to limits. No selection is required.

**70**   Capacity Provisioning Task


- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first limit.

_Table 101. Targeted actions_

**Action Description**

**View** View the selected limit. The selected limit is opened and details are
displayed.

**Modify** Modify the selected limit. The selected limit is opened and details can be
modified.

**Delete** Delete the selected limits.

**Copy** Copy the selected limits. The selected limits are copied into the clipboard.

_Table 102. General actions_

**Action Description**

**New** Define a new limit. A new limit is opened and details can be specified.

**Paste** Paste the copied limits. The limits are pasted from the clipboard.

```
Rules tab
A policy contains one or more provisioning rules for the provisioning of additional capacity.
To manage the rules of a policy, you can use the Rules tab. To define, view, or modify a rule, use the New ,
View , or Modify actions or click on the rule in the table to follow the link. When clicked, the Rule page is
opened and rule details are displayed. See help topic “Managing rules” on page 80.
```
_Table 103. Columns in the rules table_

**Columns Description**

**Name** Name of the rule.

**Description** Description of the rule.

**Default status** Indicates if the rule is enabled or disabled by default, when the policy is
activated.

```
Actions for rules
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected rule. To use a targeted action, you must select one
    or more rules. If you select more than one rule, only the actions which can be applied to several rules
    are enabled.
- **General actions:** Actions that apply to rules. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first rule.

_Table 104. Targeted actions_

**Action Description**

**View** View the selected rule. The selected rule is opened and details are
displayed.

```
Capacity Provisioning Task   71
```

```
Table 104. Targeted actions (continued)
```
```
Action Description
```
```
Modify Modify the selected rule. The selected rule is opened and details can be
modified.
```
```
Delete Delete the selected rules.
```
```
Copy Copy the selected rules. The selected rules are copied into the clipboard.
```
```
Table 105. General actions
```
```
Action Description
```
```
New Define a new rule. A new rule is opened and details can be specified.
```
```
Paste Paste the copied rules. The rules are pasted from the clipboard. New unique
names are generated for the pasted rules.
```
```
Switch to a different element of the same policy
To switch to a different element of the same policy, you do not have to navigate to it step by step. Instead,
you can take the fast path by clicking the Switch to button on the right page border and select a policy
element from the displayed policy outline. You may switch to the following element types:
```
- Policy
- Rule
- Condition
- Workload Condition

**Procedures to manage a policy**

**Create a new policy**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. From the **Actions** menu, select **New**. The Policy page containing the new policy is displayed.
4. Specify a name and description, define the provisioning scopes and add **Rules**.
5. Click **OK** to save the policy. The newly created policy is displayed in the table on the Policies page.

**Modify an existing policy**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Select the policy you want to modify
4. From the **Actions** menu, select **Modify**. The Policy page containing the selected policy is displayed.
5. Modify the name and the description and change the provisioning scopes and **Rules**.
6. Click **OK** to save the policy. The modified policy is displayed in the table on the Policies page.

**View an existing policy**

- Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed

**72**   Capacity Provisioning Task


- In the **Overview** tab, click the **Policies** link. The Policies page is displayed
- Select the policy you want to be viewed.
- From the **Actions** menu, select **View**. The Policy page containing the selected policy is displayed.

```
Managing the maximum processor scope
To manage a provisioning limit for a CPC, that restricts the temporary processor resources that can be
activated by all rules of the policy, you can use the Maximum Processor Limit page. To define, view, or
modify a processor limit in the maximum processor scope, use the New , View , or Modify actions on the
Maximum Processor Scope tab on the Policy page.
In the Maximum Processor Limit page you define the details of a processor limit in the maximum
processor scope of a policy. The details contain the CPC name, the total amount of temporary processor
resources that can be activated by all provisioning rules, and the capacity increments defined for the CPC.
The capacity increments denote the minimum capacity that can be added. They are used for workload
based capacity activation. Neither the primary nor the secondary activation amounts must exceed the
maximum capacity specified in the Max. activation (MSU) field. And you cannot define two different
limits for one CPC in the maximum processor scope of a policy.
A processor limit should define a positive value for at least one type of capacity.
To complete the definition of a policy specify the rules for the provisioning of additional capacity.
Optionally, you may specify processor limits in the logical processor scope, or capacity limits in the
maximum defined capacity scope or in the maximum group capacity scope.
The processor limit is identified by the name in the CPC field.
```
_Table 106. Fields on the Maximum Processor Limit page_

**Field Description**

**CPC** Name of the processor complex. This name is the logical name by which it
is identified at the support element (SE) of that processor complex. Refer
to “Naming Conventions” on page 124 in order to find out which names are
allowed.

**Max. activation (MSU)** Maximum amount of MSU to be activated.

**Max. zAAP processors** Maximum number of Application Assist Processors (zAAPs) to be activated.

**Max. zIIP processors** Maximum number of Integrated Information Processors (zIIPs) to be
activated.

**Primary activation (MSU)** Minimum amount of MSU to be activated with the first activation.

**Secondary activations (MSU)** Minimum amount of MSU to be activated with the second and all following
activations.

```
Open the Defined Maximum Processor Limits section to see the table of already defined limits in the
maximum processor scope of this policy to have a quick reference.
```
**Procedures to manage processor limits in the maximum processor scope**

**Add a new processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Processor Scope** tab.

```
Capacity Provisioning Task   73
```

5. From the **Actions** menu, select **New**. The Maximum Processor Limit page is displayed.
6. Specify the CPC name, the total amount of temporary processor resources that can be activated by all
    provisioning rules, and the capacity increments defined for the CPC as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
7. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The newly created processor limit is displayed in the
    **Maximum Processor Scope** table.

**Modify an existing processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Processor Scope** tab
5. Open the Maximum Processor Limit page by clicking on the CPC whose processor limit you want to
    modify.
6. Change the CPC name, the total amount of temporary processor resources that can be activated by all
    provisioning rules, and the capacity increments defined for the CPC as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
7. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The modified processor limit is displayed in the
    **Maximum Processor Scope** table.

**View an existing processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed
3. Open a policy in view mode.
4. Select the **Maximum Processor Scope** tab
5. Open the Maximum Processor Limit page by clicking on the CPC whose processor limit details you
    want to display.

```
Managing the logical processor scope
To manage a provisioning limit for the logical processors of a z/OS system, you can use the Logical
Processor Limit page. To define, view, or modify a processor limit in the logical processor scope, use the
New , View , or Modify actions on the Logical Processor Scope tab on the Policy page.
A logical processor limit defines the system where the Provisioning Manager can monitor the number
of logical processors and defines limits when the Provisioning Manager stops to issue provisioning
recommendations. Specifying a logical processor limit is optional. If a limit is defined for a system the
Provisioning Manager monitors the number of logical processors for this system and informs you when
changes are required. If a console message is displayed, follow the recommendation and perform the
activation and deactivations on the affected system yourself. When the limit is reached the Provisioning
Manager stops to recommend on additional logical processors.
In the Logical Processor Limit page you define the details of a processor limit in the logical processor
scope of the policy. The details contain the system and the sysplex name and the maximum number
```
**74**   Capacity Provisioning Task


```
of processors. The action defines on which system the console message about necessary changes is
displayed. You cannot define two different limits for one system in the logical processor scope.
To complete the definition of a policy specify the rules for the provisioning of additional capacity and
processor limits in the maximum processor scope or capacity limits in the maximum defined capacity
scope or in the maximum group capacity scope.
The processor limit is identified by the name in the System and in the Sysplex field.
```
_Table 107. Fields on the Logical Processor Limit page_

**Field Description**

**System** Name of the z/OS system for which recommendations to change the
number of logical processors are issued.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. CP Processors** Maximum number of general purpose processors

```
Select Max. possible
to specify as many logical general purpose processors as allowed by the
z/OS and LPAR configuration.
Select No additional processors
to inhibit recommendations for logical CPs.
Select Specify a value
to specify the maximum number of logical CPs.
```
**Max. zAAP Processors** Number of Application Assist Processors (zAAPs)

```
Select Max. possible
to specify as many logical zAAPs as allowed by the z/OS and LPAR
configuration.
Select No additional processors
to inhibit recommendations for logical zAAPs.
Select Specify a value
to specify the maximum number of logical zAAPs.
```
**Max. zIIP Processors** Number of Integrated Information Processors (zIIPs)

```
Select Max. possible
to specify as many logical zIIPs as allowed by the z/OS and LPAR
configuration.
Select No additional processors
to inhibit recommendations for logical zIIPs.
Select Specify a value
to specify the maximum number of logical zIIPs.
```
**Action** By default the Provisioning Manager sends a message to the system where
the Provisioning Manager runs. Alternatively you may choose to send a
message to the console on the managed system.

```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for System and
Sysplex.
Open the Defined Logical Processor Limits section to see the table of already defined limits in the logical
processor scope of this policy to have a quick reference.
```
**Procedures to manage processor limits in the logical processor scope**

```
Capacity Provisioning Task   75
```

**Add a new logical processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Logical Processor Scope** tab.
5. From the **Actions** menu, select **New**. The Logical Processor Limit page is displayed.
6. Specify the system and the sysplex name, the maximum number of processors, and the defined action
    as described in the table above.
7. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The newly created processor limit is displayed in the
    **Logical Processor Scope** table.

**Modify an existing logical processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Logical Processor Scope** tab.
5. Open the Logical Processor Limit page by clicking on the system whose logical processor limit you
    want to modify.
6. Change the system and the sysplex name, the maximum number of processors, and the defined action
    as described in the table above.
7. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The modified processor limit is displayed in the **Logical**
    **Processor Scope** table.

**View an existing logical processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Logical Processor Scope** tab.
5. Open the Logical Processor Limit page by clicking on the system whose logical processor limit details
    you want to display.

```
Managing the maximum defined capacity scope
To manage a provisioning limit for a z/OS system, that restricts how much the Defined Capacity can be
increased by all rules of the policy, you can use the Maximum Defined Capacity Limit page. To define,
view, or modify a capacity limit in the maximum defined capacity scope, use the New , View , or Modify
actions on the Maximum Defined Capacity Scope tab on the Policy page.
In the Maximum Defined Capacity Limit page you define the details of a capacity limit in the maximum
defined capacity scope of a policy. It defines how much the Defined Capacity for the z/OS system can
be increased. The details contain the system and the sysplex name and the maximum amount of MSU
by which the Defined Capacity of the system can be increased by all provisioning rules, and the capacity
increments defined for the system. The increments denote the minimum amount of MSU by which the
Defined Capacity of the system can be increased, if possible. They are used for workload based capacity
provisioning. Neither the primary nor the secondary increments must exceed the maximum increase
```
**76**   Capacity Provisioning Task


```
specified in the Max. increase (MSU) field. You cannot define two different limits for one system in the
maximum defined capacity scope of a policy.
To complete the definition of a policy specify the rules for the provisioning of additional capacity.
Optionally you may specify group capacity limits in the maximum group capacity scope or processor
limits in the maximum processor scope or in the logical processor scope.
The capacity limit is identified by the name in the System and in the Sysplex field.
```
_Table 108. Fields on the Maximum Defined Capacity Limit page_

**Field Description**

**System** Name of the z/OS system.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. increase (MSU)** Maximum amount of MSU by which the Defined Capacity of the system can
be increased.

**Primary increment (MSU)** Minimum amount of MSU by which the Defined Capacity of the system can
be increased with the first increment.

**Secondary increments (MSU)** Minimum amount of MSU by which the Defined Capacity of the system can
be increased on the second increment and all subsequent increments.

```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for System and
Sysplex.
Open the Defined Maximum Defined Capacity Limits section to see the table of already defined limits in
the maximum defined capacity scope of this policy to have a quick reference.
```
**Procedures to manage capacity limits in the maximum defined capacity scope**

**Add a new capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Defined Capacity Scope** tab.
5. From the **Actions** menu, select **New**. The Maximum Defined Capacity Limit page is displayed.
6. Specify the system and the sysplex name, the maximum amount of MSU by which the Defined Capacity
    of the system can be increased by all provisioning rules, and the capacity increments defined for the
    system as described in the table above.
7. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The newly created capacity limit is displayed in the **Maximum**
    **Defined Capacity Scope** table.

**Modify an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Defined Capacity Scope** tab
5. Open the Maximum Defined Capacity Limit page by clicking on the system whose capacity limit you
    want to modify.

```
Capacity Provisioning Task   77
```

6. Change the system and the sysplex name, the maximum amount of MSU by which the Defined
    Capacity of the system can be increased by all provisioning rules, and the capacity increments defined
    for the system as described in the table above.
7. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The modified capacity limit is displayed in the **Maximum Defined**
    **Capacity Scope** table.

**View an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Maximum Defined Capacity Scope** tab
5. Open the Maximum Defined Capacity Limit page by clicking on the system whose capacity limit you
    want to display.

```
Managing the maximum group capacity scope
To manage a provisioning limit for a capacity group, that restricts how much the Group Capacity can be
increased by all rules of the policy, you can use the Maximum Group Capacity Limit page. To define, view,
or modify a capacity limit in the maximum group capacity scope, use the New , View , or Modify actions on
the Maximum Group Capacity Scope tab on the Policy page.
A capacity group consists of a group of LPARs on the same CPC. It is possible to define multiple groups on
a CPC, but any partition (z/OS system) can only belong to one group (or no group at all). Such a capacity
group is independent of a sysplex and an LPAR cluster. For managing Group Capacity with Capacity
Provisioning, the observed systems have to run on a on a IBM zEnterprise 196 (z196) server or later.
In the Maximum Group Capacity Limit page you define the details of a capacity limit in the maximum
group capacity scope of a policy. It defines how much the Group Capacity for a capacity group of a CPC
can be increased. The details contain the name of the capacity group, the CPC name, the maximum
amount of MSU by which the Group Capacity can be increased by all provisioning rules, and the capacity
increments defined for the capacity group. The increments denote the minimum amount of MSU by which
the Group Capacity can be increased, if possible. They are used for workload based capacity provisioning.
Neither the primary nor the secondary increments must exceed the maximum increase specified in the
Max. increase (MSU) field. You cannot define two different limits for one capacity group in the maximum
group capacity scope of a policy.
To complete the definition of a policy specify the rules for the provisioning of additional capacity.
Optionally you may specify defined capacity limits in the maximum defined capacity scope or processor
limits in the maximum processor scope or in the logical processor scope.
The capacity limit is identified by the name in the Group and in the CPC field.
```
```
Table 109. Fields on the Maximum Group Capacity Limit page
```
```
Field Description
```
```
Group Name of the capacity group
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased.
```
```
Primary increment (MSU) Minimum amount of MSU by which the Group Capacity can be increased
with the first increment.
```
**78**   Capacity Provisioning Task


_Table 109. Fields on the Maximum Group Capacity Limit page (continued)_

**Field Description**

**Secondary increments (MSU)** Minimum amount of MSU by which the Group Capacity can be increased on
the second increment and all subsequent increments.

```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for Group and
CPC.
Open the Defined Maximum Group Capacity Limits section to see the table of already defined limits in
the maximum group capacity scope of this policy to have a quick reference.
```
**Procedures to manage capacity limits in the maximum group capacity scope**

**Add a new capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Group Capacity Scope** tab.
5. From the **Actions** menu, select **New**. The Maximum Group Capacity Limit page is displayed.
6. Specify the name of the capacity group, the CPC name, the maximum amount of MSU by which the
    Group Capacity can be increased by all provisioning rules, and the capacity increments defined for the
    capacity group on the CPC as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
7. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The newly created capacity limit is displayed in the **Maximum**
    **Group Capacity Scope** table.

**Modify an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Maximum Group Capacity Scope** tab
5. Open the Maximum Group Capacity Limit page by clicking on the group whose capacity limit you want
    to modify.
6. Change the name of the capacity group, the CPC name, the maximum amount of MSU by which the
    Group Capacity can be increased by all provisioning rules, and the capacity increments defined for the
    capacity group on the CPC as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
7. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The modified capacity limit is displayed in the **Maximum Group**
    **Capacity Scope** table.

```
Capacity Provisioning Task   79
```

**View an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Maximum Group Capacity Scope** tab
5. Open the Maximum Group Capacity Limit page by clicking on the group whose capacity limit you want
    to display.

```
Managing rules
To manage a rule for a policy, you can use the Rule page. To define, view, or modify a policy, use the New ,
View , or Modify actions on the Rules tab on the Policy page.
A provisioning rule contains a set of provisioning conditions and provisioning scopes which define
provisioning limits for different types of capacity. The provisioning scopes restrict the capacity that can be
provisioned by the conditions in the rule:
```
- The processor scope restricts the temporary processor resources which can be activated for CPCs.
- The defined capacity scope restricts the increase of the Defined Capacity of z/OS systems.
- The group capacity scope restricts the capacity increase for capacity groups.
In the Rule page you define the details of a rule. A rule is identified by the name in the **Rule name**
field and is described in more detail by the text in the **Description** field. Each rule must have a unique
name within the policy. A rule can be enabled or disabled. Disabled rules are ignored by the Provisioning
Manager.
A complete rule must contain at least one processor limit in the processor scope, or one capacity limit in
the defined capacity scope or one in the group capacity scope, and at least one condition.

```
Table 110. Fields on the Rule page
```
```
Field Description
```
```
Rule name Name of the rule. It must be unique within the policy.
```
```
Description Description of the rule for your reference.
```
```
Default status Indicates if the rule is enabled or disabled by default when the policy is
activated.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which values are allowed for Rule name
and Description.
```
```
Processor Scope tab
A rule contains a processor scope element, which defines the temporary processor resources which can
be activated for CPCs by all the conditions in the rule.
Only resources that are activated through a Capacity Provisioning policy are considered in this limit.
Resources that are activated manually, by using either Provisioning Manager commands or the interfaces
available on the HMC, are not managed by the Provisioning Manager.
To manage the processor scope of a rule, you can use the Processor Scope tab. To define, view, or modify
a processor limit, use the New , View , or Modify actions or in the table click on a CPC for which the
processor limit is defined to follow the link. When clicked, the Processor Limit page is opened for the CPC
and processor limit details are displayed. See help topic “Managing the processor scope” on page 84.
Note: At least one processor limit in the processor scope or one capacity limit in the defined capacity
scope or in the group capacity scope must be specified.
```
**80**   Capacity Provisioning Task


_Table 111. Columns in the Processor Scope table_

**Column Description**

**CPC** Name of the processor complex. This name is the logical name by which it is
identified at the support element (SE) of that processor complex.

**Max. Activation (MSU)** Maximum amount of MSU to be activated.

**Max. zAAP Processors** Maximum number of zAAP processors to be activated.

**Max. zIIP Processors** Maximum number of zIIP processors to be activated.

```
Defined Capacity Scope tab
A rule contains a defined capacity scope element which restricts the increase of the Defined Capacity of
z/OS systems. For each system in the table, it defines the maximum amount of MSU by which the Defined
Capacity for the z/OS system can be increased by all the contained conditions.
Only increases of Defined Capacity that are performed through a Capacity Provisioning policy are
considered in this limit. Increases that are performed manually, by using either Provisioning Manager
commands or the interfaces available on the HMC, are not managed by the Provisioning Manager.
Note: At least one processor limit in the processor scope or one capacity limit in the defined capacity
scope or in the group capacity scope must be specified.
To manage the defined capacity scope of a rule, you can use the Defined Capacity Scope tab. To define,
view, or modify a capacity limit, use the New , View , or Modify actions or in the table click on the system
for which the capacity limit is defined to follow the link. When clicked, the Defined Capacity Limit page
is opened for the system and capacity limit details are displayed. See help topic “Managing the defined
capacity scope” on page 86.
```
_Table 112. Columns in the Defined Capacity Scope table_

**Columns Description**

**System** Name of the z/OS system.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

**Max. Increase (MSU)** Maximum amount of MSU by which the Defined Capacity of the system can
be increased.

**Group Capacity Scope tab**

```
A rule contains a group capacity scope element which restricts the capacity increase for capacity groups.
For each capacity group in the table, it defines the maximum amount of MSU by which the Group Capacity
can be increased by all the contained conditions.
Only increases of the Group Capacity that are performed through a Capacity Provisioning policy are
considered in this limit. Increases that are performed manually, by using either Provisioning Manager
commands or the interfaces available on the HMC, are not managed by the Provisioning Manager.
Note: At least one processor limit in the processor scope or one capacity limit in the defined capacity
scope or in the group capacity scope must be specified.
To manage the group capacity scope of a rule, you can use the Group Capacity Scope tab. To define,
view, or modify a capacity limit, use the New , View , or Modify actions or in the table or click on the group
for which the capacity limit is defined to follow the link. When clicked, the Group Capacity Limit page
is opened for the capacity group and capacity limit details are displayed. See help topic “Managing the
group capacity scope” on page 87.
```
```
Capacity Provisioning Task   81
```

```
Table 113. Columns in the Group Capacity Scope table
```
```
Columns Description
```
```
Group Name of the capacity group
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. Increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased.
```
```
Actions for processor limits and capacity limits
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected limits. To use a targeted action, you must select
    one or more limits. If you select more than one limit, only the actions which can be applied to several
    limits are enabled.
- **General actions:** Actions that apply to limits. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first limit.

```
Table 114. Targeted actions
```
```
Action Description
```
```
View View the selected limit. The selected limit is opened and details are
displayed.
```
```
Modify Modify the selected limit. The selected limit is opened and details can be
modified.
```
```
Delete Delete the selected limits.
```
```
Copy Create a copy of the selected limits. The selected limits are copied into the
clipboard.
```
```
Table 115. General actions
```
```
Action Description
```
```
New Define a new limit. A new limit is opened and details can be specified.
```
```
Paste Paste the copied limits. The limits are pasted from the clipboard.
```
**Conditions tab**

```
A rule contains one or more provisioning conditions that describe the situations in which the Provisioning
Manager can provision additional capacity under the rule. These situations can include time conditions
indicating periods in which provisioning is allowed, and workload conditions indicating demand that can
trigger provisioning.
To manage the conditions of a rule, you can use the Conditions tab. To define, view, or modify a condition,
use the New , View , or Modify actions or click on the condition in the table to follow the link. When
clicked, the Condition page is opened and condition details are displayed. See help topic “Managing
conditions” on page 89.
```
**82**   Capacity Provisioning Task


_Table 116. Columns in the Conditions table_

**Column Description**

**Name** Name of the condition.

**Description** Description of the condition for your reference.

**Enabled** Indicates if the condition is enabled or disabled by default when the policy
is activated.

```
Actions for conditions
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected conditions. To use a targeted action, you must
    select one or more conditions. If you select more than one condition, the **Modify** action is disabled.
- **General actions:** Actions that apply to conditions. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first condition.

_Table 117. Targeted actions_

**Action Description**

**View** View the selected condition. The selected condition is opened and details
are displayed.

**Modify** Modify the selected condition. The selected condition is opened and details
can be modified.

**Delete** Delete the selected conditions.

**Copy** Create a copy of the selected conditions. The selected conditions copied
into the clipboard.

_Table 118. General actions_

**Action Description**

**New** Define a new condition. A new condition is opened and details can be
specified.

**Paste** Paste the copied conditions. The conditions are pasted from the clipboard.
New unique names are generated for the pasted conditions.

**Procedures to manage rules**

**Define a new rule**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. From the **Actions** menu, select **New**. The Rule page is displayed.
6. Specify the name, description, and default status as described in Table 110 on page 80, and specify
    the provisioning scopes and conditions for the rule.

```
Capacity Provisioning Task   83
```

7. Click **OK** to accept the changes. The newly created rule is displayed in the **Rules** table.

**Modify an existing rule**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule you want to modify.
6. Modify the name, description, and default status as described in Table 110 on page 80. You can also
    modify the provisioning scopes and conditions as needed.
7. Click **OK** to accept the changes. The modified rule is displayed in the **Rules** table.

**View an existing rule**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.

```
Managing the processor scope
To manage a provisioning limit for a CPC, that restricts the temporary processor resources that can be
activated by the conditions in the rule, you can use the Processor Limit page. To define, view, or modify a
processor limit in the processor scope, use the New , View , or Modify actions on the Processor Scope tab
on the Rule page.
In the Processor Limit page you define the details of a processor limit in the processor scope of a rule.
The details contain the CPC name and the temporary processor resources that can be activated by all the
conditions contained in the rule. And you cannot define two different limits for one CPC in the processor
scope of a rule.
If you define restrictions for a CPC in the processor scope of a rule, a limit for this CPC must also be
defined in the maximum processor scope. If it is not defined, additional capacity is not activated. The
values in the processor scope of a rule must be less than or equal to the values in the maximum processor
scope.
A processor limit should define a positive value for at least one type of capacity.
To complete the definition of a rule specify the conditions that describe the situations in which the
Provisioning Manager can activate additional capacity under the rule. Optionally, you may specify capacity
limits in the defined capacity scope or in the group capacity scope.
The processor limit is identified by the name in the CPC field.
```
```
Table 119. Fields on the Processor Limit page
```
```
Field Header
```
```
CPC Name of the processor complex. This name is the logical name by which it
is identified at the support element (SE) of that processor complex. Refer
to “Naming Conventions” on page 124 in order to find out which names are
allowed.
```
```
Max. activation (MSU) Maximum amount of MSU to be activated.
```
**84**   Capacity Provisioning Task


_Table 119. Fields on the Processor Limit page (continued)_

**Field Header**

**Max. zAAP processors** Maximum number of Application Assist Processors (zAAPs) to be activated.

**Max. zIIP processors** Maximum number of Integrated Information Processors (zIIPs) to be
activated.

```
Open the Defined Processor Limits section to see the table of already defined limits in the processor
scope of this rule to have a quick reference.
```
**Procedures to manage processor limits in the processor scope**

**Add a new processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Processor Scope** tab.
7. From the **Actions** menu, select **New**. The Processor Limit page is displayed.
8. Specify the CPC name and the temporary processor resources that can be activated by all provisioning
    conditions of the rule as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
9. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The newly created processor limit is displayed in the
    **Processor Scope** table.

**Modify an existing processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Processor Scope** tab
7. Open the Processor Limit page by clicking on the CPC whose processor limit you want to modify.
8. Change the CPC name and the temporary processor resources that can be activated by all provisioning
    conditions of the rule as described in the table above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
9. Click **OK** to accept the changes. If the processor limit contains incompatible specifications a
    “Messages” on page 125 window is displayed. The modified processor limit is displayed in the
    **Processor Scope** table.

```
Capacity Provisioning Task   85
```

**View an existing processor limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Processor Scope** tab.
7. Open the Processor Limit page by clicking on the CPC whose details you want to display.

```
Managing the defined capacity scope
To manage a provisioning limit for a z/OS system, that restricts how much the Defined Capacity can be
increased by the conditions in the rule, you can use the Defined Capacity Limit page. To define, view,
or modify a capacity limit in the defined capacity scope, use the New , View , or Modify actions on the
Defined Capacity Scope tab on the Policy page.
In the Defined Capacity Limit page you define the details of a capacity limit in the defined capacity
scope of a rule. It defines how much the Defined Capacity for the z/OS system can be increased. The
details contain the system and the sysplex name and the maximum amount of MSU by which the Defined
Capacity of the system can be increased by all the conditions contained in the rule. You cannot define two
different limits for one system in the defined capacity scope of a rule.
If you define restrictions for a system in the defined capacity scope of a rule, a limit for this system must
also be defined in the maximum defined capacity scope. If it is not defined, the defined capacity of the
system is not increased. The values in the defined capacity scope of a rule must be less than or equal to
the values in the maximum defined capacity scope.
To complete the definition of a rule specify the conditions that describe the situations in which the
Provisioning Manager can provision additional capacity under the rule. Optionally, you may specify
processor limits in the processor scope or capacity limits in the group capacity scope.
The capacity limit is identified by the name in the System and in the Sysplex field.
```
```
Table 120. Fields on the Capacity Limit page
```
```
Field Header
```
```
System Name of the z/OS system.
```
```
Sysplex Name of the sysplex to which this z/OS system belongs.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Defined Capacity can be increased.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for System and
Sysplex.
Open the Defined Capacity Limits section to see the table of already defined limits in the defined
capacity scope of this rule to have a quick reference.
```
**Procedures to manage capacity limits in the defined capacity scope**

**Add a new capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode

**86**   Capacity Provisioning Task


4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Defined Capacity Scope** tab.
7. From the **Actions** menu, select **New**. The Defined Capacity Limit page is displayed.
8. Specify the system and the sysplex name and the maximum amount of MSU by which the Defined
    Capacity of the system can be increased by all provisioning conditions of the rule as described in the
    table above.
9. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The newly created capacity limit is displayed in the **Defined**
    **Capacity Scope** table.

**Modify an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Defined Capacity Scope** tab
7. Open the Defined Capacity Limit page by clicking on the system whose defined capacity limit you want
    to modify.
8. Change the system or the sysplex name or the maximum amount of MSU by which the Defined
    Capacity of the system can be increased by all provisioning conditions of the rule as described in the
    table above.
9. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The modified capacity limit is displayed in the **Defined Capacity**
    **Scope** table.

**View an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Defined Capacity Scope** tab
7. Open the Defined Capacity Limit page by clicking on the system whose defined capacity limit you want
    to display.

**Managing the group capacity scope**

To manage a provisioning limit for a capacity group, that restricts how much the Group Capacity can be
increased by the conditions in the rule, you can use the Group Capacity Limit page. To define, view, or
modify a capacity limit in the group capacity scope, use the **New** , **View** , or **Modify** actions on the **Group
Capacity Scope** tab on the Policy page.

In the Group Capacity Limit page you define the details of a capacity limit in the group capacity scope of a
rule. It defines how much the Group Capacity for a capacity group of a CPC can be increased. The details
contain the name of the capacity group, the CPC name and the maximum amount of MSU by which the

```
Capacity Provisioning Task   87
```

```
Group Capacity for a capacity group of a CPC can be increased by all the conditions contained in the rule.
You cannot define two different limits for one capacity group in the group capacity scope of a rule.
If you define restrictions for a capacity group in the group capacity scope of a rule, a limit for this capacity
group must also be defined in the maximum group capacity scope. If it is not defined, the Group Capacity
for the capacity group is not increased. The values in the group capacity scope of a rule must be less than
or equal to the values in the maximum group capacity scope.
To complete the definition of a rule specify the conditions that describe the situations in which the
Provisioning Manager can provision additional capacity under the rule. Optionally, you may specify
processor limits in the processor scope or capacity limits in the defined capacity scope.
The capacity limit is identified by the name in the Group and in the CPC field.
```
```
Table 121. Fields on the Group Capacity Limit page
```
```
Field Header
```
```
Group Name of the capacity group
```
```
CPC Name of the processor complex on which the capacity group is defined. This
name is the logical name by which it is identified at the support element
(SE) of that processor complex.
```
```
Max. increase (MSU) Maximum amount of MSU by which the Group Capacity can be increased.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which names are allowed for Group and
CPC.
Open the Defined Group Capacity Limits section to see the table of already defined limits in the group
capacity scope of this rule to have a quick reference.
```
**Procedures to manage capacity limits in the group capacity scope**

**Add a new capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Group Capacity Scope** tab.
7. From the **Actions** menu, select **New**. The Group Capacity Limit page is displayed.
8. Specify the name of the capacity group, the CPC name, and the maximum amount of MSU by which
    the Group Capacity can be increased by all provisioning conditions in the rule as described in the table
    above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
9. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The newly created capacity limit is displayed in the **Group Capacity**
    **Scope** table.

**Modify an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.

**88**   Capacity Provisioning Task


2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Group Capacity Scope** tab.
7. Open the Group Capacity Limit page by clicking on the group whose capacity limit you want to modify.
8. Change the name of the capacity group, the CPC name or the maximum amount of MSU by which the
    Group Capacity can be increased by all provisioning conditions of the rule as described in the table
    above.
    To obtain a list of CPC names, select RETRIEVE MORE. This displays a window on which you specify
    the CPM domain that should be used to request a list of available CPCs. You can use any one
    connection that is listed in the Connections table on the Provisioning Manager page.
9. Click **OK** to accept the changes. If the capacity limit contains incompatible specifications a “Messages”
    on page 125 window is displayed. The modified capacity limit is displayed in the **Group Capacity**
    **Scope** table.

**View an existing capacity limit**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Group Capacity Scope** tab
7. Open the Group Capacity Limit page by clicking on the group whose capacity limit you want to display.

**Managing conditions**

To manage a condition for a rule, you can use the Condition page. To define, view, or modify a condition,
use the **New** , **View** , or **Modify** actions on the **Conditions** tab on the Rule page.

In the Condition page you define the details of a condition. A condition is identified by the name in the
**Condition name** field and described in more detail by the text in the **Description** field. A condition can be
enabled or disabled. Disabled conditions are ignored by the Provisioning Manager.

A provisioning condition contains:

- **Time conditions** define time periods during which additional capacity can be provisioned.
- **Utilization Conditions** define the CPC utilization thresholds that can trigger the provisioning of
    additional capacity.
- **Workload conditions** define the work that is eligible to cause provisioning of additional capacity and the
    conditions under which that work can trigger the provisioning of additional capacity.

You can choose between two different flavors of time conditions, depending on whether the time
condition may recur or not. The lower part of the Condition page contains two time condition tabs. The
tabs are:

- **Nonrecurring Time Conditions:** This allows you to specify periods, when provisioning of additional
    capacity is allowed, which is limited by a start and end point in time.
- **Recurring Time Conditions:** This allows you to specify weekly repeating periods. They describe the
    time of the day when provisioning of additional capacity is allowed and the days of the week for which
    these times apply.

```
Capacity Provisioning Task   89
```

```
A complete condition must contain at least one nonrecurring time condition or one recurring time
condition. Optionally, you can define workload conditions and utilization conditions.
If only time conditions but no workload conditions are defined, the Provisioning Manager executes
a scheduled provisioning and deprovisioning of additional capacity. At the start time of such a time
condition the amount of capacity that is specified in the rule's provisioning scopes is provisioned. At the
end time of the time condition the provisioned capacity is deprovisioned.
Using workload conditions ensures that capacity is provisioned during eligible time periods only if a
workload suffers and needs more capacity. The defined workload conditions apply to all defined time
conditions of the provisioning condition.
Using utilization conditions ensures that capacity is provisioned during eligible time periods only if the
processor utilization rises above a specified threshold. The defined utilization conditions apply to all
defined time conditions of the provisioning condition.
```
```
Table 122. Fields on the Condition page
```
```
Field Description
```
```
Condition name Name of the condition. It must be unique within the policy.
```
```
Description Description of the condition for your reference.
```
```
Default status Indicates if the condition is enabled or disabled by default when the policy
is activated.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which values are allowed for Condition
name and Description.
```
```
Nonrecurring Time Conditions tab
A nonrecurring time condition defines a period when provisioning of additional capacity is allowed, which
is limited by a start and end point in time.
To manage the nonrecurring time conditions of a condition, you can use the Nonrecurring Time
Conditions tab. To define, view, or modify a time condition, use the New , View , or Modify actions or
click on the name of a time condition in the table to follow the link. When clicked, the Nonrecurring
Time Condition page is opened for the time condition and details are displayed. See help topic “Managing
nonrecurring time conditions” on page 96.
```
```
Table 123. Columns in the Nonrecurring Time Conditions table
```
```
Column Description
```
```
Name Name of the time condition. It must be unique across all nonrecurring and
recurring time conditions in the policy.
```
```
Start Time The time at which the Provisioning Manager can start to provision additional
capacity.
```
```
Deadline Time The time when no further capacity will be provisioned.
```
```
End Time The time at which the Provisioning Manager starts to deprovision additional
capacity.
```
```
Actions for nonrecurring time conditions
The actions are described in the following tables:
```
- **Targeted actions** : Actions that apply to the selected time condition. To use a targeted action, you must
    select one or more time conditions. If you select more than one time condition, the **Modify** action is
disabled.
- **General actions** : Actions that apply to time conditions. No selection is required.

**90**   Capacity Provisioning Task


- **Table actions** : Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For details see “Table actions” on page 126.

_Table 124. Targeted actions_

**Column Description**

**View** View the selected time condition. The selected time condition is opened and
details are displayed.

**Modify** Modify the selected time condition. The selected time condition is opened
and details can be modified.

**Delete** Delete the selected time conditions.

**Copy** Create a copy of the selected time conditions. The selected time conditions
are copied into the clipboard.

_Table 125. General actions_

**Column Description**

**New** Define a new time condition. A new time condition is opened and details can
be specified.

**Paste** Paste the copied time conditions. The time conditions are pasted from the
clipboard. New unique names are generated for the pasted time conditions.

```
Recurring Time Conditions tab
A recurring time condition defines weekly repeating periods. It describes the time of the day when
provisioning of additional capacity is allowed and the days of the week to which these times apply.
To manage the recurring time conditions of a condition, you can use the Recurring Time Conditions tab.
To define, view, or modify a time condition, use the New , View , or Modify actions or click on the name of
a time condition in the table to follow the link. When clicked, the Recurring Time Condition page is opened
for the time condition and details are displayed. See help topic “Managing recurring time conditions” on
page 97.
```
_Table 126. Columns in the Recurring Time Conditions table_

**Column Description**

**Name** Name of the time condition.

**Start Date** The date of the first day on which the Provisioning Manager can provision
additional capacity.

**End Date** The date of the last day on which the Provisioning Manager can provision
additional capacity.

**Mon** Indicates if Monday is a day of the week on which provisioning of additional
capacity is allowed. The time after which additional capacity can be
provisioned on the checked day is defined in the **Start Time** column.
**Deadline** and **End Time** can be on the following day. This is the case if
these times are before the **Start Time**.

**Tue** Indicates if provisioning is allowed on Tuesday.

**Wed** Indicates if provisioning is allowed on Wednesday.

**Thu** Indicates if provisioning is allowed on Thursday.

**Fri** Indicates if provisioning is allowed on Friday.

```
Capacity Provisioning Task   91
```

```
Table 126. Columns in the Recurring Time Conditions table (continued)
```
```
Column Description
```
```
Sat Indicates if provisioning is allowed on Saturday.
```
```
Sun Indicates if provisioning is allowed on Sunday.
```
```
Start Time The time of the selected day at which the Provisioning Manager can start to
provision additional capacity.
```
```
Deadline Time The time of the selected day when no further capacity will be provisioned.
Additional capacity which is already provisioned can remain active until the
End Time or until the capacity is no longer needed. The Deadline must be
between the start and the end of the provisioning period. If the Deadline is
on the following day, the time is before Start Time.
```
```
End Time The time of the selected day at which the Provisioning Manager starts
to deprovision additional capacity. If the provisioning period ends on the
following day, End Time is before Start Time.
```
```
Actions for recurring time conditions
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected time conditions. To use a targeted action, you must
    select one or more time conditions. If you select more than one time condition, the **Modify** action is
    disabled.
- **General actions**. Actions that apply to time conditions. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For details see “Table actions” on page 126.

```
Table 127. Targeted actions
```
```
Column Description
```
```
View View the selected time condition. The selected time condition is opened and
details are displayed.
```
```
Modify Modify the selected time condition. The selected time condition is opened
and details can be modified.
```
```
Delete Delete the selected time conditions
```
```
Copy Create a copy of the selected time conditions. The selected time conditions
are copied into the clipboard.
```
```
Table 128. General actions
```
```
Column Description
```
```
New Define a new time condition. A new time condition is opened and details can
be specified.
```
```
Paste Paste the copied time conditions. The time conditions are pasted from the
clipboard. New unique names are generated for the pasted time conditions.
```
```
Workload Conditions tab
A workload condition identifies work which is eligible to cause provisioning of additional capacity, and the
conditions under which provisioning can be triggered.
To manage the workload conditions of a condition, you can use the Workload Conditions tab. To define,
view, or modify a workload condition, use the New , View , or Modify actions or click on the name of a
```
**92**   Capacity Provisioning Task


```
workload condition in the table to follow the link. When clicked, the Workload Condition page is opened
for the workload condition and details are displayed. See help topic “Managing workload conditions” on
page 99.
```
_Table 129. Columns in the Workload Conditions table_

**Column Description**

**Name** Name of the workload condition.

**Description** Description of the workload condition for your reference.

**System** The z/OS system in which the workload can run which will be considered to
trigger provisioning.

**Sysplex** Name of the sysplex to which this z/OS system belongs.

```
Actions for workload conditions
The actions are described in the following tables:
```
- **Targeted actions**. Actions that apply to the selected workload conditions. To use a targeted action,
    you must select one or more workload conditions. If you select more than one workload condition, the
    **Modify** action is disabled.
- **General actions**. Actions that apply to workload conditions. No selection is required.
- **Table actions**. Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For details see “Table actions” on page 126.

_Table 130. Targeted actions_

**Column Description**

**View** View the selected workload condition. The selected workload condition is
opened and details are displayed.

**Modify** Modify the selected workload condition. The selected workload condition is
opened and details can be modified.

**Delete** Delete the selected workload conditions.

**Copy** Copy the selected workload conditions. The selected workload conditions
are kept in the clipboard.

_Table 131. General actions_

**Column Description**

**New** Define a new workload condition. A new workload condition is opened and
details can be specified.

**Paste** Paste the copied workload conditions. The workload conditions are pasted
from the clipboard. New unique names are generated for the pasted
workload conditions.

**Utilization Conditions tab**

```
A utilization condition defines CPC utilization thresholds that can trigger the provisioning of additional
capacity.
To manage the utilization conditions of a condition, you can use the Utilization Conditions tab. To define,
view, or modify a utilization condition, use the New , View , or Modify actions or click on the name of a
utilization condition in the table to follow the link. When clicked, the Utilization Condition page is opened
```
```
Capacity Provisioning Task   93
```

```
for the utilization condition and details are displayed. See help topic “Managing utilization conditions” on
page 106.
```
```
Table 132. Columns in the Utilization Conditions table
```
```
Column Description
```
```
Name Name of the utilization condition.
```
```
CPC Name of the CPC on which the utilization condition can trigger provisioning.
This name is the logical name by which it is identified at the support
element (SE) of that processor complex.
```
```
Processor Type Processor Type for which the CPC utilization is monitored.
```
```
Provisioning Utilization (%) Processor utilization threshold for provisioning. If the provisioning utilization
is equal or higher than the specified percentage value the Provisioning
Manager triggers activation of additional temporary capacity.
It must be a number from 1-100.
```
```
Provisioning Duration (Minutes) Number of minutes the processor utilization threshold has to exceed the
specified value before the Provisioning Manager triggers the activation of
additional capacity.
It must be a number from 4-1440.
```
```
Deprovisioning Utilization (%) Processor utilization threshold for deprovisioning. If the deprovisioning
utilization is equal or lower than the specified percentage value the
Provisioning Manager triggers deactivation of additional temporary capacity.
It must be a number from 0-99.
```
```
Deprovisioning Duration
(Minutes)
```
```
Number of minutes the processor utilization threshold has to be lower
than the specified value before the Provisioning Manager triggers the
deactivation of additional capacity.
It must be a number from 4-1440.
```
```
Actions for utilization conditions
The actions are described in the following tables:
```
- **Targeted actions**. Actions that apply to the selected utilization conditions. To use a targeted action, you
    must select one or more utilization conditions. If you select more than one utilization condition, the
    **Modify** action is disabled.
- **General actions**. Actions that apply to utilization conditions. No selection is required.
- **Table actions**. Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For details see “Table actions” on page 126.

```
Table 133. Targeted actions
```
```
Column Description
```
```
View View the selected utilization condition. The selected utilization condition is
opened and details are displayed.
```
```
Modify Modify the selected utilization condition. The selected utilization condition
is opened and details can be modified.
```
```
Delete Delete the selected utilization conditions.
```
```
Copy Copy the selected utilization conditions. The selected utilization conditions
are kept in the clipboard.
```
**94**   Capacity Provisioning Task


_Table 134. General actions_

**Column Description**

**New** Define a new utilization condition. A new utilization condition is opened and
details can be specified.

**Paste** Paste the copied utilization conditions. The utilization conditions are pasted
from the clipboard. New unique names are generated for the pasted
utilization conditions.

**Procedures to manage conditions**

**Add a new condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policie** s link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. From the **Actions** menu, select **New**. The Condition page is displayed
8. Specify the name, description, and default status as described in Table 122 on page 90, and specify
    the time and workload conditions you want to use.
9. Click **OK** to accept the changes. The newly created condition is displayed in the **Conditions** table.

**Modify an existing condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Click on a rule in the table.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition you want to modify.
8. Modify the name, description, and default status as described in Table 122 on page 90. You can also
    modify the time conditions and the workload conditions as needed.
9. Click **OK** to accept the changes. The modified condition is displayed in the **Conditions** table.

**Viewing an existing condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition you want to display.

```
Capacity Provisioning Task   95
```

```
Managing nonrecurring time conditions
To manage a nonrecurring time condition for a condition, you can use the Nonrecurring Time Condition
page. To define, view, or modify a time condition, use the New , View , or Modify actions on the
Nonrecurring Time Conditions tab on the Condition page.
In the Nonrecurring Time Condition page you define the details of a nonrecurring time condition. A timed
condition is identified by the name in the Name field and described in more detail by the following fields.
A nonrecurring time condition defines a period when provisioning of additional capacity is allowed which
is limited by a start and end point in time. There must be at least one nonrecurring or one recurring time
condition for a valid condition.
The format of the date and time is determined by the language setting of your browser.
All dates and times are displayed using the time zone displayed. The time zone can be changed using the
Settings link in the Overview tab. A change affects the display of all policies. The actual date and time
values are stored in the repository as Coordinated Universal Time (UTC).
```
```
Table 135. Fields on the Nonrecurring Time Condition page
```
```
Field Description
```
```
Name Name of the time condition. It must be unique across all nonrecurring and
recurring time conditions in the policy. Refer to “Naming Conventions” on
page 124 in order to find out which names are allowed.
```
```
Start date The date for the start time.
```
```
Start time The time at which the Provisioning Manager can start to provision additional
capacity.
```
```
Deadline date The date for the deadline time.
```
```
Deadline time The time when no further capacity will be provisioned. This must be after
the Start Time.
```
```
End date The date for the end time.
```
```
End time The time at which the Provisioning Manager starts to deprovision additional
capacity. This must be on or after the Deadline.
```
```
Open the Defined Nonrecurring Time Conditions section to see the table of already defined nonrecurring
time conditions for the current condition to have a quick reference.
```
**Procedures to manage nonrecurring time conditions**

**Define a new nonrecurring time condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Nonrecurring Time Conditions** tab.
9. From the **Actions** menu, select **New**. The Nonrecurring Time Condition page is displayed.
10. Specify the name, the date and time for start, deadline, and end as described in the table above.

**96**   Capacity Provisioning Task


11. Click **OK** to accept the changes. If the time condition contains incompatible specifications a
    “Messages” on page 125 window is displayed. The newly created time condition is displayed in
    the **Nonrecurring Time Conditions** table.

**Modify an existing nonrecurring time condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.
7. Click on a condition in the table.
8. Select the **Nonrecurring Time Conditions** tab.
9. Open the Nonrecurring Time Condition page by clicking the link to the time condition you want to
    modify.
10. Change the name, the date and time for start, deadline, and end as described in the table above.
11. Click **OK** to accept the changes. If the time condition contains incompatible specifications a
“Messages” on page 125 window is displayed. The modified time condition is displayed in the
**Nonrecurring Time Conditions** table.

**View an existing nonrecurring time condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition whose details you want to display.
8. Select the **Nonrecurring Time Conditions** tab.
9. Open the Nonrecurring Time Condition page by clicking the link to the time condition whose details
    you want to display.

**Managing recurring time conditions**

To manage a recurring time condition for a condition, you can use the Recurring Time Condition page. To
define, view, or modify a time condition, use the **New** , **View** , or **Modify** actions on the **Recurring Time
Conditions** tab on the Condition page.

In the Recurring Time Condition page you define the details of a recurring time condition. A timed
condition is identified by the name in the **Name** field and described in more detail by the following fields.

A recurring time condition defines weekly repeating periods. They describe the time of the day when
provisioning of additional capacity is allowed and the days of the week for which these times apply.
The provisioning period may start on one day and end on the following day. The specification of a
recurring time condition is optional, however there must be at least one nonrecurring or one recurring
time condition for a valid condition.

The format of the date and time is determined by the language setting of your browser.

```
Capacity Provisioning Task   97
```

```
All dates and times are displayed using the time zone displayed. The time zone can be changed using the
Settings link in the Overview tab. A change affects the display of all policies. The actual date and time
values are stored in the repository as Coordinated Universal Time (UTC).
```
```
Table 136. Fields on the Recurring Time Condition page
```
```
Field Description
```
```
Name Name of the time condition. It must be unique across all nonrecurring and
recurring time conditions in the policy. Refer to “Naming Conventions” on
page 124 in order to find out which names are allowed.
```
```
Start Date The date of the first day on which the Provisioning Manager can provision
additional capacity.
```
```
End Date The date of the last day on which the Provisioning Manager can provision
additional capacity. This must be after the Start Date.
```
```
Mon Check this box, if Monday is a day of the week on which provisioning of
additional capacity is allowed. The time when the Provisioning Manager can
start to provision additional capacity on the checked day is defined in the
Start Time column. Deadline and End Time can be on the following day.
This is the case if these times are before the Start Time.
```
```
Tue Check this box, if provisioning is allowed on Tuesday.
```
```
Wed Check this box, if provisioning is allowed on Wednesday.
```
```
Thu Check this box, if provisioning is allowed on Thursday.
```
```
Fri Check this box, provisioning is allowed on Friday.
```
```
Sat Check this box, provisioning is allowed on Saturday.
```
```
Sun Check this box, provisioning is allowed on Sunday.
```
```
Start Time The time of the selected day at which the Provisioning Manager can start to
provision additional capacity.
```
```
Deadline Time The time of the selected day when no further capacity will be provisioned.
Additional capacity which is already provisioned can remain active until the
End Time or until the capacity is no longer needed. The Deadline must be
between the start and the end of the provisioning period. If the Deadline is
on the following day, the time is before Start Time.
```
```
End Time The time of the selected day at which the Provisioning Manager starts
to deprovision additional capacity. If the provisioning period ends on the
following day, End Time is before Start Time.
```
```
Open the Defined Recurring Time Conditions section to see the table of already defined recurring time
conditions for the current condition to have a quick reference.
```
**Procedures to manage recurring time conditions**

**Define a new recurring time condition**

1. Select **the Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.

**98**   Capacity Provisioning Task


6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Recurring Time Conditions** tab.
9. From the **Actions** menu, select **New**. The Recurring Time Condition page is displayed.
10. Specify the name, the start and the end date, the allowed days of the week and the start, deadline,
and end time as described in the table above.
11. Click **OK** to accept the changes. If the time condition contains incompatible specifications a
“Messages” on page 125 window is displayed. The newly created time condition is displayed in
the **Recurring Time Conditions** table.

**Modify an existing recurring time condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.
7. Click on a condition in the table.
8. Select the **Recurring Time Conditions** tab.
9. Open the Recurring Time Condition page by clicking the link to the time condition you want to modify.
10. Change the name, the start and the end date, the allowed days of the week and the start, deadline,
and end time as described in the table above.
11. Click **OK** to accept the changes. If the time condition contains incompatible specifications a
“Messages” on page 125 window is displayed. The modified time condition is displayed in the
**Recurring Time Conditions** table.

**View an existing recurring time condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition whose details you want to display.
8. Select the **Recurring Time Conditions** tab.
9. Open the Recurring Time Condition page by clicking the link to the time condition whose details you
    want to display.

**Managing workload conditions**

To manage a workload condition for a condition, you can use the Workload Condition page. To define,
view, or modify a workload condition, use the **New** , **View** , or **Modify** actions on the **Workload Conditions**
tab on the Condition page.

In the Workload Condition page you define the details of a workload condition. A workload condition is
identified by the name in the **Name** field and described in more detail by the text in the **Description** field.

```
Capacity Provisioning Task   99
```

```
A workload condition applies to all time conditions of the provisioning condition. Specifying a workload
condition is optional. If only time conditions but no workload conditions are defined, the Provisioning
Manager executes a scheduled provisioning and deprovisioning of additional capacity. At the start time
of such a time condition the amount of capacity that is specified in the rule's provisioning scopes is
provisioned. At the end time of the time condition the provisioned capacity is deprovisioned.
A workload condition defines work that is eligible to cause provisioning of additional capacity, and
specifies the conditions under which that work can trigger provisioning. The specification of eligible work
follows the workload model of the z/OS Workload Manager (WLM).
Depending on the work that is running on a system, different service classes can be business-critical. The
lower part of the Workload Condition page contains three tabs. These can be used to identify potentially
critical service class periods. The tabs are:
```
- **Importance Filters:** This tab allows you to specify service class periods to be monitored, based on their
    importance, and the performance index values and durations to trigger intervention.
- **Included Service Classes:** This tab allows you to specify service classes to be monitored in addition to
    any identified ones by importance filters, and their triggers.
- **Excluded Service Classes:** This tab allows you to specify service classes to be excluded from
    importance filters, or subsets of Included Service Classes to be excluded.
A complete workload condition must contain at least one importance filter or one included service class
filter. Optionally, you can define excluded service classes.
Depending on the work that is running on a system, different service classes can be business-critical.

```
The set of observed service class periods
The Provisioning Manager determines service class periods to be considered for provisioning as follows:
```
1. Service class periods with the specified or a higher importance on the specified system in the specified
    sysplex are chosen first.
2. This set is then extended with the periods contained in the included service classes.
3. Service class periods contained in the excluded service classes are then removed from the set.
The Provisioning Manager then checks for additional capacity for those service class periods remaining
in the set. Whenever a new WLM service policy is activated, the set of observed service class periods is
redetermined.

```
Table 137. Fields on the Workload Condition page
```
```
Field Description
```
```
Name Name of the workload condition. It must be unique within the policy.
```
```
Description Description of the workload condition for your reference.
```
```
System Name of the z/OS system on which the workload condition can trigger
provisioning.
Select Any in sysplex to apply the workload condition to all systems in the
specified sysplex.
Select Specify a value to specify the system on which workload is
considered to trigger provisioning for this workload condition. Only workload
on this system is considered to trigger provisioning for this workload
condition.
```
**100**   Capacity Provisioning Task


_Table 137. Fields on the Workload Condition page (continued)_

**Field Description**

**Sysplex** The sysplex to which the specified z/OS system belongs.

```
Select Any to apply the workload condition to the specified system in all
sysplexes of the domain.
Select Specify a value to specify the sysplex to which the specified z/OS
system belongs. Only workload that is running on the specified system in
this sysplex is considered to trigger provisioning for this workload condition.
```
```
Refer to “Naming Conventions” on page 124 in order to find out which values are allowed for Name and
Description.
```
```
Importance Filters tab
On the Importance Filters tab you specify service class periods to be monitored, based on their
importance. You can define separate provisioning criteria for each importance level.
To manage the importance filters of a workload condition, you can use the Importance Filters tab. To
define, view, or modify an importance filter, use the New , View , or Modify actions or click on the value in
the Importance column to follow the link. When clicked, the Importance Filter page is opened and details
are displayed. See help topic “Managing importance filters” on page 107.
```
_Table 138. Columns in the Importance Filters table_

**Column Description**

**Importance** Importance of the service class periods. It must be a number from 1-5,
with 1 being the highest importance and 5 being the lowest importance.
All service class periods with an importance value less than or equal to the
specified importance value match the importance filter.

**Provisioning PI** Performance index threshold for provisioning. It must be a number from
1.3-10. If the performance index of a service class period is equal or higher
than the specified value the Provisioning Manager considers the service
class period to be suffering.

**Provisioning Duration** Number of minutes a service class period has to exceed the provisioning
PI before the Provisioning Manager considers the service class period to be
suffering. It must be a number from 4-1440.

**Deprovisioning PI** Performance index threshold for deprovisioning. If the performance index of
a service class period is lower than the specified value it is not considered
to be suffering. The de-provisioning PI must be at least 0.2 less than the
provisioning PI limit, and must be a number from 1.1-9.8.

**Deprovisioning Duration** Number of minutes the PI of the selected service classes must be lower
than the specified de-provisioning PI for it to be considered no longer
suffering. It must be a number from 4-1440.

**PI Scope** Indicates which PI the other criteria apply to. The possible values are

- System and
- Sysplex.
The default is System.

```
Actions for importance filters
The actions are described in the following tables:
```
```
Capacity Provisioning Task   101
```

- **Targeted actions:** Actions that apply to the selected importance filters. To use a targeted action, you
    must select one or more importance filters. If you select more than one importance filter, only the
    actions **Copy** and **Delete** are enabled.
- **General actions:** Actions that apply to importance filters. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first importance filter.

```
Table 139. Targeted actions
```
```
Column Description
```
```
View View the selected importance filter. The selected importance filter is opened
and details are displayed.
```
```
Modify Modify the selected importance filter. The selected importance filter is
opened and details can be modified.
```
```
Delete Delete the selected importance filters.
```
```
Copy Create a copy of the selected importance filters. The selected importance
filters are copied to the clipboard.
```
```
Table 140. General Actions
```
```
Column Description
```
```
New Define a new importance filter. A new importance filter is opened and
details can be specified.
```
```
Paste Paste the copied importance filters. The importance filters limits are pasted
from the clipboard. New unique importance values are generated for the
pasted importance filters.
```
```
Included Service Classes tab
On the Included Service Classes tab you specify service classes to be monitored in addition to any
identified by importance filters. You can define separate provisioning criteria for each service class period.
To manage the included service classes of a workload condition, you can use the Included Service
Classes tab. To define, view, or modify an included service class filter, use the New , View , or Modify
actions or click on the name in the Service Definition column to follow the link. When clicked, the
Included Service Class Filter page is opened and details are displayed. See help topic “Managing included
service classes” on page 109.
```
```
Table 141. Columns in the Included Service Classes table
```
```
Column Description
```
```
Service Definition Name of the z/OS Workload Manager (WLM) service definition. The specified
service class periods are only considered if this WLM service definition is
installed.
Any service definition
Indicates that all service definitions are considered.
```
```
Service Policy Name of the service policy within the WLM service definition.
Any service policy
Indicates that all service policies are considered.
```
**102**   Capacity Provisioning Task


_Table 141. Columns in the Included Service Classes table (continued)_

**Column Description**

**Service Class** Name of the service class within the specified service policy.

```
Any service class
Indicates that all service classes are considered.
```
**Period** Highest period of the service class that should be considered by the
Provisioning Manager. This period and all periods with a lower period
number are considered eligible to trigger provisioning. If a service class has
fewer periods than this number, all periods are considered.

**Provisioning PI** Performance index threshold for provisioning. If the performance index
of a service class period is equal or higher than the specified value the
Provisioning Manager considers the service class period to be suffering.

**Provisioning Duration** Number of minutes a service class period has to exceed the provisioning
PI before the Provisioning Manager considers the service class period to be
suffering.

**Deprovisioning PI** Performance index threshold for deprovisioning. If the performance index of
a service class period is lower than the specified value it is not considered to
be suffering.

**Deprovisioning Duration** Number of minutes the PI of the selected service classes must be lower
than the specified de-provisioning PI for it to be considered no longer
suffering.

**PI Scope** Indicates which PI the other criteria apply to. The possible values are

- System and
- Sysplex.
The default is System.

```
Actions for included service classes
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected included service classes. To use a targeted action,
    you must select one or more included service classes. If you select more than one included service
    class, only the actions **Copy** and **Delete** are enabled.
- **General actions:** Actions that apply to included service classes. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first included service class.

_Table 142. Targeted actions_

**Column Description**

**View** View the selected included service class. The selected included service
class is opened and details are displayed.

**Modify** Modify the selected included service class. The selected included service
class is opened and details can be modified.

**Delete** Delete the selected included service classes.

**Copy** Copy of the selected included service class filters. The selected included
service class filters are kept in the clipboard.

```
Capacity Provisioning Task   103
```

```
Table 143. General actions
```
```
Column Description
```
```
New Define a new included service class. A new included service class is opened
and details can be specified.
```
```
Paste Paste the copied included service class filters. The service class filters are
pasted from the clipboard.
```
```
Excluded Service Classes tab
On the Excluded Service Classes tab you can exclude service classes from importance filters, that were
included by importance filters or included service class period filters. Other than for included service
classes the period identifies the lowest period of the service class that is excluded.
To manage the excluded service classes of a workload condition, you can use the Excluded Service
Classes tab. To define, view, or modify an excluded service class filter, use the New , View , or Modify
actions or click on the name in the Service Definition column to follow the link. When clicked, the
Excluded Service Class Filter page is opened and details are displayed. See help topic “Managing
excluded service classes” on page 112.
```
```
Table 144. Columns in the Excluded Service Classes table
```
```
Column Description
```
```
Service Definition Name of the WLM service definition where the service class is defined.
Any service definition
Indicates that all service definitions are considered.
```
```
Service Policy Name of the service policy within the WLM service definition to which the
WLM service class belongs.
Any service policy
Indicates that all service policies are considered.
```
```
Service Class Name of the WLM service class to be considered.
Any service class
Indicates that all service classes are considered.
```
```
Period The number of the lowest period of the service class that shall not be
considered by the Provisioning Manager. This period and all periods with a
higher period number are excluded from provisioning.
```
**Actions for excluded service classes**

```
The actions are described in the following tables:
```
- **Targeted actions:** Actions that apply to the selected excluded service classes. To use a targeted action,
    you must select one or more excluded service classes. If you select more than one excluded service
    class, only the actions **Copy** and **Delete** are enabled.
- **General actions:** Actions that apply to excluded service classes. No selection is required.
- **Table actions:** Actions that apply to the entire table such as sorting and filtering. No selection is
    required. For detailed information see “Table actions” on page 126.
A limited set of actions is available until you create the first excluded service class.

**104**   Capacity Provisioning Task


_Table 145. Targeted actions_

**Column Description**

**View** View the selected excluded service class. The selected excluded service
class is opened and details are displayed.

**Modify** Modify the selected excluded service class. The selected excluded service
class is opened and details can be modified.

**Delete** Delete the selected excluded service classes.

**Copy** Copy the selected excluded service class filters. The selected service class
filters are copied into the clipboard.

_Table 146. General actions_

**Column Description**

**New** Define a new excluded service class. A new excluded service class is
opened and details can be specified.

**Paste** Paste the copied excluded service class filters. The service class filters are
pasted from the clipboard.

**Procedures to manage workload conditions**

**Define a new workload condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Workload Conditions** tab.
9. From the **Actions** menu, select **New**. The Workload Condition page is displayed.
10. Specify the name, description, system, and sysplex as described in Table 137 on page 100, and
define the importance filters and the included and excluded service classes for the workload
condition.
11. Click **OK** to accept the changes. The newly created workload condition is displayed in the **Workload
Conditions** table.

**Modify an existing workload condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.

```
Capacity Provisioning Task   105
```

7. Click on a condition in the table.
8. Select the **Workload Conditions** tab.
9. Open the Workload Condition page by clicking the link to the workload condition you want to modify.
10. Modify the name, description, system, and sysplex as described in Table 137 on page 100. You can
also modify the importance filters and the included and excluded service classes as needed. The
modified workload condition is displayed in the **Workload Conditions** table.

**Viewing an existing workload condition**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition you want to display
8. Select the **Workload Conditions** tab.
9. Open the Workload Condition page by clicking the link to the workload condition you want to display.

```
Managing utilization conditions
To manage a utilization condition for a condition, you can use the Utilization Condition page. To
define, view, or modify a utilization condition, use the New , View , or Modify actions on the Utilization
Conditions tab on the Condition page.
In the Utilization Condition page you define the details of a utilization condition. A utilization condition is
identified by the name in the Name field and described in more detail by the text in the Description field.
A utilization condition applies to all time conditions of the provisioning condition. Specifying a utilization
condition is optional. If only time conditions but no utilization conditions and no workload conditions are
defined, the Provisioning Manager executes a scheduled provisioning and deprovisioning of additional
capacity. At the start time of such a time condition the amount of capacity that is specified in the rule's
provisioning scopes is provisioned. At the end time of the time condition the provisioned capacity is
deprovisioned.
A utilization condition defines processor utilization thresholds that can trigger provisioning for a CPC.
```
```
Table 147. Fields on the Utilization Condition page
```
```
Field Description
```
```
Name Name of the utilization condition. It must be unique within the policy.
```
```
CPC Name of the CPC on which the utilization condition can trigger provisioning.
This name is the logical name by which it is identified at the support
element (SE) of that processor complex.
Select Any CPC to apply the utilization condition to all CPCs.
Select Specify a value to specify the CPC on which utilization conditions
can trigger provisioning.
Select RETRIEVE MORE to obtain a list of CPC names. This displays a
window on which you specify the CPM domain that should be used to
request a list of available CPCs. You can use any one connection that is
listed in the Connections table on the Provisioning Manager page.
```
**106**   Capacity Provisioning Task


_Table 147. Fields on the Utilization Condition page (continued)_

**Field Description**

**Processor Type** Processor Type for which the utilization thresholds shall be defined.

```
Select a processor type. CP, zAAP and zIIP can be selected.
```
**Provisioning Utilization (%)** Processor utilization threshold for provisioning. If the provisioning utilization
is equal or higher than the specified percentage value the Provisioning
Manager triggers activation of additional temporary capacity.
It must be a number from 1-100.

**Provisioning Duration (Minutes)** Number of minutes the processor utilization threshold has to exceed the
specified value before the Provisioning Manager triggers the activation of
additional capacity.
It must be a number from 4-1440.

**Deprovisioning Utilization (%)** Processor utilization threshold for deprovisioning. If the deprovisioning
utilization is equal or lower than the specified percentage value the
Provisioning Manager triggers deactivation of additional temporary capacity.
It must be a number from 0-99.

**Deprovisioning Duration
(Minutes)**

```
Number of minutes the processor utilization threshold has to be lower
than the specified value before the Provisioning Manager triggers the
deactivation of additional capacity.
It must be a number from 4-1440.
```
```
Managing importance filters
To manage an importance filter for a workload condition, you can use the Importance Filter page. To
define, view, or modify an importance filter use the New , View , or Modify actions on the Importance
Filter tab on the Workload Condition page.
The specification of importance filters is optional, however there must be at least one importance filter
or one included service class filter for a valid workload condition. All service class periods with an
importance level equal to or higher than the specified value will be monitored by the Provisioning Manager
and can trigger provisioning. For each specified importance level additional provisioning criteria must be
defined.
An importance filter is identified by the number in the Importance field.
```
_Table 148. Fields on the Importance Filter page_

**Field Description**

**Importance** Importance of the service class periods. It must be a number from 1-5,
with 1 being the highest importance and 5 being the lowest importance.
All service class periods with an importance value less than or equal to the
specified importance value match the importance filter.

**Provisioning PI** Performance index threshold for provisioning. It must be a number from
1.3-10. If the performance index of a service class period is equal or higher
than the specified value the Provisioning Manager considers the service
class period to be suffering.

**Provisioning duration** Number of minutes the performance index must exceed the specified
provisioning PI before the Provisioning Manager considers a service class
period to be suffering. It must be a number from 4-1440.

```
Capacity Provisioning Task   107
```

```
Table 148. Fields on the Importance Filter page (continued)
```
```
Field Description
```
```
Deprovisioning PI Performance index threshold for deprovisioning. If the performance index of
a service class period is lower than the specified value it is not considered
to be suffering. The de-provisioning PI must be at least 0.2 less than the
provisioning PI limit, and must be a number from 1.1-9.8.
```
```
Deprovisioning duration Number of minutes the performance index must be lower than the
deprovisioning PI before the Provisioning Manager considers a service class
period to be no longer suffering. It must be a number from 4-1440.
```
```
PI Scope Indicates if the provisioning PI and deprovisioning PI values refer to the
sysplex PI or the system PI of the service class period.
Select System to indicate that the performance index of the service class
period on each system in the sysplex is used. The system PI is also referred
to as the local performance index (local PI). This is the default and the
recommended setting.
Select Sysplex to indicated that the performance index of the service class
period within the sysplex is used. A sysplex PI should only be chosen if all
systems joining the sysplex are defined to the provisioning domain. If you
choose PI scope "Sysplex", the Provisioning Manager monitors in addition to
monitoring the sysplex PI also the system PI. Only if the monitored system
is actually suffering, the Provisioning Manager starts to take actions.
```
```
Open the Defined Importance Filters section to see the table of already defined importance filters for
the current workload condition to have a quick reference.
```
**Procedures to manage importance filters**

**Add a new importance filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Workload Conditions** tab.
9. Create a new workload condition or open an existing one.
10. Select the **Importance Filters** tab.
11. From the **Actions** menu, select **New**. The Importance Filter page is displayed.
12. Specify the importance, the provisioning and the deprovisioning PI, the corresponding durations, and
the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed.

**108**   Capacity Provisioning Task


**Modify an existing importance filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.
7. Click on a condition in the table.
8. Select the **Workload Conditions** tab.
9. Click on a workload condition in the table.
10. Select the **Importance Filters** tab.
11. Open the Importance Filter page by clicking on the importance of the importance filter you want to
modify.
12. Modify the importance, the provisioning and the deprovisioning PI, the corresponding durations, and
the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed.

**View an existing importance filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition whose details you want to display.
8. Select the **Workload Conditions** tab.
9. Open the Workload Condition page by clicking the link to the workload condition whose details you
    want to display.
10. Select the **Importance Filters** tab.
11. Open the Importance Filter page by clicking on the importance of the importance filter you want to
display.

**Managing included service classes**

To manage an included service class filter for a workload condition, you can use the Included Service
Classes page. To define, view, or modify an included service class filter use the **New** , **View** , or **Modify**
actions on the **Included Service Classes** tab on the Workload Condition page.

The specification of included service classes filters is optional, however at least one importance filter or
one included service class filter must be specified for a valid workload condition. All service classes listed
in the **Included Service Classes** table can trigger provisioning when they are in the defined service class
period. For each specified service class period additional provisioning criteria must be defined.

An included service class filter is identified by the name in the **Service Definition** , the **Service Policy** and
in the **Service Class** field.

```
Capacity Provisioning Task   109
```

```
Table 149. Fields on the Included Service Class Filter page
```
```
Field Description
```
```
Service Definition Name of the z/OS Workload Manager (WLM) service definition. The specified
service class periods are only considered if this WLM service definition is
installed.
To match the name of any service definition, select Any service definition.
Select Specify a value to specify a particular WLM service definition.
```
```
Service Policy Name of the service policy within the WLM service definition. The specified
service class periods are considered if a service policy with that name is
activated.
To match the name of any service policy, select Any service policy.
Select Specify a value to specify a particular WLM service policy.
```
```
Service Class Name of the WLM service class to consider.
To match the name of any service class, select Any service class.
Select Specify a value to specify a particular WLM service class.
```
```
Period Highest period of the service class that should be considered by the
Provisioning Manager. This period and all periods with a lower period
number are considered eligible to trigger provisioning. If a service class has
fewer periods than this number, all periods are considered.
```
```
Provisioning PI Performance index threshold for provisioning. It must be a number from
1.3-10. If the performance index of a service class period is equal or higher
than the specified value the Provisioning Manager considers the service
class period to be suffering.
```
```
Provisioning Duration Number of minutes the performance index must exceed the specified
provisioning PI before the Provisioning Manager considers a service class
period to be suffering. It must be a number from 4-1440.
```
```
Deprovisioning PI Performance index threshold for deprovisioning. If the performance index of
a service class period is lower than the specified value it is not considered
to be suffering. The de-provisioning PI must be at least 0.2 less than the
provisioning PI limit, and must be a number from 1.1-9.8.
```
```
Deprovisioning Duration Number of minutes the performance index must be lower than the
deprovisioning PI before the Provisioning Manager considers a service class
period to be no longer suffering. It must be a number from 4-1440.
```
```
PI Scope Indicates if the provisioning PI and deprovisioning PI values refer to the
sysplex PI or the system PI of the service class period.
Select System to indicate that the performance index of the service class
period on each system in the sysplex is used. The system PI is also referred
to as the local performance index (local PI). This is the default and the
recommended setting.
Select Sysplex to indicated that the performance index of the service class
period within the sysplex is used. A sysplex PI should only be chosen if all
systems joining the sysplex are defined to the provisioning domain. If you
choose PI scope "Sysplex", the Provisioning Manager monitors in addition to
monitoring the sysplex PI also the system PI. Only if the monitored system
is actually suffering, the Provisioning Manager starts to take actions.
```
**110**   Capacity Provisioning Task


Refer to “Naming Conventions” on page 124 in order to find out which names are allowed.

Open the **Defined Included Service Class Filters** section to see the table of already defined included
service class filters for the current workload condition to have a quick reference.

**Procedures to manage included service class filters**

**Add an included service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Workload Conditions** tab.
9. Create a new workload condition or open an existing one.
10. Select the **Included Service Classes** tab.
11. From the **Actions** menu, select **New**. The Included Service Class Filter page is displayed.
12. Specify the business critical service class periods, the provisioning and the deprovisioning PI, the
corresponding durations, and the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed. The newly created filter is displayed in the **Included Service Classes**
table.

**Modify an existing included service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.
7. Click on a condition in the table.
8. Select the **Workload Conditions** tab.
9. Click on a workload condition in the table.
10. Select the **Included Service Classes** tab.
11. In the **Service Definition** column click on the name of the service definition for which you want to
modify the filter. The Included Service Class Filter page is displayed.
12. Modify the business critical service class periods, the provisioning and the deprovisioning PI, the
corresponding durations, and the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed. The modified filter is displayed in the **Included Service Classes** table.

```
Capacity Provisioning Task   111
```

**View an existing included service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition whose details you want to display.
8. Select the **Workload Conditions** tab.
9. Open the Workload Condition page by clicking the link to the workload condition whose details you
    want to display.
10. Select the **Included Service Classes** tab.
11. In the **Service Definition** column click on the name of the service definition whose filter details you
want to display. The Included Service Class Filter page is displayed.

```
Managing excluded service classes
To manage an excluded service class filter for a workload condition, you can use the Excluded Service
Classes page. To define, view, or modify an excluded service class filter use the New , View , or Modify
actions on the Excluded Service Classes tab on the Workload Condition page.
The specification of excluded service classes filters is optional. It is used to exclude selected service
classes which would otherwise be included by an importance filter or an included service classes filter.
The service classes listed in the Excluded Service Classes table cannot trigger provisioning even if they
match the importance filters or the included service classes criteria.
An excluded service class filter is identified by the name in the Service Definition , the Service Policy and
in the Service Class field.
```
```
Table 150. Fields on the Excluded Service Class Filter page
```
```
Field Description
```
```
Service Definition Name of the z/OS Workload Manager (WLM) service definition where the
service class is defined.
Select Any service definition to specify all service definitions.
Select Specify a value to specify a particular WLM service definition.
```
```
Service Policy Name of the service policy within the WLM service definition to which the
WLM service class belongs.
Select Any service policy to specify all service policies in the specified WLM
service definition.
Select Specify a value to specify a particular WLM service policy.
```
```
Service Class Name of the WLM service class to consider.
Select Any service class to specify all service classes in the specified WLM
service policies.
Select Specify a value to specify a particular WLM service class.
```
```
Period The number of the lowest period of the service class that shall not be
considered by the Provisioning Manager. This period and all periods with a
higher period number are excluded from provisioning.
```
**112**   Capacity Provisioning Task


Refer to “Naming Conventions” on page 124 in order to find out which names are allowed.

Open the **Defined Excluded Service Class Filters** section to see the table of already defined excluded
service class filters for the current workload condition to have a quick reference.

**Procedures to manage excluded service class filters**

**Add a new excluded service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode.
4. Select the **Rules** tab.
5. Create a new rule or open an existing one.
6. Select the **Conditions** tab.
7. Create a new condition or open an existing one.
8. Select the **Workload Conditions** tab.
9. Create a new workload condition or open an existing one.
10. Select the **Excluded Service Classes** tab.
11. From the **Actions** menu, select **New**. The Excluded Service Class Filter page is displayed.
12. Specify the uncritical service class periods, the provisioning and the deprovisioning PI, the
corresponding durations, and the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed. The newly created filter is displayed in the **Excluded Service Classes**
table.

**Modify an existing excluded service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open the policy you want to modify in modify mode. Select the Rules tab.
4. Select the **Rules** tab.
5. Clink on a rule in the table.
6. Select the **Conditions** tab.
7. Click on a condition in the table.
8. Select the **Workload Conditions** tab.
9. Click on a workload condition in the table.
10. Select the **Excluded Service Classes** tab.
11. In the **Service Definition** column click on the name of the service definition for which you want to
modify the filter. The Excluded Service Class Filter page is displayed.
12. Modify the uncritical service class periods, the provisioning and the deprovisioning PI, the
corresponding durations, and the PI scope as described in the table above.
13. Click **OK** to accept the changes. If the filter contains incompatible specifications a “Messages” on
page 125 window is displayed. The modified filter is displayed in the **Excluded Service Classes** table.

```
Capacity Provisioning Task   113
```

**View an existing excluded service class filter**

1. Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Open a policy in view mode.
4. Select the **Rules** tab.
5. Open the Rule page by clicking the link to the rule whose details you want to display.
6. Select the **Conditions** tab.
7. Open the Condition page by clicking the link to the condition whose details you want to display.
8. Select the **Workload Conditions** tab.
9. Open the Workload Condition page by clicking the link to the workload condition whose details you
    want to display.
10. Select the **Excluded Service Classes** tab.
11. In the **Service Definition** column click on the name of the service definition whose filter details you
want to display. The Excluded Service Class Filter page is displayed.

#### Installing policies

```
To install a policy use the Install action provided in the Policies page.
Installing a policy transfers a policy from the z/OSMF repository to the policy repository of a domain.
Optionally, you can activate the policy after successful installation.
The Provisioning Manager which is responsible for the domain owns a policy repository and a domain
configuration repository. You can store multiple policies for different purposes in the policy repository, but
only one policy can be active in the domain. To install a policy, a connection to the Provisioning Manager
must be established and you must be a member of the Provisioning Manager control security group.
Before installing a policy, verify that the policy to be installed is correct and does not contain any errors.
Then select the domain on which to install the policy. Finally, specify if you want to activate the policy
after installation. The policy is transferred to the policy repository of the selected domain. If the transfer is
not successful, the policy is not activated.
```
```
Table 151. Fields in the Install Policy window
```
```
Field Description
```
```
Policy name Name of the policy to be installed.
```
```
Policy description Description of the policy to be installed.
```
```
Last modified Date and time the policy was last modified.
```
```
Modified by User ID of the last user who modified the policy.
```
```
Attention Hint whether there are warnings indicating that optional but recommended
parts are missing.
```
```
Connection Connection to the system where the provisioning manager for the domain is
running. Host address, port and protocol are displayed.
```
```
Domain Domain where the policy is to be installed.
```
```
Activate policy immediately
after installation
```
```
Indicator of whether the policy will be activated immediately after it is
installed in the domain. If selected, the policy will be activated. Otherwise,
you can use the Activate action, which is provided on the Policies page, to
activate the policy later.
```
**114**   Capacity Provisioning Task


**Procedure to install a policy**

1. To install a policy select the **Capacity Provisioning** task under the Performance category in the
    navigation area.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Select the policy you want to install.
4. From the **Actions** menu, select **Install**.
    **Note:** You cannot install polices that contain messages with an error severity.
5. Select a connection and a domain from the list of domains that can be reached using the selected
    connection.
6. Optionally, if you want to activate the policy after installation select the **Activate policy immediately**
    **after successful installation** checkbox.
7. Click **OK**.

```
Result
If the installation completed successfully, you will see a message indicating the successful installation.
If you specified the optional step to also activate the policy you will see a second message about the
successful activation.
```
#### Activating policies

```
To activate an installed policy, you can use the Activate action provided in the Policies page.
Activating a policy changes the global processing information of the domain to use the selected policy of
the policy repository.
When a policy is activated for the domain, the Provisioning Manager starts to use this policy to control the
domain. The policy must be installed in the policy repository of the domain.
You can store multiple policies for different purposes in the repository, but only one policy can be active in
the domain. To be able to activate a policy, a connection to the Provisioning Manager must be established
and you must be a member of the Provisioning Manager control security group. The Provisioning Manager
validates the content before the policy is activated.
```
```
Table 152. Fields in the Activate Installed Policy window
```
```
Field Description
```
```
Connection Connection to the system where a provisioning manager for the domain is
running. Host address, port, and protocol are displayed.
```
```
Domain Domain where the policy shall be activated.
```
```
Policy name Name of the policy to be activated.
```
**Procedure to activate a policy**

1. To activate an installed policy select the **Capacity Provisioning** task under the Performance category
    in the navigation area
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. From the **Actions** menu, select **Activate**.
4. Select a connection.
5. Select a domain from the list of domains that can be reached using the selected connection.
6. Select the name of the policy that you want to activate from the list of policies which are installed in
    the repository of the Provisioning Manager.
7. Click **OK**.

```
Capacity Provisioning Task   115
```

```
Result
If the activation completed successfully, you will get a message indicating the successful activation.
```
#### Exporting policies to a file

```
To export a policy from the z/OSMF repository to a file on your workstation, you can use the Export To File
action provided in the Policies page.
The policy is transferred to the local workstation and is stored in the specified location.
```
```
Before you begin
If you are using Microsoft Internet Explorer, ensure that automatic prompting for file downloads is
enabled for the Web link (URL) to the active z/OSMF instance. If the feature is disabled, when you attempt
to display the File Download window, the browser window refreshes and all of your selections and
unsaved changes are discarded. To enable automatic prompting for file downloads, complete the steps
provided in help topic Enabling automatic prompting for file downloads.
```
**Procedure to export a policy to a file**

1. To export a policy, select the **Capacity Provisioning** task under the Performance category in the
    navigation area.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. Select the policy you want to export. You can select only one policy.
4. From the **Actions** menu, select **Export To File**.
5. Select a location to store the XML file or open it with a local XML viewer of your choice.
6. Click **OK**.

```
Result
If the file was exported, it is listed in your local download directory or displayed in the XML viewer you
selected. The policy is exported as an XML file named policy-name.xml , where policy-name is the name of
the policy you exported.
```
#### Importing policies from a file

```
To import a policy from a file on the local workstation to the z/OSMF repository, you can use the Import >
From File action provided in the Policies page.
```
```
Table 153. Fields of the Import Policy window
```
```
Field Description
```
```
File to import File containing the policy to be imported.
```
```
Import Select this option to import the policy with the name of the policy that is
specified in the file to be imported.
```
```
Import with new name Select this option to import the policy using a new name. Then, in the Policy
name field, enter the name to be used.
```
```
Policy name Enter the name to use for the policy. The name must comply with the syntax
rules described in help topic “Naming Conventions” on page 124.
```
```
Replace existing policy with
same name
```
```
If this policy has the same name as a provisioning policy that already exists
in z/OSMF, select this option to overwrite the existing policy.
```
**116**   Capacity Provisioning Task


**Procedure**

- To import a policy select the **Capacity Provisioning** task under the Performance category in the
    navigation area.
- In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
- From the **Actions** menu, select **Import > From File**.
- Click **Browse** to select the file containing the policy to be imported. The policy must be in XML format.
- Decide whether you want to save the imported policy with the current name or with a new name.
- Enter the new name if you decided to change the name.
- Decide whether you want to overwrite an existing policy.
- Click **OK**.

```
Result
If the policy was imported, it is listed in the table on the Policies page using the policy name contained in
the XML file or the name you specified.
Note: The file name may differ from the policy name contained in the file.
```
#### Importing policies from a domain

```
To import a policy from a domain into z/OSMF, you can use the Import > From Domain action provided in
the Policies page.
The policy is transferred from the policy repository of the selected domain to the z/OSMF repository. To
import a policy from a domain, a connection to the Provisioning Manager must be established and you
must be a member of the Provisioning Manager control security group.
```
```
Table 154. Fields of the Import Policy From Domain window
```
```
Field Description
```
```
Connection Connection to the system where a provisioning manager for the domain is
running. Host address, port, and protocol are displayed.
```
```
Domain Domain owning the policy repository.
```
```
Policy The policy to be imported.
```
```
Import Select this option to import the policy with the name as in the policy
repository.
```
```
Import with new name Select this option to import the policy using a new name. Then, in the Policy
name field, enter the name to be used.
```
```
Policy name Enter the name to use for the policy. The name must comply with the syntax
rules described in help topic “Naming Conventions” on page 124.
```
```
Replace existing policy with
same name
```
```
If this policy has the same name as a provisioning policy that already exists
in z/OSMF, select this option to overwrite the existing policy.
```
**Procedure**

1. To import a policy select the **Capacity Provisioning** task under the Performance category in the
    navigation area.
2. In the **Overview** tab, click the **Policies** link. The Policies page is displayed.
3. From the **Actions** menu, select **Import > From Domain**.
4. Select a connection and a domain.
5. Select the policy that you want to import.

```
Capacity Provisioning Task   117
```

6. Decide whether you want to save the imported policy with the current name or with a new name.
7. Enter the new name if you decided to change the name.
8. Decide whether you want to overwrite an existing policy.
9. Click **OK**.

```
Result
If the policy was imported, it is listed in the table on the Policies page.
```
### Settings

```
On the Settings page you may specify settings for the z/OSMF Capacity Provisioning task. The settings
apply per user.
You have the choice between GMT and local time to be used for the display of date and time data. The
local time zone is determined by your browser settings.
The specified time zone is the offset added to GMT when date and time is displayed in the reports or the
Last Refresh information (which shows the date and time the status information was last gathered).
If local time is selected and this is a time zone that uses daylight saving time, the actual date and time
values used for recurring time conditions might be one hour later or earlier than the time displayed. In this
case a message is shown indicating that a time change for daylight saving will occur during this recurring
time condition.
When you switch the time zone all dates and times for your report will be adjusted.
```
**Procedure**

- Select the **Capacity Provisioning** task under the Performance category in the navigation area. The
    Capacity Provisioning page is displayed.
- In the **Overview** tab, click the **Settings** link. The Settings page is displayed.

### Capacity Provisioning Basics

```
Connections, domain configurations, and provisioning policies are stored in the z/OSMF repository. For
defining and displaying the different elements, tables are used. The actions that can be applied to
different elements or table entries are unique all over the Capacity Provisioning task. Chosen names must
conform to the rules of the naming conventions.
```
#### Domain configuration

```
Manage domain configurations, defining the CPCs to be managed and the systems to be observed.
Transfer the domain configurations to the Provisioning Manager.
```
```
CPC
Central Processor Complex (CPC). A physical collection of hardware that consists of main storage, one or
more central processors, timers, and channels.
```
```
Record ID
Unique identification token of an On/Off Capacity On Demand upgrade record.
```
```
OOCoD Record
A Licensed Internal Code Configuration Control (LICCC) record for a temporary On/Off Capacity On
Demand upgrade for System z. Records for temporary upgrade can be ordered using the Customer
Initiated Upgrade (CIU) application on Resource Link or by calling your IBM sales representative to order
```
**118**   Capacity Provisioning Task


```
the upgrades. For further details see the "Capacity on Demand User's Guide, IBM zEnterprise System -
SC28-2605".
```
```
System
A configured instance of a z/OS Operating System identified through its MVS system name and the name
of the z/OS sysplex to which it belongs.
```
```
Sysplex
A set of z/OS systems that communicate with each other through certain multisystem hardware
components and software services.
```
#### Provisioning Policy

```
A set of rules that controls the provisioning of additional capacity.
```
```
Maximum processor scope
The total amount of CP, zAAP and zIIP capacity a policy can activate. In addition specifies the increments
for workload triggered activations. See also processor scope.
```
```
Logical processor scope
Limits for the number of logical processors for systems in the provisioning domain. When this limit is
reached the Provisioning Manager stops to recommend on additional logical processors.
```
```
Logical processor
A processor that is defined in an LPAR profile. It can be either configured online, offline, or be reserved.
Only online logical processors are dispatched on physical processors.
```
```
Maximum defined capacity scope
The total amount of MSU by which a policy can increase Defined Capacity. In addition specifies the
increments for workload triggered increases. See also defined capacity scope. See also defined capacity
scope.
```
```
Maximum group capacity scope
The total amount of MSU by which a policy can increase Group Capacity. In addition specifies the
increments for workload triggered increases. See also group capacity scope.
```
```
Rule
Links a provisioning scope to time conditions and can also link it to workload conditions.
```
```
Processor scope
The amount of CP, zAAP and zIIP capacity a rule can activate. CP capacity is measured in MSU, zAAP and
zIIP capacity is measured in processors. See also maximum processor scope.
```
```
Defined capacity scope
The amount of MSU by which a rule can increase Defined Capacity. See also maximum defined capacity
scope.
```
```
Defined capacity
A limit to the capacity of an LPAR, measured in MSU. WLM constrains the LPAR's workload if the its rolling
4-hour average utilization exceeds this limit.
```
```
Capacity Provisioning Task   119
```

```
Group capacity scope
The amount of MSU by which a rule can increase Group Capacity. See also maximum group capacity
scope.
```
```
Group capacity
An extension of the defined capacity concept. A common capacity limit, measured in MSU, is shared by
multiple LPARs of the same CPC.
```
```
Condition
Provisioning conditions describe the situations in which capacity changes are allowed. Two types of
conditions are supported: Time conditions and Workload conditions. See time condition, workload
condition.
```
```
Time condition
A specification of time periods during which additional capacity can be provisioned or deprovisioned by a
rule. See also recurring time condition.
```
```
Start time
The start of a time condition, at which point the Provisioning Manager starts to provision additional
capacity. See also deadline, end time.
```
```
Deadline
The time within the duration of a time condition after which provisioning of additional capacity is no longer
allowed. Additional capacity that is provisioned between start time and deadline remains active until the
end time or until the capacity is no longer needed. See also start time, end time.
```
```
End time
The end of a time condition, after which the Provisioning Manager starts to deprovision any additional
capacity proviisioned in the time condition. See also start time, deadline.
```
```
Recurring Time condition
A specification of regularly repeating time periods on a weekday basis, during which additional capacity
can be provisioned or deprovisioned by a rule.
```
```
Utilization Condition
A definition of CPC utilization thresholds that can trigger the provisioning of additional capacity.
```
```
Workload condition
A definition of work that is eligible to cause provisioning of additional capacity and the conditions under
which provisioning occurs.
```
```
Importance filter
A table that assigns service class importance levels to sets of provisioning criteria.
```
```
Provisioning PI
The maximum of the performance index range for a service class period, at or beyond which the
Provisioning Manager considers the service class period to be negatively impacted. A performance index
(PI) is a measure of the performance of a system, based on metrics such as transaction rates or response
times.
```
**120**   Capacity Provisioning Task


```
Provisioning Utilization
The value of the physical utilization of the shared processor pool, at or above which the Provisioning
Manager considers the CPC to suffer from a processor bottleneck.
```
```
Included service classes
A table that assigns certain service class periods to sets of provisioning criteria.
```
```
Service class
A group of work items which have the same performance goals, resource requirements, or business
importance. For workload management a service goal and optionally a resource group are assigned to a
service class.
```
```
Excluded service classes
A table that makes certain service class periods ineligible for classifications of importance filters. See also
importance filters.
```
#### Repository

```
Connections, domain configurations and provisioning policies that have been defined in z/OSMF are
stored in the z/OSMF repository. They are listed in the repository table on the according Provisioning
Manager, Domain Configurations or Policies page.
The repository refers to the directory in the z/OSMF data file system in which the data for the Capacity
Provisioning task is stored. The z/OSMF administrator defines permissions for the repository when setting
up the z/OSMF data file system. If z/OSMF cannot open, read from, or write to the repository, contact your
z/OSMF administrator. You can access the repository using only the z/OSMF graphical user interface.
When you create a policy or a domain configuration it is created as a temporary version. If you log out of
z/OSMF or close the Capacity Provisioning tab before closing the temporary version of an entity, when
you reopen the Policies or Domain Configurations tab, the value in the Activity column for the original
entity is Changes pending. z/OSMF automatically releases the lock three minutes after you logged out or
closed the tab of the task.
To continue working with the temporary copy, complete the following steps:
```
1. Select the original entity.
2. If the entity is not locked, select **Modify** from the **Actions** menu or context menu. Otherwise, select
    **Copy** or wait until the lock is released and then select **Modify**.
3. In the resulting window, select the temporary entity. Doing so opens it in a **Modify** tab. All of the
    changes that you applied or saved are preserved.
**Note:** If your browser is busy and cannot communicate with the z/OSMF server within three minutes,
z/OSMF assumes that the entity is not in use and releases any locks. If this situation occurs, you might
notice one of the following:
- The state in the **Activity** column does not reflect the actual state of the domain configuration. For
example, if the domain configuration is open in view or edit mode, the activity might be blank even
though you are modifying or viewing the domain configuration.
- Another user deleted the entity while you were viewing or modifying it.
If such situations occur frequently, try working with fewer tabs, or consider using a different browser. For
a list of the tested browsers, see Configuring your workstation.
The following table provides a brief description of the values that can be displayed in the **Activity** column
in the repository table.

```
Capacity Provisioning Task   121
```

```
Table 155. Values in the Activity column
```
```
Activity Description
```
```
Being viewed The entity is being viewed by any user. If the z/OSMF role to which your user ID
is assigned is authorized to view, copy, or modify entities, you can complete these
actions. When the entity is already open, the tab is focussed. You cannot, however,
delete the entity.
```
```
Being modified The entity is locked and cannot be modified because it is being modified by any user.
If the z/OSMF role to which your user ID is assigned is authorized to view or copy
entities, you can complete these actions. You cannot, however, delete the entity or
open it again in view or edit mode.
```
```
Changes pending A temporary or working copy of the entity was created, but the changes you made
were not incorporated into the original entity before you logged out or closed the
task. All of the changes that you applied or saved are preserved. To incorporate your
changes into the entity, select the entity and select Modify from the Actions menu or
context menu. In the resulting window, select the temporary entity. Doing so opens it
in a Modify tab. If you open the original entity in a Modify tab, the temporary copy is
deleted.
```
```
Being viewed,
changes pending
```
```
The entity is being viewed, and a temporary copy of the entity exists. With proper
authority, you can view, copy, or modify the original or temporary entity; however,
you cannot delete the entity. To continue working with the temporary copy, select
the original entity and select Modify from the Actions menu or context menu. In the
resulting window, select the temporary entity. Doing so opens it in a Modify tab. All of
the changes that you applied or saved are preserved. If you open the original entity in
a Modify tab, the temporary copy is deleted.
```
```
Being modified,
changes pending
```
```
The entity is locked and is being modified by some user, and a temporary copy of
the entity exists. With proper authority, you can view or create a copy of the original
or temporary entity; however, you cannot modify or delete the entity. To continue
working with the temporary copy, select the original entity and select Copy from the
Actions menu or context menu. In the resulting window, select the temporary entity.
Doing so opens it in a Modify tab. All of the changes that you applied or saved are
preserved. You can also wait until the lock is released, and use the Modify action to
open it in a Modify tab. If you open the original entity in a Modify tab, the temporary
copy is deleted.
```
```
Temporary The entity is a temporary version. It has not been permanently saved in the
repository. Temporary entities are listed in the table when you create a new entity
using the New or Copy action. Other users cannot see it or access it. When you log out
all of the changes that you applied or saved are preserved. To permanently save the
entity, open it in a Modify tab and click OK to save and close it.
```
```
No user works with this entity and no temporary version of the entity exists.
```
```
Managing the content of the repository
Depending on the Activity state of an entity the actions on the repository have different results. A limited
set of actions is available until you create the first domain configuration.
```
**122**   Capacity Provisioning Task


_Table 156. Targeted actions_

**Action Description**

**View** View the selected entity.

- When the entity is being viewed, the **View** tab is focussed.
- When changes are pending, you will be asked whether you want to open the
    temporary or the original version of the entity. The selected entity is opened in a
    new tab in view mode.
- When the selected entity is being modified, the original version of the selected
    entity is opened in a new tab in view mode. When it is already open in view mode,
    the **View** tab is focussed. If a previous temporary version of the selected entity is
    already open, you will see this version.
- When the entity is in activity state _Temporary_ the temporary version of the selected
    entity is opened in a new tab in view mode.
**Click Close**
    to close the tab. The activity state is now empty.

**Modify** Modify the selected entity. When changes are pending, you will be asked whether you
want to open the temporary or the original version of the entity. The selected entity is
opened in a new tab in edit mode. When it is already open in edit mode, the **Modify**
tab is focussed. When you modify an entity, you are modifying a copy of the original
entity. The original entity is locked so that other z/OSMF users cannot modify it. The
changes you make to the copy are not reflected in the original entity until you click **OK**
to save your changes and close the tab.

**Delete** Delete the selected entities. This is only possible if the entities are not in state _Being
Viewed_ or _Being Modified_.

**Copy** Create a copy of the selected entity. The copied entity is opened in a new tab in edit
mode and gets the state _Temporary_.

**New** Define a new entity. A new entity without name and description is added to the
repository with activity state _Temporary_ and your changes are not visible to other
z/OSMF users.
**Click Apply**
to save the entity under the specified name in the repository. It is still in activity
state _Temporary_.
**Click OK**
to save the entity and make it visible to other users. The tab is closed. The activity
state is now empty.

**Import** Import a domain configuration or policy. The entity is imported with activity state
empty. If an entity with this name already exists, the entity can only be replaced when
it is not viewed or modified.

**Apply** Apply changes and check the entity for errors. The changes are saved temporarily so
that they are not made visible to other z/OSMF users and the tab is kept open. If you
have not made changes to the entity, the **Apply** button is disabled (grayed out).

```
Capacity Provisioning Task   123
```

```
Table 156. Targeted actions (continued)
```
```
Action Description
```
```
OK Accept changes and close the page.
On page defining a table entry
You are switched to the table which is the previous item in the breadcrumb trail
and the changes are reflected in the table.
On Policy or Domain Configuration page
In addition to the page the tab is closed. The entity is saved and its content is
checked for errors. The changes are saved in the original entity, this makes the
changes visible to other users and releases the lock.
On other pages
You are switched to the previous item in the breadcrumb trail. The changes are
applied and the entity is checked for errors. The changes are not made visible to
other users.
```
```
Reset Discard the changes you made since you last applied changes and keep the tab open,
or discard all of the changes you made to the entity and keep the tab open. After the
changes are discarded the entity is checked for errors. If you have not made changes
to the entity, the Reset button is disabled (grayed out).
```
```
Cancel Discard changes and close the page. If there are changes, which have not been
applied, you are given the option either to discard only the not applied changes or to
discard all of the changes you made to the entity.
On page defining a table entry
You are switched to the table which is the previous item in the breadcrumb trail
and the table is unchanged. All changes to this page are discarded, the decision
dialog is not necessary.
On Policy or Domain Configuration page
In addition to the page the tab is closed. If changes have been applied and not all
changes are discarded, the entity is saved and its content is checked for errors.
The content is saved in the original entity, this makes the content visible to other
users and releases the lock.
On other pages
You are switched to the previous item in the breadcrumb trail. The changes are
discarded and the entity is checked for errors. The remaining changes are not
made visible to other users.
```
```
Close Close the page.
On Policy or Domain Configuration page
In addition to the page the tab is closed.
On other pages
You are switched to the previous item in the breadcrumb trail.
```
```
X Clicking the X in the tab closes the tab. In the New and Modify tabs, if there are
unsaved changes, you are given the option either to discard the unsaved changes or to
discard all of the changes you made to the entity. The X is also displayed in the View
tab.
```
#### Naming Conventions

```
Policy names and configuration names must be unique within the z/OSMF repository. The names of policy
elements must be unique within that policy. If there is an element with the same name and type in the
current policy an error is reported in the z/OS Management Facility. If you paste a policy element with a
name that already exists, the name is altered to make it unique.
```
**124**   Capacity Provisioning Task


```
The length of names and the character set that can be used are restricted.
Named elements within a provisioning policy or a domain configuration, and elements referencing
external entities such as a system name or the logical name of a CPC must conform to the rules defined in
Table 157 on page 125. In this table, the hyphen (-) indicates that any ASCII character within the range is
valid.
```
```
Table 157. Naming restrictions
```
```
Name
```
```
Minimum
length
```
```
Maximum
length Initial character Subsequent characters
```
```
Domain 1 8 A - Z A - Z, 0 - 9, #
```
```
Provisioning policy 1 8 A - Z A - Z, 0 - 9, #
```
```
Provisioning rule 1 12 A - Z, a - z A - Z, a - z, 0 - 9, #, _
```
```
Provisioning condition 1 12 A - Z, a - z A - Z, a - z, 0 - 9, #, _
```
```
Time condition 1 12 A - Z, a - z A - Z, a - z, 0 - 9, #, _
```
```
Workload condition 1 12 A - Z, a - z A - Z, a - z, 0 - 9, #, _
```
```
Utilization condition 1 12 A - Z, a - z A - Z, a - z, 0 - 9, #, _
```
```
WLM service definition 1 8 A - Z, a - z, 0 - 9, #, $, %, @ A - Z, a - z, 0 - 9, #, $, %, @,
_
```
```
WLM service policy 1 8 A - Z, a - z, 0 - 9, #, $, %, @ A - Z, a - z, 0 - 9, #, $, %, @,
_
```
```
WLM service class 1 8 A - Z, a - z, 0 - 9, #, $, %, @ A - Z, a - z, 0 - 9, #, $, %, @,
_
```
```
Domain configuration 1 8 A - Z A - Z, 0 - 9, #
```
```
System 1 8 A - Z, 0 - 9, #, $, @ A - Z, 0 - 9, #, $, @
```
```
Sysplex 1 8 A - Z, 0 - 9, #, $, @ A - Z, 0 - 9, #, $, @
```
```
CPC 1 8 A - Z, 0 - 9, #, $, @ A - Z, 0 - 9, #, $, @
```
```
CPC record ID 8 8 A - Z, 0 - 9 A - Z, 0 - 9
```
```
Description 0 128 A - Z, a - z, 0 - 9, #, $, %, @,
_, blank, new line, period
```
```
A - Z, a - z, 0 - 9, #, $, %, @,
_, blank, new line, period
```
```
Group 1 8 A - Z, 0 - 9, #, $, @ A - Z, 0 - 9, #, $, @
```
#### Messages

```
This window shows a list of messages that are related to the managed policy or domain configuration. You
can use the messages list to easily navigate to elements that have messages.
Messages indicate that a policy or domain configuration is not complete or that it contains incompatible
specifications. Error messages and warning messages indicate the next steps you should take.
For a description of the columns in the Messages table, see Table 1. For a description of the actions listed
in the Actions menu, see “Table actions” on page 126.
Actions which display the Messages window:
OK (on a leaf)
The element on the current page is checked for errors. The Messages window is displayed, showing
the resulting errors and warnings for this element. You can click Continue to accept the validation
errors or click Cancel to correct them.
```
```
Capacity Provisioning Task   125
```

```
Apply/Paste/Delete/Reset
The element on the current page is checked for errors. The number of messages on the right top is
updated. To display the messages for the whole entity click on the Messages link.
OK/Cancel (in a policy or domain configuration)
The policy or domain configuration is checked for errors and the tab is closed. An indication whether
the entity contains errors or warnings is displayed in the Messages column of the repository table.
To display the messages for the whole entity click on the link in the Messages column. The entity is
opened in view mode and the Messages window is displayed. When the entity is already open in view
mode, the tab is focussed and the messages which existed at the point of time, when the tab was
opened are displayed.
```
**The Messages table**

```
Table 158. Columns in the Messages table
```
```
Column name Description
```
```
Message ID Identifier for the message. To display the help for the message, you can
click the status icon or message ID link. With focus on the cell, you can
also press Ctrl+Q or Enter to display the help.
```
```
Message Text Text of the message.
```
- **Warning.** These messages are issued in situations that can
    prevent successful completion. They are displayed if optional but
    recommended parts are missing. Check whether the situation is OK
    or if you need to take corrective action.
- **Error.** These messages are displayed if required parts are
    missing or the specifications are incompatible. Policies and domain
    configurations which contain errors can not be installed or activated.

```
Element Element of a policy or a domain configuration for which the message
occurred. To navigate to the element, click the element link. With focus
on the cell, you can also press Enter to navigate to the item. (This
column is only displayed, when the messages for the whole policy or
domain configuration are displayed.)
```
```
In the View tab, the Messages window lists the messages that exist for the version of the entity that
is listed in the repository table. In the Modify tab, the Messages window lists the messages that exist
for your working copy of the entity. If you are working with an entity in a View and a Modify tab, the
Messages window might list different messages because the list in the View tab is not updated until you
complete the following actions:
```
- In the **Modify** tab, save your changes, and then close the tab or apply your changes.
- Close and reopen the **View** tab and display the Messages window again.

#### Table actions

```
This page shows information about the domain configuration and policy table actions. It lists actions such
as sorting and filtering. No selection is required.
```
```
Table 159. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
**126**   Capacity Provisioning Task


_Table 159. Table actions (continued)_

**Action Description**

**Configure Columns** Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.

**Show Filter Row** Display the filter row. This action is listed only when the filter row is not displayed
in the table.

```
Capacity Provisioning Task   127
```

IBM®


_Table 32. Columns in the Tenant Resource Groups table (continued)_

**Memory Limit** Maximum amount of memory that address spaces
associated with the tenant resource group through
classification can consume on the local system, which is
specified as an absolute value in GB. It has a system scope.
Tenant resource groups cannot be applied to service
classes representing transaction-oriented work, such as
CICS or IMS transactions. To explicitly restrict memory
consumption of CICS or IMS transaction servers, assign a
tenant resource group with a memory limit to the service
class of the CICS or IMS region.
Similarly, tenant resource groups with a memory limit
cannot be applied to enclave service classes. As for CICS
or IMS, a tenant resource group with a memory limit must
be assigned to the service class of the address spaces that
join the enclaves.
A memory limit overrules the storage critical attribute of
classification rules and also any protective storage target
managed through SRM.

**Description** Description of the resource group. The description is
optional. It can contain up to 32 characters.

**Messages** Indicates the highest severity message that has occurred
for the entire tenant resource group. This field does not
provide an indicator for the attribute-specific messages (if
any). One of the following message indicators is displayed:

- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages
    might also exist.
- **Error.** Error messages exist. Information and warning
    messages might also exist.
To display the messages, you can click the link or status
icon, or you can select the cell that contains the link or icon
and press Ctrl+M. You can also select the corresponding
item and select **View Messages** from the **Actions** menu
or context menu. A window is displayed that lists the
messages.

**Last Modified** Date and time the item was last modified.

**Modified By** User ID of the person who last modified the item.

```
Actions for tenant resource groups
The actions are described in the following tables:
```
- Table 33 on page 54. Actions that apply to the selected tenant resource groups. To use a targeted
    action, you must select one or more tenant resource groups.
- Table 34 on page 54. Actions that apply to tenant resource groups. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.

```
Workload Management task   53
```

```
Except where noted, the actions are available in the New , View , Modify , and Copy tabs. A limited set of
actions is available until you create the first tenant resource group.
```
```
Table 33. Targeted actions
```
```
Action Description
```
```
Cut to Clipboard Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the New , Modify , and Copy tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.
```
```
Copy to Clipboard Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.
```
```
Delete Delete the selected rows. This action is listed only in the New , Modify , and Copy
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.
```
```
View Cross-References View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.
```
```
View Messages View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.
```
```
Table 34. General actions
```
```
Action Description
```
```
New Define a new tenant resource group. This action is listed only in the New , Modify ,
and Copy tabs.
```
```
Paste Insert the items that were copied to the clipboard into the table. This action is
listed only in the New , Modify , and Copy tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.
```
```
Table 35. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
**54**   Workload Management task


```
Defining new tenant resource groups
To define a new tenant resource group, use the New action provided in the Tenant Resource Groups
table in the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Tenant Resource Groups** table.
2. From the **Actions** menu, select **New**. A new row is added to the table.
3. Specify the appropriate settings. You must provide a name for the tenant resource group that is unique
    in the service definition.
    The solution ID, tenant ID, tenant name, type, description, Include Specialty Processor Consumption
    option, and the capacity maximum are optional. For more details, see help topic “Tenant Resource
    Groups” on page 50.
4. Click **OK** or **Apply** to save your changes.

#### Service Classes

```
A service class is a named group of work within a workload with similar performance goals, resource
requirements, or business importance. In z/OSMF, with proper authorization, you can define, view, and
modify service classes and assign service classes to a workload and, optionally, to a resource group.
You must define at least one service class. You can define up to 100 service classes. Each service class
must contain at least one performance period. You can specify up to eight performance periods in a single
service class. You use performance periods to assign service goals and importance levels to a service
class for a specific duration.
The Service Classes table lists all of the service classes that are defined in the service definition. For a
description of the columns in the Service Classes table, see Table 36 on page 55. For a description of
the actions that you can take against service classes and periods, see “Actions for service classes and
periods” on page 58.
For more information about service classes, see z/OS MVS Planning: Workload Management.
```
**Columns in the Service Classes table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 36. Columns in the Service Classes table
```
```
Column Description
```
```
Name Name of the service class. The name can contain up to eight characters including
alphanumeric characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \),
punctuation marks (! : " [ ]), and the following special characters: %, $, #, @, ^, and
_. The name cannot begin with the characters SYS or the characters $SRM. The
name is required and must be unique in the service definition. Service class names
are not case sensitive; for example, SCTEST and SCTest are the same service
class.
```
```
Workload Management task   55
```

```
Table 36. Columns in the Service Classes table (continued)
```
```
Column Description
```
```
Period Number of the period in the service class. When work is assigned to a service
class, z/OS Workload Manager (WLM) manages the work according to the goals of
period number 1, then period number 2, and so on. A service class can have up to
eight periods. At least one period is required. z/OSMF automatically populates this
column.
```
```
Importance Indicates how important it is that the goal of this period be met relative to other
goals. The importance values can be: 1 for highest, 2 for high, 3 for medium, 4 for
low, and 5 for lowest. Importance levels should stay the same or decrease as the
transactions move from one performance period to the next. Importance applies
only if a goal is not being met during the duration of the period. The importance is
required. The default importance is 3.
The importance levels are highlighted by corresponding background colors.
```
```
Duration Amount of service (in service units) that the work can consume before it is
switched to the goals of the next period. The duration ranges from 1 - 999999999
service units. If you are defining a single period goal, you should not specify a
duration. If you are defining multiple periods, you are required to specify a duration
for each period except the last.
```
```
Goal Type Type of performance goal. A goal type is required. You can select one of the
following types:
```
- **Average Response Time.** The expected amount of time required to complete the
    work submitted to the service class.
- **Percentile Response Time.** The percentage of work in a period that should
    complete within the specified response time.
- **Velocity.** Measure of how fast work should run when ready without being
    delayed for resources managed by WLM.
- **Discretionary.** WLM defined goal. Associate this goal with work for which you do
    not have a specific performance goal. Work with a discretionary goal is run when
    excess resources are available.

```
Response Time Goal Expected amount of time required to complete the work submitted under the
service class. Response time goals range from 1 millisecond to 24 hours and has
the format hh : mm : ss. ttt where:
```
- _hh_ represents the number of hours
- _mm_ represents the number of minutes
- _ss_ represents the number of seconds
- _ttt_ represents the number of milliseconds
You can abbreviate this format, as needed. For example, you can specify 1.2
instead of 00:00:01.200.
If you selected the **Average Response Time** or the **Percentile Response Time** goal
type, you are required to specify a response time goal.

```
Percentile Goal Percentage of work in the period that should complete within the specified
response time. Percentile boundaries range from 1 - 99 and must be a whole
number. If you selected the Percentile Response Time goal type, you are required
to specify a percentile goal.
```
**56**   Workload Management task


_Table 36. Columns in the Service Classes table (continued)_

**Column Description**

**Velocity Goal** Percentage of work in the period that must run without being delayed for resources
managed by WLM. The percentage is a number from 1 - 99 and must be a whole
number. If you selected the **Velocity** goal type, you are required to specify a
velocity goal.

**CPU Critical** Indicates whether long-term CPU protection should be assigned to the service
class. You must select **Yes** or **No**. If you select **Yes** , you ensure that less
important work will generally have a lower dispatch priority. This protection can
be valuable to work which is extremely CPU-sensitive, such as certain CICS® and
IMS transactions. Specifying too many CPU critical service classes, however, limits
the ability of WLM to manage the system dynamically. By default, CPU protection is
not assigned to the service class; **No** is selected.

**I/O Priority Group** Indicates the I/O priority group of the service class. **High** ensures that work in this
service class always has higher I/O priority than work in service classes assigned
to I/O priority group **Normal**.
**Normal** and **High** are the only valid groups. The default is **Normal**.
Group **High** will only be honored if dynamic I/O priority management is enabled,
that is, workload management dynamically manages your I/O priorities based on
service class goals and importance. To turn on I/O priority management, specify
**Yes** on the Service Options field **Enable I/O priority management** on the **Service
Definition Details** panel.

**Honor Priority** Whether a service class is exempted from default IFAHONORPRIORITY or
IIPHONORPRIORITY processing. Specify Default or No.
**Default**
Current values of the IFAHONORPRIORITY and IIPHONORPRIORITY
parameters in parmlib member IEAOPT _xx_ are used when there is insufficient
specialty engine capacity for the workload demand in the service class. This is
the default.
**No**
Independent of the current value of the IFAHONORPRIORITY and
IIPHONORPRIORITY parameters in parmlib member IEAOPT _xx_ , work in this
service class is not allowed to overflow to standard processors when there is
insufficient capacity on specialty engines (System z® Integrated Information
Processors, or zIIPs, or System z Application Assist Processors, or zAAPs)
for the workload demand in the service class. The only exception is if it is
necessary to resolve contention for resources with standard processor work.

**Resource Group** Name of the resource group to which the service class is assigned. Assigning a
service class to a resource group is optional. This field lists the names of the
resource groups that are defined in the Resource Groups section of the service
definition.
Keep in mind your service class goals when you assign a service class to a
resource group. Given the combination of goals, the importance level, and the
resource capacity, some goals may not be achievable when capacity is restricted.
You cannot assign a resource group to service classes representing transaction-
oriented work, such as CICS or IMS transactions. For most systems, you can let
WLM decide how to manage the resources in the sysplex and not use resource
groups.

```
Workload Management task   57
```

```
Table 36. Columns in the Service Classes table (continued)
```
```
Column Description
```
```
Workload Name of the workload to which the service class is assigned. Assigning a service
class to a workload is required. This field lists the names of the workloads that are
defined in the Workloads section of the service definition.
```
```
Rules The number of classification rules that the service class is referenced by.
```
```
Description Description of the service class. The description is optional. It can contain up to 32
characters.
```
```
Messages Indicates the highest severity message that has occurred for the entire service
class or its periods. One of the following message indicators is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.
To display the periods that have messages, expand the service class.

```
Last Modified Date and time the item was last modified.
```
```
Modified By User ID of the person who last modified the item.
```
```
Actions for service classes and periods
The actions are described in the following tables:
```
- Targeted actions for service classes. Actions that apply to the selected service classes. To use a
    targeted action, you must select one or more service classes.
- Targeted actions for periods. Actions that apply to the selected periods. To use actions that apply to
    periods, you must select one or more performance periods, and you must not select any service classes.
- General actions. Actions that apply to service classes. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first service class.

```
Table 37. Targeted actions for service classes
```
```
Action Description
```
```
Expand Expand the selected parent nodes so that the rows that contain the
corresponding child nodes are visible. This action is listed only when you
are displaying the tree view of the table. To enable this action, you must
select one or more rows that contain parent nodes.
```
```
Collapse Collapse the selected parent nodes so that the rows that contain the
corresponding child nodes are hidden. This action is listed only when you
are displaying the tree view of the table. To enable this action, you must
select one or more rows that contain parent nodes.
```
**58**   Workload Management task


_Table 37. Targeted actions for service classes (continued)_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard.
This action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is
enabled only when you have selected one or more rows. This action is
disabled (grayed out) in the non-tree view of the table if a sort or filter
other than the default sort or filter (if any) has been applied to the table.
You cannot cut an item that is being referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must
select one or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** ,
and **Copy** tabs, and it is enabled only when you have selected one or
more rows. This action is disabled (grayed out) in the non-tree view of the
table if a sort or filter other than the default sort or filter (if any) has been
applied to the table. You cannot delete an item that is being referenced by
another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To
enable this action, you must select only one item. If the action is disabled
(grayed out), there might not be any cross-references for the selected
item.

**View Messages** View the messages that exist for the selected item. To enable this action,
you must select only one item. If the action is disabled (grayed out), there
might not be any messages for the selected item.

**View Performance of Selected** View the performance of the selected item. To enable this action you must
select only one item. If the action is disabled (grayed out), performance
data is not available for the selected item. If the action is not displayed in
the menu, a provider of appropriate performance data is not available. If a
service policy of the service definition is active and this action is disabled
for a service class, the service class is overridden in the active service
policy. To view the performance of the service class you have to use the
**View Performance of Selected** action for the corresponding service class
override item on the **Properties for Active Service Policy** panel. You can
use the **View Cross-References** action of the **Service Classes** table to
navigate to the service class override items.

_Table 38. Targeted actions for periods_

**Action Description**

**New Period** Define a new period and insert it before or after the selected period. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled
when you have selected only one period. This action is disabled (grayed out)
in the non-tree view of the table if a sort or filter other than the default sort
or filter (if any) has been applied to the table.

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard.
This action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled
only when you have selected one or more rows. This action is disabled
(grayed out) in the non-tree view of the table if a sort or filter other than the
default sort or filter (if any) has been applied to the table. You cannot cut an
item that is being referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must
select one or more rows.

```
Workload Management task   59
```

```
Table 38. Targeted actions for periods (continued)
```
```
Action Description
```
```
Paste Periods Insert the periods that were copied to the clipboard before or after the
selected period. This action is listed only in the New , Modify , and Copy tabs,
and it is enabled when you have selected only one period. This action is
disabled (grayed out) in the non-tree view of the table if a sort or filter other
than the default sort or filter (if any) has been applied to the table.
```
```
Move Periods Move the selected periods up or down one row. This action is listed only in
the New , Modify , and Copy tabs, and it is enabled when you have selected
one or more periods. This action is disabled (grayed out) in the non-tree view
of the table if a sort or filter other than the default sort or filter (if any) has
been applied to the table.
```
```
Delete Delete the selected rows. This action is listed only in the New , Modify , and
Copy tabs, and it is enabled only when you have selected one or more rows.
This action is disabled (grayed out) in the non-tree view of the table if a sort
or filter other than the default sort or filter (if any) has been applied to the
table. You cannot delete an item that is being referenced by another item.
```
```
View Messages View the messages that exist for the selected item. To enable this action, you
must select only one item. If the action is disabled (grayed out), there might
not be any messages for the selected item.
```
```
View Performance of Selected View the performance of the selected item. To enable this action you must
select only one item. If the action is disabled (grayed out), performance
data is not available for the selected item. If the action is not displayed in
the menu, a provider of appropriate performance data is not available. If a
service policy of the service definition is active and this action is disabled for
a service class period, the service class is overridden in the active service
policy. To view the performance of the service class you have to use the View
Performance of Selected action for the corresponding service class override
item on the Properties for Active Service Policy panel. You can use the
View Cross-References action of the Service Classes table to navigate to
the service class override items.
```
```
Table 39. General actions
```
```
Action Description
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that
contain child nodes are visible. This action is listed only when you are
displaying the tree view of the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows
that contain child nodes are hidden. This action is listed only when
you are displaying the tree view of the table.
```
```
New Service Class Define a new service class. This action is listed only in the New ,
Modify , and Copy tabs. This action is disabled (grayed out) in the
non-tree view of the table if a sort or filter other than the default sort
or filter (if any) has been applied to the table.
```
**60**   Workload Management task


_Table 39. General actions (continued)_

**Action Description**

**Paste Service Classes** Insert the items that were copied to the clipboard into the table. This
action is listed only in the **New** , **Modify** , and **Copy** tabs. The items
being pasted must be of the same type as the items contained in
the table into which they are being pasted. The items are inserted
according to the sort and filter criteria specified. If an item to be
pasted duplicates the name of an item contained in the table, an
underscore (_) and a number are appended to the name of the item
being pasted. This action is disabled (grayed out) in the non-tree
view of the table if a sort or filter other than the default sort or filter
(if any) has been applied to the table.

**View Performance of All** View the performance of all items. If the action is disabled (grayed
out), performance data is not available for the items. If the action
is not displayed in the menu, a provider of appropriate performance
data is not available.

_Table 40. Table actions_

**Action Description**

**Select All** Select all of the rows in the table.

**Deselect All** Deselect all of the selected rows in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.

**Show Filter Row** Display the filter row. This action is listed only when the filter row is not displayed
in the table.

**Clear Sorts** Clear the sort from all of the columns in the table.

**Clear Search** Clear the search.

**Switch to Non-Tree View** Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
You can switch between tree view, non-tree view, and flat view. The selected items
are reselected after switching views.

**Switch to Tree View** Display the hierarchical view of the table. This action is listed only when you are
displaying the non-tree view of the table.
You can switch between tree view, non-tree view, and flat view. The selected items
are reselected after switching views.

```
Workload Management task   61
```

```
Table 40. Table actions (continued)
```
```
Action Description
```
```
Switch to Flat View (Sort
All)
```
```
Display the flat view of the table. In the flat view, the table displays only the child
nodes. The attributes of each parent node are flattened into its child nodes, so that
the overall sorting function is performed within the whole table. This action is listed
only when you are displaying the tree view or non-tree view of the table.
You can switch between tree view, non-tree view, and flat view. The selected items
are reselected after switching views.
This action is enabled only when you are in the View tab. In the New , Modify , and
Copy tabs, the tips icon ( ) near the disabled action is displayed.
If you are displaying the flat view of the table in the View tab and select
Editable Version of Service Definition from the Switch To menu, then the table
automatically switches back to the tree view and the selected items are reselected
after switching.
```
```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
New and Properties pages for service policies
In z/OSMF, you can use the New Service Policy page to define a new service policy, and you can use the
Properties for service policy page to view or modify existing service policies.
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new service classes
To define a new service class, use the New Service Class action provided in the Service Classes table in
the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Service Classes** table.
2. From the **Actions** menu, select **New Service Class**. A new row is added to the table. This action is
    disabled (grayed out) in the non-tree view of the table if a sort or filter other than the default sort or
    filter (if any) has been applied to the table.
3. Specify the appropriate settings. You must:
    a) Provide a name for the service class that is unique in the service definition.
b) Indicate whether long-term CPU protection should be assigned to this service class.

**62**   Workload Management task


```
c) Assign the service class to a workload.
d)Define at least one period. For each period, specify the importance, goal type, and goal information.
If you are defining a single period goal, you should not specify a duration. If you are defining
multiple periods, you are required to specify a duration for each period except the last.
For more details, see help topic “Service Classes” on page 55.
```
4. Click **OK** or **Apply** to save your changes.

**Defining new performance periods**

To define a new performance period, use the **New Period** > **Before** and **New Period** > **After** actions
provided in the **Service Classes** and **Service Class Overrides** tables in the **New** , **Modify** , and **Copy** tabs.

**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Service Classes** table or the **Service Class Overrides**
    table.
2. Select the period that you want to define a new period before or after. You can select only one period.
3. From the **Actions** menu or context menu, select **New Period** > **Before** or **New Period** > **After**. A new
    row is added to the table in the specified position. This action is disabled (grayed out) in the non-tree
    view of the table if a sort or filter other than the default sort or filter (if any) has been applied to the
    table.
4. Specify the appropriate settings. You must:
    a) Indicate the importance of the period.
b) Specify a duration. If you are defining a single period goal, you should not specify a duration. If you
are defining multiple periods, you are required to specify a duration for each period except the last.
    c) Select the goal type.
d) Enter the goal information in the corresponding goal columns.
    For more details, see help topic “Service Classes” on page 55.
5. Click **OK** or **Apply** to save your changes.

**Related reference**

New and Properties pages for service policies
In z/OSMF, you can use the **New Service Policy** page to define a new service policy, and you can use the
**Properties for service policy** page to view or modify existing service policies.

**Moving performance periods**

When work is assigned to a service class, z/OS Workload Manager (WLM) manages the work according
to the goals of period number 1, then period number 2, and so on. To change the period numbers, you
can use the **Move Periods** > **Up** and **Move Periods** > **Down** actions provided in the **Service Classes** and
**Service Class Overrides** tables in the **New** , **Modify** , and **Copy** tabs.

**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Service Classes** table or the **Service Class Overrides**
    table.
2. Select the period that you want to move up or down a row. You can select multiple periods.
3. From the **Actions** menu or context menu, select **Move Periods** > **Up** or **Move Periods** > **Down**. The
    period is moved to the specified position and the periods are renumbered, as needed. This action is
    disabled (grayed out) in the non-tree view of the table if a sort or filter other than the default sort or
    filter (if any) has been applied to the table.
4. Click **OK** or **Apply** to save your changes.

```
Workload Management task   63
```

```
Related reference
New and Properties pages for service policies
In z/OSMF, you can use the New Service Policy page to define a new service policy, and you can use the
Properties for service policy page to view or modify existing service policies.
```
#### Report Classes

```
A report class is a group of work for which you want reporting data. z/OS Workload Manager (WLM)
provides data for reporting on all of the service definition terms by service class period and workload. You
can use report classes to provide more granular reporting for subsets of work within a single service class
or for combining different service classes within one report class. In z/OSMF, with proper authorization,
you can define, view, and modify report classes and assign work to a report class.
You can define up to 2,047 report classes and, optionally, assign work to a report class. To assign work
to a report class, in the Classifications section, assign the corresponding classification or rule to a report
class.
The Report Classes table lists all of the report classes that are defined in the service definition. For a
description of the columns in the Report Classes table, see Table 41 on page 64. For a description of the
actions that you can take against report classes, see “Actions for report classes” on page 65.
For more information about report classes, see z/OS MVS Planning: Workload Management.
```
**Columns in the Report Classes table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 41. Columns in the Report Classes table
```
```
Column Description
```
```
Name Name of the report class. The name can contain up to eight characters including
alphanumeric characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \),
punctuation marks (! : " [ ]), and the following special characters: %, $, #, @, ^, and
_. The name is required and must be unique in the service definition. There must
not be a tenant report class with a name equal to the name of a legacy report class.
Report class names are not case sensitive; for example, RCTEST and RCTest are
the same report class.
```
```
Description Description of the report class. The description is optional. It can contain up to 32
characters.
```
**64**   Workload Management task


_Table 41. Columns in the Report Classes table (continued)_

**Column Description**

**Messages** Indicates the highest severity message that has occurred for the entire report
class. This field does not provide an indicator for the attribute-specific messages (if
any). One of the following message indicators is displayed:

- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.

**Last Modified** Date and time the item was last modified.

**Modified By** User ID of the person who last modified the item.

```
Actions for report classes
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected report classes. To use a targeted action, you must
    select one or more report classes.
- General actions. Actions that apply to report classes. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first report class.

_Table 42. Targeted actions_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

```
Workload Management task   65
```

```
Table 42. Targeted actions (continued)
```
```
Action Description
```
```
View Performance of
Selected
```
```
View the performance of the selected item. To enable this action you must select
only one item. If the action is disabled (grayed out), performance data is not
available for the selected item. If the action is not displayed in the menu, a
provider of appropriate performance data is not available. If a service policy of
the service definition is active and this action is disabled for a service class, the
service class is overridden in the active service policy. To view the performance of
the service class you have to use the View Performance of Selected action for the
corresponding service class override item on the Properties for Active Service
Policy panel. You can use the View Cross-References action of the Service
Classes table to navigate to the service class override items.
```
```
Table 43. General actions
```
```
Action Description
```
```
New Define a new report class. This action is listed only in the New , Modify , and Copy
tabs.
```
```
Paste Insert the items that were copied to the clipboard into the table. This action is
listed only in the New , Modify , and Copy tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.
```
```
View Performance of All View the performance of all items. If the action is disabled (grayed out),
performance data is not available for the items. If the action is not displayed in
the menu, a provider of appropriate performance data is not available.
```
```
Table 44. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
```
**66**   Workload Management task


```
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new report classes
To define a new report class, use the New action provided in the Report Classes table in the New ,
Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Report Classes** table.
2. From the **Actions** menu, select **New**. A new row is added to the table.
3. Enter a name for the report class. The name can contain up to eight characters including alphanumeric
    characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \), punctuation marks (! : " [ ]), and the
    following special characters: %, $, #, @, ^, and _. The name is required and must be unique in the
    service definition. There must not be a tenant report class with a name equal to the name of a legacy
    report class. Report class names are not case sensitive; for example, **RCTEST** and **RCTest** are the
    same report class.
4. Enter a description of the report class. The description is optional. It can contain up to 32 characters.
5. Click **OK** or **Apply** to save your changes.

#### Tenant Report Classes

```
A tenant report class is a group of work for which you want reporting data, and for which you optionally
specify capacity boundaries. It is associated with a Tenant Resource Group. z/OS Workload Manager
(WLM) provides data for reporting on all of the service definition terms by service class period and
workload. You can use tenant report classes to provide more granular reporting for subsets of work within
a single service class or for combining different service classes within one tenant report class. In z/OSMF,
with proper authorization, you can define, view, and modify tenant report classes and assign work to a
tenant report class.
You can define up to 2,047 tenant report classes and, optionally, assign work to a tenant report class. To
assign work to a tenant report class, in the Classifications section, assign the corresponding classification
or rule to a tenant report class.
The Tenant Report Classes table lists all of the tenant report classes that are defined in the service
definition. For a description of the columns in the Tenant Report Classes table, see “Columns in the
Tenant Report Classes table” on page 67. For a description of the actions that you can take against
tenant report classes, see “Actions for tenant report classes” on page 68.
For more information about tenant report classes, see z/OS MVS Planning: Workload Management.
```
```
Columns in the Tenant Report Classes table
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
```
Workload Management task   67
```

- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 45. Columns in the Tenant Report Classes table
```
```
Column Description
```
```
Name Name of the tenant report class. The name can contain up to eight characters
including alphanumeric characters (A-Z, a-z, and 0-9), mathematical symbols (| ~
{ } \), punctuation marks (! : " [ ]), and the following special characters: %, $, #, @,
^, and _. The name is required and must be unique in the service definition. There
must not be a tenant report class with a name equal to the name of a legacy report
class. Report class names are not case sensitive; for example, RCTEST and RCTest
are the same report class.
```
```
Tenant Resource Group Tenant resource group of the tenant report class. The tenant resource group is
required. You can select one tenant resource group.
```
```
Description Description of the tenant report class. The description is optional. It can contain up
to 32 characters.
```
```
Messages Indicates the highest severity message that has occurred for the entire tenant
report class. This field does not provide an indicator for the attribute-specific
messages (if any). One of the following message indicators is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.

```
Last Modified Date and time the item was last modified.
```
```
Modified By User ID of the person who last modified the item.
```
**Actions for tenant report classes**

```
The actions are described in the following tables:
```
- Table 46 on page 69. Actions that apply to the selected tenant report classes. To use a targeted action,
    you must select one or more tenant report classes.
- Table 47 on page 69. Actions that apply to tenant report classes. No selection is required.
- Table 48 on page 69. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first tenant report class.

**68**   Workload Management task


_Table 46. Targeted actions_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

**View Performance of
Selected**

```
View the performance of the selected item. To enable this action you must select
only one item. If the action is disabled (grayed out), performance data is not
available for the selected item. If the action is not displayed in the menu, a
provider of appropriate performance data is not available. If a service policy of
the service definition is active and this action is disabled for a service class, the
service class is overridden in the active service policy. To view the performance of
the service class you have to use the View Performance of Selected action for the
corresponding service class override item on the Properties for Active Service
Policy panel. You can use the View Cross-References action of the Service
Classes table to navigate to the service class override items.
```
_Table 47. General actions_

**Action Description**

**New** Define a new tenant report class. This action is listed only in the **New** , **Modify** , and
**Copy** tabs.

**Paste** Insert the items that were copied to the clipboard into the table. This action is
listed only in the **New** , **Modify** , and **Copy** tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.

**View Performance of All** View the performance of all items. If the action is disabled (grayed out),
performance data is not available for the items. If the action is not displayed in
the menu, a provider of appropriate performance data is not available.

_Table 48. Table actions_

**Action Description**

**Select All** Select all of the rows in the table.

**Deselect All** Deselect all of the selected rows in the table.

```
Workload Management task   69
```

```
Table 48. Table actions (continued)
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Defining new tenant report classes
To define a new tenant report class, use the New action provided in the Tenant Report Classes table in
the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Tenant Report Classes** table.
2. From the **Actions** menu, select **New**. A new row is added to the table.
3. Enter a name for the tenant report class. The name can contain up to eight characters including
    alphanumeric characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \), punctuation marks (! :
    " [ ]), and the following special characters: %, $, #, @, ^, and _. The name is required and must be
    unique in the service definition. There must not be a tenant report class with a name equal to the name
    of a legacy report class. Tenant Report class names are not case sensitive; for example, **TRCTEST** and
    **TRCTest** are the same tenant report class.
4. Enter a description of the tenant report class. The description is optional. It can contain up to 32
    characters.
5. Click **OK** or **Apply** to save your changes.

#### Classification Groups

```
A classification group is a collection of qualifier values for a single qualifier type. You can use a
classification group to identify all of the possible values that a qualifier type might have for a particular
subsystem. To simplify classification, you can create one rule that refers to the classification group
instead of creating separate rules for each qualifier value. In z/OSMF, with proper authorization, you
can define, view, and modify classification groups and associate classification groups with one or more
classification rules.
If you intend to use classification groups, define the groups before you create the classification rules. To
associate a classification group with one or more classification rules, switch to the Classifications section.
The Classification Groups table lists all of the classification groups that are defined in the service
definition. For a description of the columns in the Classification Groups table, see Table 49 on page 71.
For a description of the actions that you can take against classification groups and qualifier values, see
“Actions for classification groups and qualifier values” on page 72.
For more information about classification groups, see z/OS MVS Planning: Workload Management.
```
**Columns in the Classification Groups table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
**70**   Workload Management task


- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

_Table 49. Columns in the Classification Groups table_

**Column Description**

**Name** Name of the classification group. The name can contain up to eight characters
including alphanumeric characters (A-Z, a-z, and 0-9), mathematical symbols (|
~ { } \), punctuation marks (! : " [ ]), and the following special characters: $, #,
@, ^, and _. The name is required and must be unique in the service definition.
Classification group names are not case sensitive; for example, **CGTEST** and
**CGTest** are the same classification group.

**Qualifier Type** Type of work qualifier. A qualifier type is required. This field lists the qualifier types
for which you can create classification groups. You must select a qualifier type
from the list.
In a classification group, each qualifier value has the same type; therefore, the
**Qualifier Type** column is automatically populated for each qualifier value that is
added to the group after the first.

**Qualifier Value** Characters to be matched for the selected qualifier type in incoming work
requests. A qualifier value is required. The qualifier value is case sensitive; for
example, **CDBC*** and **cdbc*** are not the same qualifier value and do not match the
same work requests.
The qualifier value is eight characters long. If the value to be matched contains
fewer than eight characters, you must use the percent sign (%) or the asterisk (*)
as placeholders for the null characters. If you do not use the asterisk at the end of
the value or if you do not insert a percent sign in each null position, the qualifier
value will be padded with blanks to eight characters, and the blanks are used when
making a match.
The percent sign is a placeholder for any single character within a qualifier value.
This allows any character to match the position in the rule. Use a percent sign in
the position where the character would be. You can use multiple percent signs
successively for multiple character replacement. If you specify a percent sign at
the end of a character string, it could match on a null value or a single character.
The asterisk is a placeholder for any number of characters (zero or more) within a
qualifier value. You can use the asterisk as the last position of a character string or
embed it within a string. If the qualifier value contains an asterisk in any position
other than the last, the asterisk is treated as a character to be matched. Otherwise,
the asterisk is treated as a wildcard character.
The following qualifier values are not valid because they always match incoming
work requests of the selected type:

- An asterisk only.
- Eight percent signs only.
- An asterisk in the last position that is preceded by percent signs only.

```
Workload Management task   71
```

```
Table 49. Columns in the Classification Groups table (continued)
```
```
Column Description
```
```
Start Indicates how far to index into the character string for a match for work qualifiers
longer than eight characters. The range of values that you can enter into the
Start field depends on the work qualifier type. For example, for the subsystem
parameter qualifier type, the value can range from 1 - 255. When no start
parameter is specified, WLM matches the name field for work qualifiers according
to the number of characters specified in the Qualifier Value field.
For more information about work qualifiers, see z/OS MVS Planning: Workload
Management.
```
```
Description Description of the classification group. The description is optional. It can contain
up to 32 characters.
```
```
Messages Indicates the highest severity message that has occurred for the entire
classification group or its qualifier values. One of the following message indicators
is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.
To display the qualifier values that have messages, expand the classification group.

```
Last Modified Date and time the item was last modified.
```
```
Modified By User ID of the person who last modified the item.
```
```
Actions for classification groups and qualifier values
The actions are described in the following tables:
```
- Targeted actions for classification groups. Actions that apply to the selected classification groups. To
    use a targeted action, you must select one or more classification groups.
- Targeted actions for qualifier values. Actions that apply to the selected qualifier values. To use actions
    that apply to qualifier values, you must select one or more qualifier values, and you must not select any
    classification groups.
- General actions. Actions that apply to classification groups. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first classification group.

```
Table 50. Targeted actions for classification groups
```
```
Action Description
```
```
Expand Expand the selected parent nodes so that the rows that contain the corresponding
child nodes are visible. This action is listed only when you are displaying the tree
view of the table. To enable this action, you must select one or more rows that
contain parent nodes.
```
**72**   Workload Management task


_Table 50. Targeted actions for classification groups (continued)_

**Action Description**

**Collapse** Collapse the selected parent nodes so that the rows that contain the
corresponding child nodes are hidden. This action is listed only when you are
displaying the tree view of the table. To enable this action, you must select one or
more rows that contain parent nodes.

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only when
you have selected one or more rows. This action is disabled (grayed out) in the
non-tree view of the table if a sort or filter other than the default sort or filter (if
any) has been applied to the table. You cannot cut an item that is being referenced
by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table. You cannot delete an
item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

_Table 51. Targeted actions for qualifier values_

**Action Description**

**New Qualifier Value** Define a new qualifier value. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled when you have selected only one classification group. This
action is disabled (grayed out) in the non-tree view of the table if a sort or filter
other than the default sort or filter (if any) has been applied to the table.

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only when
you have selected one or more rows. This action is disabled (grayed out) in the
non-tree view of the table if a sort or filter other than the default sort or filter (if
any) has been applied to the table. You cannot cut an item that is being referenced
by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Paste Qualifier Values** Insert the qualifier values that were copied to the clipboard into the selected
classification group. This action is listed only in the **New** , **Modify** , and **Copy** tabs,
and it is enabled when you have selected only one classification group. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table.

```
Workload Management task   73
```

```
Table 51. Targeted actions for qualifier values (continued)
```
```
Action Description
```
```
Delete Delete the selected rows. This action is listed only in the New , Modify , and Copy
tabs, and it is enabled only when you have selected one or more rows. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table. You cannot delete an
item that is being referenced by another item.
```
```
View Messages View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.
```
```
Table 52. General actions
```
```
Action Description
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
New Classification Group Define a new classification group. This action is listed only in the New , Modify , and
Copy tabs. This action is disabled (grayed out) in the non-tree view of the table if
a sort or filter other than the default sort or filter (if any) has been applied to the
table.
```
```
Paste Classification
Groups
```
```
Insert the items that were copied to the clipboard into the table. This action is
listed only in the New , Modify , and Copy tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table.
```
```
Table 53. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
**74**   Workload Management task


_Table 53. Table actions (continued)_

**Action Description**

**Switch to Non-Tree View** Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.

**Switch to Tree View** Display the hierarchical view of the table. This action is listed only when you are
displaying the non-tree view of the table.

```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new classification groups
To define a new classification group, use the New Classification Group action provided in the
Classification Groups table in the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Classification Groups** table.
2. From the **Actions** menu, select **New Classification Group**. A new row is added to the table. This action
    is disabled (grayed out) in the non-tree view of the table if a sort or filter other than the default sort or
    filter (if any) has been applied to the table.
3. Specify the appropriate settings. You must:
    a) Provide a name for the classification group that is unique in the service definition.
b) Specify one or more work qualifiers. To specify a work qualifier, you must select the qualifier type
and enter the value to be matched. After you specify the first work qualifier, all of the qualifier
values specified in the group inherit the selected qualifier type.
    For more details, see help topic “Classification Groups” on page 70.
4. Click **OK** or **Apply** to save your changes.

```
Defining new qualifier values
To define a new qualifier value, use the New Qualifier Value action provided in the Classification Groups
table in the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Classification Groups** table.

```
Workload Management task   75
```

2. Select the classification group in which you want to define a new qualifier value. You can select only
    one classification group.
3. From the **Actions** menu or context menu, select **New Qualifier Value**. A new row is added to the table.
    This action is disabled (grayed out) in the non-tree view of the table if a sort or filter other than the
    default sort or filter (if any) has been applied to the table.
4. Enter the qualifier value. A value is required. The qualifier type is inherited from the first work qualifier
    specified in the group.
    For more details, see help topic “Classification Groups” on page 70.
5. Click **OK** or **Apply** to save your changes.

#### Classifications

```
Classification rules are the filters that z/OS Workload Manager (WLM) uses to associate the external
properties of work, also called work qualifiers, with a service class and, optionally, a report class.
Classification rules are organized in a hierarchy, where the first level of each hierarchy is the classification,
also called the subsystem type qualifier. A classification specifies the subsystem type that receives the
work request and contains all of the classification rules for that subsystem. In z/OSMF, with proper
authorization, you can define, view, and modify classifications.
The Classifications table lists all of the subsystem types that are defined in the service definition. For a
description of the columns in the Classifications table, see Table 54 on page 76. For a description of the
actions that you can take against classifications, see “Actions for classifications” on page 77.
For more information about subsystem types and classification rules, see z/OS MVS Planning: Workload
Management.
```
**Columns in the Classifications table**

```
Table 54. Columns in the Classifications table
```
```
Column Description
```
```
Subsystem Type Name of the subsystem. The name is displayed as a hyperlink. When clicked, the
name link opens the Properties for classification page.
```
```
Service Class Name of the default service class for the subsystem type. If a subsystem receives
a work request and none of the classification rules defined for the subsystem type
match the work qualifiers, then the request is assigned to the default service class.
```
```
Report Class Name of the default report class for the subsystem type. If a subsystem receives
a work request and none of the classification rules defined for the subsystem type
match the work qualifiers, then the request is assigned to the default report class.
```
```
Description Description of the classification.
```
```
Messages Indicates the highest severity message that has occurred for the classification or
its rules. One of the following message indicators is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.
To display the classification rules that have messages, display the **Properties for
classification** page.

**76**   Workload Management task


_Table 54. Columns in the Classifications table (continued)_

**Column Description**

**Last Modified** Date and time the item was last modified.

**Modified By** User ID of the person who last modified the item.

```
Actions for classifications
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected classifications. To use a targeted action, you must
    select one or more classifications.
- General actions. Actions that apply to classifications. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first classification.

_Table 55. Targeted actions_

**Action Description**

**Properties** Display additional information about the selected classification. The information
includes, for example, the classification rules defined for the classification. To
enable this action, you must select only one classification.

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

_Table 56. General actions_

**Action Description**

**New** Define a new classification. This action is listed only in the **New** , **Modify** , and **Copy**
tabs.

**Paste** Insert the items that were copied to the clipboard into the table. This action is
listed only in the **New** , **Modify** , and **Copy** tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.

```
Workload Management task   77
```

```
Table 57. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
```
```
Properties for classifications
To display details about a classification such as its name, description, and set of classification rules, you
can use the Properties action provided in the Classifications table in the New , View , Modify , and Copy
tabs.
```
**Procedure**

1. In the **New** , **View** , **Modify** , or **Copy** tab, display the **Classifications** table.
2. Complete one of the following actions:
    - Select the classification for which you want to display the details, and then select **Properties** from
       the **Actions** menu or context menu.
    - Click the subsystem type link that corresponds with the classification for which you want to display
       the details.

```
Results
The properties for the selected classification are displayed.
```
**78**   Workload Management task


```
Defining new classifications
To define a new classification, use the New action provided in the Classifications table in the New ,
Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Classifications** table.
2. From the **Actions** menu, select **New**. The **New Classification** page opens.
3. Specify the appropriate settings. You must:
    a) Select or enter the name of the subsystem type.
b) If you want to assign any of the work requests received in a subsystem to a service class, select a
default service class.
You can also select a default report class or a tenant report class and define one or more classification
rules. For more details, see help topic “New and Properties pages for classifications” on page 79.
4. Click **OK** or **Apply** to save your changes.

```
New and Properties pages for classifications
In z/OSMF, you can use the New Classification page to define a new classification, and you can use the
Properties for classification page to view or modify existing classifications.
The items that are displayed on the New Classification and Properties for classification pages are
described in the following sections:
```
- “Fields on the New and Properties pages for classifications” on page 79
- “Classification rules” on page 80
- “Columns in the Classification Rules table” on page 80
- “Actions for classification rules” on page 83

**Fields on the New and Properties pages for classifications**

_Table 58. Fields on the New and Properties pages for classifications_

**Field Description**

**Subsystem type** Name of the subsystem. This field lists the names of the IBM-supplied subsystems.
You can select a subsystem from the list, or you can enter the name of a new
subsystem. The name can contain up to four characters including alphanumeric
characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \), punctuation marks
(! : " [ ]), and the following special characters: %, $, #, @, ^, and _. The name is
required and must be unique in the service definition. Subsystem names are not
case sensitive; for example, **JES** and **Jes** are the same subsystem.

**Service class** Name of the default service class for the selected subsystem type. If a subsystem
receives a work request and none of the classification rules that are defined for
the subsystem type match the work qualifiers, then the request is assigned to
the default service class. This field lists the names of the service classes that are
defined in the service definition.
If you want to assign any of the work requests received in a subsystem to a service
class, a default service class is required. For the STC subsystem type, however, you
are not required to assign a default service class even if you assign started tasks to
different service classes.
If you want to assign work running in a subsystem to report classes only, then you
are not required to assign a default service class for that subsystem type.

```
Workload Management task   79
```

```
Table 58. Fields on the New and Properties pages for classifications (continued)
```
```
Field Description
```
```
Report class Name of the default report class for the selected subsystem type. If a subsystem
receives a work request and none of the classification rules that are defined for
the subsystem type match the work qualifiers, then the request is assigned to the
default report class. This field lists the names of the report classes that are defined
in the service definition.
```
```
Description Description of the classification. The description is optional. It can contain up to 32
characters.
```
```
Classification rules
Classification rules are typically organized in a nested hierarchy. The top level or container is the
subsystem type or classification. You can define up to four levels of nesting within the classification.
To do so, add rules to the Classification Rules table. The order in which z/OS Workload Manager (WLM)
searches the rules is determined by the order in which you specify the rules. You can use a different
hierarchy for each subsystem type.
When a subsystem receives a work request, WLM uses the work qualifiers to sequentially check for a
match against each level one rule defined within the classification. When it finds a match, it continues
through the level two rules nested within the matching level one rule until it finds a match. WLM continues
searching the levels and the sub-rules of the matching levels until the last matching rule is found. The last
matching rule determines the service class and report class to be assigned.
```
**Columns in the Classification Rules table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 59. Columns in the Classification Rules table
```
```
Column Description
```
```
Qualifier Type Type of work qualifier. A qualifier type is required. This field lists the qualifier types
that are supported by the subsystem. You must select a qualifier type from the list.
If you want a rule to refer to a classification group, you are required to complete
the following steps:
```
1. In the **Qualifier Type** field, select the group qualifier type that is the same as
    the qualifier type of the classification group. For example, if the qualifier type
    of the classification group is **Userid** , you must select **Userid Group** for the
    **Qualifier Type** field.
2. In the **Qualifier Value** field, select the name of the classification group.

**80**   Workload Management task


_Table 59. Columns in the Classification Rules table (continued)_

**Column Description**

**Qualifier Value** Characters to be matched for the selected qualifier type in incoming work
requests. A qualifier value is required. The qualifier value is case-sensitive; for
example, **CDBC*** and **cdbc*** are not the same qualifier value and do not match the
same work requests.
The qualifier value is eight characters long. If the value to be matched contains
fewer than eight characters, you must use the percent sign (%) or the asterisk (*)
as placeholders for the null characters. If you do not use the asterisk at the end of
the value or if you do not insert a percent sign in each null position, the qualifier
value will be padded with blanks to eight characters, and the blanks are used when
making a match.
The percent sign is a placeholder for any single character within a qualifier value.
This allows any character to match the position in the rule. Use a percent sign in
the position where the character would be. You can use multiple percent signs
successively for multiple character replacement. If you specify a percent sign at
the end of a character string, it could match on a null value or a single character.
The asterisk is a placeholder for any number of characters (zero or more) within a
qualifier value. You can use the asterisk as the last position of a character string or
by itself. If the qualifier value contains an asterisk in any position other than the
last, the asterisk is treated as a character to be matched. Otherwise, the asterisk is
treated as a wildcard character.
If you want a rule to refer to a classification group, you are required to complete
the following steps:

1. In the **Qualifier Type** field, select the group qualifier type that is the same as
    the qualifier type of the classification group. For example, if the qualifier type
    of the classification group is **Userid** , you must select **Userid Group** for the
    **Qualifier Type** field.
2. In the **Qualifier Value** field, select the name of the classification group.
    When you select a group qualifier type in the **Qualifier Type** field, the **Qualifier**
    **Value** field lists the names of the classification groups that have been defined
    in the service definition. If the classification group name is fewer than eight
    characters, you do not need to pad the name with the percent sign or the
    asterisk.

**Start** Indicates how far to index into the character string for a match for work qualifiers
longer than eight characters. The range of values that you can enter into the **Start**
field depends on the work qualifier and the subsystem type. For example, for the
subsystem parameter qualifier type, the value can range from 1 - 255 for the DDF
subsystem and it can range from 1 - 47 for the IWEB subsystem. When no start
parameter is specified, WLM matches the name field for work qualifiers according
to the number of characters specified in the qualifier value field.
For more information about work qualifiers, see z/OS MVS Planning: Workload
Management.

**Service class** Name of the service class to which matching work is assigned. This field lists the
names of the service classes that are defined in the service definition. You can
select a service class from the list. If you do not select a service class, the rule
inherits the service class from the higher-level rule; in which case, the service class
name is preceded by the inherited icon ( ).

```
Workload Management task   81
```

```
Table 59. Columns in the Classification Rules table (continued)
```
```
Column Description
```
```
Report class Name of the report class to which matching work is assigned. This field lists the
names of the report classes that are defined in the service definition. You can
select a report class from the list. If you do not select a report class, the rule
inherits the report class from the higher-level rule; in which case, the report class
name is preceded by the inherited icon.
```
```
Storage Critical Indicates whether long-term storage protection should be assigned to the rule.
You are required to select Yes or No. By default, No is selected. If you select
Yes , storage protection is assigned to all address spaces that match the rule. You
can assign storage protection for the following subsystems: ASCH, CICS, IMS, JES,
OMVS, STC, and TSO. To assign storage protection to ASCH, JES, OMVS, STC, and
TSO work, the service class must have only one performance period and have
either a velocity goal or a response time goal of over 20 seconds.
When you assign long-term storage protection to critical work, WLM restricts
storage donations to other work. This option can be useful for work that needs
to retain storage during long periods of inactivity because it cannot afford paging
delays when it becomes active again. With long-term storage protection assigned,
this work loses storage only to other work of equal or greater importance that
needs the storage to meet performance goals.
Note: If the service class that is assigned in this classification rule is associated
with a resource group with a memory limit, the Storage Critical option is
disregarded.
```
```
Reporting Attribute Indicates whether a classification rule infers a special reporting attribute. The
value can be:
None
No special reporting attribute. This is the default.
Mobile
Mobile transaction.
CategoryA
First general purpose subset of work, provided for future use. Use only under
direction of IBM.
CategoryB
Second general purpose subset of work, provided for future use. Use only
under direction of IBM.
Reporting Attribute can be set for all subsystems except user-defined subsystems.
```
```
Goals Used To Manage
Region
```
```
Indicates to which goals a CICS or IMS region is managed. The value can either be
Transaction , Region , or Both. By default, Transaction is selected. If you select
Transaction , the CICS/IMS region is managed to the response time goals of
the transactions that it processes. If you select Region , the CICS/IMS region is
managed to the performance goal of the service class that is assigned to the region
(address space). If you select Both , the region is managed to the performance
goal of the service class assigned to the region, but also a book keeping of all
transaction completions is done so that WLM can still manage CICS service classes
with response time goals. You should only use option Both for CICS TORs. For all
CICS AORs, you should use Transaction.
```
```
Boost Indicates whether shutdownstart and restart of the started task initiates a
Recovery Process (RP) boost. Select Yes or No. By default, No is selected. Yes
can be selected only for the STC subsystem type.
```
**82**   Workload Management task


_Table 59. Columns in the Classification Rules table (continued)_

**Column Description**

**Description** Description of the classification rule. The description is optional. It can contain up
to 32 characters.

**Messages** Indicates the highest severity message that has occurred for the entire rule or its
sub-rules. One of the following message indicators is displayed:

- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.
To display the sub-rules that have messages, expand the higher level rule.

```
Actions for classification rules
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected classification rules. To use a targeted action, you
    must select one or more rules.
- General actions. Actions that apply to classification rules. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first rule.

_Table 60. Targeted actions_

**Action Description**

**Expand** Expand the selected rules so that corresponding sub-rules are visible. To enable
this action, you must select one or more rules.

**Collapse** Collapse the selected rules so that the corresponding sub-rules are hidden. To
enable this action, you must select one or more rules.

**New Rule** Define a new rule. You can insert the new rule before or after the selected rule, or
you can nest it within the selected rule. If you select **New Rule** > **Before** or **New
Rule** > **After** , the new rule is inserted on the same level as the selected rule. For
example, if you select a level two rule, the new rule is inserted as a level two rule.
If you select **New Rule** > **Nested** , the new rule is nested within the selected rule.
For example, if you select a level three rule, the new rule is nested as a level four
rule within the selected level three rule.
This action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled when
you have selected only one rule.

**Cut to Clipboard** Remove the selected rules from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only when
you have selected one or more rules.

**Copy to Clipboard** Copy the selected rules to the clipboard. To enable this action, you must select one
or more rules.

```
Workload Management task   83
```

```
Table 60. Targeted actions (continued)
```
```
Action Description
```
```
Paste Rules Insert the rules that were copied to the clipboard into the table. You can insert the
rules before or after the selected rule, or you can nest them within the selected
rule. If you select Paste Rules > Before or Paste Rules > After , the first level rules
are inserted on the same level as the selected rule and the sub-rules are nested
at the appropriate level to maintain the hierarchy of the rules that you are pasting.
For example, if you select a level two rule and the clipboard contains rules with two
levels of nesting, the top level rule is inserted as a level two rule, the first nested
level is inserted as a level three rule, and the second nested level is inserted as a
level four rule.
If you select Paste Rules > Nested , the process is similar to pasting rules before
and after. The only difference is that the top level rule is inserted as a sub-rule or
child of the selected rule. Then, the remaining rules are nested at the appropriate
level to maintain the hierarchy.
This action is listed only in the New , Modify , and Copy tabs, and it is enabled when
you have selected only one rule.
```
```
Move Rules Move the selected rules up or down one row in the table. This action is listed only
in the New , Modify , and Copy tabs. To enable this action, the following criteria
must be satisfied:
```
- One or more rules must be selected, and the selected rules must be contiguous.
- All of the selected rules must be on the same level.
- All of the selected rules must have the same parent.
You can move the selected rules up or down within the parent rule only.

```
Nest Rules Nest the selected rules in or out one level in the hierarchy. This action is listed
only in the New , Modify , and Copy tabs. To enable the Nest Rules > In action, the
following criteria must be satisfied:
```
- One or more rules must be selected, and the selected rules must be contiguous.
- All of the selected rules must be on the same level. For example, let's say that all
    of the selected rules are level two rules.
- All of the selected rules must have the same parent rule. For example, let's say
    that rule XYZ is the parent of all of the selected rules.
- A rule must immediately precede the selected rules that can become the new
    parent rule. For example, let's say that rule ABC is the level two rule that
    precedes the selected rules; therefore, when you nest in the selected rules, the
    new parent rule is rule ABC.
To enable the **Nest Rules** > **Out** action, the following criteria must be satisfied:
- One or more rules must be selected. The selection does not have to be
    contiguous.
- All of the selected rules must be on the same level.
- All of the selected rules must have the same parent. Using the previous example,
    let's say you nested out the selected rules. In this case, the rules are displayed
    on the same level as rule XYZ.
When you nest a rule in or out, if the rule has sub-rules, the sub-rules are also
nested in or out one level to preserve the hierarchy.

```
Delete Rule Delete the selected rules. This action is listed only in the New , Modify , and Copy
tabs, and it is enabled only when you have selected one or more rules.
```
**84**   Workload Management task


_Table 60. Targeted actions (continued)_

**Action Description**

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

_Table 61. General actions_

**Action Description**

**Expand All** Expand all of the rules in the table so that all of the sub-rules are visible.

**Collapse All** Collapse all of the rules in the table so that all of the sub-rules are hidden.

**New Level One Rule** Define a new level one rule. This action is listed only in the **New** , **Modify** , and **Copy**
tabs.

**Paste Level One Rules** Insert the rules that were copied to the clipboard into the table. The top level rules
are inserted as level one rules and the sub-rules are nested at the appropriate level
to maintain the hierarchy of the rules that you are pasting. This action is listed only
in the **New** , **Modify** , and **Copy** tabs.

_Table 62. Table actions_

**Action Description**

**Select All** Select all of the rows in the table.

**Deselect All** Deselect all of the selected rows in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.

**Show Filter Row** Display the filter row. This action is listed only when the filter row is not displayed
in the table.

**Clear Sorts** Clear the sort from all of the columns in the table.

**Clear Search** Clear the search.

```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
```
```
Workload Management task   85
```

```
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new classification rules
To define a new classification rule, use the New Level One Rule , New Rule > Before , New Rule > After ,
and New Rule > Nested actions provided in the Classification Rules table in the New , Modify , and Copy
tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the properties of the classification for which you want to add
    a new classification rule.
2. Complete one of the following actions:
    - If no rules have been defined for the classification or if you want to define a new level one rule,
       select **New Level One Rule** from the **Actions** menu in the **Classification Rules** table. A new row is
       added to the table.
    - If one or more rules have been defined for the classification, in the **Classification Rules** table,
       select the rule that you want to define a new rule before or after or select the rule in which you want
       to nest a rule, and then select **New Rule** > **Before** , **New Rule** > **After** , or **New Rule** > **Nested** from
       the **Actions** or context menu. If you select **New Rule** > **Before** or **New Rule** > **After** , a new rule is
       inserted on the same level as the selected rule. For example, if you select a level two rule, the new
       rule is inserted as a level two rule.
       If you select **New Rule** > **Nested** , a new rule is nested within the selected rule. For example, if you
       select a level three rule, the new rule is nested as a level four rule within the selected level three
       rule.
3. Specify the appropriate settings. You must:
    a) Select the qualifier type.
b) Specify the qualifier value.
c) Indicate whether long-term storage protection should be assigned to the rule.
d) If you are defining rules for the CICS or IMS subsystem types, indicate how you want z/OS
Workload Manager (WLM) to manage goals in the CICS or IMS region.
    For more details, see help topic “New and Properties pages for classifications” on page 79.
4. Click **OK** or **Apply** to save your changes.

```
Moving classification rules
The order in which z/OS Workload Manager (WLM) searches the rules is determined by the order in which
you specify the rules. To control the order of the rules, you can use the Move Rules > Up and Move Rules
> Down actions provided in the Classification Rules table in the New , Modify , and Copy tabs.
```
**About this task**

```
To enable the move rules actions, the following criteria must be satisfied:
```
- One or more rules must be selected, and the selected rules must be contiguous.
- All of the selected rules must be on the same level.
- All of the selected rules must have the same parent.

**86**   Workload Management task


```
You can move the selected rules up or down within the parent rule only.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the properties of the classification for which you want to
    move one or more classification rules.
2. In the **Classification Rules** table, select the rule that you want to move up or down a row. You can
    select multiple rules.
3. From the **Actions** menu or context menu, select **Move Rules** > **Up** or **Move Rules** > **Down**. The
    selected rule and its sub-rules are moved to the specified position.
4. Click **OK** or **Apply** to save your changes.

```
Nesting classification rules
Classification rules are typically organized in a nested hierarchy. The top level or container is the
subsystem type or classification. You can define up to four levels of nesting within the classification.
z/OS Workload Manager (WLM) searches all of the level one rules, then the matching level two rules, and
so on until it locates the last matching rule. To control the level of each rule within the hierarchy, you can
use the Nest Rules > In and Nest Rules > Out actions provided in the Classification Rules table in the
New , Modify , and Copy tabs.
```
**About this task**

```
To enable the Nest Rules > In action, the following criteria must be satisfied:
```
- One or more rules must be selected, and the selected rules must be contiguous.
- All of the selected rules must be on the same level. For example, let's say that all of the selected rules
    are level two rules.
- All of the selected rules must have the same parent rule. For example, let's say that rule XYZ is the
    parent of all of the selected rules.
- A rule must immediately precede the selected rules that can become the new parent rule. For example,
    let's say that rule ABC is the level two rule that precedes the selected rules; therefore, when you nest in
    the selected rules, the new parent rule is rule ABC.
To enable the **Nest Rules** > **Out** action, the following criteria must be satisfied:
- One or more rules must be selected. The selection does not have to be contiguous.
- All of the selected rules must be on the same level.
- All of the selected rules must have the same parent. Using the previous example, let's say you nested
    out the selected rules. In this case, the rules are displayed on the same level as rule XYZ.

**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the properties of the classification for which you want to nest
    one or more classification rules.
2. In the **Classification Rules** table, select the rule that you want to nest in or out a level in the hierarchy.
    Nesting a rule in a level, for example, moves the rule from level one to level two. Nesting a rule out a
    level, for example, moves the rule from level three to level two. You can select multiple rules.
3. From the **Actions** menu or context menu, select **Nest Rules** > **In** or **Nest Rules** > **Out**. The selected
    rule and its sub-rules are nested in or out one level.
4. Click **OK** or **Apply** to save your changes.

#### Application Environments

```
An application environment is a group of application functions invoked by request and executed in server
address spaces. Each application environment should represent a named group of server functions that
require access to the same application libraries. Grouping server functions helps simplify library security,
```
```
Workload Management task   87
```

```
application program change control, performance management, and system operation. In z/OSMF, with
proper authorization, you can define, view, and modify application environments.
The Application Environments table lists all of the application environments that are defined in the
service definition. For a description of the columns in the Application Environments table, see Table 63
on page 88. For a description of the actions that you can take against application environments, see
“Actions for application environments” on page 90.
For more information about application environments, see z/OS MVS Planning: Workload Management.
```
```
Columns in the Application Environments table
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 63. Columns in the Application Environments table
```
```
Column Description
```
```
Name Name of the application environment. The name can contain up to 32 characters
including alphanumeric characters (A-Z, a-z, and 0-9) and special characters (@
$ # _). The name cannot begin with the characters SYS. The name is required
and must be unique in the service definition. Application environment names are
not case sensitive; for example, AETEST and AETest are the same application
environment.
```
```
Subsystem Type Name of the subsystem associated with the application environment. This field
lists the names of the IBM-supplied subsystems for which you can define
application environments and the names of the last ten subsystems you entered.
You can select a subsystem from the list, or you can enter the name of a new
subsystem. The name can contain up to four characters including alphanumeric
characters (A-Z, a-z, and 0-9), mathematical symbols (| ~ { } \), punctuation marks
(! : " [ ]), and the following special characters: %, $, #, @, ^, and _. The name is
required and must be unique in a service definition. Subsystem names are not case
sensitive; for example, JES and Jes are the same subsystem. The subsystem type
is provided to WLM when the specified subsystem initializes.
```
**88**   Workload Management task


_Table 63. Columns in the Application Environments table (continued)_

**Column Description**

**Limit** Indicates the number of server address spaces that can be started for a subsystem
instance. You are required to select one of the following options:

1. **NoLimit.** Managed by z/OS Workload Manager (WLM).
2. **SingleASPerSystem.** Limited to a single address space per system.
3. **SingleASPerSysplex.** Limited to a single server address space per sysplex.
The options that are valid for a subsystem depend on its scope: single-system or
sysplex. Options 1 and 2 apply when the subsystem type supports single-system
scope. Options 1 and 3 apply when the subsystem type supports sysplex scope.
Managed by WLM for single-system scope means any number of servers can
be created for the subsystem instance on the system where it is connected to
WLM. Managed by WLM for sysplex scope means servers may be created for the
subsystem instance on any number of systems in the sysplex.
For the System Object Model (SOM) subsystem type, the default limit is
**SingleAsPerSysplex**. For all other subsystem types, the default limit is **NoLimit**.

**Procedure Name** Name of the job control language (JCL) procedure you want WLM to use when
starting server address spaces. The name can contain up to eight characters
including alphanumeric characters (A-Z, a-z, and 0-9) and special characters (@
$ # ). The first character must be an alphabetic or special character.
If you want WLM to start and stop server address spaces automatically, enter
the JCL procedure name. If you want to start server address spaces manually or
through automation, leave the **Procedure Name** field blank.
To ensure that an application environment uses the same JCL procedure across the
sysplex, either identical procedure proclibs must be maintained across the sysplex
or all the procedures must be stored in a single, shared proclib.

**Start Parameter** Parameters required for the JCL procedure specified in the **Procedure Name** field.
These parameters define how WLM should start the server address spaces. The
field can contain up to 115 characters. Specify the same parameters that you
would use when starting a server address space with an MVS™ **START** command.
The parameters you specify in the **Start Parameter** field override the parameters
specified in the JCL procedure.
If you specify the variable **&IWMSSNM** , when the subsystem specified in
the Subsystem Type column initializes, WLM replaces the variable with the
subsystem's name. To use the variable, you must include the ampersand character
before the letters IWMSSNM.

**Description** Description of the application environment. The description is optional. It can
contain up to 32 characters.

```
Workload Management task   89
```

```
Table 63. Columns in the Application Environments table (continued)
```
```
Column Description
```
```
Messages Indicates the highest severity message that has occurred for the entire application
environment. This field does not provide an indicator for the attribute-specific
messages (if any). One of the following message indicators is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.

```
Actions for application environments
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected application environments. To use a targeted action,
    you must select one or more application environments.
- General actions. Actions that apply to application environments. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first application environment.

```
Table 64. Targeted actions
```
```
Action Description
```
```
Cut to Clipboard Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the New , Modify , and Copy tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.
```
```
Copy to Clipboard Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.
```
```
Delete Delete the selected rows. This action is listed only in the New , Modify , and Copy
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.
```
```
View Messages View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.
```
```
Table 65. General actions
```
```
Action Description
```
```
New Define a new application environment. This action is listed only in the New , Modify ,
and Copy tabs.
```
**90**   Workload Management task


_Table 65. General actions (continued)_

**Action Description**

**Paste** Insert the items that were copied to the clipboard into the table. This action is
listed only in the **New** , **Modify** , and **Copy** tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.

_Table 66. Table actions_

**Action Description**

**Select All** Select all of the rows in the table.

**Deselect All** Deselect all of the selected rows in the table.

**Configure Columns** Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.

**Hide Filter Row** Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.

**Show Filter Row** Display the filter row. This action is listed only when the filter row is not displayed
in the table.

**Clear Sorts** Clear the sort from all of the columns in the table.

**Clear Search** Clear the search.

```
Related tasks
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new application environments
To define a new application environment, use the New action provided in the Application Environments
table in the New , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Application Environments** table.
2. From the **Actions** menu, select **New**. A new row is added to the table.
3. Specify the appropriate settings. You must:
    a) Provide a name for the application environment that is unique in the service definition.

```
Workload Management task   91
```

```
b) Enter or select the subsystem type.
c) Indicate whether you want WLM to manage the number of servers or whether you want to limit the
number of servers that can be created for a subsystem instance.
d) If you want WLM to manage the number of servers, enter the name of the JCL start procedure.
e) If you entered a procedure name and the procedure requires parameters to be entered when you
issue the MVS START command, enter those parameters in the Start Parameter column.
For more details, see help topic “Application Environments” on page 87.
```
4. Click **OK** or **Apply** to save your changes.

#### Resources

```
A resource represents the potential availability of a resource on a z/OS system. That resource can be
an actual physical entity such as a data base or a peripheral device or it can be an intangible quality
such as a certain time of day or a certain day of the week. The resource names are abstract and have no
inherent meaning. In z/OSMF, with proper authorization, you can define, view, and modify resources and
add resources to scheduling environments.
You can define up to 999 unique resources in a service definition. A resource can be associated
with multiple scheduling environments. To add a resource to a scheduling environment, switch to the
Scheduling Environments section.
The Resources table lists all of the resources that are defined in the service definition. For a description of
the columns in the Resources table, see Table 67 on page 92. For a description of the actions that you
can take against resources, see “Actions for resources” on page 93.
For more information about resources, see z/OS MVS Planning: Workload Management.
```
**Columns in the Resources table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 67. Columns in the Resources table
```
```
Column Description
```
```
Name Name of the resource. The name can contain up to 16 characters including
alphanumeric characters (A-Z, a-z, and 0-9) and special characters (@ $ # _).
The name cannot begin with the characters SYS_. The name is required and must
be unique in the service definition. Resource names are not case sensitive; for
example, RESDB2 and ResDB2 are the same resource.
```
```
Description Description of the resource. The description is optional. It can contain up to 32
characters.
```
**92**   Workload Management task


_Table 67. Columns in the Resources table (continued)_

**Column Description**

**Messages** Indicates the highest severity message that has occurred for the entire resource.
This field does not provide an indicator for the attribute-specific messages (if any).
One of the following message indicators is displayed:

- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.

```
Actions for resources
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected resources. To use a targeted action, you must select
    one or more resources.
- General actions. Actions that apply to resources. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first resource.

_Table 68. Targeted actions_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only
when you have selected one or more rows. You cannot cut an item that is being
referenced by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. You cannot
delete an item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

_Table 69. General actions_

**Action Description**

**New** Define a new resource. This action is listed only in the **New** , **Modify** , and **Copy** tabs.

```
Workload Management task   93
```

```
Table 69. General actions (continued)
```
```
Action Description
```
```
Paste Insert the items that were copied to the clipboard into the table. This action is
listed only in the New , Modify , and Copy tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted.
```
```
Table 70. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Notes window
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
Tips window
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
```
Defining new resources
To define a new resource, use the New action provided in the Resources table in the New , Modify , and
Copy tabs.
```
**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Resources** table.

**94**   Workload Management task


2. From the **Actions** menu, select **New**. A new row is added to the table.
3. Enter the name of the resource. The name can contain up to 16 characters including alphanumeric
    characters (A-Z, a-z, and 0-9) and special characters (@ $ # _). The name cannot begin with the
    characters **SYS_**. The name is required and must be unique in the service definition. Resource names
    are not case sensitive; for example, **RESDB2** and **ResDB2** are the same resource.
4. Enter a description of the resource. The description is optional. It can contain up to 32 characters.
5. Click **OK** or **Apply** to save your changes.

#### Scheduling Environments

```
A scheduling environment is a list of resource names along with their required states. By associating
incoming work with a scheduling environment, you ensure that work is assigned to a z/OS image only if
that image satisfies all of the resource state requirements. In z/OSMF, with proper authorization, you can
define, view, and modify scheduling environments and add resources to scheduling environments.
You can define up to 999 unique scheduling environments. A scheduling environment can contain
multiple resources and a resource can belong to multiple scheduling environments. To add a resource
to a scheduling environment, the resource must be predefined in the Resources section.
The Scheduling Environments table lists all of the scheduling environments that are defined in the
service definition. For a description of the columns in the Scheduling Environments table, see Table 71
on page 95. For a description of the actions that you can take against scheduling environments and
resources, see “Actions for scheduling environments and resources” on page 96.
For more information about scheduling environments, see z/OS MVS Planning: Workload Management.
```
**Columns in the Scheduling Environments table**

```
If messages exist for a specific attribute, one of the following status icons is displayed in the table cell of
the attribute for which the message was created:
```
- An information message exists.
- A warning message exists.
- An error message exists.
To display the message or help for the message, with focus on the cell that contains the status icon, press
Ctrl+M (message) or press Ctrl+Q (message help). To display the message, you can also click the status
icon ( **View** tab) or press the Ctrl key and click the status icon ( **New** , **Modify** , and **Copy** tabs).

```
Table 71. Columns in the Scheduling Environments table
```
```
Column Description
```
```
Name Name of the scheduling environment. The name can contain up to 16 characters
including alphanumeric characters (A-Z, a-z, and 0-9) and special characters (@
$ # _). The name cannot begin with the characters SYS_. The name is required
and must be unique in the service definition. Scheduling environment names are
not case sensitive; for example, SETEST and SETest are the same scheduling
environment.
```
```
Resource Name Name of the resource. A resource name is required. This field lists the resources
that are defined in the Resources section of the service definition. You must select
a resource from the list.
```
```
Required State State the selected resource must have on a z/OS image for the work associated
with the scheduling environment to be assigned to that image. You must select
either On or Off. The default required state is Off.
```
```
Description Description of the scheduling environment. The description is optional. It can
contain up to 32 characters.
```
```
Workload Management task   95
```

```
Table 71. Columns in the Scheduling Environments table (continued)
```
```
Column Description
```
```
Messages Indicates the highest severity message that has occurred for the entire scheduling
environment or its resources. One of the following message indicators is displayed:
```
- **Blank.** No messages exist.
- **Information.** Information messages exist.
- **Warning.** Warning messages exist. Information messages might also exist.
- **Error.** Error messages exist. Information and warning messages might also exist.
To display the messages, you can click the link or status icon, or you can select
the cell that contains the link or icon and press Ctrl+M. You can also select the
corresponding item and select **View Messages** from the **Actions** menu or context
menu. A window is displayed that lists the messages.
To display the resources that have messages, expand the scheduling environment.

```
Actions for scheduling environments and resources
The actions are described in the following tables:
```
- Targeted actions for scheduling environments. Actions that apply to the selected scheduling
    environments. To use a targeted action, you must select one or more scheduling environments.
- Targeted actions for resources. Actions that apply to the selected resources. To use actions that
    apply to resources, you must select one or more resources, and you must not select any scheduling
    environments.
- General actions. Actions that apply to scheduling environments. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.
Except where noted, the actions are available in the **New** , **View** , **Modify** , and **Copy** tabs. A limited set of
actions is available until you create the first scheduling environment.

```
Table 72. Targeted actions for scheduling environments
```
```
Action Description
```
```
Expand Expand the selected parent nodes so that the rows that contain the corresponding
child nodes are visible. This action is listed only when you are displaying the tree
view of the table. To enable this action, you must select one or more rows that
contain parent nodes.
```
```
Collapse Collapse the selected parent nodes so that the rows that contain the
corresponding child nodes are hidden. This action is listed only when you are
displaying the tree view of the table. To enable this action, you must select one or
more rows that contain parent nodes.
```
```
Add Resource Add a resource to the scheduling environment. The resource to be added must
be predefined in the Resources table. This action is listed only in the New ,
Modify , and Copy tabs. To enable this action, you must select only one scheduling
environment. This action is disabled (grayed out) in the non-tree view of the table
if a sort or filter other than the default sort or filter (if any) has been applied to the
table.
```
**96**   Workload Management task


_Table 72. Targeted actions for scheduling environments (continued)_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only when
you have selected one or more rows. This action is disabled (grayed out) in the
non-tree view of the table if a sort or filter other than the default sort or filter (if
any) has been applied to the table. You cannot cut an item that is being referenced
by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Paste Resources** Insert the items that were copied to the clipboard into the table. This action is
listed only in the **New** , **Modify** , and **Copy** tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table. You cannot delete an
item that is being referenced by another item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

_Table 73. Targeted actions for resources_

**Action Description**

**Cut to Clipboard** Remove the selected rows from the table and copy them to the clipboard. This
action is listed only in the **New** , **Modify** , and **Copy** tabs, and it is enabled only when
you have selected one or more rows. This action is disabled (grayed out) in the
non-tree view of the table if a sort or filter other than the default sort or filter (if
any) has been applied to the table. You cannot cut an item that is being referenced
by another item.

**Copy to Clipboard** Copy the selected rows to the clipboard. To enable this action, you must select one
or more rows.

**Delete** Delete the selected rows. This action is listed only in the **New** , **Modify** , and **Copy**
tabs, and it is enabled only when you have selected one or more rows. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table. You cannot delete an
item that is being referenced by another item.

**View Cross-References** View the items that reference or are referenced by the selected item. To enable
this action, you must select only one item. If the action is disabled (grayed out),
there might not be any cross-references for the selected item.

**View Messages** View the messages that exist for the selected item. To enable this action, you must
select only one item. If the action is disabled (grayed out), there might not be any
messages for the selected item.

```
Workload Management task   97
```

```
Table 74. General actions
```
```
Action Description
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
New Scheduling
Environment
```
```
Define a new scheduling environment. This action is listed only in the New , Modify ,
and Copy tabs. This action is disabled (grayed out) in the non-tree view of the table
if a sort or filter other than the default sort or filter (if any) has been applied to the
table.
```
```
Paste Scheduling
Environments
```
```
Insert the items that were copied to the clipboard into the table. This action is
listed only in the New , Modify , and Copy tabs. The items being pasted must be of
the same type as the items contained in the table into which they are being pasted.
The items are inserted according to the sort and filter criteria specified. If an item
to be pasted duplicates the name of an item contained in the table, an underscore
(_) and a number are appended to the name of the item being pasted. This action
is disabled (grayed out) in the non-tree view of the table if a sort or filter other than
the default sort or filter (if any) has been applied to the table.
```
```
Table 75. Table actions
```
```
Action Description
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
```
Switch to Tree View Display the hierarchical view of the table. This action is listed only when you are
displaying the non-tree view of the table.
```
```
Related tasks
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
Viewing messages for service definition items
```
**98**   Workload Management task


To view the messages that exist for a specific service definition item, you can use the **View Messages**
action provided in the **New** , **View** , **Modify** , and **Copy** tabs.

**Related reference**

Notes window
You can use the **Notes** window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.

Tips window

The **Tips** window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the **Tips** window, click the
tips icon. If the icon is not displayed, no tips are available for the item.

**Defining new scheduling environments**

To define a new scheduling environment, use the **New Scheduling Environment** action provided in the
**Scheduling Environments** table in the **New** , **Modify** , and **Copy** tabs.

**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Scheduling Environments** table.
2. From the **Actions** menu, select **New Scheduling Environment**. A new row is added to the table. This
    action is disabled (grayed out) in the non-tree view of the table if a sort or filter other than the default
    sort or filter (if any) has been applied to the table.
3. Specify the appropriate settings. You must:
    a) Provide a name for the scheduling environment that is unique in the service definition.
b) Add one or more resources to the scheduling environment. For each resource, you must indicate its
name and required state.
    For more details, see help topic “Scheduling Environments” on page 95.
4. Click **OK** or **Apply** to save your changes.

**Adding resources to scheduling environments**

To add a resource to a scheduling environment, use the **Add Resource** action provided in the **Scheduling
Environments** table in the **New** , **Modify** , and **Copy** tabs.

**Procedure**

1. In the **New** , **Modify** , or **Copy** tab, display the **Scheduling Environments** table.
2. Select the scheduling environment to which you want to add a resource. You can select only one
    scheduling environment.
3. From the **Actions** menu or context menu, select **Add Resource**. A new row is added to the table. This
    action is disabled (grayed out) in the non-tree view of the table if a sort or filter other than the default
    sort or filter (if any) has been applied to the table.
4. Specify the appropriate settings. You must:
    a) Select a resource.
b) Indicate the required state of the resource.
    For more details, see help topic “Scheduling Environments” on page 95.
5. Click **OK** or **Apply** to save your changes.

```
Workload Management task   99
```

#### Apply service class overrides

```
A list of all the service classes contained in the service definition where the overrides specified in the
selected service policy are reflected in the corresponding service classes. You can select a service policy
and apply its service class overrides to the base definitions and display an overview of the changed
values.
By default, the service policy to be applied is omitted. All of the service classes contained in the service
definition are displayed in the Apply Service Class Overrides table.
To apply the service class overrides specified in a selected service policy in the Apply Service Class
Overrides table, from the Actions menu or the context menu, select Apply Service Policy , and then
select a service policy. Hover over the tips icon ( ) near the changed value to display what the base value
is.
The table contains the same columns that are included in the Service Classes table and allows similar
actions with a few exceptions:
```
- You are only allowed to view the service classes or service class overrides in the **Apply Service Class**
    **Overrides** table. To define, modify, and delete service classes or service class overrides, switch to the
    **Service Classes** table or the **Service Class Overrides** table.
For more details about the columns in the **Apply Service Class Overrides** table and the actions you can
take against service classes or service class overrides, see “Service Classes” on page 55.
Related tasks
“Viewing cross-references” on page 105
To view the items in a service definition that reference or are referenced by a specific item, you can use
the **View Cross-References** action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
“Viewing messages for service definition items” on page 36
To view the messages that exist for a specific service definition item, you can use the **View Messages**
action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
Related reference
“Service Classes” on page 55
A **service class** is a named group of work within a workload with similar performance goals, resource
requirements, or business importance. In z/OSMF, with proper authorization, you can define, view, and
modify service classes and assign service classes to a workload and, optionally, to a resource group.
“New and Properties pages for service policies” on page 37
In z/OSMF, you can use the **New Service Policy** page to define a new service policy, and you can use the
**Properties for service policy** page to view or modify existing service policies.

#### Apply resource group overrides

```
A list of all the resource groups contained in the service definition where the overrides specified in the
selected service policy are reflected in the corresponding resource groups. You can select a service policy
and apply its resource group overrides to the base definitions and display an overview of the changed
values.
By default, the service policy to be applied is omitted. All of the resource groups contained in the service
definition are displayed in the Apply Resource Group Overrides table.
To apply the resource group overrides specified in a selected service policy in the Apply Resource Group
Overrides table, from the Actions menu or the context menu, select Apply Service Policy , and then
select a service policy. Hover over the tips icon ( ) near the changed value to display what the base value
is.
The table contains the same columns that are included in the Resource Groups table and allows similar
actions with a few exceptions:
```
**100**   Workload Management task


- You are only allowed to view the resource group or resource group overrides in the **Apply Resource**
    **Group Overrides** table. To define, modify, and delete the resource group or resource group overrides,
    switch to the **Resource Group** table or the **Resource Group Overrides** table.
For more details about the columns in the **Apply Resource Group Overrides** table and the actions you
can take against resource groups or resource group overrides, see “Resource Groups” on page 46.
Related tasks
“Viewing cross-references” on page 105
To view the items in a service definition that reference or are referenced by a specific item, you can use
the **View Cross-References** action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
“Viewing messages for service definition items” on page 36
To view the messages that exist for a specific service definition item, you can use the **View Messages**
action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
Related reference
“Resource Groups” on page 46
A **resource group** defines the minimum and maximum amount of processing capacity that is available to
the service classes contained in that group. In z/OSMF, with proper authorization, you can define, view,
and modify resource groups and assign service classes to a resource group.
“New and Properties pages for service policies” on page 37
In z/OSMF, you can use the **New Service Policy** page to define a new service policy, and you can use the
**Properties for service policy** page to view or modify existing service policies.

#### Apply tenant resource group overrides

```
A list of all the tenant resource groups contained in the service definition where the overrides specified
in the selected service policy are reflected in the corresponding tenant resource groups. You can select
a service policy and apply its tenant resource group overrides to the base definitions and display an
overview of the changed values.
By default, the service policy to be applied is omitted. All of the tenant resource groups contained in the
service definition are displayed in the Apply Tenant Resource Group Overrides table.
To apply the tenant resource group overrides specified in a selected service policy in the Apply Resource
Group Overrides table, from the Actions menu or the context menu, select Apply Service Policy , and
then select a service policy. Hover over the tips icon ( ) near the changed value to display what the base
value is.
The table contains the same columns that are included in the Tenant Resource Groups table and allows
similar actions with a few exceptions:
```
- You are only allowed to view the tenant resource group or tenant resource group overrides in the **Apply**
    **Tenant Resource Group Overrides** table. To define, modify, and delete the tenant resource group or
    tenant resource group overrides, switch to the **Tenant Resource Group** table or the **Tenant Resource**
    **Group Overrides** table.
For more details about the columns in the **Apply Tenant Resource Group Overrides** table and the actions
you can take against tenant resource groups or tenant resource group overrides, see “Tenant Resource
Groups” on page 50.
Related tasks
“Viewing cross-references” on page 105
To view the items in a service definition that reference or are referenced by a specific item, you can use
the **View Cross-References** action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
“Viewing messages for service definition items” on page 36
To view the messages that exist for a specific service definition item, you can use the **View Messages**
action provided in the **New** , **View** , **Modify** , and **Copy** tabs.
Related reference
“Tenant Resource Groups” on page 50

```
Workload Management task   101
```

```
A tenant resource group is a group of work for which you want common metering and reporting, and
optional capacity boundaries that are intended for work that is associated through tenant report classes.
In z/OSMF, with proper authorization, you can define, view, and modify tenant resource groups and assign
tenant service classes to a tenant resource group. In z/OSMF with proper authorization, you can define,
view, and modify tenant resource groups and assign service classes to a tenant resource group.
“New and Properties pages for service policies” on page 37
In z/OSMF, you can use the New Service Policy page to define a new service policy, and you can use the
Properties for service policy page to view or modify existing service policies.
```
#### Messages

```
The service definition message log lists all of the messages that exist for a service definition. You can use
the log to easily navigate to service definition items that have messages.
In the View tab, the message log lists the messages that exist for the version of the service definition
that is listed in the Service Definitions table. In the New , Modify , and Copy tabs, the message log lists
the messages that exist for your working copy of the service definition. If you are working with a service
definition in a View and a Modify tab, the message logs might list different messages because the log in
the View tab is not updated until you complete the following actions:
```
- In the **Modify** tab, save your changes, and then close the tab.
- Close and reopen the **View** tab and display the **Messages** table.
For a description of the columns in the **Messages** table, see Table 76 on page 102. For a description of the
actions listed in the **Actions** menu, see Table 77 on page 102.
In the **Workload Management** task, you can use the **Settings** tab to suppress information messages that
indicate that an action completed. Doing so does not suppress the messages that are displayed in the log
because those messages cannot be suppressed. For more details, see help topic “Settings tab” on page
118.

**Columns in the Messages table**

```
Table 76. Columns in the Messages table
```
```
Column Description
```
```
Message ID Identifier for the message. To display the help for the message, you can click the
status icon or message ID link. With focus on the cell, you can also press Ctrl+Q or
Enter to display the help.
```
```
Message Text Text of the message.
```
```
Service Definition Item Service definition item for which the message occurred. To navigate to the item,
click the item link. With focus on the cell, you can also press Enter to navigate to
the item.
```
**Actions for messages**

```
Table 77. Table actions
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
**102**   Workload Management task


```
Table 77. Table actions (continued)
```
```
Action Description
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Related concepts
Comments for service definition actions
Comments that you provide when taking actions against service definitions help to describe the actions.
Related tasks
Viewing messages for service definitions
To view the messages that exist for a service definition, you can use the View Messages action provided
in the Service Definitions tab or you can select Messages from the Switch To menu in the New , View ,
Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Settings tab
You can use the Settings tab in the Workload Management task to specify how long to keep the service
definition history, to define the code page, time zone, and backup sequential data set for the sysplex, to
enable or disable the service definition and service policy consistency checking feature, and to display or
suppress information messages.
```
#### Analysis messages

```
A list of the analysis messages coming from the Policy Advisor view. This section is listed only when you
are navigating back to the Workload Management task from the opened Policy Advisor view to view the
definition of the target element.
The table contains the same columns that are included in the Messages table and allows similar actions.
For more details, see “Messages” on page 102.
Related concepts
“Policy Advisor” on page 122
The Policy Advisor view provides support to analyze a WLM service definition that has collected SMF
performance measurements while your service policy was active. It presents miscellaneous graphics
which compare your definition with actual performance data and gives advice on potential improvements
for unfavorable goal settings.
Related reference
“Messages” on page 102
The service definition message log lists all of the messages that exist for a service definition. You can use
the log to easily navigate to service definition items that have messages.
```
#### Notes window

```
You can use the Notes window to document additional information about the service definition. For
example, when you modify a service definition, you might want to document what change was made and
why.
If you display the Notes window within the View tab, you can only view the notes. If you display the
window within the New , Modify , or Copy tab, you can modify the notes.
```
```
Workload Management task   103
```

```
The Notes window can contain up to 1000 lines with up to 80 characters per line for a total of 80,000
characters. If you paste information into the window that exceeds the maximum number of characters or
lines, you must reduce the number of characters or lines before you can save and close the window.
```
#### Cross-References

```
In the New , View , Modify , and Copy tabs, many of the items in the service definition refer to or are
referenced by other items. You can use the View Cross-References action to navigate to the items that
reference or are referenced by an item. The following table lists the items that can reference or be
referenced by each item in the service definition.
```
```
Table 78. Cross-References by Item
```
```
Item Cross-References
```
```
Service Definition Details None
```
```
Service Policies and
Overrides
```
```
Cross-references do not exist between items and an entire service policy. Cross-
references do, however, exist between service class overrides or resource group
overrides and other items in the service definition.
Cross-references can exist between service class overrides and the following
items:
```
- Service Classes
- Resource Groups
Cross-references can exist between resource groups and resource group overrides.

```
Workloads Service Classes
```
```
Service Classes • Workloads
```
- Resource Groups
- Service Class Overrides
- Classifications
- Classification Rules

```
Resource Groups • Service Classes
```
- Resource Group Overrides
- Service Class Overrides

```
Report Classes • Classifications
```
- Classification Rules

```
Classification Groups Classification Rules
```
```
Classifications and Rules Cross-references can exist between classifications and the following items:
```
- Report Classes
- Service Classes
Cross-references can exist between classification rules and the following items:
- Report Classes
- Service Classes
- Classification Groups

```
Application
Environments
```
```
None
```
**104**   Workload Management task


```
Table 78. Cross-References by Item (continued)
```
```
Item Cross-References
```
```
Resources Scheduling Environments
```
```
Scheduling Environments Resources. Scheduling environments contain a list of resources and the required
state of those resources. The resources that are contained within the scheduling
environment reference resources that have been defined in the service definition.
```
```
Viewing cross-references
To view the items in a service definition that reference or are referenced by a specific item, you can use
the View Cross-References action provided in the New , View , Modify , and Copy tabs.
```
**Procedure**

1. In the **New** , **View** , **Modify** , or **Copy** tab, display the section in the service definition that contains the
    item for which you want to view cross-references.
2. In the table, select the item. You can select only one item. From the **Actions** menu or context menu,
    select **View Cross-References** , and then select the item to which you want to navigate.
    The **View Cross-References** submenu lists the items that reference or are referenced by the selected
    item. The menu lists the type of item and the name of the specific item that cross-references the
    selected item. For example, if you select this action in the **Service Classes** table, **Workload WKJES**
    might be listed. This means that a workload with the name **WKJES** is referenced by the selected
    service class.

```
Results
The selected cross-reference is displayed.
```
#### Tips window

```
The Tips window displays hints or instructions related to the item near or in which the tips icon ( ) is
displayed. For example, if the icon is displayed in the table toolbar, the tips can include information about
how to enable an editable cell so that you can modify its contents. To display the Tips window, click the
tips icon. If the icon is not displayed, no tips are available for the item.
```
### Install and Activate tab

```
You can use the Install and Activate tab in the Workload Management task in IBM z/OS Management
Facility (z/OSMF) to complete the steps in the Install and Activate wizard. With the wizard, you can install
a service definition into the z/OS Workload Manager (WLM) couple data set and, optionally, activate a
service policy. This topic describes the pages that are displayed in the wizard.
Related tasks
Activating service policies
To activate a service policy, you can use the Activate action provided in the Service Policies table in the
Service Policies for sysplex tab.
Installing service definitions
```
```
Workload Management task   105
```

```
To install a service definition into the z/OS Workload Manager (WLM) couple data set for the sysplex and,
optionally, activate a service policy, you can use the Install and Activate action provided in the Service
Definitions tab.
```
#### Welcome page

```
On the Welcome page in the Install and Activate wizard, verify that the service definition to be installed
is correct.
Table 79 on page 106 lists and describes the fields that are included on the page.
```
```
Table 79. Fields on the Welcome page
```
```
Field Description
```
```
Current installed service
definition
```
```
Name, description, and modification details for the service definition currently
installed in the z/OS Workload Manager (WLM) couple data set. The modification
details includes the date and time the service definition was last modified and the
user ID of the user who last modified the service definition, as well as comments
describing that modification.
```
```
Service definition to be
installed
```
```
Name, description, and modification details for the service definition selected to
be installed in the WLM couple data set. The modification details includes the
date and time the service definition was last modified and the user ID of the
user who last modified the service definition, as well as comments describing that
modification.
```
```
Comments Comments for the install operation. Comments are recorded in the service
definition history.
Depending on your settings, comments may be required.
If there are comments from the previous modification, you can import them using
Import.
```
```
Import Import comments from the most recent modification of the service definition to be
installed. This is unavailable if no comments exist.
```
#### Select a Service Policy page

```
On the Select a Service Policy page in the Install and Activate wizard, select the service policy to be
activated.
Table 80 on page 106 lists and describes the fields that are included on the page.
```
```
Table 80. Fields on the Select a Service Policy page
```
```
Field Description
```
```
Current active service
policy
```
```
Name of the service policy currently active in the sysplex. The name and
description of the service definition in which the service policy is defined is also
provided.
```
```
Service policy to be
activated
```
```
List of the service policies defined in the service definition to be installed. If you do
not want to activate a service policy, select Do not activate a new service policy.
In this case, the service definition is installed, but z/OS Workload Manager (WLM)
continues to use the current active service policy to manage the workloads.
```
```
Comments for this
activation
```
```
Comments for the activation operation. Comments are recorded in the service
definition history.
Depending on your settings, comments may be required.
```
**106**   Workload Management task


#### Install and Activate page

```
On the Install and Activate page in the Install and Activate wizard, verify that the service definition to
be installed and the service policy to be activated are correct. When you click Finish , the current installed
service definition and active policy are replaced with the selected service definition and policy.
Table 81 on page 107 lists and describes the fields that are included on the page.
```
```
Table 81. Fields on the Install and Activate page
```
```
Field Description
```
```
Current installed service
definition and active
policy
```
```
Lists details about the current installed service definition and active policy. Details
include the name of the sysplex; the name, description, and modification details
for the installed service definition; and the name of the active service policy. The
modification details includes the date and time the service definition was last
modified and the user ID of the user who last modified the service definition.
```
```
Replace with Lists details about the service definition to be installed and the service policy
to be activated. Details include the name of the sysplex; the name, description,
and modification details for the service definition to be installed; and the name
of service policy to be activated. The modification details includes the date and
time the service definition was last modified and the user ID of the user who last
modified the service definition. If you selected Do not activate a new service
policy , the value in the Service Policy column is Use current active policy.
```
```
Comments for this
installation
```
```
Comments for the install operation. Comments are recorded in the service
definition history.
Depending on your settings, comments may be required.
```
```
Comments for this
activation
```
```
Comments for the activation operation. Comments are recorded in the service
definition history.
Depending on your settings, comments may be required.
```
### Print Preview tab

```
You can use the Print Preview tab in the Workload Management task in IBM z/OS Management Facility
(z/OSMF) to preview an HTML formatted version of a service definition or a service policy before printing
it.
When you preview a service definition or a service policy, all of the items defined within the service
definition or policy are displayed in HTML format using a nested table structure. The nested table
structure shows which items are contained within or are used by other items. For example, information
about a service class is displayed within the corresponding workload in the Workloads section.
The HTML formatted service policy is similar to the HTML formatted service definition except in how
service policy information is displayed. In the formatted service definition, the Service Policies section
lists all of the service policies defined within the service definition. In the formatted service policy,
however, the Service Policies section is omitted and the overrides specified in the selected service policy
are reflected in the corresponding service classes and resource groups. The HTML formatted service
policy contains the information that would be included in the policy if it were activated.
To switch between previewing the formatted service definition and its formatted service policies, use the
Switch To menu.
To customize the items that are displayed in the Print Preview tab, click the Filter link that is displayed in
the top right corner of the tab. A window opens. Select which items you want to display within the tab.
To print the items that are displayed in the Print Preview tab, click the Print link that is displayed in the
top right corner of the tab. A new browser window opens and displays only the items that are shown in the
Print Preview tab. Use the browser print function to print the displayed items.
```
```
Workload Management task   107
```

```
Related tasks
Printing service definitions
To print an HTML formatted version of the entire service definition or of parts of the service definition, you
can use the Print Preview action provided in the Service Definitions tab.
Printing service policies
To print an HTML formatted version of a service policy with overrides applied, you can use the Print
Preview action provided in the Service Policies table in the Service Policies for sysplex tab.
```
#### Print Preview Filter window

```
You can use the Print Preview Filter window to specify which items of the service definition or service
policy you want to display in the Print Preview tab.
Table 82 on page 108 lists and describes the fields that are included in the window.
```
```
Table 82. Fields in the Print Preview Filter window
```
```
Field Description
```
```
Display All To display the entire service definition or service policy, the notes, and the
messages, select this option.
```
```
Display Selection To select the items to be displayed, select this option, and then select the items.
You can select multiple items.
```
```
Do you want to include
the description and
modification details for
the service definition
items?
```
```
For the selected items, if you want to display the description of each item, the
last date and time the item was modified, and the user ID of the person who last
modified the item, select Yes.
```
### Service Policies for sysplex tab

```
You can use the Service Policies for sysplex tab in the Workload Management task in IBM z/OS
Management Facility (z/OSMF) to activate and print service policies that are defined in the service
definition that is installed in the z/OS Workload Manager (WLM) couple data set.
The items displayed in the Service Policies for sysplex tab are described in the following sections:
```
- “Fields in the Service Policies for sysplex tab” on page 108
- “Columns in the Service Policies table” on page 109
- “Actions for service policies” on page 109
For more information about service policies, see help topic “Service Policies” on page 32.

**Fields in the Service Policies for sysplex tab**

```
Table 83. Fields in the Service Policies for sysplex tab
```
```
Field Description
```
```
Installed service
definition
```
```
Name of the service definition that is installed in the WLM couple data set.
```
```
Description Description of the installed service definition.
```
**108**   Workload Management task


**Columns in the Service Policies table**

_Table 84. Columns in the Service Policies table_

**Column Description**

**Name** Name of the service policy. If the z/OSMF role to which your user ID is assigned is
authorized to view service definitions, the name is displayed as a hyperlink. When
clicked, the name link opens the installed service definition in a **View** tab and
displays the properties for the selected service policy.
If your installation is using other tools or products, such as the WLM Administrative
Application, to manage your service definitions and policies, z/OSMF might not
accurately identify the service policy that is active in the sysplex.

**Activation Status** Indicates the activation status of the service policy. The service policy can have
one of the following status:

- **Blank.** The service policy is not active and is not being activated.
- **Active.** The service policy is active on all of the systems in the sysplex.
- **Not Activated on All.** The service policy is not active on all of the systems in the
    sysplex.
- **Activation in Progress.** The service policy is currently being activated in the
    sysplex.
- **Unknown.** z/OSMF is unable to determine the activation status of the service
    policy.

**Description** Description of the service policy.

**Last Modified** Date and time the item was last modified.

**Modified By** User ID of the person who last modified the item.

**Actions for service policies**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected service policy. To use a targeted action, you must
    select only one service policy.
- Table 86 on page 110. Actions that apply to workloads. No selection is required.
- Table actions. Actions that apply to the entire table. No selection is required.

_Table 85. Targeted actions_

**Action Description**

**Activate** Activate the selected service policy. If the action is not listed, the z/OSMF role to
which your user ID is assigned might not be authorized to activate service policies.
To obtain authorization, contact your z/OSMF administrator.

**Properties** Display details about the selected service policy such as its name, description,
service class overrides, and resource group overrides. To enable this action, you
must select only one service policy. When you select this action, the installed
service definition is displayed in a **View** tab and the properties for the selected
service policy are shown.

**Print Preview** Preview an HTML formatted version of the service policy with overrides applied
before printing it. Select which items to preview or print. To enable this action, you
must select only one service policy.

```
Workload Management task   109
```

```
Table 86. General actions
```
```
Action Description
```
```
View Performance of
Active Policy
```
```
View the performance of the active policy. If the action is disabled (grayed out),
performance data is not available because non of the service policies is active. If
the action is not displayed in the menu, a provider of appropriate performance data
is not available.
```
```
Table 87. Table actions
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
#### Activating service policies

```
To activate a service policy, you can use the Activate action provided in the Service Policies table in the
Service Policies for sysplex tab.
```
```
Before you begin
The service definition that contains the service policy that you want to activate must be installed in the
z/OS Workload Manager (WLM) couple data set. If you want to activate a service policy when you install a
service definition, use the Install and Activate wizard. For more details, see help topic “Installing service
definitions” on page 15.
The z/OSMF role to which your user ID is assigned must be authorized to activate service policies.
```
**Procedure**

1. Select the **Workload Management task** under the Performance category in the navigation area. The
    **Workload Management** page opens.
2. In the **Overview** tab, click **Service Policies for Sysplex**. The **Service Policies for Sysplex** tab opens.
3. In the **Service Policies** table, select the service policy to be activated.
4. From the **Actions** menu or context menu, select **Activate**. A window is displayed.
5. Click **OK** to activate the selected service policy. After you click **OK** , you cannot cancel the activation.
**Related tasks**
Installing service definitions
To install a service definition into the z/OS Workload Manager (WLM) couple data set for the sysplex and,
optionally, activate a service policy, you can use the **Install and Activate** action provided in the **Service
Definitions** tab.
**Related reference**
Install and Activate tab
You can use the **Install and Activate** tab in the Workload Management task in IBM z/OS Management
Facility (z/OSMF) to complete the steps in the **Install and Activate** wizard. With the wizard, you can install

**110**   Workload Management task


```
a service definition into the z/OS Workload Manager (WLM) couple data set and, optionally, activate a
service policy. This topic describes the pages that are displayed in the wizard.
```
#### Printing service policies

```
To print an HTML formatted version of a service policy with overrides applied, you can use the Print
Preview action provided in the Service Policies table in the Service Policies for sysplex tab.
```
**Procedure**

1. Select the **Workload Management task** under the Performance category in the navigation area. The
    **Workload Management** page opens.
2. In the **Overview** tab, click **Service Policies for Sysplex**. The **Service Policies for Sysplex** tab opens.
3. In the **Service Policies** table, select the service policy to be printed.
4. From the **Actions** menu or context menu, select **Print Preview**. An HTML formatted version of the
    service policy with overrides applied is displayed in a **Print Preview** tab.
5. To select which items to display in the **Print Preview** tab, complete the following steps:
    a) Click **Filter**. A window is displayed.
b) Indicate whether you want to display the entire service policy (All) or whether you want to select
the items to be displayed (Selection).
    c) If you chose **Selection** , indicate which items you want to display. You can select multiple items.
d) Indicate whether you want to also display the following information for the selected items:
description of the item, last date and time the item was modified, and the user ID of the person who
last modified the item.
    e) Click **OK**. Only the selected items are displayed in the **Print Preview** tab.
6. To print the items that are displayed in the **Print Preview** tab, click **Print**. A new browser window
    opens and displays the contents of the **Print Preview** tab.
7. Use the browser print function to print the selected items.
**Related reference**
Print Preview tab
You can use the **Print Preview** tab in the Workload Management task in IBM z/OS Management Facility
(z/OSMF) to preview an HTML formatted version of a service definition or a service policy before printing
it.

### WLM Resource Pools tab

```
You can use the WLM Resource Pools tab in the Workload Management task to view and modify WLM
resource pools.
A WLM resource pool is used in support of IBM Cloud Provisioning and Management for z/OS. It
associates cloud information, such as a tenant name and domain ID, with WLM elements, such as report
classes and classification rules. You define domains and tenants with the Resource Management task in
the Cloud Provisioning category.
```
**Columns in the WLM Resource Pools table**

```
Table 88. Columns in the WLM Resource Pools table
```
```
Column Description
```
```
Name Name of the WLM resource pool definition.
```
```
Tenant Name Name of the tenant that the WLM resource pool is associated with.
```
```
Template Type Type of template that the WLM resource pool is associated with.
```
```
Workload Management task   111
```

```
Table 88. Columns in the WLM Resource Pools table (continued)
```
```
Column Description
```
```
Created By User ID for the creator of the WLM resource pool.
```
```
Created Time Time that the WLM resource pool was created.
```
```
Status Status of the WLM resource pool.
```
```
Last Modified (GMT) Date and time the item was last modified.
```
```
Modified By User ID of the person who last modified the item.
```
```
Actions for WLM resource pools
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected resource pool. To use a targeted action, you must
    select a resource pool.
- Table actions. Actions that apply to the entire table. No selection is required.

```
Table 89. Targeted actions
```
```
Action Description
```
```
View Display details about the selected resource pool.
```
```
Modify Modify and complete the selected resource pool. If the action is not listed, the
z/OSMF role to which your user ID is assigned might not be authorized to modify
WLM resource pools. To obtain authorization, contact your z/OSMF administrator.
```
```
Delete Delete the selected resource pool or resource pools. If the action is not listed, the
z/OSMF role to which your user ID is assigned might not be authorized to delete
WLM resource pools. To obtain authorization, contact your z/OSMF administrator.
```
```
Table 90. Table actions
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
#### Viewing resource pools

```
To view a resource pool, you can use the View action provided in the Resource Pools tab.
```
**Procedure**

1. Select the **Workload Management task** under the Performance category in the navigation area. The
    **Workload Management** page opens.
2. In the **Overview** tab, click the **WLM Resource Pools** link. The **WLM Resource Pools** tab is displayed.

**112**   Workload Management task


3. Complete one of the following actions:
    - Select a resource pool. From the **Actions** menu or context menu, select **View**. You can select only
       one resource pool.
    - Click the resource pool name link for a specific resource pool.

```
Results
The selected resource pool is displayed.
```
#### Values on the View window

```
WLM resource pool name
Name of the WLM resource pool definition.
Tenant name
Name of the tenant that the WLM resource pool is associated with.
Domain name
Name of the domain that the WLM resource pool is associated with.
Service class mapping
Service class mapping.
Template name
Name of the template that the resource pool is associated with.
Subsystem
Name of the subsystem.
Qualifier type
Type of qualifier.
Report class
Name of the report class.
```
#### Modifying resource pools

```
To modify a resource pool, you can use the Modify action provided in the Resource Pools tab.
```
**Procedure**

1. Select the **Workload Management task** under the Performance category in the navigation area. The
    **Workload Management** page opens.
2. In the **Overview** tab, click the **WLM Resource Pools** link. The **WLM Resource Pools** tab is displayed.
3. Select a resource pool. From the **Actions** menu or context menu, select **Modify**. You can select only
    one resource pool.
4. Make changes as needed.
5. Click **Save** or **Complete** to save your changes.
    - **Save** saves any changes that you made.
    - **Complete** saves the changes and indicates that the WLM resource pool definition is complete and
       ready for use by a provisioning and deprovisioning classification rule. The report class specified in
       the WLM resource pool is provisioned.

#### Values on the Modify window

```
WLM resource pool name
Name of the WLM resource pool definition.
Tenant name
Name of the tenant that the WLM resource pool is associated with.
```
```
Workload Management task   113
```

```
Domain name
Name of the domain that the WLM resource pool is associated with.
Service class mapping
Specify the service class mapping.
Template name
Name of the template that the resource pool is associated with.
Subsystem
Name of the subsystem.
Qualifier type
Specify the type of qualifier.
Report class
Specify the report class.
```
### WLM Status tab

```
You can use the WLM Status tab in the Workload Management task in IBM z/OS Management Facility
(z/OSMF) to view details about the active service policy and the installed service definition. You can also
view details about each system in the sysplex such as the service policy that is in effect and the z/OS
Workload Manager (WLM) status.
The information that is displayed in the WLM Status tab is retrieved from the WLM component running on
the z/OSMF host system. The information is displayed in the following sections:
```
- “Active Service Policy” on page 114
- “Systems” on page 115
- “Installed Service Definition” on page 118
If you enabled **Automatic refresh** , the information refreshes automatically every 30 seconds. Otherwise,
click the **Refresh** button to obtain the latest information.

```
Active Service Policy
This section provides information about the service policy that is active in the sysplex. Table 91 on page
114 lists and describes the fields that are displayed in this section.
The link View performance of active policy enables you to view the performance of the active service
policy. If the link is not displayed a provider of appropriate performance data is not available.
If your installation is using only z/OSMF to manage WLM service definitions, the service policy information
should be the same as the policy information that is stored in the WLM couple data set. The only
exception is when a service policy is currently being activated. In this case, this section displays details
about the previous active service policy. After the current activation completes, the information is
updated.
If your installation is also using the WLM Administrative Application to manage service definitions,
inconsistencies could also occur for the following reasons:
```
- The service policy was activated from a system other than the z/OSMF host system and the host system
    has not activated the policy yet.
- The service policy that was activated has a functionality level that is higher than the functionality level
    of WLM on the host system; therefore, the host system cannot activate the service policy.
To minimize the possibility of inconsistencies, it is recommended that your installation use only one tool
to manage your WLM service definitions.

```
Table 91. Fields in the Active Service Policy section
```
```
Field Description
```
```
Name Name of the active service policy.
```
**114**   Workload Management task


_Table 91. Fields in the Active Service Policy section (continued)_

**Field Description**

**Description** Description of the active service policy.

**Activated** Date and time the service policy was activated.

**Activated by** User ID of the person who activated the service policy and the name of the system
from which it was activated.

**Related service
definition**

```
Name of the service definition that contains the active service policy.
```
**Functionality level** Functionality level of the active service policy.

**Installed** Date and time the service definition was installed.

**Installed by** User ID of the person who installed the service definition and the name of the
system from which it was installed.

```
Systems
The Systems table lists the status of all of the systems in the sysplex. For a description of the columns in
the Systems table, see Table 92 on page 115. For a description of the actions listed in the Actions menu,
see Table 93 on page 118.
If you removed a system from the sysplex, it might still be listed because WLM retains knowledge of
the system for a certain amount of time in case your installation decides to reactivate the system. If the
system is not activated within several days, the system is automatically removed from the list of systems.
The link View performance of systems enables you to view the performance of the systems in the
sysplex. If the link is not displayed a provider of appropriate performance data is not available.
```
_Table 92. Columns in the Systems table_

**Column Description**

**Name** Name of the system.

**Used Service Policy** Name of the service policy that WLM is using to manage the workload on the
system.

**Activated** Date and time the service policy was activated.

```
Workload Management task   115
```

```
Table 92. Columns in the Systems table (continued)
```
```
Column Description
```
```
WLM Status Status of WLM on the system. WLM can have one of the following status:
```
- **Initializing.** There is no workload management function available because WLM
    is initializing.
- **Active.** The system is processing towards the active service policy.
- **Active, Not Running with Active Policy.** WLM is active, but the active service
    policy is not available for one of the following reasons:
    - There is no WLM couple data set.
    - The system is not connected to the WLM couple data set.
    - The system is connected to the WLM couple data set but a service policy has
       not been activated.
    - A service policy is currently activating, but the system has not activated it yet.
    - The active service policy failed to activate on the system.
    - The service definition has over 100 service classes defined.
- **Quiesce In Progress.** WLM is in the process of an orderly shutdown.
- **Cleanup Initiated by System** **_system-name_****.** WLM is inactive. Termination was
    not orderly and another system running WLM is performing recovery actions on
    behalf of this system, where _system-name_ is the name of the system performing
    the recovery.
- **WLM Inactive, Cleanup Complete.** WLM is inactive. It either terminated through
    an orderly shutdown or cross-system recovery actions have been completed.
- **System Inactive, Cleanup Pending.** The system is not currently part of the
    sysplex. Cross-system recovery is scheduled to be performed on the system.
- **System Inactive, Cleanup Complete.** The system is not currently part of the
    sysplex. However, before the system became inactive, cross-system recovery
    actions were completed.
- **Unknown.** A system running WLM has detected that another system running
    WLM contains unreliable information. When this happens the system with the
    unreliable information is isolated and its WLM state is set to unknown. Error
    processing is started to determine the true WLM state for the system.
- **Not Available.** The system might be in the process of coming up.

**116**   Workload Management task


_Table 92. Columns in the Systems table (continued)_

**Column Description**

**GPMP Status** Status of the guest platform management provider (GPMP), which provides policy
information to WLM so that WLM understands the platform wide performance goals
of the workloads in which z/OS is participating.
**Note:** Beginning with z/OS V2R3, the GPMP is no longer available. If activation is
enabled (YES is selected), WLM starts the GPMP only on systems that are z/OS
V2R2 and below.
The guest platform management provider can have one of the following status:

- **Unknown.** The status of the GPMP could not be retrieved.
- **Inactive.** The GPMP was not started.
- **Unavailable.** A platform performance management function is not available.
- **Started.** The GPMP has been started, but has not connected to WLM.
- **Active.** The GPMP is active and is connected to WLM, but has not established a
    connection to the IBM z Unified Resource Manager.
- **Failed.** WLM attempted to start the GPMP; however, the agent did not connect
    to the IBM z Unified Resource Manager within the timeframe allotted. This state
also occurs when WLM is unable to stop the GPMP.
- **Severe Failed.** WLM attempted to start the GPMP. The request failed twice within
    10 minutes, or the GPMP connection unexpectedly terminated twice within 10
    minutes.
- **Connected.** The GPMP is active and is connected to WLM and the IBM z Unified
    Resource Manager.
- **Stopped.** The GPMP was manually stopped using either the **MODIFY**
    **WLM,GPMP,STOP** command or the **MODIFY WLM,AM=DISABLE** command. If
    the Application Response Measurement (ARM) component of WLM is disabled,
    you must enable it before you can restart GPMP. To enable ARM, issue the
    **MODIFY WLM,AM=ENABLE** command. Then, to restart GPMP, issue the **MODIFY**
    **WLM,GPMP,START** command.
- **Disabled.** The ARM component of WLM is disabled.
- **Early IPL.** Unix System Services or TCP/IP is not running.
- **Shutdown** **_x_****.** GPMP termination is currently in progress, where _x_ is a number.

**WLM Version Level** Version of WLM that is running on the system. The WLM version level is displayed
only for the z/OSMF host system.

**CDS Format Level** Format of the WLM couple data set (CDS) created via the XCF IXCL1DSU utility. If
the WLM couple data set format level can be determined, then one of the following
valid formats is shown:

- **FORMAT 1.** Original format, as built in MVS/SP™ Release 5.1. This is the format
    level for MVS/SP Release 5.1 and 5.2.
- **FORMAT 2.** Format updated in OS/390 Release 3, with the addition of application
    environments. This is the format level for OS/390 Release 3 only.
- **FORMAT 3.** Format updated in OS/390 Release 4, with the addition of scheduling
    environments. This is the format level for OS/390 Release 4 and later.
The couple data set format level is displayed only for the z/OSMF host system.

```
Workload Management task   117
```

```
Table 92. Columns in the Systems table (continued)
```
```
Column Description
```
```
Connected CF Structures Names of the coupling facility (CF) structures to which the z/OSMF host system
is connected. Only the names of the coupling facility structures that are defined
for multisystem enclaves and for logical partition (LPAR) clustering are shown, if
applicable.
```
```
Table 93. Table actions for the Systems table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns, and
designate which columns should be fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view. This action is listed only when the filter row is
displayed in the table.
```
```
Show Filter Row Display the filter row. This action is listed only when the filter row is not displayed
in the table.
```
```
Clear Sorts Clear the sort from all of the columns in the table.
```
```
Clear Search Clear the search.
```
```
Installed Service Definition
This section lists details about the service definition that is installed in the WLM couple data set for the
sysplex. Table 94 on page 118 lists and describes the fields that are displayed in this section. When you
display or refresh the WLM Status tab, z/OSMF automatically extracts the installed service definition and
updates the information that is displayed in the tab.
```
```
Table 94. Fields in the Installed Service Definition section
```
```
Field Description
```
```
Name Name of the service definition that is installed in the WLM couple data set for the
sysplex.
```
```
Description Description of the service definition that is installed in the WLM couple data set for
the sysplex.
```
```
Installed Date and time the service definition was installed.
```
```
Installed by User ID of the person who installed the service definition and the name of the
system from which it was installed.
```
### Settings tab

```
You can use the Settings tab in the Workload Management task to specify how long to keep the service
definition history, to define the code page, time zone, and backup sequential data set for the sysplex, to
enable or disable the service definition and service policy consistency checking feature, and to display or
suppress information messages.
The settings are available to all users authorized to access the Workload Management task. The items in
the User Settings section are user-specific; whereas, the other settings impact all users. For example, if
you want to suppress information messages, those messages are suppressed for you only. However, if you
enable the consistency checking feature, it is enabled for all users.
Table 95 on page 119 lists and describes the items that are included in the tab.
```
**118**   Workload Management task


_Table 95. Items in the Settings tab_

**Item Description**

**Number of months
to keep the service
definition history**

```
Select the number of months z/OSMF is to keep the service definition history. By
default, the history is maintained for two months.
```
**Require comments for
service definition actions**

```
Specify whether comments are required for service definition actions:
```
- **Yes.** Comments are required.
- **No.** Comments are optional. This is the default.
The service definition actions are modify, install, import, export, and service policy
activation. When you add a comment when performing any of these actions, the
comment is recorded in the service definition history.

```
Workload Management task   119
```

```
Table 95. Items in the Settings tab (continued)
```
```
Item Description
```
```
Consistency Checking Select the following settings for consistency checking:
```
- **Enable consistency checking between z/OSMF and the z/OS Workload**
    **Manager (WLM) couple data set**.
    Select one of the following options:
    - **Yes.** z/OSMF periodically examines the WLM couple data set to verify that the
       installed service definition and the active policy identified in z/OSMF match
       the service definition and policy contained in the couple data set. This option
       is selected by default.
       Select this option if your installation is using other tools or products, such as
       the WLM Administrative Application, to manage your service definitions and
       policies. Otherwise, z/OSMF might inaccurately identify the service definition
       and policy installed and active in the sysplex.
    - **No.** z/OSMF assumes that the last service definition and policy installed and
       activated using z/OSMF are installed and active in the sysplex.
       Select this option if your installation is using only z/OSMF to manage your
       service definitions and policies. Doing so improves the performance of the
       Workload Management task.
- **Enable tracking of all service policy activations in the sysplex**.
    Select one of the following options:
    - **Yes.** z/OSMF periodically queries the WLM status in the background to track
       all service policy activations in the sysplex. This information is necessary to
       identify the correct service policy if an Application Linking event requestor
       asks z/OSMF Workload Management to display items of a service policy that
       was active in the past. This option is selected by default.
       Select this option if your installation is using other tools or products, such as
       the WLM Administrative Application, to activate service policies and you are
       exploiting the linking from other z/OSMF tasks (such as the z/OSMF Resource
       Monitoring task) to the z/OSMF Workload Management task. Otherwise, z/
       OSMF might inaccurately identify service policies that were active in the past.
- **No.** z/OSMF is only aware of service policy activations triggered from z/OSMF,
but it is not aware of service policy activations triggered outside of z/OSMF,
e.g. from the MVS console or the WLM Administrative Application.
Select this option if your installation is using only z/OSMF to activate service
policies or if you do not exploit the linking from other z/OSMF tasks (such as
the z/OSMF Resource Monitoring task) to the z/OSMF Workload Management
task. Doing so reduces the overhead produced by the Workload Management
task.
- **Number of seconds between WLM status queries.** Number of seconds that
    z/OSMF waits until the WLM status is retrieved again to examine which service
    definition is installed in the WLM couple data set and which service policy is
    active in the sysplex. By default the WLM status is queried every 30 seconds.
    If you select a larger value, the overhead produced by the Workload Management
    task is reduced, but the exactness of the displayed WLM status information in
    z/OSMF reduces.

**120**   Workload Management task


_Table 95. Items in the Settings tab (continued)_

**Item Description**

**Sysplex Settings** Specify the following settings for the sysplex:

- **Sysplex name**. Name of the sysplex in which the z/OSMF host system is a
    member. The sysplex name is provided by default and cannot be modified.
- **Code page for the sysplex**. Select the code page to be used to encode a service
    definition when it is exported to or imported from a host data set or when it is
    installed in the WLM couple data set. The code page is required. The default code
    page is IBM-1047.
    A code page is required because z/OSMF stores service definitions in XML format
    and encodes them using UTF-8. When a service definition is exported to or
    imported from a host data set or when it is installed in the WLM couple data set,
    however, it must be encoded with a single-byte character code page.
- **Time zone for the sysplex.** Select the time zone of the z/OSMF host system.
    z/OSMF uses the time zone to calculate the GMT offset to be used to convert the
    last modified date and time of service definition items to either the time zone of
    the host system or GMT, as needed. If you do not specify a time zone, z/OSMF
    uses the GMT offset provided by the local z/OS system.
- **Backup sequential data set for the sysplex**. Specify the sequential data set
    name for z/OSMF to use when creating a backup copy of a service definition. The
    data set name must comply with z/OS data set naming conventions. The data set
    name is optional.
    You can include the variables _&&USER&&_ and _&&TIME&&_ in the data
    set name. To use the variables, you must include the two ampersand
    characters before and after the words USER and TIME. For example,
    **&&USER&&.SERVDEF.&&TIME&&.XML**. When the data set is allocated, the
    variable _&&USER&&_ is changed to your z/OSMF user ID and the variable
    _&&TIME&&_ is changed to the last eight digits of the current time in milliseconds.
       z/OSMF creates a backup copy when the service definition is installed and stores
       it in XML format on the z/OSMF host system. If you do not specify a data set
       name, a backup copy is not created.

**User Settings** In the **Display information messages that notify you that an object was created,
modified, deleted, or imported** field, select **Yes** to display these messages or
select **No** to suppress them. Typically, you can see the result of the corresponding
actions in the interface. For example, if you delete a service class, it is removed
from the **Service Classes** table.

**Buttons** The following buttons are included in the tab:

- **OK**. Save your changes and close the tab. Multiple users can modify the settings
    simultaneously. When you save, if another user modified the settings while you
    were modifying the settings, you can override that user's changes or discard your
    changes.
- **Cancel**. Discard the changes you made since you last clicked **OK** , and close the
    tab.

```
Related concepts
Comments for service definition actions
Comments that you provide when taking actions against service definitions help to describe the actions.
Related tasks
Viewing messages for service definitions
```
```
Workload Management task   121
```

```
To view the messages that exist for a service definition, you can use the View Messages action provided
in the Service Definitions tab or you can select Messages from the Switch To menu in the New , View ,
Modify , and Copy tabs.
Viewing messages for service definition items
To view the messages that exist for a specific service definition item, you can use the View Messages
action provided in the New , View , Modify , and Copy tabs.
Related reference
Messages
The service definition message log lists all of the messages that exist for a service definition. You can use
the log to easily navigate to service definition items that have messages.
```
#### Comments for service definition actions

```
Comments that you provide when taking actions against service definitions help to describe the actions.
The comments are recorded with the service definition history. To view the history of a service definition,
you can use the View History action provided in the Service Definitions tab.
You can provide comments when taking these actions against service definitions: create, modify, install,
import, export, and service policy activation.
When you choose to require comments for service definition actions, using the Settings tab, you ensure
that there will be a comment in the history for each action.
Related tasks
Viewing the history of service definitions
To view the history of a service definition, you can use the View History action provided in the Service
Definitions tab. The history might contain details about when the service definition was installed or
modified or when a service policy was activated.
Related reference
Messages
The service definition message log lists all of the messages that exist for a service definition. You can use
the log to easily navigate to service definition items that have messages.
Settings tab
You can use the Settings tab in the Workload Management task to specify how long to keep the service
definition history, to define the code page, time zone, and backup sequential data set for the sysplex, to
enable or disable the service definition and service policy consistency checking feature, and to display or
suppress information messages.
```
### Policy Advisor

```
The Policy Advisor view provides support to analyze a WLM service definition that has collected SMF
performance measurements while your service policy was active. It presents miscellaneous graphics
which compare your definition with actual performance data and gives advice on potential improvements
for unfavorable goal settings.
You can open the Policy Advisor view from the Workload Management task to examine your WLM service
definition for potential error-prone policy definitions and get recommendations on goal and importance
level settings based on selected SMF performance data.
```
```
Key features
The Policy Advisor view provides support to analyze a WLM service definition:
```
- Detailed analysis and data visualizations for proactive problem identification and prevention.
- Assistance with best practice recommendations for service definitions.
- Simplification of WLM policy definition tasks.

**122**   Workload Management task


```
For more information about WLM or workload management concepts, see z/OS MVS Planning: Workload
Management.
```
```
Getting started
You can start the Policy Advisor in two ways from the Workload Management task:
```
- In the Analyze section of the **Overview** tab, click **Policy Advisor**. The service definition that contains the
    active service policy opens in the Policy Advisor view.
- Navigate to the **Service Definitions** tab. Select a WLM service definition from the table. Click the
    **Actions** menu, and select **Open Policy Advisor**.
The Policy Advisor opens to the **Data** tab, which displays the WLM service definition name and a details
table.

```
Important: To use the full capabilities of the Policy Advisor, you must load a z/OS data set containing
SMF type 72 subtype 3 performance data that belongs to one of the policies contained in the service
definition. For more information, see “Data tab” on page 123.
```
#### Data tab

```
You can use the Data tab in the Workload Management Policy Advisor in IBM z/OS Management Facility
(z/OSMF) to load SMF performance data from a z/OS host and enable the full capabilities of the tool.
To use the complete analysis functions of Policy Advisor, you must load SMF 72.3 performance data that
was gathered while the selected WLM service definition was active on your system.
Before SMF performance data is loaded, the tab displays a Details table with the name, description, last
modified date, and the user who modified the selected service definition.
To load SMF data, you must specify a data set qualifier for a host data set containing SMF 72.3 data in the
Data set name field. Click Scan SMF data to scan the specified data set for usable SMF 72.3 records. The
button turns into a spinning circle while scanning is in progress.
If appropriate SMF records are found, three dropdown fields display. Select one policy and one or more
systems and days to load. A value must be selected for each field to continue.
After making your selections, click Load SMF data to begin extracting SMF data from the selected data
set. The button turns into a spinning circle while the load process is running. You can navigate to another
tab while the process is running, and loading continues in the background.
When the process finishes, a message is displayed to indicate the completion status. Table 96 on page
123 summarizes the potential outcomes. Investigate the logs for further details.
```
```
Table 96. Messages and outcomes from scanning and loading SMF data
```
```
Message ID Message text Possible outcome
```
```
IZUPA001I The SMF data set ${0} was
scanned successfully.
```
```
All records were processed without errors.
```
```
IZUPA002W The SMF data set ${0} was
scanned, but ${1} records could
not be processed.
```
```
Some records were not processed
successfully.
```
```
IZUPA003I The SMF data set ${0} was loaded
successfully.
```
```
All records were processed without errors.
```
```
IZUPA004W The SMF data set ${0} was
loaded, but ${1} records could
not be processed.
```
```
Some records were not processed
successfully.
```
```
Workload Management task   123
```

```
Table 96. Messages and outcomes from scanning and loading SMF data (continued)
```
```
Message ID Message text Possible outcome
```
```
IZUPA005W The SMF data set ${0} does
not contain appropriate SMF 72.3
records.
```
```
The specified data set was successfully
accessed, but no SMF 72.3 records were
found with appropriate service class data.
A reason for this result can be that the
selected combination of policy, systems
and days did not occur. There might be SMF
72.3 records that contain report classes in
your data set, but the z/OSMF WLM Policy
Advisor relies on service class data for its
analysis.
```
```
IZUPA006E The SMF data set ${0} cannot
be accessed. An error with the
catalog occurred. The data set
might not exist.
```
```
An error occurred accessing the data set,
either because it does not exist or because
the user does not have the correct access
privileges.
```
```
IZUPA007E The SMF data could not be loaded
due to memory constraints.
```
```
The requested SMF data set might be
too large. Consider loading a subset of
SMF data or increase your Java Virtual
Machine's memory limit.
```
```
IZUPA008E The data set ${0} does not
contain SMF records or cannot be
read due to its format.
```
```
An error occurred when trying to access the
requested SMF data set. It does not appear
to contain SMF records or cannot be read
due to its format.
```
```
IZUPA009E The SMF data set ${0} does
not contain any service policies
from the service definition
${1}. Select a different SMF
data set.
```
```
The service policies that are contained in
the service definition that was used to
launch the Policy Advisor do not match the
policies that were scanned from the SMF
data set. Therefore, applying the Policy
Advisor functions by using the selected
SMF data set is not possible.
```
```
When the SMF performance data is successfully loaded, you can conduct a detailed analysis of the service
definition by viewing one of the other tabs:
```
- The **Importance** tab helps to balance the importance levels used in the service definition. For more
    information, see “Importance tab” on page 124.
- The **Performance Index** tab helps to examine the performance achievement of your workload. For
    more information, see “Performance index tab” on page 126.
- The **Goal** tab helps to review the defined goals in a policy. For more information, see “Goal tab” on page
    129.

#### Importance tab

```
The Importance tab of the Policy Advisor provides an overview of the assigned workload balance across
the range of importance levels for a selected WLM service policy. If performance data is loaded, it
also shows the actual distribution of workload across all importance levels. Additionally, best practices
checks are performed on the current service definition and the loaded SMF data. If unfavorable workload
assignments are found, the results are displayed.
The importance analysis provides data visualizations to help balance the importance levels used in the
service definition.
```
**124**   Workload Management task


- View the absolute number of service class periods for each importance level. Assigning the same
    importance to too many service class periods can cause Workload Management to take longer to
reprioritize resources for a workload that does not meet its performance goal.
- Identify if any importance levels are not used. Not assigning work to one or more importance levels
    means that more service class periods are assigned to other importance levels, which can cause
    Workload Management to take longer to reprioritize resources.
- Determine whether the workload at a specific importance level unexpectedly dominates the service
    consumption on your system.
- Determine if the workload that is assigned to a certain importance level is not running at all.

```
Since the number of service class periods at an importance level does not necessarily correlate with
the actual amount of work that runs at this level, the actual distribution of workload across importance
levels can be different from the static distribution of service class periods across importance levels.
Comparing both values per importance level helps to identify orphaned work classifications or
unexpected service consumption behavior.
```
- Determine whether the workload of a certain importance is over-specified by too many service class
    periods. If the percentage of work that is running is low compared to the percentage of service class
    periods defined for an importance level, it can indicate over-specification of work. In such cases, the
    number of service class periods can be reduced.

**Distribution of service class periods**

```
This visualization shows the distribution of service class periods across available importance levels
as defined in the service definition. Two chart types are rendered and both use the same importance
colors.
```
- A bar chart displays the absolute number of service class periods per importance level.
- A donut-style pie chart displays the percentage of service class periods that are assigned to each
    importance level. The center of the chart displays the total number of service class periods.
Initially, when there is no SMF performance data loaded, both charts show the distribution of periods
according to the base definition. None of the available service class overrides from a service policy are
applied by default. You can choose to apply service class overrides from a defined service policy by
selecting a policy from the drop down menu **Apply overrides from service policy**.
After SMF performance data is loaded, the dropdown menu **Apply overrides from service policy** is
preselected with the chosen service policy to ensure that you do not inadvertently compare data from
different service policies. You can select another service policy from the dropdown menu to override
this selection, or select None. If you select a service policy from the dropdown menu, the visualization
displays the selected policy name in the chart title.
By default, both charts include only service classes that are referenced by a classification rule in
the service definition. Service classes that are not referenced by a classification rule are considered
unused, as WLM does not assign work to them and their periods do not come into effect. You can
choose to incorporate periods of unused service classes by flipping the toggle switch **Skip periods
without work classifications**.

**Actual distribution of work**

```
This visualization shows the actual distribution of service class periods across available importance
levels as reflected in the SMF 72.3 performance data. It is rendered only after you have loaded SMF
performance data. Two charts are used to display the distribution.
```
- A bar chart displays the accumulated service consumption of all running workloads with a specified
    importance, which is measured in service units.
- A donut-style pie chart displays the percentage of accumulated service consumption. The center of
    the chart displays the total number of service units consumed.
In addition to the user-defined workload in importance levels 1 through 5 and discretionary, the
workload distribution charts also display system work that is running in the system provided
service classes SYSTEM and SYSSTC. Unclassified workload that is running in SYSOTHER is added

```
Workload Management task   125
```

```
to the amount of discretionary work, as this work is handled as discretionary work by Workload
management.
Checks and hints
This table shows a list of any available messages from best practices checks based on the current
service definition and loaded SMF data. This helps you to streamline the current service definition and
to avoid common pitfalls:
```
- Identify unused service classes
- Identify unclassified workload that will not be managed by WLM

```
Data selection
You can filter the data that is rendered in the data visualizations by using the fields that are described in
Table 97 on page 126.
```
```
Table 97. Fields on the Importance levels analysis tab
```
```
Field name Description
```
```
Apply overrides from
service policy
```
```
Select a service policy to apply service class overrides, if any are defined. When an
option is selected, the charts under Static distribution of service class periods
render again with the updated data. Select the option None to revert to the base
definition. The default selection is None.
```
```
Skip periods without
work classification
```
```
Toggle whether to incorporate periods of unused service classes into the
visualizations. The default is on.
```
#### Performance index tab

```
Use the Performance index analysis tab of the Policy Advisor to display the comparison of the
performance of a workload on a system to its defined goals.
The performance index analysis provides metrics and data visualizations for each service class period to
examine the performance achievement of your workload.
```
- Identify workloads that are not achieving a defined goal. An under-performing workload can result in
    not meeting defined service level agreements. High importance work that does not meet the defined
    goals requires further analysis.
- Identify workloads that are overachieving a defined goal. An over-performing workload can be an
    indicator for deprecated performance goals, such as goals that were not adapted to faster hardware or
    more capacity. Workload Manager does not actively manage over-performing workloads, but may take
    away resources to help another workload that is missing its defined goals or discretionary work.
- Identify service class periods where no workloads are running at all. If nothing is running in a service
    class period even if the service definition assigns work to it, this can indicate that the work classification
    is outdated.
- Depending on the system configuration, your workload mix, and the business goals, underachieved
    goals and overachieved goals for a specific service class period can be intentional and justified.
If the performance index tab is loaded before any SMF performance data is available, a message displays
to indicate that there is no performance data to show.
After SMF performance data is loaded, several dropdown fields and color-coded performance index
values for all service class periods are displayed.

```
PI heat map
The PI heat map displays color-coded PI values line-by-line for each service class period that is sorted by
the defined importance levels, starting with the highest defined importance. In each line the color-coded
```
**126**   Workload Management task


```
PI values are rendered according to increasing timestamps, with the x-axis representing time. Values are
grouped by day.
When you hover over a specific PI value field, a tooltip displays the defined goal, importance level, and
duration of the selected service class period, the selected timestamp, and the numeric value of the
performance index. When you click on a PI value field, a modal window opens with more details for the
selected service class period. For more information, see “Service class details” on page 128.
As indicated by the legend, all performance index values are color-coded according to a numeric value
that is defined in the Table 98 on page 127.
```
```
Table 98. PI heat map values
```
```
PI range Description Suggested action
```
```
PI == 0 Inactive, workload is not running. Check for unused service classes on all
systems and determine whether they can
be removed from the service definition.
```
PI > 0.0 and PI < 0.8 Low PI range, workload is overachieving
the defined goal.

```
Check whether goals have to be adapted
for updated hardware or increases in
capacity.
```
PI >= 0.8 and PI <=
1.2

```
Target range, workload is meeting the
defined goal.
```
```
No action needed.
```
PI >1.2 High PI range, workload missed the
defined goal.

```
Further analysis is needed.
```
Not available The service class period has a system or
discretionary goal. No performance index is
available.

```
No action needed.
```
```
Data selection
PI heat map shows data for all service class periods on the first system available for the entire SMF
recording interval when it is loaded for the first time. Filter the data rendered in the PI heat map using the
fields described in Table 99 on page 127.
```
_Table 99. Fields on the Performance Index analysis tab_

**Field name Description**

**System** The name of the selected system that the workload is running on. Since the data
is shown per system, you must select one entry from the **System** dropdown first.
For a complete overview of your workload performance, you must examine each
system in your sysplex one by one.

**Day(s)** Select one or more days to consider. You can select one or more individual days
if recorded SMF data contains multiple days. The selected days do not need to be
consecutive.

**Start time** Select the start time of the range to consider. This selection applies to every
selected day, but only data within the selected interval is shown.

**End time** Select the end time of the range to consider. This selection applies to every
selected day, but only data within the selected interval is shown.

**Importance** Select one or more levels of importance to show that are assigned to a service
class period.

**Skip periods without
activity**

```
Select whether inactive service class periods are excluded or not. The default value
is Off so that periods without any activity are shown.
```
```
Workload Management task   127
```

```
Service class details
The Details modal opens when you click on a Performance index value field within the PI heat map of the
Performance Index tab of the Workload Management Policy Advisor.
The Service class details modal shows the goal definition of the selected service class period as defined
by the selected service policy.
```
**PI statistics tab**

```
The PI statistics tab is the default tab and provides a line chart showing the actual PI values within
the selected interval from the heat map. The timestamp where the user clicked into the PI heat map is
marked with a red circle on the PI line to easier find the point of interest in this chart. The background of
the PI chart is filled with colors corresponding to the PI ranges. This helps to visually identify how close
the PI value is to a certain range.
The percentage of time a workload spent in different PI ranges is also shown in a table. This information
helps to assess whether a service class period primarily misses or overachieves its goal within the
selected time interval.
```
```
Goal tab
The Goal tab provides the user with charts that visualize the goal attainment of the selected service class
period.
```
- For velocity goals, the **Execution velocity** chart is rendered for the selected interval.
- For response time goals, the **Response time distribution** chart is rendered for the selected timestamp.
**Execution velocity**
    The execution velocity chart shows the execution velocity for the selected service class period and
    days over a selected interval. A red line shows the defined goal. A black line shows the actual average
    execution velocity of the service class period.
    Days are shown in chronological order by default. You can flip the toggle switch **Overlay days** to have
    them overlap and easily show similarities between the days.
    The interval is applied to each day, so you can inspect a specific interval for all days at the same time.
    If one or more days are skipped in between, they are hidden in the chart to focus only on what is
    selected.
**Response time distribution**
    The response time distribution chart shows the response time distribution of the selected service
    class period and timestamp. If no transactions occurred during the selected timestamp, this chart is
    not displayed. A red line shows the defined goal.
    The visualization is a combination of two chart types.
    - The bar chart shows the distribution of the transactions across the buckets. The midpoint bucket is
       labeled **100% goal**.
    - The line chart shows the percent of total transactions that are accumulated over the buckets.
    The goal of the service class period is plotted as a horizontal red line across the axis. The goal is
    achieved at the intersection where the lines cross.
**Note:** For discretionary goals or system service class periods, this tab is empty because there is no goal
definition for this type of service class period.

**SCP definition tab**

```
The SCP definition tab displays two tables of detailed information about the selected service class period
from the current service definition. This helps you to quickly identify work that is meant to be run in the
```
**128**   Workload Management task


```
selected service class without having to switch to the WLM editor view. Reviewing work classifications
helps to identify outdated rules, especially for inactive service class periods.
```
- The **Attributes** table lists all of the defined attributes for the selected period.
- The **Classifications** table shows all of the classification rules for the service class that the selected
    period belongs to.

```
Actions for the Service class details modal
General actions that apply to the entire Service class details modal. No selection is required.
```
```
Table 100. General actions
```
```
Action Description
```
```
Open in WLM task Opens the definition of the selected service class period inside the z/OSMF WLM
task to review or edit the goal definitions of the service class.
```
```
Open in Goal tab Navigates to the Goal tab and automatically opens the goal analysis charts for
the selected service class period, system, and time interval for a velocity goal or
timestamp for a response time goal.
```
```
Close To close the modal, click the X button or click anywhere outside of the modal
window.
```
#### Goal tab

```
The Goal analysis tab of the Policy Advisor provides an overview of the execution velocity and response
time goals for a selected service class period.
Goal analysis provides filterable metrics and data visualizations to help review the defined goals in a
policy.
Use the dropdown fields to filter the data that is shown in the charts. When a new selection is made,
the other fields update so that matching values only are displayed. For example, if the start time of the
interval is no longer available in the selected system, the first available start time is selected.
Execution velocity
The line chart shows the actual execution velocity for the selected service class period and days over
a selected interval. If the defined goal of the service class period is an execution velocity goal, a red
line representing the defined goal is shown. A black line representing the average actual execution
velocity within the selected time period displays how well-attained the defined goal is.
Days are shown in chronological order by default. You can change the view to overlay the days with
the toggle switch Overlay days. This view enables you to easily determine similarities between the
days.
The interval is applied to each day, so you can inspect a specific interval for all days at the same time.
If one or more days are skipped in between, they are hidden in the chart to focus only on what is
selected.
Response time distribution
The response time distribution chart shows how the response time for the selected service class
period and the timestamp is distributed. This representation helps to identify if the response time is
tightly distributed around the desired goal or whether there are extreme outliers which run faster than
half the goal or longer than 2 or 4 times the goal.
If no transactions occurred during the selected timestamp, this chart is not displayed. If the service
class period has a percentile response time goal, a red line showing the defined goal is displayed.
The visualization is a combination of two chart types.
```
```
Workload Management task   129
```

- The bar chart shows the distribution of the transactions across the buckets. The midpoint bucket is
    labeled **100% goal**.
- The line chart shows the percent of total transactions that are accumulated over the buckets.
The goal of the service class period is plotted as a horizontal red line across the axis. The goal is
achieved at the intersection where the lines cross.
You can quickly cycle through timestamps by using the arrow buttons on each side of the chart. The
button on the right side navigates to the next timestamp and the button on the left navigates to the
previous timestamp. The selected timestamp is reflected in the chart title.

```
Data selection
You can filter the data rendered in the data visualizations using the fields described in Table 101 on page
130.
```
```
Table 101. Fields on the Goal analysis tab
```
```
Column Description
```
```
System Name of the system that the workload is running on.
```
```
Service class period The service class period for analysis.
```
```
Day(s) Indicates the selected date or date range.
```
```
Start time Indicates the selected start time of the range.
```
```
End time Indicates the selected end time of the range.
```
```
Overlay days Toggle the chart view to display multiple days overlaying each other or side by side
chronologically.
```
**Actions for the Goal tab**

```
General actions that apply to the entire Goal tab. No selection is required.
```
```
Table 102. General actions
```
```
Action Description
```
```
Open in WLM task Opens the definition of the selected service class period inside the z/OSMF WLM
task to review or edit the goal definitions of the service class.
```
**130**   Workload Management task


## Index

**A**

activating service policies 110
active service policy 114
adding resources to scheduling environments 99
analysis messages for service definitions 103
application environments 87
Apply button 24
apply resource group overrides 100
apply service class overrides 100
apply tenant resource group overrides 101

**C**

Cancel button 24
classification groups 70
classification rules 76, 79
classifications 76
copying service definitions 15 , 24
creating application environments 19, 91
creating classification groups 75
creating classification rules 86
creating classifications 79
creating performance periods 63
creating qualifier values 75
creating report classes 67
creating resource group overrides 42
creating resource groups 50
creating resources 94
creating scheduling environments 99
creating service class overrides 41
creating service class periods 63
creating service classes 62
creating service definitions 20 , 24
creating service policies 36, 37
creating tenant report classes 70
creating tenant resource group overrides 42
creating tenant resource groups 55
creating workloads 45
cross-references 104

**D**

Data tab 123
defining application environments 19, 91
defining classification groups 75
defining classification rules 86
defining classifications 79
defining performance periods 63
defining qualifier values 75
defining report classes 67
defining resource group overrides 42
defining resource groups 50
defining resources 94
defining scheduling environments 99
defining service class overrides 41
defining service class periods 63

```
defining service classes 62
defining service definitions 20 , 24
defining service policies 36, 37
defining tenant report classes 70
defining tenant resource group overrides 42
defining tenant resource groups 55
defining workloads 45
deleting service definitions 16
```
**E**

```
exporting service definitions 17 –19
```
**F**

```
filtering the print preview 108
formatted service definitions 107
formatted service policies 107
functionality levels 29
```
**G**

```
Goal tab 129
```
**I**

```
Importance tab 124
importing service definitions 21 –23
installed service definition 108 , 111, 114
installing service definitions 15 , 105–107
```
```
L
locking service definitions 10
```
**M**

```
messages for service definitions 102
modifiying resource pools 113
modifying classifications 78 , 79
modifying service definitions 10 , 24
modifying service policies 35, 37
moving classification rules 86
moving performance periods 63
moving service class periods 63
```
```
N
nesting classification rules 87
```
**O**

```
OK button 24
overview 1, 122
Overview tab 3
```
```
Index   131
```

**P**

Performance index tab 126, 128
performance periods 55
print previewing service definitions 107
print previewing service policies 107
printing service definitions 16 , 107
printing service policies 107, 111
properties for classifications 78 , 79
properties for service policies 35, 37

**R**

report classes 64
Reset button 24
resource group overrides 37
resource groups 46
resources 92

**S**

scheduling environments 95
service class overrides 37
service class periods 55
service classes 55
service definition activity 9
service definition details 27
service definition history 13
service definition history settings 118
service definition notes 103
service definition repository 4
service definitions 4
service policies 32, 108
settings 118
subsystem type qualifiers 76
Switch To menu 24
sysplex settings 118
systems in sysplex 114

**T**

tenant report classes 67
tenant resource group overrides 37
tenant resource groups 50
tips 105

**V**

viewing classifications 78 , 79
viewing cross-references 105
viewing messages for service definitions 11 , 36
viewing resource pools 112
viewing service definitions 11 , 24
viewing service policies 35, 37
viewing the history of service definitions 13

**W**

WLM resource pools 111
WLM status 114
work qualifiers 70
Workload Management Policy Advisor 122–124, 126, 128
Workload Management task 1

```
Workload Manager (WLM) status 114
Workload Manager Policy Advisor 129
workloads 42
```
**Z**

```
z/OS Workload Manager (WLM) status 114
```
**132**   Workload Management task



IBM®


## Problem Determination

# IBM


## Contents

**Problem Determination..........................................................................................1**

**Index.................................................................................................................... 2**

**ii**


**Problem Determination**

```
This section, when the appropriate plugins are installed, describes the z/OSMF task that you can use to
diagnose system problems and send diagnostic data to IBM® or other vendors for further diagnostics.
```
```
Problem Determination   1
```

## Index

**P**

problem determination 1

**2**   Problem Determination



IBM®


- Examine the job settings for errors. The job settings might contain syntax errors even if the Incident Log
    does not issue an error message. If the job settings contain errors, re-invoke the _Send Diagnostic Data_
    wizard, enter valid information, and then re-send the diagnostic data.
- Verify that the FTP.DATA and the TCPIP.DATA files exist and that you have permission to read the files.
- Specify a shorter SSH proxy command in the SFTP profile, or add spaces to the command so that
    z/OSMF can split the command onto multiple lines.
- For more details about the JCL error, complete the steps provided in help topic “Viewing the details of
    an FTP or SFTP job” on page 41, and correct any errors.

If the problem persists, contact your z/OSMF administrator or system programmer.

**_Failed. The FTP job was not initialized._**
The send failed because the FTP or SFTP job could not be started.

**Explanation**

The FTP or SFTP job was not started because z/OSMF could not complete all of the prerequisite steps
required in order for the job to begin. Some of the possible causes of this error are, as follows:

1. The temporary directory is full or you might not have permission to write to it, resulting in out of
    space permission errors for step STEP0010, WBEMIN, STEP0020, STEP0050, or STEP0080. For more
    information, see help topic “Temporary files created during a send” on page 26.
2. There is no room for the temporary partitioned data set (PDS) that is allocated at the beginning of the
    job (STEP0010).
3. The wbemexec program could not be found or you might not have permission to read the program file,
    resulting in an error at STEP0040.
4. If you are using the z/OS Problem Documentation Upload Utility transfer method, z/OSMF might not be
    able to find the utility.

**System programmer response**

1. Ensure that there is sufficient space in the temporary directory and verify that the user is authorized to
    write to it.
2. Ensure that there is a device in the SYSDA pool that has at least one track of storage available. Verify
    that the user is authorized to create the PDS.
3. Ensure that the wbemexec program was specified correctly when z/OSMF was installed. Verify that the
    program exists and that the user has permission to read the program file. For more information, see
    Quick guide: CIM server setup and verification in _z/OS Common Information Model User's Guide_.
4. Ensure that the z/OS Problem Documentation Upload Utility is configured properly. For more details,
    see z/OS MVS Diagnosis: Tools and Service Aids.

Ensure that z/OSMF is configured properly. For more information, see the topic about The z/OSMF nucleus
in IBM z/OS Management Facility Configuration Guide.

Check the z/OSMF logs and operator messages for additional information. If the problem persists, contact
the IBM Support Center.

**User response**

To obtain more information about the FTP or SFTP job, complete the steps provided in help topic “Viewing
the details of an FTP or SFTP job” on page 41. Correct any errors or contact your z/OSMF administrator or
system programmer.

```
Incident Log task   51
```

```
Failed. The FTP job was not submitted to z/OS.
The send failed because an error occurred while submitting the FTP or SFTP job.
```
**Explanation**

```
The FTP or SFTP job was not submitted to z/OS because an error occurred while creating or submitting
the job control language (JCL).
```
**System programmer response**

```
Ensure that z/OSMF is configured properly. For more information, see the topic about The z/OSMF nucleus
in IBM z/OS Management Facility Configuration Guide.
Check the z/OSMF logs and operator messages for additional information. If the problem persists, contact
the IBM Support Center.
```
```
User response
To obtain more information about the FTP or SFTP job, complete the steps provided in help topic “Viewing
the details of an FTP or SFTP job” on page 41. Correct any errors or contact your z/OSMF administrator or
system programmer.
```
```
The FTP job was not found.
The request was not completed because the FTP or SFTP job could not be found.
```
```
Explanation
A request was made to refresh the job status information and the FTP or SFTP job was not found.
Typically, this status error occurs when another user deleted the FTP or SFTP job, the system experienced
a problem, or z/OSMF was launched on a system other than the system that originally submitted the job.
```
**System programmer response**

```
To determine why z/OSMF could not find the job, check the z/OS hardcopy log (for example, the syslog). If
the problem persists, contact the IBM Support Center.
```
**User response**

```
Contact your service provider to confirm that they received the file. If your service provider did not receive
the file, re-send it. For more information about why the FTP or SFTP job failed, look up the job in SDSF or a
similar tool. Correct any errors or contact your z/OSMF administrator or system programmer.
```
```
Send in progress
The diagnostic data file is currently being sent to the FTP or SFTP server.
```
**Explanation**

```
The diagnostic data file is currently being sent to the FTP or SFTP server.
```
```
System programmer response
No action is required.
```
**User response**

```
No action is required.
```
**52**   Incident Log task


### Create Incident

```
You can use the Create Incident page in the Incident Log task to manually create an incident with or
without an existing dump set, however the dump set cannot be stored on multiple volumes or it fails to
be added to the SDDIR. If you provide a dump data set name, it is sent to CEA through the CIM API along
with other parameters. Then, CEA tries to read this dump data set by using the IPCS tool to retrieve the
content to fill in the incident fields, such as ComponentID, Load Module, CSECT, Tracking ID,etc. If there
is no value for these fields, your input is used. If no dump data set name is specified, the newly created
incident is stored in zOSMF's persistence file. All the modify, delete, query operations are managed by
zOSMF.
```
**Fields on the Create Incident Page**

```
Table 28. Fields on the Create Incident Page
```
```
Field Description
```
```
Description Input a description of your newly created incident.
If the dump data set name is provided and the
dump data set name has a description, then the
user input is ignored. This field is required.
```
```
Dump data set name If the field is filled with a valid value, then the
incident is persisted in SDDIR. If the field is not
filled, then the incident is persisted in the z/OSMF
repository. This field is optional.
```
```
System name (sysplex.system) Choose the system that you wish to create the
incident on via the drop-down. This field is
optional.
```
```
z/OS release Choose the z/OS release that you are using to
create the incident via the drop-down. This field
is optional.
```
```
Tracking ID Input the tracking ID of the incident. This field is
optional.
```
```
CASE/PMR number Input the CASE/PMR number of the incident. This
field is optional.
problemNumberIsIBM
Identify the problem number as an IBM PMR
and verify the syntax. If the check box is
checked, you can only input an IBM CASE/PMR
number, or you can input a CASE/Problem
number, which is the same as the set CASE/
Problem number function.
```
```
Component ID Input the component ID of the incident. This field
is optional.
```
```
Abend code Input the abend code of the incident. This field is
optional.
```
```
CSECT Input the CSECT of the incident. This field is
optional.
```
```
Load Module Input the load module of the incident. This field is
optional.
```
```
Incident Log task   53
```

```
Table 28. Fields on the Create Incident Page (continued)
```
```
Field Description
```
```
Date/Time The date and time should either both be provided
together or excluded together. If one is provided
without the other than the create button is
disabled. The date and time user input is assumed
as GMT time, or the current GMT time is used as
the default time.
```
```
Notes Enter any notes that you have about the incident.
This field is optional.
```
```
Validation
When you click the Create button the system validates all fields that are filled in. If validation is passed
the incident is created and persisted in the SDDIR or z/OSMF persistence file. If the validation is not
passed, then the system returns an error to let you know why it failed to create an incident.
```
**The incident is created successfully**

```
After the incident is created successfully, you are able to view the diagnostic details on the View
diagnostic details page. Refer to “View Diagnostic Details page” on page 16.
```
### Allowing the next dump

```
To capture the next instance of an SVC dump being suppressed by dump analysis and elimination (DAE),
use the Allow Next Dump action provided on the Incident Log page.
```
```
About this task
z/OSMF recognizes an incident by the occurrence of an SVC dump. If the installation has DAE enabled,
DAE suppresses dump requests that have the same symptom string as a dump that was previously taken.
Each time DAE suppresses a dump request, the system does not collect data for the dump or write the
dump to a data set. In this case, z/OSMF might not be able to create a new incident if the symptom recurs
because the dump is not captured.
To update DAE so that it will not suppress the next dump request that has the same symptoms as the
dump associated with the selected incident, use the Allow Next Dump action. After the duplicate dump is
taken, DAE resumes suppressing subsequent SVC dumps that match the symptom string.
Each time you request to allow the next dump, DAE is recycled for each system in the sysplex. If DAE was
not enabled on a system in the sysplex, invoking this action starts DAE.
The Allow Next Dump action is not enabled for User Initiated incidents because those dumps are not
suppressed by DAE.
```
**Procedure**

1. Complete the steps provided in help topic “Selecting the sysplexes for which to display incidents” on
    page 7.
2. Select the incident that contains the SVC dump you want to capture when it recurs.
    You can select only one incident.
3. From the _Actions_ menu or context menu, select **Allow Next Dump**.
    A window opens.
4. Click **OK** to capture the next instance of the dump.

**54**   Incident Log task


```
Results
The next time an SVC dump is requested for a problem with the same symptoms, the dump will be taken
by the system and a new incident will be created.
Related tasks
Deleting incidents
To delete an incident and all of its FTP job status information and diagnostic data (such as the operations
log, error log, and SVC dumps), use the Delete Incident action provided on the Incident Log page.
Related information
Selecting items in multi-select tables
Using tables in z/OSMF
```
### Deleting incidents

```
To delete an incident and all of its FTP job status information and diagnostic data (such as the operations
log, error log, and SVC dumps), use the Delete Incident action provided on the Incident Log page.
```
**Before you begin**

- If dump analysis and elimination (DAE) is active and the selected incidents have the type _ABEND_ , when
    an SVC dump is requested that has the same symptom string as the SVC dump associated with any of
    those incidents, that dump might be suppressed by DAE. If you do not want to suppress the next dump
    request that has the same symptoms, you can update DAE by “Allowing the next dump” on page 54.
- Review the status of all associated FTP jobs. You cannot delete incidents that have FTP jobs that are in
    progress.

```
About this task
When you select the Delete Incident action, the incident and all of its FTP job status information and
diagnostic data (such as the operations log, error log, and SVC dumps) are deleted from z/OSMF. This
action does not clean up any FTP job information stored on z/OS and it does not remove diagnostic data
files from the FTP or SFTP servers.
```
**Procedure**

1. Complete the steps provided in help topic “Selecting the sysplexes for which to display incidents” on
    page 7.
2. Select the incident to be deleted.
    You can select multiple incidents. Selecting more than five incidents might increase the amount of
    time required to complete the action.
3. From the _Actions_ menu or context menu, select **Delete Incident**.
    A window opens.
4. If the allow next dump option is available and you want to allow the next dump of the selected
    incident, select _Allow next dump_.
    If the deletion fails because the incident has FTP jobs that are in progress, the _Allow next dump_ is not
    completed. If the _Allow next dump_ fails, the incident is not deleted.
5. Click **OK** to delete the selected incidents.
    After you click **OK** , the incident and all incident-related information are permanently deleted. You
    cannot undo this action.

**Results**

```
If the incidents were deleted, they are removed from the Incident Log table.
```
```
Incident Log task   55
```

```
Related tasks
Allowing the next dump
To capture the next instance of an SVC dump being suppressed by dump analysis and elimination (DAE),
use the Allow Next Dump action provided on the Incident Log page.
Displaying all the FTP or SFTP jobs for an incident
On the FTP Job Status page, you can view or delete the status of an FTP or SFTP job or browse or cancel
a job. To display the status of all of the FTP or SFTP jobs associated with an incident, use the FTP Job
Status action provided on the Incident Log page.
Displaying the FTP or SFTP jobs for specific diagnostic data
On the FTP Job Status page, you can view or delete the status of an FTP or SFTP job or browse or cancel a
job. To display the FTP or SFTP job status for a subset of the diagnostic data, use the View Status button
provided on the Diagnostic Data tab on the View Diagnostic Details page.
Related reference
After deleting an incident with multi-system dumps, the remote dumps were not deleted
You invoked the Delete action in the incident log for an incident with multi-system dumps. The incident
and all incident-related information was deleted from z/OSMF. However, only the primary dump was
deleted, the remote dumps were not deleted.
Related information
Selecting items in multi-select tables
Using tables in z/OSMF
```
### Displaying the FTP Servers page

```
On the FTP Servers page, you can specify the settings required for z/OSMF to access an FTP or SFTP
server and upload diagnostic data files. To display this page, use the FTP Servers action provided on the
Incident Log page.
```
**Procedure**

1. Complete the steps provided in help topic “Selecting the sysplexes for which to display incidents” on
    page 7.
2. From the _Actions_ menu, select **FTP Servers**.

**Results**

```
The FTP Servers page is displayed.
Tip: The target selected for the Incident Log task impacts the actions you can perform for servers as
follows:
```
- If the target for the Incident Log task is a sysplex, CPC, or group, the **Add** action in the FTP Servers
    table is disabled. In this case, to add a server definition, open another instance of the Incident Log task
    and make the target the system definition that defines the z/OSMF instance for which you want to add
    a server definition. Then, select FTP Servers from the **Actions** menu on the Incident Log page in that
    z/OSMF instance, and complete the steps provided in help topic Adding servers.
- If the target for the Incident Log task is a sysplex, CPC, or group, you must select only one FTP or SFTP
    server to enable the **Associate FTP Profile** action in the FTP Servers table. Otherwise, the action is
    disabled.
**Related information**
Selecting items in multi-select tables
Using tables in z/OSMF

**56**   Incident Log task


### Displaying the FTP Profiles page

```
On the FTP Profiles page, you can specify the FTP or SFTP settings for z/OSMF to use when sending
diagnostic data to an FTP or SFTP server. To display this page, use the FTP Profiles action provided on the
Incident Log page.
```
**Procedure**

1. Complete the steps provided in help topic “Selecting the sysplexes for which to display incidents” on
    page 7.
2. From the _Actions_ menu, select **FTP Profiles**.

**Results**

```
The FTP Profiles page is displayed.
Tip: If the target for the Incident Log task is a sysplex, CPC, or group, the Add action in the FTP Profiles
table is disabled. In this case, to add a profile, open another instance of the Incident Log task and make
the target the system definition that defines the z/OSMF instance for which you want to add a profile.
Then, select FTP Profiles from the Actions menu on the Incident Log page in that z/OSMF instance, and
complete the steps provided in help topic Adding profiles.
Related information
Selecting items in multi-select tables
Using tables in z/OSMF
```
### Troubleshooting tips for incidents and diagnostic data

```
This section provides troubleshooting tips for common problems that might occur with incidents and
diagnostic data.
```
#### Incidents not appearing in the incident log

```
This topic provides troubleshooting tips that you can use to determine why an incident is not listed in the
incident log.
```
**Possible Causes**

- The incidents do not satisfy the specified filter criteria.
- The sysplex dump directory contains more than 500 incidents that match the specified date and time
    filter criteria. z/OSMF can display a maximum of 500 incidents in the log; therefore, other incidents (if
    any) that match the date and time filter criteria are excluded from the log.
- The z/OS system is not configured to write dumps to data sets.
- An error occurred when the dumping services address space (DUMPSRV) attempted to write
    information about the SVC dump to the sysplex dump directory. DUMPSRV makes several attempts
    to update the sysplex dump directory with information describing the dump. If these attempts fail, no
    entry is made and no information about the dump incident is retrieved.

**System programmer response**

- Ensure that dump data set handling has been configured for the z/OS system. For more information, see
    Configuring automatic dump data set allocation in _IBM z/OS Management Facility Configuration Guide_.
- If you know the dump data set name, you can add it to the sysplex dump directory by running a job that
    issues the **ADDDUMP** Interactive Problem Control System (IPCS) command.
    **Attention:** Never access the sysplex dump directory from an IPCS user session. Doing so ties up
    DUMPSRV and the common event adapter (CEA). Always use a batch job to perform this operation. For

```
Incident Log task   57
```

```
more information about the sysplex dump directory, see Creating the sysplex dump directory in IBM
z/OS Management Facility Configuration Guide.
```
**User response**

- Modify or clear the filter criteria.
- If the sysplex dump directory contains more than 500 incidents that match the date and time filter
    criteria, you can narrow the filter criteria or you can delete incidents from the log. Deleting incidents
    removes them from the sysplex dump directory.
If the problem persists, contact your z/OSMF administrator or system programmer.

#### Operations log, error log, and error log summary are not listed

```
One or more SVC dumps are listed for the incident in the Diagnostic Data table; however, the operations
log, the error log, and the error log summary are not listed.
```
**Possible Causes**

- System on which the incident occurred is running z/OS V1R9 or earlier.
- The system ran out of space when gathering the diagnostic log snapshots.

**System programmer response**

```
Check SYSLOG for message CEA0600I and resolve the issue. Ensure that SNAPSHOT(Y) is specified
in your active CEAPRMxx parmlib member. This setting enables the collection of incident related data.
Also, verify that the sysplex dump directory, error log recording, and the source for diagnostic snapshots
(OPERLOG or SYSLOG) has sufficient space in the volume or storage class, as appropriate. Check SYSLOG
for CEA060xI messages.
```
```
User response
If the system is running z/OS V1R9 or earlier, no action is required. This processing is normal when
the detecting system is at a lower level. A subset of the properties are captured, but not all of them.
If the system is running a later z/OS version and release, contact your z/OSMF administrator or system
programmer.
Related reference
Only the dump data set name is provided for an incident
An entry was created for the incident in the Incident Log table; however, z/OSMF provided only the
incident type property. Also, one or more SVC dumps are listed for the incident in the Diagnostic Data
table; however, the operations log, the error log, and the error log summary are not listed.
```
#### Only the dump data set name is provided for an incident

```
An entry was created for the incident in the Incident Log table; however, z/OSMF provided only the
incident type property. Also, one or more SVC dumps are listed for the incident in the Diagnostic Data
table; however, the operations log, the error log, and the error log summary are not listed.
```
**Possible Causes**

- System on which the incident occurred is running z/OS V1R9 or earlier.
- SVC dump was not cataloged when the system programmer added it to the sysplex dump directory
    through the **ADDDUMP** Interactive Problem Control System (IPCS) command; therefore, no incident
    properties could be located.

**58**   Incident Log task


```
System programmer response
Catalog the SVC dump data set on the system and run the IPCS ADDDUMP job to add information about the
dump to the sysplex dump directory. Never access the sysplex dump directory from an IPCS user session.
Doing so ties up the dumping services address space (DUMPSRV) and the common event adapter (CEA).
Always use a batch job to perform this operation as quickly as possible.
```
**User response**

```
If the system is running z/OS V1R9 or earlier, no action is required. This processing is normal when
the detecting system is at a lower level. A subset of the properties are captured, but not all of them.
If the system is running a later z/OS version and release, contact your z/OSMF administrator or system
programmer.
Related reference
Operations log, error log, and error log summary are not listed
One or more SVC dumps are listed for the incident in the Diagnostic Data table; however, the operations
log, the error log, and the error log summary are not listed.
```
#### Error log summary is not listed

```
The SVC dumps, operations log, and error log are listed for the incident in the Diagnostic Data table;
however, the error log summary is not listed.
```
**Possible Cause**

```
ABEND dumps that occur within a small time window (10 minutes) do not result in the system creating
a logrec or error log summary report. This is a self-protecting feature of the system to prevent inordinate
amounts of duplicate data from being collected.
```
```
System programmer response
If the SVC dump occurred in isolation and the logrec summary information is missing, to obtain additional
diagnostic information, check SYSLOG for message CEA0600I or CEA0602I.
```
**User response**

```
If the dumps are being collected within minutes of each other, the system is working as designed and no
action is required. If this is not the case, contact your z/OSMF administrator or system programmer.
```
#### Error log summary is not listed, and only 10 minutes of data is captured in

#### the dumps and logs that are listed

```
The SVC dumps, operations log, and error log are listed for the incident in the Diagnostic Data table;
however, the error log summary is not listed. Also, the content of the dumps and logs that are listed is
incomplete.
```
**Possible Cause**

```
When the common event adapter (CEA) detects that ABEND SVC dumps are occurring frequently
(within 10 minutes of each other), the amount of data collected is reduced on each subsequent dump
encountered. This behavior protects the system from collecting inordinate amounts of duplicate data in a
recurring dump situation.
```
**System programmer response**

```
No action is required; the system behavior is normal.
```
```
Incident Log task   59
```

```
User response
No action is required; the system behavior is normal.
```
#### Error log is not listed

```
The SVC dumps, operations log, and error log summary are listed for the incident in the Diagnostic Data
table; however, the error log is not listed.
```
```
Possible Cause
Ensure that your installation's logrec and error log data is being recorded correctly. Verify that the sysplex
dump directory, error log recording, and the source for diagnostic snapshots (OPERLOG or SYSLOG) has
sufficient space in the volume or storage class, as appropriate.
```
**System programmer response**

```
Ensure that the logrec data is being written to an error recording medium (a log stream or the logrec
data set). To do so, enter the DISPLAY LOGREC command to display the current settings and verify that
LOGREC is not set to IGNORE.
For more information, see Configure the Incident Log service in IBM z/OS Management Facility
Configuration Guide.
```
```
User response
Contact your z/OSMF administrator or system programmer.
```
#### Error log could not be created because of an authorization error

```
The system could not create the error log for the incident because the user does not have sufficient
authorization.
```
```
Symptom
User receives messages CEA0602I, IKJ56893I, and IGD17012I.
```
**Possible Cause**

```
The user is not authorized to define common event adapter (CEA) data sets.
```
**System programmer response**

1. Authorize the user to access CEA data sets. For example:

```
PERMIT 'CEA.*' CLASS(DATASET) ID(ZOSMFAD) ACCESS(ALTER)
```
2. If errors continue, check for message CEA0602I in SYSLOG. Review the messages to understand the
    problem and determine a solution.

**User response**

```
Contact your z/OSMF administrator or system programmer.
```
**60**   Incident Log task


#### Incident information does not match the dump content

```
When a dump is opened, its information does not match the information provided in the incident log. For
example, the incident is identified as a z/OS global resource serialization (GRS) dump, but the associated
dump is for a z/OS UNIX System Services (z/OS UNIX) incident.
```
**Possible Causes**

1. Your installation has not configured automatic dump data set allocation. The common event adapter
    (CEA) expects that automatic dump data set allocation is in use, and that data set names are created
    dynamically based on a specified naming convention. If your installation uses pre-allocated dump data
    sets (SYS1.DUMPxx) instead of automatic dump data set allocation, it is possible that the Incident Log
    task has accessed a dump data set that has been reused.
2. The dump was copied to another data set and was renamed, for example, through an installation-
    supplied automation program.
3. The dump was copied to an uncataloged data set. If so, the system cannot locate the dump, which
    results in the following problems:
    - CEA cannot locate the dump
    - Incident Log task cannot identify the dump data set
    - Send Diagnostic Data wizard cannot include the dump with the other diagnostic materials.

```
System programmer response
1.Configure automatic dump data set allocation. If your installation uses pre-allocated dump data
sets (SYS1.DUMPxx), modify your dump data set copy job to invoke the CEAMODSD program.
This job modifies the sysplex dump directory to refer to the new dump data set name. For more
information, see Configuring automatic dump data set allocation in IBM z/OS Management Facility
Configuration Guide and Ensuring that dump data set names are correct in IBM z/OS Management
Facility Configuration Guide.
```
2. If your installation has automation that copies the dump to another data set with a different name, the
    automation must also invoke a program that modifies the sysplex dump directory to use the new dump
    data set name. For more information, see Ensuring that dump data set names are correct in _IBM z/OS_
    _Management Facility Configuration Guide_.
3. If dumps are being copied to an uncataloged data set, modify the data set to be cataloged.

**User response**

```
Contact your z/OSMF administrator or system programmer.
```
#### After deleting an incident with multi-system dumps, the remote dumps were

#### not deleted

```
You invoked the Delete action in the incident log for an incident with multi-system dumps. The incident
and all incident-related information was deleted from z/OSMF. However, only the primary dump was
deleted, the remote dumps were not deleted.
```
**Possible Cause**

```
Dump storage is not set up to be shared across the systems in the sysplex.
```
```
System programmer response
Delete the remote dumps manually. Then, define the dump storage using an SMS storage class or a
shared volume managed through a shared catalog in the sysplex.
```
```
Incident Log task   61
```

```
User response
Contact your z/OSMF administrator or system programmer.
Related tasks
Deleting incidents
To delete an incident and all of its FTP job status information and diagnostic data (such as the operations
log, error log, and SVC dumps), use the Delete Incident action provided on the Incident Log page.
```
**62**   Incident Log task


## Index

**A**

adding attachments 20
adding notes to incidents 14–16
allowing the next dump 54
attaching diagnostic data 19, 20, 24
attachments 19, 20, 28

**B**

browsing FTP jobs 41
browsing logs 22
browsing SFTP jobs 41

**C**

canceling FTP jobs 42
canceling SFTP jobs 42
CASE/problem number 8
CASE/problem numbers 9
cipher key 32
copying a joblog to a data set 21

**D**

date and time filter 2
deleting FTP job status 43
deleting incidents 55
deleting SFTP job status 43

**E**

editing JCL 38
encrypting diagnostic data 32

**F**

file compression 27
FTP job status 44, 47–52
FTP profiles 33 , 57
FTP servers 29, 56

**I**

incident log 2
Incident Log task 1
incidents 1, 2
IZU_TEMP_DIR 26

**J**

JCL 38
job control language 38
job settings 34

```
M
managing incidents for multiple z/OS sysplexes 6
managing multiple sysplexes 7
monitoring FTP job status 40
monitoring SFTP job status 40
```
**O**

```
overview 1
```
**R**

```
removing incidents 55
```
```
S
Search for matching service 12, 14, 53
sending diagnostic data 19, 22, 24, 25, 28, 29, 32–34, 36,
38
setting CASE/problem numbers 8, 10, 16, 28
setting tracking IDs 11, 16
SFTP job status 44, 47, 48, 51, 52
SFTP profiles 33 , 57
SFTP servers 29, 56
system-supplied diagnostic data 2, 19, 24
```
**T**

```
temporary files 26
tracking ID 8
troubleshooting 57–61
```
**U**

```
user-supplied diagnostic data 19, 20, 24, 28
```
**V**

```
viewing diagnostic data 15
viewing FTP job status 19, 40, 41
viewing incident properties 15, 16
viewing JCL 38
viewing logs 22
viewing SFTP job status 40
```
```
Index   63
```

IBM®


## Software

# IBM


## Contents

**Software............................................................................................................... 1**

**Index.................................................................................................................... 2**

**ii**


**Software**

```
This section, when the appropriate plugins are installed, describes the z/OSMF task that you can use
to manage your z/OS software inventory, deploy SMP/E packaged and installed software, and generate
reports about your software.
```
```
Software   1
```

## Index

**S**

software 1

**2**   Software



IBM®


IBM®


## Software Update task

# IBM


## Contents

```
Software Update task............................................................................................ 1
Types of software updates...........................................................................................................................2
Starting new updates...................................................................................................................................2
Selecting a software instance and update type.....................................................................................3
Selecting updates to install....................................................................................................................6
Preparing updates................................................................................................................................ 19
Resolving HOLDs.................................................................................................................................. 21
Verifying updates..................................................................................................................................25
Reviewing the pre-installation summary.............................................................................................27
Installing updates.................................................................................................................................29
Resolving post-installation holds.........................................................................................................31
Reviewing the installation summary....................................................................................................34
Managing in-progress updates..................................................................................................................36
Viewing in-progress updates............................................................................................................... 36
Canceling in-progress updates............................................................................................................ 37
Resuming in-progress updates............................................................................................................37
Values on the View Updates in Progress window............................................................................. 38
Viewing completed updates...................................................................................................................... 40
Values on the Completed Updates window....................................................................................... 41
Setting preferences....................................................................................................................................42
Changing the Settings ..........................................................................................................................43
Values on the Settings window........................................................................................................... 44
```
**ii**


**Software Update task**

```
The Software Update task provides a graphical user interface that z/OS® system administrators and
system programmers can use to easily manage updates for installed SMP/E managed software. With the
Software Update task, you can apply updates to existing software instances and manage in-progress
and completed update processes. This task provides a simple alternative to the complex task of running
SMP/E JCL and then manually combing through the output and messages to interpret results and take the
necessary actions.
```
**Key features**

```
With the Software Update task, you can complete three main tasks:
Install software updates
With the Start New Software Update window, you can select a software instance and zone and then
choose to install either corrective, recommended, or functional updates on it, as available. For more
information about the different types of software updates, see “Types of software updates” on page
2.
Manage in-progress software updates
With the View Updates in Progress window, you can view details about update processes that are
currently in progress and select to cancel or resume them.
View completed software updates
With the Completed Updates window, you can view details about completed update processes.
The Software Update task updates software. If you need to install new software, do so with the z/OSMF
Software Management task. For more information about installing new software, see Deploying software.
```
```
Getting started
Ensure that Software Update is configured and set up for use. For more information, see in IBM z/OS
Management Facility Configuration Guide.
To get started with the Software Update task, complete the following steps:
```
1. In the z/OSMF desktop area, click the App Center icon ( ) on the taskbar. The **App Center** window
    opens.
2. Double-click the Software Update icon ( ). The **Software Update** window opens.
Updates are installed on existing software instances. To use the capabilities provided in the Software
Update task, you must have at least one software instance defined. For more information about software
instances and how to define them with the z/OSMF Software Management task, see Defining your
software to z/OSMF
**Useful resources:**
- For a list of terms you might encounter and need to know as you use the Software Update task, see
Terminology.
- For a summary of some basic SMP/E concepts that you might need to understand before you can fully
use all the features that are provided in the Software Update task, see SMP/E concepts.
**Note:** Throughout this information, the term **update** might refer to either an individual update or the
process to install updates.

```
To view the product documentation for any window in the Software Update task, click Help.
For more information about the actions listed on the Software Update window, see Table 1 on page 2.
```
```
Software Update task   1
```

```
Table 1. Actions for the Software Update task
```
```
Action Additional Information
```
```
Start New Software Update “Starting new software updates” on page 2
```
```
View Updates in Progress “Managing in-progress software updates” on page 36, which includes
information about canceling and resuming in-progress update processes
```
```
Show Completed Updates “Viewing completed software updates” on page 40
```
```
Modify Settings “Setting Preferences ” on page 42
```
### Types of software updates

```
Use the Software Update task to install three types of software updates that are each associated with a
particular use case.
Corrective updates
Install corrective software updates to fix a problem. In this situation, you already identified the
individual updates that you must install to fix the particular problem, so you specify each by name
(ID).
Recommended updates
Install software updates that are recommended by the software vendor. The Software Update task
uses the vendor defined source ID to identify recommended updates.
Functional updates
Install functional software updates to support new hardware, software, or function. The Software
Update task identifies the fix categories that are associated with available functional updates. You
then select fix categories to install all contained updates.
```
### Starting new software updates

**Navigation title:** Starting new updates
Follow this process to easily apply updates to existing software instances of installed SMP/E managed
software.

**Before you begin**

```
Important: Ensure that the software that you are updating is not running.
Before you install updates, acquire the updates to receive them into the global zone for the software
instance. For more information about the receive process, see in z/OS SMP/E User's Guide.
```
```
About this task
Complete the following steps to install corrective, recommended, or functional updates on your software
instances.
Important: After you complete a step, you cannot return to it. If you need to make a change in a
previously completed step, cancel and restart the update process.
```
**Procedure**

1. Select the software instance and zone on which you want to install the updates, and the type of update
    to install.
2. Select the updates to install, depending on the update type.
3. Monitor the update preparation.
4. Resolve HOLDs.
5. Monitor the update verification.

**2**   Software Update task


6. Review the pre-installation summary.
7. Monitor the update installation.
8. Resolve any post-installation holds.
9. Review the installation summary.

#### Selecting a software instance and update type

```
The Start New Software Update window is the main window for starting a new software update process.
Here, you select a software instance and zone to update. You also select the type of update to install.
```
**About this task**

```
The Start New Software Update window lists all software instances that are defined in z/OSMF. Clicking
a software instance expands it to display all zones that the software instance includes.
For more information about the values and elements on the Start New Software Update window, see
“Values on the Start New Software Update window” on page 3.
Complete the following steps to select a software instance and zone and select the type of update to
install.
```
**Procedure**

1. In the Software Update task, open the **Start New Software Update** window.
    The **Start New Software Update** window is opened automatically when you first start the Software
    Update task. To access it from elsewhere in the Software Update task, click either the **Start New**
    **Software Update** button or the Software Update link in the breadcrumb trail.
    The **Start New Software Update** window opens.
2. Expand the target software instance and then select the zone that you want to update.
    **Tip:** You can also search the list of software instances, by name, to quickly find the one that you want
    to update.
3. Click the option that corresponds with the type of update that you want to install.
    **Install Corrective**
       Begins the process to install corrective updates on the selected software instance and zone.
    **Install Recommended**
       Begins the process to install recommended updates on the selected software instance and zone.
    **Install Functional**
       Begins the process to install functional updates on the selected software instance and zone.

```
Results
The process to select updates of the chosen type begins and you can continue on to select updates to
install.
```
```
Values on the Start New Software Update window
The Start New Software Update window contains elements and values with which you interact when you
install software updates.
The Start New Software Update window applies to the following tasks:
```
- “Starting new software updates” on page 2
- “Selecting a software instance and update type” on page 3

```
Software Update task   3
```

```
Software Instances and Zones
Search field
Provides a search capability for the list of software instances in the Software Instances and Zones
table. Enter one or more characters of a value in any column except the Zone to filter the list and more
quickly find a software instance. As you type, the list dynamically filters to include only the software
instances with values that match the string.
Software Instances and Zones table
List of software instances and zones from which you select the software instance and zone to update.
You can sort the information for all columns except "Description". The table defaults to displaying 10
items per page. You can change the number of items that are displayed on each page, and you can
toggle between the pages if not all software instances are displayed on one page. Note that the search
functionality queries the entire list of software instances, not just those that are currently displayed.
For more information about the information that is displayed in the Software Instances and Zones
table, see Table 2 on page 4.
```
```
Table 2. Columns in the Software Instances and Zones table
```
```
Column Description
```
```
Name Name of the software instance. When you click a software instance name, it
expands to list the zones in this same column. The name of each zone and when
recommended updates were last installed is displayed.
```
```
System z/OSMF host system that has access to the volumes and data sets where the
software instance resides. For more information about systems, see Defining your
systems to z/OSMF.
```
```
Description Optional description of the software instance. Hover your cursor over the notes
icon ( ) to display the description text.
```
**4**   Software Update task


_Table 2. Columns in the Software Instances and Zones table (continued)_

**Column Description**

**Status** The status of the software instance in relation to its availability for update.

```
Note: If a software instance has more than one applied action, for example both
deploy and export, the Status column lists status values for all active actions.
The following values are possible:
Ready
The software instance is available for you to update.
```
```
Being deployed
The software instance is locked because it is either being deployed or replaced
in a deployment that is in progress. You cannot modify, remove, update, or
deploy the software instance, and you cannot use another deployment to
replace it. If the software instance is being replaced in an active deployment,
you also cannot deploy the software instance.
To complete these actions, wait until the current deployment is completed or
use the z/OSMF Software Management task to cancel it. For more information
about canceling software instance deployments, see Canceling deployments.
```
```
Being exported
The software instance is locked because it is being exported by another user.
You cannot modify, remove, update, or deploy the software instance, and you
cannot use another deployment to replace it.
After the jobs run and the portable copy of the software instance is created, the
export operation is complete.
```
```
Being modified
The software instance is locked because it is being modified by another user.
You cannot modify, remove, update, or deploy the software instance, and you
cannot use another deployment to replace it.
You can use the z/OSMF Software Management task to determine the user ID
of the user who is modifying the software instance and the date and time the
user started modifying it. For more information, see Software Instances page.
For more information about obtaining the lock for the software instance, see
Locking objects in z/OSMF.
```
```
Being updated
The software instance is locked because it is being updated. You cannot start
any other update processes on the software instance until the current update
process completes or is canceled.
You can use the View Updates in Progress window to view details about the
update process and take any additional actions. For more information, see
“Managing in-progress software updates” on page 36.
```
```
Deleting catalog aliases
The software instance is locked because temporary catalog aliases are being
deleted by another user. You cannot modify, remove, update, or deploy the
software instance, and you cannot use another deployment to replace it.
```
```
Workflows being performed
The software instance is locked because workflows are being performed on it
by another user. You cannot modify, remove, update, or deploy the software
instance, and you cannot use another deployment to replace it.
```
```
Software Update task   5
```

```
Table 2. Columns in the Software Instances and Zones table (continued)
```
```
Column Description
```
```
Global zone CSI CSI data set that contains the global zone used to manage the software.
```
```
Categories Categories to which the software instance is assigned.
```
```
Created Date and time the software instance was created.
```
```
Created By User ID of the user who created the software instance.
```
```
Refresh
Refreshes the information that is displayed in the Software Instances and Zones table.
Install Corrective
Begins the process to install corrective updates on the selected software instance and zone.
Install Recommended
Begins the process to install recommended updates on the selected software instance and zone.
Install Functional
Begins the process to install functional updates on the selected software instance and zone.
```
#### Selecting updates to install

```
The steps that you follow to select the updates to install vary depending on what type of updates you are
installing.
```
**About this task**

```
For more information about the different types of software updates, see “Types of software updates” on
page 2.
```
```
Procedure
Complete the appropriate set of steps, depending on the update process that you chose, to select the
updates to install.
Option Description
```
```
Select corrective updates Follow these steps if you chose Install Corrective.
```
```
Select recommended updates Follow these steps if you chose Install Recommended.
```
```
Select functional updates Follow these steps if you chose Install Functional.
```
```
Results
After you follow the steps to select the updates to install, regardless of the type of update, the Preparing
updates window is displayed and you can continue on to monitor the update preparation.
```
```
Selecting corrective updates to install (prior to APAR PH58221)
Complete the following steps to select corrective updates to install.
```
```
About this task
After you click Install Corrective , the Install Updates window opens. Here, you either enter the names of
individual updates that you want to install or upload a list of updates that you want to install.
For more information about the different types of software updates, see “Types of software updates” on
page 2.
```
**6**   Software Update task


For more information about the values and elements on the **Install Updates** window, see “Values on the
Install Updates window” on page 7.

**Procedure**

1. On the **Install Updates** window, ensure that the listed Software Instance and Zone are accurate.
2. Use one of the following two methods to identify the updates to install.
    - Enter Update Names
       a. In the **Enter Update Names** field, enter the full name of the update, for example RO12345, that
          you want to install.
          **Note:** To install more than one update, enter all the names and separate them with commas,
          spaces, or semicolons.
b. When you are done entering names, press **Submit**.
    - Upload list
       a. To use a text file that lists multiple update names, click **Upload list**.
          **Important:** Ensure that the update names in the file are separated by commas, spaces, or
          semicolons, and that the file is no larger than 500KB.
b. Locate and select the desired file. Its contents are loaded into the **Enter Update Names** field.
c. Review the list of updates in the **Enter Update Names** field and make any needed changes.
d. Click **Submit**.
    Software Update retrieves information about the identified updates and displays it in either the Ready
    table or the Not Installable table.
    **Note:** To take additional actions on a listed update, including viewing and exporting its holds, click
    the details icon ( ) and select **Details**. The **Details for Update** window is displayed. For information
    about the values and elements on the **Details for Update** window, see “Values on the Details for
    Update window” on page 9.
3. Optional: Click on **Not Installable** to review the updates in the Not Installable table. Take any needed
    actions to resolve updates that you still want to install and ensure that they move to the Ready table.
4. Click on **Ready** to view the Ready table.
5. Select the updates to install.
    **Tip:** If you want to install all listed updates, click the checkbox in the column header to select all
    updates in the list.
6. Click **Install selected**.
    The update installation process begins.

**Results**
The **Preparing updates** window is displayed and you can continue on to monitor the update preparation.

**_Values on the Install Updates window_**
The **Installing Updates** window contains elements and values with which you interact when you install
software updates.

The **Installing Updates** window applies to the following tasks:

- “Installing updates” on page 29“Selecting corrective updates to install (prior to APAR PH58221) ” on
    page 6

```
Software Update task   7
```

```
Timeline of progress through update process steps
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
**Software Instance, Zone, and Notes**

```
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**Process and Status**

```
Provides status information for the current update process step.
The following elements are included:
Process
The current update process step. On the Installing Updates window, this value is always "Installing
Updates".
Status
The status of the current update process step. The following values are possible:
```
```
Done
The process completed and all selected updates were successfully installed.
```
```
Error occurred short description of error
An error occurred. The error message is displayed. To further identify the error and potential fixes,
click Download full SMP/E output (ZIP file) to download a compressed file of the SMP/E
output from the update process. Additionally, see the Error report section for just the SMPOUT
portion of the SMP/E output from the update process.
```
```
Working
The Software Update task is installing the updates. SMP/E APPLY is running to install the updates
to the software instance.
```
```
Error report
If an error occurs, provides the SMPOUT portion of the SMP/E output from the update process. To see
more information in the field, click within the field and then click Show more. Optionally, click the copy
icon ( ) to copy the entire contents of the error report to the clipboard so you can paste it elsewhere.
```
**8**   Software Update task


**Window actions**

**Save and Exit**
Saves progress on the update process through the current step. The step window closes and you
return to the **Start New Software Update** window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.

**Next**
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.

**_Values on the Details for Update window_**
The **Details for Update** window contains elements and values with which you interact when you install
software updates.

The **Details for Update** window applies to the following tasks:

- “Selecting corrective updates to install (prior to APAR PH58221) ” on page 6

**Update Details**

The **Details for Update** window displays general information about the selected update.

**Update Name and Status**
Displays the name and status of the update for which details are displayed.

**Additional information**
Displays general information about the update, if available. If an update does not contain additional
details, "No additional information is available for this Update." is displayed.
**Tips:**

- Click the copy icon ( ) to copy all the text of the details.
- Click **Show less code** to minimize the amount of text that is displayed.

```
Download full SMP/E output (ZIP file)
Clicking this link downloads a compressed file of the SMP/E output from the query.
```
**HOLDs**

When selected, the **Details for Update** window displays information about each of the holds that are
associated with the update.

**Search field**
Provides a search capability for the list of holds in the table. Enter one or more characters of a value in
any column to filter the list and more quickly find a hold.
**Note:** The hold text is not included in the search.
As you type, the list dynamically filters to include only the holds with values that match the string.

**HOLDs table**

Displays information about each of the holds that are associated with the update. Each hold is listed on a
separate row. Click the row for a hold to display the hold information.

```
Software Update task   9
```

```
Table 3. Columns in the HOLDs table
```
```
Column Description
```
```
Type The hold type of the hold. The following values are possible:
```
- ERROR
- FIXCAT
- SYSTEM
- USER
For more information about hold types see in _z/OS SMP/E Reference_.

```
Reason The provider-defined reason value for the hold.
For the list of possible reason values used by IBM® and more information about
each value, see in z/OS SMP/E Reference.
```
```
FMID The FMID associated with the hold.
```
```
Update Name The name of the update that is associated with the hold.
```
```
Window actions
Close
Returns you to the Install Updates window.
```
```
Selecting corrective updates to install
Complete the following steps to select corrective updates to install.
```
```
About this task
After you click Install Corrective , the Software Updates window opens. z/OSMF displays a list of
software updates from which you can select one or more updates to install.
For more information about the values and elements on the Software Updates window, see “Values on the
Software Updates window” on page 11.
```
**Procedure**

1. On the **Software Updates** window, z/OSMF analyzes the global zone and selected target zone for the
    software instance and displays the list of software updates which are:
    - Received in the global zone
    - Applicable to the target zone
    - Not yet installed in the target zone
    If a software update is not received in the global zone, or not applicable to the selected target zone, or
    already installed in the selected target zone, then that software update is not displayed.
2. Optional: To take additional actions on a listed update, which includes viewing and exporting its
    HOLDs, click the details icon (...) and select **Details**. The **Details for Update window** is displayed.
    For information about the values and elements on the Details for Update window, see “Values on the
    Details for Update window” on page 12.
3. Select the updates to install.
4. Click **Install selected**. The update installation process begins.

```
Results
The Preparing updates window is displayed and you can continue on to monitor the update preparation.
```
**10**   Software Update task


**_Values on the Software Updates window_**
The **Software Updates** window contains elements and values with which you interact when you install
software updates.

The **Software Updates** window applies to the following tasks:

- “Selecting corrective updates to install ” on page 10

**Software Instance and Zone**

Displays the name of the software instance and zone on which Software Update installs the updates. The
following elements are included:

**Software Instance**
Name of the software instance on which the update process will run.

**Zone**
Name of the software instance zone on which the update process will run.

**Software Updates table**

Lists the software updates you can select to install. z/OSMF analyzes the global zone and selected target
zone for the software instance and displays the list of software updates which are:

- Received in the global zone
- Applicable to the target zone
- Not yet installed in the target zone

If a software update is not received in the global zone, or not applicable to the selected target zone, or
already installed in the selected target zone, then the software update is not displayed.

**Search field**

```
Provides a search capability for the columns in the table. Enter one or more characters to filter the list
and more quickly find updates. As you type, the list dynamically filters to include only the rows with a
column value that matches the typed string.
```
**Install selected**

```
The Install selected action appears after you select at least one update. After you select all the
updates that you want to install, click Install selected to begin the installation process.
```
You can sort the information for all columns. For more information about the columns that are displayed
in the Software Updates table, see Table 4 on page 11.

```
Table 4. Columns in the Software Updates table
```
```
Column Description
```
```
Update Name The name of the update.
```
```
SYSMOD Type The SYSMOD type for the update: APAR, PTF, or
USERMOD.
```
```
FMID The FUNCTION Modification Identifier (FMID) for
the update. This is the function SYSMOD to which
the update is applicable.
```
```
FMID Description The short description of the FMID for the update.
This value is optional and displayed only when
the FUNCTION SYSMOD contains a DESCRIPTION
subentry.
```
```
Software Update task   11
```

```
Table 4. Columns in the Software Updates table (continued)
```
```
Column Description
```
```
Source IDs The source identifiers assigned to the update, if
any. The source IDs can indicate where or how
the update was acquired, whether the update is
recommended by the vendor and when, or the
categories to which this update belongs. Source
IDs may be defined and assigned by a vendor, the
consumer, and SMP/E.
```
```
Rework May indicate the date when the update was
published. This value is optional and displayed only
when the SYSMOD contains a REWORK subentry.
For IBM updates the rework value will be of the
form “yyyyddd” where “yyyy” is the year and “ddd”
is the Julian date when the update was published.
```
```
System HOLDs The reason ID for SYSTEM type HOLDs contained
in the update, if any. System type HOLDs may
describe actions which must be considered or
taken when the update is installed, updates to
related documentation, dependencies on or for the
update, or new function introduced by the update.
You can click the details icon (...) and select Details
to display the full text of the SYSTEM HOLDs.
```
```
SYSMOD Description The short description of the update. This value
is optional and displayed only when the SYSMOD
contains a DESCRIPTION subentry.
```
```
Receive Date The date and time the update was received into the
global zone.
```
```
Window actions
Cancel
Closes the Software Updates window and returns you to the Start New Software Update window.
```
```
Values on the Details for Update window
The Details for Update window contains elements and values with which you interact when you install
software updates.
The Details for Update window applies to the following tasks:
```
- “Selecting corrective updates to install ” on page 10

**Update Details**

```
The Details for Update window displays general information about the selected update.
Update Name and Status
Displays the name and status of the update for which details are displayed.
Additional information
Displays general information about the update, if available. If an update does not contain additional
details, "No additional information is available for this Update." is displayed.
Tips:
```
- Click the copy icon ( ) to copy all the text of the details.

**12**   Software Update task


- Click **Show less code** to minimize the amount of text that is displayed.

```
Download full SMP/E output (ZIP file)
Clicking this link downloads a compressed file of the SMP/E output from the query.
```
```
HOLDs
When selected, the Details for Update window displays information about each of the holds that are
associated with the update.
Search field
Provides a search capability for the list of holds in the table. Enter one or more characters of a value in
any column to filter the list and more quickly find a hold.
Note: The hold text is not included in the search.
As you type, the list dynamically filters to include only the holds with values that match the string.
```
**HOLDs table**

```
Displays information about each of the holds that are associated with the update. Each hold is listed on a
separate row. Click the row for a hold to display the hold information.
```
_Table 5. Columns in the HOLDs table_

**Column Description**

**Type** The hold type of the hold. The following values are possible:

- ERROR
- FIXCAT
- SYSTEM
- USER
For more information about hold types see in _z/OS SMP/E Reference_.

**Reason** The provider-defined reason value for the hold.

```
For the list of possible reason values used by IBM and more information about
each value, see in z/OS SMP/E Reference.
```
**FMID** The FMID associated with the hold.

**Update Name** The name of the update that is associated with the hold.

```
Window actions
Close
Returns you to the Install Updates window.
```
```
Selecting recommended updates to install (prior to APAR PH58221)
Complete the following steps to install recommended updates that are available.
```
```
About this task
After you click Install Recommended , the Finding Updates window opens. Here, Software Update looks
for available recommended updates for the selected software instance and zone. You can then choose to
install all recommended updates that are available.
Recommended software updates are identified using source IDs. The following source IDs are currently
used by IBM and other software vendors to identify recommended software updates:
```
```
Software Update task   13
```

##### • CAR*

##### • HIPER

##### • PRP

##### • RSL*

##### • RSU*

##### • SECINT

```
For more information about source IDs, see in z/OS SMP/E Reference.
For more information about the different types of software updates, see “Types of software updates” on
page 2.
For more information about the values and elements on the Finding Updates window, see “Values on the
Finding Updates window” on page 14.
```
**Procedure**

1. On the **Finding Updates** window, wait for the Software Update task to determine whether
    recommended updates are available for your selected software instance and zone.
2. Choose the following set of steps that depend on whether recommended updates are available:
    **Note:** If an error occurs, use the provided SMP/E output information to fix the error, then click **Retry** to
    retry the search for recommended updates.
    - Recommended updates are available.
       When recommended updates are found, click **Next** to install all the updates.
    - Recommended updates are not available.
       If no recommended updates are found, click **Cancel** to return to the main Software Update window.

```
Results
If recommended updates are available and you selected to continue, the Preparing updates window is
displayed. You can continue on to monitor the update preparation.
```
```
Values on the Finding Updates window
The Finding Updates window contains elements and values with which you interact when you install
software updates.
The Finding Updates window applies to the following tasks:
```
- “Selecting recommended updates to install (prior to APAR PH58221)” on page 13

```
Software Instance and Zone
Displays the name of the software instance and zone on which Software Update installs the updates. The
following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
```
**Status**

```
The status of the process to find recommended updates. The following values are possible:
```
```
Finding Updates failed
An error occurred during the action of finding updates.
```
**14**   Software Update task


```
No updates were found to satisfy the selection criteria for recommended updates.
No recommended updates were found. The field also provides more information about how to
continue to identify and install recommended updates.
```
**Recommended updates have been found and are ready to be installed. Click "Next" to install the
updates.**
Recommended updates were found and you can install them.

```
Working
The Software Update task is searching for recommended updates.
```
The following actions are available:

**Retry**
If an error occurs and you make changes to fix the error, click **Retry** to retry the process to find
recommended updates.

```
Download full SMP/E output (ZIP file)
Clicking this link downloads a compressed file of the SMP/E output from the update process. The
SMP/E output is especially valuable when debugging update process errors.
```
**Error report**

If an error occurs, provides the SMPOUT portion of the SMP/E output from the update process. To see
more information in the field, click within the field and then click **Show more**. Optionally, click the copy

icon ( ) to copy the entire contents of the error report to the clipboard so you can paste it elsewhere.

**Window actions**

**Cancel**
If no recommended updates are found or an error occurred, click **Cancel** to close the **Finding
Updates** window and return to the **Start New Software Update** window.

**Next**
If recommended updates are found, click **Next** to continue with the installation of the updates.

**Selecting recommended updates to install**

Complete the following steps to select to install any recommended updates.

**About this task**
After you click **Install Recommended** , the **Source IDs** for Recommended Updates window opens. z/
OSMF displays a list of source IDs, which have been assigned to updates that are available to be installed.
You can select one or more source IDs to install all updates that are assigned to those source IDs.

For more information about the values and elements on the **Source IDs** for Recommended Updates
window, see “Values on the Source IDs for Recommended Updates window” on page 16.

**Procedure**

1. On the **Source IDs** for Recommended Updates window, z/OSMF analyzes the global zone and selected
    target zone for the software instance and displays the list of source IDs assigned to software updates
    which are:
    - Received in the global zone
    - Applicable to the target zone
    - Not yet installed in the target zone

```
Software Update task   15
```

```
If a software update is not received in the global zone, or not applicable to the selected target zone,
or already installed in the selected target zone, then source IDs for that software update are not
displayed.
```
2. Select the source IDs to install all updates that are assigned to those source IDs.
3. Click **Install selected**.
    The update installation process begins.

```
Results
The Preparing updates window is displayed. You can continue on to monitor the update preparation.
```
```
Values on the Source IDs for Recommended Updates window
The Source IDs for Recommended Updates window contains elements and values which you interact
when you install software updates.
The Source IDs for Recommended Updates window applies to the following tasks:
```
- “Selecting recommended updates to install ” on page 15

**Software Instance and Zone**

```
Displays the name of the software instance and zone on which Software Update installs the updates. The
following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
```
```
Source IDs table
Lists the source IDs assigned to software updates you can install. z/OSMF analyzes the global zone and
selected target zone for the software instance and displays the list of source IDs assigned to software
updates which are:
```
- Received in the global zone
- Applicable to the target zone
- Not yet installed in the target zone
If a software update is not received in the global zone, or not applicable to the selected target zone, or
already installed in the selected target zone, then source IDs for the software update are not displayed.
When the Source IDs for Recommended Updates window is initially displayed, Software Update
automatically selects the source IDs which identify vendor recommended software updates. The
following source IDs are currently used by IBM® and other software vendors to identify recommended
software updates:
- CAR*
- HIPER
- PRP
- RSL*
- RSU*
- SECINT
You may unselect any of the pre-selected source IDs or select additional source IDs from the list based
on your preferences for identifying recommended updates to install.

**16**   Software Update task


**Search field**
Provides a search capability for the columns in the table. Enter one or more characters to filter the list
and more quickly find source IDs. As you type, the list dynamically filters to include only the rows with
a column value that matches the typed string.

**Install Selected**

```
The Install selected action appears after you select at least one source ID. After you select all source
IDs assigned to the updates that you want to install, click Install selected to begin the installation
process.
```
You can sort the information for all columns. For more information about the columns that are displayed
in the Source IDs table, see Table 6 on page 17.

```
Table 6. Columns in the Source IDs table
```
```
Column Description
```
```
Source ID The source identifiers (IDs) assigned to one or
more updates. The source IDs can indicate where
or how updates were acquired, whether updates
are recommended by the vendor and when, or
the categories of updates. Source IDs may be
defined and assigned by a vendor, the consumer,
and SMP/E.
```
```
Number of Updates The number of updates assigned to the source ID.
```
**Window actions**

**Cancel**
Closes the Source IDs window and returns you to the **Start New Software Update** window.

**Selecting functional updates to install**

Complete the following steps to select a functional update (fix) category to install its associated software
updates.

**About this task**
After you click **Install Functional** , the **Fix Categories for Functional Updates** window opens. Here,
Software Update looks for available functional updates for the selected software instance and zone and
displays the fix categories that contain available updates.

For more information about the different types of software updates, see “Types of software updates” on
page 2.

For more information about the values and elements on the **Fix Categories for Functional Updates**
window, see “Values on the Fix Categories for Functional Updates window” on page 18.

**Procedure**

1. On the **Fix Categories for Functional Updates** window, ensure that the listed Software Instance and
    Zone are accurate.
2. Wait for the Software Update task to determine whether functional updates are available for your
    selected software instance and zone.
3. Choose the following set of steps that depend on whether functional updates are available:
    - Functional updates are available.
       When functional updates are found, their fix categories are listed in the Fix Categories table.
       Complete the following steps to start installation:

```
Software Update task   17
```

```
a. In the Fix Categories table, locate a category by scrolling through or searching the list.
b. Select the one or more fix categories that contain updates that you want to install. The Software
Update task will install all available updates in each selected fix category.
Tip: If you want to install updates for all listed fix categories, click the checkbox in the column
header to select all fix categories in the list.
c. Click Install selected. The update installation process begins.
```
- Functional updates are not available.
    If no functional updates are found, click **Cancel** to return to the main Software Update window.

```
Results
If functional updates are available and you clicked Install selected , the Preparing updates window is
displayed and you can continue on to monitor the update preparation.
```
```
Values on the Fix Categories for Functional Updates window
The Fix Categories for Functional Updates window contains elements and values with which you
interact when you install software updates.
The Fix Categories for Functional Updates window applies to the following tasks:
```
- “Selecting functional updates to install” on page 17

**Software Instance and Zone**

```
Displays the name of the software instance and zone on which Software Update installs the updates. The
following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
```
```
List of fix categories
Search field
Provides a search capability for the list of fix categories in the table. Enter one or more characters of a
fix category name to filter the list and more quickly find a fix category. As you type, the list dynamically
filters to include only the fix categories with names that match the string.
Install selected
Install selected appears after you select at least one fix category. After you select all the fix
categories that contain updates that you want to install, click Install selected to begin the installation
process.
List of fix categories table
List of fix categories that contain available functional updates. Select the categories that contain
updates that you want to install.
```
```
Window actions
Cancel
Cancels the process of installing functional updates and returns you to the main Software Update
window.
```
**18**   Software Update task


#### Preparing updates

```
The Preparing Updates window shows the status of the process to prepare updates for installation. Use it
to monitor update preparation.
```
```
About this task
On the Preparing Updates window, the Software Update task shows the status of its work to prepare the
updates for installation. This preparation involves ensuring that there are no missing requisite software
updates and analyzing the software updates to determine the holds that you need to review.
For more information about the values and elements on the Preparing Updates window, see “Values on
the Preparing Updates window” on page 19.
Complete the following steps to monitor the preparation of software updates for installation.
```
**Procedure**

1. Use one of the following two methods to display the **Preparing Updates** window:
    - If you are starting a new update:
       a. In the Software Update task, click **Start New Software Update**. The **Start New Software**
          **Update** window opens.
b. Progress through the update process steps until this window is displayed.
    - If you are resuming an update process and this step is the one on which you left off:
       a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
          window opens.
b. Select the update process and click **Resume Update**. The **Resume update in progress** window
opens.
       c. On the **Resume update in progress** window, click **Resume**. This window is displayed.
    **Note:** At any point in the processing of this step, you can optionally add brief notes to the update
    process. Use the notes to, for example, track questions that are generated during the process or
    comments about it that you want to reference later. You can view and update the notes for an update
    process during any step of the update process. The current notes are displayed in the **Software**
    **instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Wait for update preparation to complete.
3. When the preparation is complete, click **Next** to continue with the update process.

```
Results
The Resolve HOLDs window is displayed and you can continue on to resolve holds.
```
```
Values on the Preparing Updates window
The Preparing Updates window contains elements and values with which you interact when you install
software updates.
The Preparing Updates window applies to the following tasks:
```
- “Preparing updates” on page 19

**Timeline of progress through update process steps**

```
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
```
Software Update task   19
```

```
Software Instance, Zone, and Notes
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**Process and Status**

```
Provides status information for the current update process step.
The following elements are included:
Process
The current update process step. On the Preparing Updates window, this value is always "Preparing
Updates".
Status
The status of the current update process step. The following values are possible:
```
```
Done
The process completed and no holds were found.
```
```
Error occurred short description of error
An error occurred. The error message is displayed. To further identify the error and potential fixes,
click Download full SMP/E output (ZIP file) to download a compressed file of the SMP/E
output from the update process. Additionally, see the Error report section for just the SMPOUT
portion of the SMP/E output from the update process.
```
```
New HOLDs Found
The process completed and holds were found. You will review them during the next step of the
update process.
```
```
Working
The Software Update task is preparing the updates. SMP/E APPLY CHECK is running to determine
whether there are any missing requisites and identify the holds that you will review in the next
step of the updates process.
```
**Error report**

```
If an error occurs, provides the SMPOUT portion of the SMP/E output from the update process. To see
more information in the field, click within the field and then click Show more. Optionally, click the copy
icon ( ) to copy the entire contents of the error report to the clipboard so you can paste it elsewhere.
```
**20**   Software Update task


```
Window actions
Cancel
Cancels the software update process and returns you to the Start New Software Update window.
The Cancel Software Update warning window is displayed, on which you click Cancel to return to the
process or OK to confirm the process cancellation.
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
#### Resolving HOLDs

```
The Resolve HOLDs window lists all holds that require resolution for the selected updates so that you can
choose which action to take on each.
```
```
About this task
On the Resolve HOLDs window, all holds that require resolution for the selected updates are listed for
you to review and act upon. The holds might be associated with the selected updates or other related
updates. For more information about holds, see in z/OS SMP/E Reference.
For more information about the values and elements on the Resolve HOLDs window, see “Values on the
Resolve HOLDs window” on page 22.
Complete the following steps to review holds and act upon them.
```
**Procedure**

1. Use one of the following two methods to display the **Resolve HOLDs** window:
    - If you are starting a new update:
       a. In the Software Update task, click **Start New Software Update**. The **Start New Software**
          **Update** window opens.
b. Progress through the update process steps until this window is displayed.
    - If you are resuming an update process and this step is the one on which you left off:
       a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
          window opens.
b. Select the update process and click **Resume Update**. The **Resume update in progress** window
opens.
       c. On the **Resume update in progress** window, click **Resume**. This window is displayed.
    **Note:** At any point in the processing of this step, you can optionally add brief notes to the update
    process. Use the notes to, for example, track questions that are generated during the process or
    comments about it that you want to reference later. You can view and update the notes for an update
    process during any step of the update process. The current notes are displayed in the **Software**
    **instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Click **Unresolved** to display the list of unresolved holds that require your attention.
3. Locate a specific hold by scrolling through the list, searching the list, or selecting one or more of the
    supplied filters to refine the list.
4. Expand the hold and review its contents.
5. Take one of the following actions on the hold that depends on when and whether you want to resolve
    it.

```
Software Update task   21
```

```
Tip: If you want to take the same action on all listed holds, click the checkbox in the column header to
select all holds in the list.
```
- To resolve the hold immediately, review its contents, complete any necessary actions, and then
    click **Resolve HOLD**. The hold moves to the **Resolved** list.
- To commit to resolve the hold after installation of the update, click **Resolve HOLD after**
    **installation**. The hold moves to the **Resolve after installation** list and the Software Update task
    will remind you of the hold after the update is installed.
- If the hold contains actions that you choose to not complete during the update installation process
    and you choose to exclude the update, click **Exclude Update from installation**. The hold moves to
    the **Excluded** list.
6. Continue processing unresolved holds until the **Unresolved** list contains zero holds.
7. Optional: Click each list title to review the holds on each of the **Resolved** , **Resolve after installation** ,
and **Excluded** lists.
If a hold has an incorrect resolution value and is on the wrong list, you can change its resolution value
and move it to the correct list. Every list provides buttons that you can click to change one or more
holds to any of the other three resolution values after you take the needed action on the hold.
8. Click **Next**.

```
Results
The Verifying Updates window is displayed and you can continue on to monitor the update verification.
```
```
Values on the Resolve HOLDs window
The Resolve HOLDs window contains elements and values with which you interact when you install
software updates.
The Resolve HOLDs window applies to the following tasks:
```
- “Resolving HOLDs” on page 21

```
Timeline of progress through update process steps
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
**Software Instance, Zone, and Notes**

```
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**22**   Software Update task


**Unresolved, Resolved, Resolve after Installation, Excluded lists**

List all holds of the selected resolution type that require resolution for the selected updates. Click each
of the **Unresolved** , **Resolved** , **Resolve after installation** , and **Excluded** list titles to list all holds of the
selected resolution type in the table. The title of the list also displays the number of holds that are in the
list. You can filter the list by hold type or reason, search the list, and export the holds to a text file. When
holds are selected, you can act on the holds.

**Filter by Type**
Provides you with the ability to filter holds based on the hold type value. The following hold type
values are available:

- ERROR
- FIXCAT
- SYSTEM
- USER
Each hold type filter also displays the number of holds of that hold type that are in the list. If no holds
of a certain hold type are in the list, that hold type filter is disabled.
For more information about hold types see in _z/OS SMP/E Reference_.

**Filter by Reason**
Provides the ability to filter holds based on the hold reason value. A reason filter is available only if
one or more holds with that reason value are in the list. Each reason filter also displays the number of
holds with that reason value that are in the list.
For the list of possible reason values used by IBM and more information about each value, see in _z/OS
SMP/E Reference_.

**Reset all filters**
Resets all filters to not selected so that the list of holds is complete and not filtered.

**Search field**
Provides a search capability for the list of holds in the table. Enter one or more characters of a value in
any column to filter the list and more quickly find a hold.
**Note:** The hold text is not included in the search.
As you type, the list dynamically filters to include only the holds with values that match the string.

**Export**
Downloads a text file of all holds in the list. Any holds that you filtered out of the list are not included
in the exported content.

**HOLDs table**
Lists all holds that require resolution for the selected updates. Only the holds of the selected
resolution type, for example unresolved or resolved, are displayed. The list is filtered for any filters
that you selected and matches any search criteria that you entered. You can sort the information for
all columns.
For more information about the information that is displayed in the HOLDs table, see Table 7 on page
24.

```
Software Update task   23
```

```
Table 7. Columns in the HOLDs table
```
```
Column Description
```
```
Type The hold type of the hold. The following values are possible:
```
- ERROR
- FIXCAT
- SYSTEM
- USER
For more information about hold types see in _z/OS SMP/E Reference_.

```
Reason The provider-defined reason value for the hold.
For the list of possible reason values used by IBM and more information about
each value, see in z/OS SMP/E Reference.
```
```
FMID The FMID associated with the hold.
```
```
Update Name The name of the update that is associated with the hold.
```
```
To change the resolution of a hold in the list, select the hold and then click the action that you want
to take. Three of the following four actions are available, depending on the resolution type that is
displayed:
Exclude Update from Installation
Changes the resolution value of the hold to excluded, which means that the associated update is
excluded from the update process, and moves the hold to the Excluded list.
Resolve Hold
Changes the resolution value of the hold to resolved and moves it to the Resolved list.
Resolve Hold after Installation
Changes the resolution value of the hold to resolve after installation and moves it to the Resolve
after installation list.
Unresolve
Changes the resolution value of the hold to unresolved and moves it to the Unresolved list.
```
```
Window actions
Cancel
Cancels the software update process and returns you to the Start New Software Update window.
The Cancel Software Update warning window is displayed, on which you click Cancel to return to the
process or OK to confirm the process cancellation.
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
**24**   Software Update task


#### Verifying updates

```
The Verifying Updates window shows the status of the process to verify your hold resolution choices for
the selected updates. Use it to monitor the process.
```
```
About this task
On the Verifying Updates window, the Software Update task shows the status of its work to ensure that
there are no missing requisite software updates, based on your hold resolution choices.
For more information about the values and elements on the Verifying Updates window, see “Values on
the Verifying Updates window” on page 25.
Complete the following steps to monitor the verification of the hold resolution choices for the selected
updates.
```
**Procedure**

1. Use one of the following two methods to display the **Verifying Updates** window:
    - If you are starting a new update:
       a. In the Software Update task, click **Start New Software Update**. The **Start New Software**
          **Update** window opens.
b. Progress through the update process steps until this window is displayed.
    - If you are resuming an update process and this step is the one on which you left off:
       a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
          window opens.
b. Select the update process and click **Resume Update**. The **Resume update in progress** window
opens.
       c. On the **Resume update in progress** window, click **Resume**. This window is displayed.
    **Note:** At any point in the processing of this step, you can optionally add brief notes to the update
    process. Use the notes to, for example, track questions that are generated during the process or
    comments about it that you want to reference later. You can view and update the notes for an update
    process during any step of the update process. The current notes are displayed in the **Software**
    **instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Wait for verification to complete.
3. When the verification is complete, click **Next** to continue with the update process.

```
Results
The Pre-install Summary window is displayed and you can continue on to review the pre-installation
summary.
```
```
Values on the Verifying Updates window
The Verifying Updates window contains elements and values with which you interact when you install
software updates.
The Verifying Updates window applies to the following tasks:
```
- “Verifying updates” on page 25

**Timeline of progress through update process steps**

```
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
```
Software Update task   25
```

```
Software Instance, Zone, and Notes
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**Process and Status**

```
Provides status information for the current update process step.
The following elements are included:
Process
The current update process step. On the Verifying Updates window, this value is always "Verifying
Updates".
Status
The status of the current update process step. The following values are possible:
```
```
Done
The process completed and all hold resolution choices for the selected updates were successfully
verified.
```
```
Error occurred short description of error
An error occurred. The error message is displayed. To further identify the error and potential fixes,
click Download full SMP/E output (ZIP file) to download a compressed file of the SMP/E
output from the update process. Additionally, see the Error report section for just the SMPOUT
portion of the SMP/E output from the update process.
```
```
Working
The Software Update task is verifying the updates. SMP/E APPLY CHECK is running with your hold
resolution choices to ensure that there are no missing requisites.
```
**Error report**

```
If an error occurs, provides the SMPOUT portion of the SMP/E output from the update process. To see
more information in the field, click within the field and then click Show more. Optionally, click the copy
icon ( ) to copy the entire contents of the error report to the clipboard so you can paste it elsewhere.
```
```
Window actions
Cancel
Cancels the software update process and returns you to the Start New Software Update window.
The Cancel Software Update warning window is displayed, on which you click Cancel to return to the
process or OK to confirm the process cancellation.
```
**26**   Software Update task


```
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
#### Reviewing the pre-installation summary

```
The Pre-install Summary window summarizes the installation status of the updates.
```
```
About this task
On the Pre-install Summary window, all updates that are selected for installation or were excluded from
the installation are listed for you to review. Until this point in the update installation process, no updates
are installed. If you continue after this step, your software instance will be updated.
For more information about the values and elements on the Pre-install Summary window, see “Values on
the Pre-install Summary window” on page 28.
Complete the following steps to review the pre-installation summary.
```
**Procedure**

1. Use one of the following two methods to display the **Pre-install Summary** window:
    - If you are starting a new update:
       a. In the Software Update task, click **Start New Software Update**. The **Start New Software**
          **Update** window opens.
b. Progress through the update process steps until this window is displayed.
    - If you are resuming an update process and this step is the one on which you left off:
       a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
          window opens.
b. Select the update process and click **Resume Update**. The **Resume update in progress** window
opens.
       c. On the **Resume update in progress** window, click **Resume**. This window is displayed.
    **Note:** At any point in the processing of this step, you can optionally add brief notes to the update
    process. Use the notes to, for example, track questions that are generated during the process or
    comments about it that you want to reference later. You can view and update the notes for an update
    process during any step of the update process. The current notes are displayed in the **Software**
    **instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Locate a specific update by scrolling through the list, searching the list, or selecting one or more of the
    supplied filters to refine the list.
3. Review all the updates to ensure that you are satisfied with the installation status for each update.
    **Note:** If you need to change the installation status for any updates, click **Cancel** to cancel the update
    process. You can then start a new update process.
4. Click **Next** to install the updates that are slated for installation.

```
Results
The Installing Updates window is displayed and you can continue on to monitor the update installation.
```
```
Software Update task   27
```

```
Values on the Pre-install Summary window
The Pre-install Summary window contains elements and values with which you interact when you install
software updates.
The Pre-install Summary window applies to the following tasks:
```
- “Reviewing the pre-installation summary” on page 27

**Timeline of progress through update process steps**

```
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
```
Software Instance, Zone, and Notes
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**Updates to be installed**

```
Lists all updates that will be installed or excluded from the installation.
Filter by Installation Status
Provides the ability to filter updates based on the installation status value. The following values are
available:
Excluded
The Software Update task will not install the update because it or one of its requisites was
excluded from the update installation process.
Will be installed
The Software Update task will install the update.
Will be installed (satisfies dependencies)
The Software Update task will install the update because a selected update depends on it.
Search field
Provides a search capability for the list of updates in the table. Enter one or more characters of a value
in any column to filter the list and more quickly find an update. As you type, the list dynamically filters
to include only the updates with values that match the string.
```
```
Export
Downloads a text file of all updates in the list. Any updates that you filtered out of the list are not
included in the exported content.
```
**28**   Software Update task


```
Updates to be installed table
Lists all updates to be installed or excluded from the update installation process. The list is filtered
for any filters that you selected and matches any search criteria that you entered. You can sort the
information for all columns.
For more information about the information that is displayed in the Updates to be installed table, see
Table 8 on page 29.
```
```
Table 8. Updates to be installed table
```
```
Column Description
```
```
Update Name The name of the update.
```
```
Installation status The installation status of the update. The following values are possible:
Excluded
The Software Update task will not install the update because it or one of its
requisites was excluded from the update installation process.
Will be installed
The Software Update task will install the update.
Will be installed (satisfies dependencies)
The Software Update task will install the update because a selected update
depends on it.
```
```
Window actions
Cancel
Cancels the software update process and returns you to the Start New Software Update window.
The Cancel Software Update warning window is displayed, on which you click Cancel to return to the
process or OK to confirm the process cancellation.
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
#### Installing updates

```
The Installing Updates window shows the status of the process to install updates. Use it to monitor
update installation.
```
```
About this task
On the Installing Updates window, the Software Update task shows the status of its work to install the
selected updates on the selected software instance.
For more information about the values and elements on the Installing Updates window, see “Values on
the Install Updates window” on page 7.
Complete the following steps to monitor the installation of the chosen software updates.
```
**Procedure**

1. Use one of the following two methods to display the **Installing Updates** window:
    - If you are starting a new update:

```
Software Update task   29
```

```
a. In the Software Update task, click Start New Software Update. The Start New Software
Update window opens.
b. Progress through the update process steps until this window is displayed.
```
- If you are resuming an update process and this step is the one on which you left off:
    a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
       window opens.
b. Select the update process and click **Resume Update**. This window is displayed.
**Note:** At any point in the processing of this step, you can optionally add brief notes to the update
process. Use the notes to, for example, track questions that are generated during the process or
comments about it that you want to reference later. You can view and update the notes for an update
process during any step of the update process. The current notes are displayed in the **Software
instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Wait for the update installation process to complete.
3. When the installation is complete, click **Next** to continue with the update process.

```
Results
The Review Post-installation HOLDs window is displayed and you can continue on to resolve any post-
installation holds.
```
```
Values on the Install Updates window
The Installing Updates window contains elements and values with which you interact when you install
software updates.
The Installing Updates window applies to the following tasks:
```
- “Installing updates” on page 29“Selecting corrective updates to install (prior to APAR PH58221) ” on
    page 6

```
Timeline of progress through update process steps
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
**Software Instance, Zone, and Notes**

```
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
Notes
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.
Edit Notes
Provides the ability to create or update the notes that are displayed under Notes.
```
**Process and Status**

```
Provides status information for the current update process step.
```
**30**   Software Update task


```
The following elements are included:
Process
The current update process step. On the Installing Updates window, this value is always "Installing
Updates".
Status
The status of the current update process step. The following values are possible:
```
```
Done
The process completed and all selected updates were successfully installed.
```
```
Error occurred short description of error
An error occurred. The error message is displayed. To further identify the error and potential fixes,
click Download full SMP/E output (ZIP file) to download a compressed file of the SMP/E
output from the update process. Additionally, see the Error report section for just the SMPOUT
portion of the SMP/E output from the update process.
```
```
Working
The Software Update task is installing the updates. SMP/E APPLY is running to install the updates
to the software instance.
```
**Error report**

```
If an error occurs, provides the SMPOUT portion of the SMP/E output from the update process. To see
more information in the field, click within the field and then click Show more. Optionally, click the copy
icon ( ) to copy the entire contents of the error report to the clipboard so you can paste it elsewhere.
```
```
Window actions
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
#### Resolving post-installation holds

```
The Review Post-installation HOLDs window lists all holds that you chose to resolve after the updates
are installed so that you can review and resolve each.
```
```
About this task
On the Review Post-installation HOLDs window, all holds that you chose to resolve after the updates are
installed are listed for you to review and act upon. For more information about holds, see in z/OS SMP/E
Reference.
For more information about the values and elements on the Review Post-installation HOLDs window,
see “Values on the Review Post-installation HOLDs window” on page 32.
Complete the following steps to review post-installation holds and act upon them.
```
**Procedure**

1. Use one of the following two methods to display the **Review Post-installation HOLDs** window:
    - If you are starting a new update:
       a. In the Software Update task, click **Start New Software Update**. The **Start New Software**
          **Update** window opens.

```
Software Update task   31
```

```
b. Progress through the update process steps until this window is displayed.
```
- If you are resuming an update process and this step is the one on which you left off:
    a. In the Software Update task, click **View Updates in Progress**. The **View Updates in Progress**
       window opens.
b. Select the update process and click **Resume Update**. This window is displayed.
**Note:** At any point in the processing of this step, you can optionally add brief notes to the update
process. Use the notes to, for example, track questions that are generated during the process or
comments about it that you want to reference later. You can view and update the notes for an update
process during any step of the update process. The current notes are displayed in the **Software
instance, Zone, and Notes** section, under **Notes**. Click **Edit Notes** to update the notes.
2. Click **Unresolved** to display the list of unresolved holds that require your attention.
3. Locate a specific hold by scrolling through the list, searching the list, or selecting one or more of the
supplied filters to refine the list.
4. Expand the hold and review its contents.
5. For each unresolved hold, review its contents, complete any necessary actions, and then click **Resolve
HOLD**.
**Tip:** If you want to resolve all listed holds, click the checkbox in the column header to select all holds
in the list and then click **Resolve HOLD**.
The hold moves to the **Resolved** list.
6. Continue processing unresolved holds until the **Unresolved** list contains zero holds.
7. Click **Next**.

```
Results
The Installation Summary window is displayed and you can continue on to review the installation
summary.
Note: After you complete this step, the update moves from the View Updates in Progress window to the
Completed Updates window. For more information, see “Viewing completed software updates” on page
40.
```
```
Values on the Review Post-installation HOLDs window
The Review Post-installation HOLDs window contains elements and values with which you interact when
you install software updates.
The Review Post-installation HOLDs window applies to the following tasks:
```
- “Resolving post-installation holds” on page 31

```
Timeline of progress through update process steps
Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.
```
**Software Instance, Zone, and Notes**

```
Provides information about the target software instance and zone. If any notes were added at any time
during the update process, they are displayed here. You can optionally edit the notes.
The following elements are included:
Software Instance
Name of the software instance on which the update process will run.
Zone
Name of the software instance zone on which the update process will run.
```
**32**   Software Update task


**Notes**
Notes about the update. A user who works on any step of the update installation process has the
opportunity to create or update notes with any pertinent information. If notes are available, they are
displayed here.

**Edit Notes**
Provides the ability to create or update the notes that are displayed under **Notes**.

**Unresolved and Resolved lists**

List all post-installation holds of the selected resolution type that require resolution for the selected
updates. Click each of the **Unresolved** and **Resolved** list titles to list all holds of the selected resolution
type in the table. The title of the list also displays the number of holds that are in the list. You can filter the
list by hold type or reason, search the list, and export the holds to a text file. When holds are selected, you
can act on the holds.

**Filter by Type**
Provides you with the ability to filter holds based on the hold type value. The following hold type
values are available:

- ERROR
- FIXCAT
- SYSTEM
- USER
Each hold type filter also displays the number of holds of that hold type that are in the list. If no holds
of a certain hold type are in the list, that hold type filter is disabled.
For more information about hold types see in _z/OS SMP/E Reference_.

**Filter by Reason**
Provides the ability to filter holds based on the hold reason value. A reason filter is available only if
one or more holds with that reason value are in the list. Each reason filter also displays the number of
holds with that reason value that are in the list.
For the list of possible reason values used by IBM and more information about each value, see in _z/OS
SMP/E Reference_.

**Reset all filters**
Resets all filters to not selected so that the list of holds is complete and not filtered.

**Search field**
Provides a search capability for the list of holds in the table. Enter one or more characters of a value in
any column to filter the list and more quickly find a hold.
**Note:** The hold text is not included in the search.
As you type, the list dynamically filters to include only the holds with values that match the string.

**Export**
Downloads a text file of all holds in the list. Any holds that you filtered out of the list are not included
in the exported content.

**HOLDs table**
Lists all holds that require resolution for the selected updates. Only the holds of the selected
resolution type, either unresolved or resolved, are displayed. The list is filtered for any filters that
you selected and matches any search criteria that you entered. You can sort the information for all
columns.
For more information about the information that is displayed in the HOLDs table, see Table 9 on page
34.

```
Software Update task   33
```

```
Table 9. Columns in the HOLDs table
```
```
Column Description
```
```
Type The hold type of the hold. The following values are possible:
```
- ERROR
- FIXCAT
- SYSTEM
- USER
For more information about hold types see in _z/OS SMP/E Reference_.

```
Reason The provider-defined reason value for the hold.
For the list of possible reason values used by IBM and more information about
each value, see in z/OS SMP/E Reference.
```
```
FMID The FMID associated with the hold.
```
```
Update Name The name of the update that is associated with the hold.
```
```
To change the resolution of a hold in the list, select the hold and then click the action that you want to
take. One of the following two actions is available, depending on the resolution type that is displayed:
Resolve Hold
Changes the resolution value of the hold to resolved and moves it to the Resolved list.
Unresolve
Changes the resolution value of the hold to unresolved and moves it to the Unresolved list.
```
```
Window actions
Save and Exit
Saves progress on the update process through the current step. The step window closes and you
return to the Start New Software Update window. You can then return to the update process at any
time. For more information, see “Resuming in-progress updates” on page 37.
Next
Saves progress on the update process through the current step and opens the next step so that you
can continue with the installation of the updates.
```
#### Reviewing the installation summary

```
The Installation Summary window provides links to download the SMP/E output for the update process
and information about the holds for you to review.
```
```
About this task
On the Installation Summary window, select to download and view the SMP/E output and hold
information from the completed software update process.
For more information about the values and elements on the Installation Summary window, see “Values
on the Installation Summary window” on page 35.
Complete the following steps to review the installation summary.
```
**Procedure**

1. Complete the following steps to display the **Installation Summary** window:
    a. In the Software Update task, click **Start New Software Update**. The **Start New Software Update**
       window opens.

**34**   Software Update task


```
b. Progress through the update process steps until this window is displayed.
```
2. In the list of update process outputs, click the name of the file that you want to download.
    The following outputs are available:
    **All SMP/E Output**
       Compressed file of the SMP/E output from the entire update installation process.
    **Post-Install HOLDs**
       Text file of the post-installation holds. It is the same information that you can download on the
       **Review Post-installation HOLDs** window.
    **All HOLDs**
       Text file of all the holds that required resolution for the selected updates. Holds that you resolved
       both before and after installation are included, as well as holds for updates that you excluded from
       the installation.
    The file downloads.
3. After you download all needed files, click **Close** to return to the main Software Update window.

**Results**
The selected updates are installed and you have all the information that you need about the update
installation process. To review information about the update process at any future time, find it on the
**Completed Updates** window. For more information, see “Viewing completed software updates” on page
40.

**Values on the Installation Summary window**

The **Installation Summary** window contains elements and values with which you interact when you
install software updates.

The **Installation Summary** window applies to the following tasks:

- “Reviewing the installation summary” on page 34

**Timeline of progress through update process steps**

Provides a visual indication of the current step within the overall update process. The current step
is named above the timeline and highlighted on the timeline with a solid circle. Completed steps are
highlighted on the timeline with a check mark, and future steps are disabled.

**Software Instance, Zone, and Status**

Provides information about the target software instance and zone and the final status of the update
installation process.

The following elements are included:

**Software Instance**
Name of the software instance on which the update process ran.

**Zone**
Name of the software instance zone on which the update process ran.

**Status**
The final status of the update installation process The following values are possible:

```
Completed
The update installation process completed successfully.
```
**Downloads**

The downloads section contains the list of update process outputs and the type of each file. The following
outputs are available:

```
Software Update task   35
```

```
All SMP/E Output
Clicking this link downloads a compressed file of the SMP/E output from the entire update installation
process.
Post-Install HOLDs
Clicking this link downloads a text file of the post-installation holds. It is the same information that
you can download on the Review Post-installation HOLDs window.
All HOLDs
Clicking this link downloads a text file of all the holds that required resolution for the selected
updates. Holds that you resolved both before and after installation are included, as well as holds for
updates that you excluded from the installation.
```
```
Window actions
Close
Closes the Installation Summary window and returns you to the main Software Update window.
```
### Managing in-progress software updates

**Navigation title:** Managing in-progress updates
If a software update installation process was started but not finished, use the **View Updates in Progress**
window to view in-progress update processes or select an in-progress update process to cancel or
resume.

**About this task**

```
The View Updates in Progress window lists all in-progress software updates. Details about the update
process and status information in the form of the last completed update step are included. In addition to
viewing the details about an update, you can also select an update process and then cancel it or resume it
from the step on which the process left off.
For more information about the values and elements on the View Updates in Progress window, see
“Values on the View Updates in Progress window” on page 38.
For more information about the actions listed on the View Updates in Progress window, see Table 10 on
page 36.
```
```
Table 10. Actions for the View Updates in Progress task
```
```
Action Additional Information
```
```
View Updates (default action) “Viewing in-progress updates” on page 36
```
```
Cancel Update “Canceling in-progress updates” on page 37
```
```
Resume Update “Resuming in-progress updates” on page 37
```
#### Viewing in-progress updates

```
If you want to view details about an in-progress update process, including the last completed update
process step, you can do so on the View Updates in Progress window.
```
**About this task**

```
On the View Updates in Progress window, you can view details that include information about the target
software instance, the type of update, and any associated notes. You can also see when the update
process was last modified and the update process step that was last completed.
For more information about the values and elements on the View Updates in Progress window, see
“Values on the View Updates in Progress window” on page 38.
Complete the following steps to view details about an in-progress update process.
```
**36**   Software Update task


**Procedure**

1. In the Software Update task, click **View Updates in Progress**.
    The **View Updates in Progress** window opens.
2. In the list of in-progress update processes, locate the update process for which you want to view
    details.
    **Tip:** You can also search the list of update processes to quickly find the one that you want.
3. View the details for the in-progress update process.
    **Note:** If the details for an update process seem outdated, or you want to always ensure that you have
    the latest information, click **Refresh**.

#### Canceling in-progress updates

```
If you want to cancel an in-progress update process, you can do so on the View Updates in Progress
window.
```
```
About this task
For more information about the values and elements on the View Updates in Progress window, see
“Values on the View Updates in Progress window” on page 38.
Complete the following steps to cancel an in-progress update process.
```
**Procedure**

1. In the Software Update task, click **View Updates in Progress**.
    The **View Updates in Progress** window opens.
2. In the list of in-progress update processes, locate the update process that you want to cancel and
    select it.
    **Tip:** You can also search the list of update processes to quickly find the one that you want.
3. Click **Cancel Update**.
    A confirmation dialog, with additional details, is displayed.
4. Click **OK** to confirm the cancellation.

```
Results
The update process is canceled and moved to the list of Completed Updates. For more information about
completed update processes, see “Viewing completed software updates” on page 40.
```
#### Resuming in-progress updates

```
If you want to resume an in-progress update process from the step on which the process left off, you can
do so on the View Updates in Progress window.
```
```
About this task
For more information about the values and elements on the View Updates in Progress window, see
“Values on the View Updates in Progress window” on page 38.
Complete the following steps to resume the software update process.
```
**Procedure**

1. In the Software Update task, click **View Updates in Progress**.
    The **View Updates in Progress** window opens.

```
Software Update task   37
```

2. In the list of in-progress update processes, locate the update process that you want to resume and
    select it.
    **Tip:** You can also search the list of update processes to quickly find the one that you want.
3. Click **Resume Update**.
    Depending on the last completed step, either the window for the last completed step opens directly or
    you are first given the opportunity to rerun the last completed step.
    - If the last completed step is **Installing updates** , the window for the last completed step opens
       directly.
    - If the last completed step is any value other than **Installing updates** , the **Resume update in**
       **progress** window opens, displaying information about the update process and supplying further
       available actions. On the **Resume update in progress** window, optionally select **Rerun last step on**
       **resume** and then click **Resume**. The window for the last completed step opens and, if you selected
       to rerun the step, reruns the step.

#### Values on the View Updates in Progress window

```
The View Updates in Progress window contains elements and values with which you interact when you
install software updates.
The View Updates in Progress window applies to the following tasks:
```
- “Viewing in-progress updates” on page 36
- “Canceling in-progress updates” on page 37
- “Resuming in-progress updates” on page 37

```
Updates in Progress
Search field
Provides a search capability for the list of update processes in the Updates in Progress table. Enter
one or more characters of a value in any column to filter the list and more quickly find an update. As
you type, the list dynamically filters to include only the update processes for software instances with
values that match the string.
Updates in Progress table
Lists in-progress software update processes. You can sort the information for all columns except
"Notes". The table defaults to displaying 10 items per page. You can change the number of items
that are displayed on each page, and you can toggle between the pages if not all software update
processes are displayed on one page.
For more information about the information that is displayed in the Updates in Progress table, see
Table 11 on page 38.
```
```
Table 11. Columns in the Updates in Progress table
```
```
Column Description
```
```
Software Instance Name of the software instance on which the updates are installing.
```
```
Zone Name of the software instance zone on which the updates are installing.
```
```
System z/OSMF host system that has access to the volumes and data sets where the target
software instance resides. For more information about systems, see Defining your
systems to z/OSMF.
```
**38**   Software Update task


_Table 11. Columns in the Updates in Progress table (continued)_

**Column Description**

**Type** The type of update that is currently installing on the software instance. The
following values are possible:
**C**
Corrective updates were selected for installation on the software instance.
**F**
Functional updates were selected for installation on the software instance.
**R**
Recommended updates were selected for installation on the software instance.
For more information about the different types of software updates, see “Types of
software updates” on page 2.

**Notes** Notes about the update. A user who performs any step of the update installation
process has the opportunity to create or update notes with any pertinent
information. If notes are available, the notes icon ( ) appears in this column.
Click the notes icon to display a read-only version of the notes.

**Last Modified (local)** The local system date and time at which the update installation process was last
modified. This value is updated when a step in the update process is accessed, not
only when a step is completed.

**Last Completed Step** The last step that was completed in the update process. The following values are

```
possible:
Preparing Updates
The update process was stopped after the preparing updates step. For more
information about this process step, see “Preparing updates” on page 19.
Resolve HOLDs
The update process was stopped after the resolving HOLDs step. For more
information about this process step, see “Resolving HOLDs” on page 21.
Note: When you resume an update process that lists Resolve HOLDs as its last
completed step, you are returned to the preparing updates step.
Verifying Updates
The update process was stopped after the verifying updates step. For more
information about this process step, see “Verifying updates” on page 25.
Pre-install Summary
The update process was stopped after the reviewing the pre-installation
summary step. For more information about this process step, see “Reviewing
the pre-installation summary” on page 27.
Installing Updates
The update process was stopped after the installing updates step. For more
information about this process step, see “Installing updates” on page 29.
Review post-installation HOLDs
The update process was stopped after the reviewing the post-installation
HOLDs step. For more information about this process step, see “Resolving
post-installation holds” on page 31.
Note: When you resume an update process that lists Review post-installation
HOLDs as its last completed step, you are returned to the installing updates
step.
```
```
Software Update task   39
```

```
Refresh
Refreshes the information that is displayed in the Updates in Progress table.
Cancel Update
Cancels the selected in-progress update process.
Resume Update
Resumes the selected in-progress update process.
```
```
Resume update in progress window
The Resume update in progress window is displayed if you select to resume an update process that has
a last completed step of any value other than Installing updates , meaning that the updates are not yet
installed. You get the opportunity to rerun the last completed step before resuming where the update
process left off. This is helpful if you want to take an action during a step, for example resolving additional
holds, that was perhaps not previously taken.
The following actions are available on the Resume update in progress window:
Rerun last step on resume
Selecting Rerun last step on resume before clicking Resume reruns the last completed step in the
update process.
Cancel
Cancels the resume action and returns you to the View Updates in Progress window.
Resume
Opens the window that is associated with the last completed step in the update process. Unless
Rerun last step on resume was selected, the last completed step is not rerun. You can then resume
installing the updates from that step.
```
### Viewing completed software updates

**Navigation title:** Viewing completed updates
Use the **Completed Updates** window to view details about all completed or canceled software update
processes.

**About this task**

```
The Completed Updates window lists all software update processes that are completed or canceled. In
addition to viewing the details about a completed or canceled update process, you can also download
outputs that were generated during the update process.
For more information about the values and elements on the Completed Updates window, see “Values on
the Completed Updates window” on page 41.
```
**Procedure**

1. In the Software Update task, click **Show completed updates**.
    The **Completed Updates** window opens.
2. In the list of completed or canceled update processes, locate the update process for which you want
    to view details.
    **Tip:** You can also search the list of update processes to quickly find the one that you want.
3. View the details for the update process.
    **Note:** If the details for an update process seem outdated, or you want to always ensure that you have
    the latest information, click **Refresh**.

**40**   Software Update task


#### Values on the Completed Updates window

```
The Completed Updates window contains elements and values with which you interact when you install
software updates.
The Completed Updates window applies to the following tasks:
```
- “Viewing completed software updates” on page 40

```
Completed Updates
Search field
Provides a search capability for the list of updates in the Completed Updates table. Enter one or more
characters of the name of the software instance on which the updates were installed to filter the list
and more quickly find an update. As you type, the list dynamically filters to include only the updates
for software instances with names that match the string.
Completed Updates table
Lists completed software update processes. You can sort the information for all columns except
"Notes" and the untitled column for downloading outputs that were generated during the update
process. The table defaults to displaying 10 items per page. You can change the number of items
that are displayed on each page, and you can toggle between the pages if not all software update
processes are displayed on one page.
Note: The search functionality queries the entire list of software update processes, not just those that
are currently displayed.
For more information about the information that is displayed in the Completed Updates table, see
Table 12 on page 41.
```
```
Table 12. Columns in the Completed Updates table
```
```
Column Description
```
```
Software Instance Name of the software instance on which the updates were installed or the software
update process was canceled.
```
```
Zone Name of the software instance zone on which the updates were installed or the
software update process was canceled.
```
```
System z/OSMF host system that has access to the volumes and data sets where the target
software instance resides. For more information about systems, see Defining your
systems to z/OSMF.
```
```
Type The type of updates that were selected for installation. The following values are
possible:
C
Corrective updates were selected for installation on the software instance.
F
Functional updates were selected for installation on the software instance.
R
Recommended updates were selected for installation on the software instance.
For more information about the different types of software updates, see “Types of
software updates” on page 2.
```
```
Notes Notes about the update. A user who performs any step of the update installation
process has the opportunity to create or update notes with any pertinent
information. If notes are available, the notes icon ( ) appears in this column.
Click the notes icon to display a read-only version of the notes.
```
```
Software Update task   41
```

```
Table 12. Columns in the Completed Updates table (continued)
```
```
Column Description
```
```
Date Completed (local) The local system date and time at which the update installation process completed
or was canceled.
```
```
Status The status of the software update installation process after completion. The
following values, each preceded by a unique status icon, are possible:
```
```
Canceled
The update process was canceled. The software instance was not updated.
```
```
Canceled with errors
The update process was canceled at the Installing Updates step. The software
instance was potentially partially updated. For more information, download
and review all SMP/E output.
```
```
Completed
The update process that is completed successfully and the software instance
was updated.
```
```
Refresh
Refreshes the information that is displayed in the Completed Updates table.
```
```
Table 13. Actions for the Completed Updates table
```
```
Action Description
```
```
Delete This action deletes the completed or canceled
update process and all of the saved SMP/E output
that was generated for that process.
```
```
Export All SMP/E Output Download a zip archive that contains text files of
the SMP/E output for every step in the update
process.
```
```
Export All HOLDs This action downloads a text file that lists all of the
++HOLD information for the software updates that
were selected for installation.
```
```
Export Post-install HOLDs This action downloads a text file that lists
the subset of ++HOLDs that were selected for
resolution after installation.
```
### Setting Preferences

**Navigation title:** Setting preferences
Use the **Settings** window to set current user preferences for each system that contains software
instances. For example, you can change the allocation parameters for temporary data sets.
**Note:** Changing the Software Update preferences on the **Settings** window changes them for only the
currently logged in user. The preferences that are set for any other users are not affected.
For more information about the values and elements on the **Settings** window, see “Values on the Settings
window” on page 44.
For more information about the preferences that you can set on the **Settings** window, see Table 14 on
page 43.

**42**   Software Update task


```
Table 14. Preferences that you can set with the Settings task
```
```
Preference Additional Information
```
```
Change the settings for a system “Changing the Settings ” on page 43
```
#### Changing the Settings

```
Software Update runs SMP/E to perform software install actions that sometimes require UNIX superuser
authority. By default, SMP/E runs as the identity of your z/OSMF user ID. To specify a different user ID that
has superuser authority, use the Settings window that is provided in the Software Update task.
Temporary data sets are allocated for each SMP/E operation and are deleted upon completion of the
operation. These temporary data sets contain output that SMP/E and system utilities generate. To change
the allocation parameters for temporary data sets, use the Settings window that is provided in the
Software Update task.
```
**About this task**

```
Specify an alternate user ID that has superuser authority if your z/OSMF user ID does not have superuser
authority. Your z/OSMF user ID acts as a surrogate user to run SMP/E on behalf of the specified user.
Change the allocation parameters for temporary data sets if you encounter or anticipate problems when
running an SMP/E operation. Problems include running out of space, encountering data set allocation
errors, and so on.
For more information about the values and elements on the Settings window, see “Values on the Settings
window” on page 44.
```
**Procedure**

1. In the Software Update task, click **Settings**.
    The **Settings** window opens.
2. Under **Select a System** , find the system for which you want to change the parameters and select it.
    The fields in which you can enter new values for each of the parameters that you want to change are
    displayed.
3. Enter the appropriate value in the field for the allocation parameter or related setting that you want to
    change.
    You can change the following settings:
    - SMP/E user ID
    - Storage Class
    - Data Class
    - Management Class
    - Data Set Name Prefix
    - Unit
    - Volume Serial
    For more information about a setting, including defaults and rules for new values, click the help icon
    ( ) next to the setting field title.
    To reset a changed value back to the default value, either before or after saving any changes, click the
    reset parameter to default icon ( ) next to the field. To reset all values back to the default values, click
    **Reset all parameters**.
    **Note:** If you change settings for a system and then try to navigate away before saving the changes,
    the **Unsaved Changes** warning window appears. Examples of navigating away are clicking **Close** or

```
Software Update task   43
```

```
selecting a different system on the Settings window. On the Unsaved Changes window, click the
button for the action that you want to take.
```
4. Click **Save** to save your changes.
    The message **Changes have been saved!** is displayed. You can close the **Settings** window. When
    temporary data sets are allocated, the parameters that you set are used instead of the default
    parameters.

#### Values on the Settings window

```
The Settings window contains elements and values with which you interact when you install software
updates.
The Settings window applies to the following tasks:
```
- “Changing the Settings ” on page 43

```
Select a System
System selector field
Provides a list of all the z/OSMF host systems that are defined in the z/OSMF Systems task. Scroll up
and down the list to see all the systems. Selecting a system displays the fields that you use to modify
the parameters and related settings for the selected system.
SMP/E user ID
Directs the Software Update task to run SMP/E operations as the identity of the specified user ID
instead of your z/OSMF user ID. Your z/OSMF user ID acts as a surrogate user to run SMP/E on behalf
of the specified user. The currently set value is displayed in the field.
```
```
Table 15..
```
```
The following access requirements must be satisfied to run SMP/E operations as the specified user ID:
```
```
Resource class Resource name Who needs access? Type of access required
```
```
SURROGAT <smpe-user-
id>.ZOSMF.TSO
```
```
z/OSMF user ID READ
```
##### SERVAUTH CEA.CEATSO.TSOREQUE

##### ST

```
SMP/E user ID READ
```
```
ACCTNUM IZUACCT SMP/E user ID READ
```
```
TSOPROC IZUFPROC SMP/E user ID READ
```
```
Temporary Data Set Allocation Parameters
For more information about SMS classes, see in z/OS DFSMS Introduction.
Storage Class
Changes the value of the Storage Class allocation parameter to the value that you specify. The
currently set value is displayed in the field. New values must adhere to the rules that are included in
the information that is displayed when you click the help icon ( ) next to the field title.
Data Class
Changes the value of the Data Class allocation parameter to the value that you specify. The currently
set value is displayed in the field. New values must adhere to the rules that are included in the
information that is displayed when you click the help icon ( ) next to the field title.
Management Class
Changes the value of the Management Class allocation parameter to the value that you specify. The
currently set value is displayed in the field. New values must adhere to the rules that are included in
the information that is displayed when you click the help icon ( ) next to the field title.
```
**44**   Software Update task


**Data Set Name Prefix**
Changes the value of the data set name prefix to the value that you specify. The Software Update task
then generates the data set name using the prefix that you specified instead of the default prefix. The
currently set value is displayed in the field. New values must adhere to the rules that are included in
the information that is displayed when you click the help icon ( ) next to the field title.
For more information about data set prefixes, see Target System tab.

**Unit**

```
Directs the Software Update task to use the specified device unit. The currently set value is displayed
in the field. New values must adhere to the rules that are included in the information that is displayed
when you click the help icon ( ) next to the field title.
```
**Volume Serial**
Changes the volume on which temporary data sets are allocated to the value that you specify. The
currently set value is displayed in the field. New values must adhere to the rules that are included in
the information that is displayed when you click the help icon ( ) next to the field title.

**Help icon ( ), next to each setting field title**
Provides specific information about a setting, including defaults and rules for new values.

**Reset parameter to default icon ( ), next to each setting field**
Resets a changed value back to the default value for the associated setting. The default value for each
setting is included in the information that is displayed when you click the help icon ( ) next to the
field title.

**Reset all parameters**
Resets all changed allocation parameter values for the selected system back to the default values.
The default value for each setting is included in the information that is displayed when you click the
help icon ( ) next to the field title.

**Window actions**

**Close**
Closes the **Settings** window and returns you to the **Start New Software Update** window.

**Save**
Saves all changes.

**Unsaved Changes window**

The **Unsaved Changes** window is displayed if you change parameters for a system and then try to
navigate away before saving the changes.

The following actions are available on the **Unsaved Changes** window:

**Exit without saving**
Closes the **Unsaved Changes** warning window and opens the other system or window that you
selected. Any changes that you made to the initially selected system on the **Settings** window are not
saved.

**Save and exit**
Closes the **Unsaved Changes** warning window and opens the other system or window that you
selected. All changes that you made to the initially selected system on the **Settings** window are
saved.

```
Software Update task   45
```

IBM®


## Sysplex Management task

# IBM


## Contents

```
Sysplex Management task..................................................................................... 1
About the sysplex.........................................................................................................................................1
Introduction............................................................................................................................................2
Characteristics of a sysplex....................................................................................................................2
Topology view ..............................................................................................................................................3
System status values..............................................................................................................................6
View Sysplex...........................................................................................................................................8
View Coupling Facility.............................................................................................................................8
View System......................................................................................................................................... 10
Notifications about the health of the sysplex......................................................................................12
Physical view of a sysplex..........................................................................................................................13
View Properties for Couple Data Sets..................................................................................................20
Display the physical view..................................................................................................................... 20
View Properties for Sysplex Couple Data Sets.................................................................................... 21
View CPC...............................................................................................................................................21
Coupling Facility Structures views ............................................................................................................23
Display a Coupling Facilities Structures View......................................................................................24
View Coupling Facility Structures........................................................................................................ 24
View Coupling Facility Structures by type .......................................................................................... 31
CF Structure .........................................................................................................................................35
View Properties for CF Structure .........................................................................................................37
CF Connectivity view .................................................................................................................................43
Display the CF connectivity view......................................................................................................... 46
CF Connectivity Details view .....................................................................................................................46
Display the CF Connectivity Details View............................................................................................ 51
View Connection Details for CPC to CPC...................................................................................................52
Display the View Connection Details from CPC to CPC page.............................................................. 56
CFRM Administrative Policies....................................................................................................................57
CFRM Policy Editor and Sizer............................................................................................................... 58
Rename a CFRM policy...................................................................................................................... 137
Copy a CFRM policy............................................................................................................................138
Submit updates for a policy............................................................................................................... 138
Activate a CFRM policy.......................................................................................................................138
Delete a CFRM policy......................................................................................................................... 139
Import a CFRM administrative policy................................................................................................ 139
Export a CFRM administrative policy.................................................................................................141
Compare Administrative Policies.......................................................................................................142
Commands Log ....................................................................................................................................... 142
Write to Operator with Reply (WTOR) Message................................................................................ 144
Commands Output............................................................................................................................. 145
Cleanup Settings................................................................................................................................ 145
Sysplex Management Commands .....................................................................................................145
```
**Index................................................................................................................ 165**

**ii**


**Sysplex Management task**

```
The Sysplex Management task lets you view sysplex resources.
You can view sysplexes as well as systems in a sysplex. You can view physical configurations, such as
coupling facilities and LPARs, as well as logical resources, such as couple data sets and coupling facility
structures. Graphical views help you to visualize the topology of your sysplex. From the graphical view,
you can drill down to see details.
```
**Preparing to use the Sysplex Management task**

```
You must first define systems with the Systems task in the z/OSMF Settings.
```
- Add a z/OSMF instance for each sysplex to manage by current z/OSMF instance.
- Enable single-sign (SSO) for each secondary z/OSMF instance. To do this, you use the **Enable Single**
    **Sign-on** action in the **Systems** table.
- To prepare for using the physical view for the local sysplex, either use the **Discover** action in the
    **Systems** table to automatically create system definitions for those systems, or use the **Add CPC** action
    to manually add all CPC information for the local z/OSMF instance.
- To prepare for using the physical view for a remote sysplex, either use the **Discover** action in the
    **Systems** table to automatically create system definitions for those systems, or use the **Add CPC** action
    to manually add all CPC information for the remote z/OSMF instance in that sysplex.

```
Using the Sysplex Management task
Expand the Sysplex category in the navigation area, then select Sysplex Management.
Many of the pages in the Sysplex Management task include both a graphic view and a table view. You can
drag the divider that separates the views to expand or reduce each section.
The graphic view is located in the upper portion of the window. Sysplex objects, such as CPCs and
coupling facilities, are shown in graphic form. Click the right mouse button on a link inside an object
(typically the name of the object) to display a menu of actions for the object.
Filters that you set in the table can affect the graphic view.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.
The table view lets you select specific resources for further action, such as viewing properties. You can
customize the tables with filtering and by configuring the columns.

### About the sysplex

```
This topic provides an introduction to the sysplex.
For information about the sysplex, see z/OS MVS Setting Up a Sysplex. The following topics are excerpts
from that document.
```
```
Sysplex Management task   1
```

#### Introduction

```
A sysplex is a collection of z/OS® systems that cooperate, using certain hardware and software products,
to process workloads. The products that make up a sysplex cooperate to provide higher availability,
easier systems management, and improved growth potential over a conventional computer system of
comparable processing power.
The cross system coupling facility (XCF) component of z/OS provides simplified multisystem
management. XCF services allow authorized programs on one system to communicate with programs
on the same system or on other systems. If a system fails, XCF services also provide the capability for
batch jobs and started tasks to be restarted on another eligible system in the sysplex.
Server Time Protocol (STP) or a Sysplex Timer is required to synchronize the time-of-day (TOD) clocks for
systems in a sysplex that run on different processors. Note, however, that Sysplex Timer connections are
no longer supported starting with the z196/z114 servers.
In a Parallel Sysplex, central processing complexes (CPCs) are connected through channel-to-channel
(CTC) communications or through a coupling facility.
A coupling facility enables parallel processing and improved data sharing for authorized programs running
in the sysplex. The cross-system extended services (XES) component of MVS™ enables applications and
subsystems to take advantage of the coupling facility.
A shared sysplex couple data set records status information for the sysplex.
```
#### Characteristics of a sysplex

```
A sysplex can include the following software and hardware:
```
- z/OS
    These products include the cross-system coupling facility (XCF) component, which enables authorized
    programs in a sysplex to communicate with programs on the same MVS system or other MVS systems;
    and the global resource serialization component, which serializes sysplex resources.
    z/OS provides support for the coupling facility, which provides high-speed access to shared data across
    applications and subsystems running on different MVS systems.
- Signaling paths between MVS systems
    There must be at least two operational signaling paths (one inbound and one outbound path) between
    each of the MVS systems in the sysplex. The signaling paths can be defined through:
    - Coupling facility list structures
    - ESCON or FICON® channels operating in CTC mode
    - 3088 Multisystem Channel Communication Unit
- Sysplex couple data set
    MVS requires a DASD data set (and an alternate data set is recommended for availability) to be shared
    by all systems in the sysplex. On the sysplex couple data set, MVS stores information related to the
    sysplex, systems, XCF groups, and their members. An XCF group is the set of related members that
    a multisystem application defines to XCF. A multisystem application can be an installation-defined
    program, an MVS component or subsystem, or a program product.
    A sysplex couple data set is always required for a multisystem sysplex and for most single-system
    sysplexes. However, you can define a single system sysplex that does not require a sysplex couple data
    set.
- Common time reference
    When the sysplex consists of multiple MVS systems running on two or more processors, MVS requires
    that the processors be connected to the same time source to synchronize TOD clocks across CPCs.
    This can be done by using a common 9037 Sysplex Timer or through STP. Starting with the z114/z196
    servers, connections to the 9037 Sysplex Timer are no longer supported. MVS uses the Sysplex Timer to
    synchronize TOD clocks across systems.

**2**   Sysplex Management task


```
For a multisystem sysplex defined on a single processor (under PR/SM or VM) the SIMETRID parameter
in the CLOCKxx parmlib member must specify the simulated Sysplex Timer identifier to synchronize
timings for the MVS systems. When a sysplex with LPARs resides on two or more physical CECs, it
requires ETRMODE YES or STPMODE YES to be defined in the CLOCKxx parmlib member.
To manage certain aspects of your sysplex, you can install one or more additional couple data sets, for:
```
- Coupling facility resource management (CFRM), to define how the system is to manage coupling facility
    resources.
- Sysplex failure management (SFM), to define how the system is to manage system and signaling
    connectivity failures and PR/SM reconfiguration actions.
- Workload management (WLM), to define service goals for workloads.
- Automatic restart management (ARM), to define how to process restarts for started tasks and batch
    jobs that have registered with automatic restart management.
- System logger (LOGR, LOGRY and LOGRZ), to define, update, or delete structure or log stream
    definitions.
- z/OS UNIX System Services (z/OS UNIX), to contain file information when using a shared file system in a
    sysplex.

### Topology view

```
Use the topology view to see and manage your sysplex topology.
The topology view displays the relationship between sysplexes, coupling facilities (CFs), and systems. It
displays the sysplex that z/OSMF resides on, and the systems and coupling facilities that are included in
the sysplex.
The topology view includes both a graphic view and a table view. You can drag the divider that separates
the views to expand or reduce each section.
If you set a filter in the table, the filter is also applied to the graphic view, meaning sysplexes and their
associated systems and coupling facilities may be excluded.
```
```
Display the topology view
To see the topology view of a sysplex, expand the Sysplex category in the navigation area, then select the
Sysplex Management task.
```
**Graphic view of the topology view**

```
Sysplexes and their associated coupling facilities and systems are shown in graphic form. A sysplex is
represented by a single object containing the associated coupling facilities and systems.
```
```
Sysplex Management task   3
```

```
Figure 1. Sample graphic view showing sysplex PLEX1 with systems SY1 and SY2, and coupling facilities
LF01N and TESTCFN
```
```
Click a link, such as the sysplex name, to view details. Click the right mouse button on a link to display a
menu of actions for the object. For a description of the actions, see Table 2 on page 5.
```
```
Notifications: The notification icon, , indicates that warning or error notifications exist, related to the
following conditions:
```
- Single point of failure for a couple data set
- Channel path is not online
- Coupling facility is in maintenance mode
- CPC is not configured correctly.
Click the icon to show information about the notifications.
**Toolbar:** The graphic view includes a tool bar with several handy functions:
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

**Table view of the topology view**

```
For a description of the columns in the table, see Table 1 on page 4. For a description of the actions
that you can take, refer to “Actions” on page 5.
```
```
Table 1. Columns in the Topology table
```
```
Column Description
```
```
Sysplex / CF or System
Name
```
```
Name of the sysplex. Expand the row to see the name of the associated coupling
facilities and systems.
```
```
Message Message issued for the item, if any.
```
```
Partition Partition number.
```
**4**   Sysplex Management task


_Table 1. Columns in the Topology table (continued)_

**Column Description**

**CPCID** Central Processor Complex (CPC) ID.

**Volatile** Indicates whether the coupling facility storage is volatile.

**CF Level** Level of the coupling facility control code (CFCC).

**CFCC Release** Release of the coupling facility control code.

**Service Level** Service level.

**Total Space** Total amount of storage.

**Free Space** Amount of free storage.

**System Status** Status of the system. See “System status values” on page 6

**Timing** The sysplex timing method on the system.

**Status Time** Time that the status was recorded.

**CPC CPUID** CPU ID for the CPC.

```
Actions
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 2 on page 5.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 3
    on page 6.

_Table 2. Targeted actions for the Topology view_

**Action Objects Description**

**Open Physical View** Sysplex Opens the physical view of the sysplex. See “Physical view of
a sysplex” on page 13. **Open** requires that BCPii interfaces to
invoke zSeries Hardware APIs are enabled.

**Open CF
Connectivity View**

```
Sysplex Opens a view that lets you manage physical connections among
systems and coupling facilities.
```
**Open CF
Connectivity
Details View**

```
Sysplex Opens a view that lets you see details of connectivity between a
coupling facility and a system.
```
**Open Structures,
Open Structures
View**

```
Syplex, Coupling
Facility
```
```
Opens the coupling facility view of the sysplex or coupling facility.
```
**Properties** Sysplex, System Displays the details view.

**CFRM Policies** Sysplex Opens a view that lets you manage the Coupling Facility Resource
Management (CFRM) policies for the current sysplex.

```
Sysplex Management task   5
```

```
Table 3. Table actions for the Topology table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
#### System status values

```
This topic describes the system status values.
The status values are as follows.
BEING REMOVED
XCF is removing the system from the sysplex. This can mean that:
```
- A VARY XCF command was entered to remove the system from the sysplex.
- The system lost signalling connectivity to the other systems in the sysplex.
- The system lost access to the common clock being used by the sysplex.
_msysname_ is the system name of the system that is monitoring the removal of system _msysname_ from
the sysplex. If the monitoring system cannot be determined, _msysname_ appears as N/A
**MONITOR-DETECTED STOP**
The system has not updated its status on the couple data set within the time interval specified on that
COUPLExx parmlib member of the system. This can mean that:
- The system is issuing an SVC dump.
- The system is going through reconfiguration.
- A spin loop is occurring.
- The operator pressed stop.
- The system is in a restartable wait state.
- The system lost access to the couple data set.
**XCF-LOCAL MODE**
The system is running in XCF-local mode. No other systems can join a sysplex in XCF-local mode. The
sysplex is not using couple data sets.

**6**   Sysplex Management task


##### XCF-LOCAL MODE TM=SIMETR

```
The system is running in XCF-local mode. No other systems can join a sysplex in XCF-local mode. The
sysplex is not using couple data sets. The TOD clock of this system is synchronized by simulated ETR.
```
**XCF-LOCAL MODE TM=ETR**
The system is running in XCF-local mode. No other systems can join a sysplex in XCF-local mode. The
sysplex is not using couple data sets. The TOD clock of this system is synchronized by stepping to the
ETR Sysplex Timer.

**XCF-LOCAL MODE TM=STP**
The system is running in XCF-local mode. No other systems can join a sysplex in XCF-local mode. The
sysplex is not using couple data sets. The TOD clock of this system is synchronized by steering to the
ETR Sysplex Timer or to the STP Facility.

**XCF-LOCAL MODE TM=LOCAL**
The system is running in XCF-local mode. No other systems can join a sysplex in XCF-local mode. The
sysplex is not using couple data sets. The TOD clock of this system is not synchronized to any external
time source.

**MONOPLEX MODE**
The system is running in monoplex mode which prevents any other systems from joining this sysplex.
The sysplex is using couple data sets.

**MONOPLEX MODE TM=SIMETR**
The system is running in monoplex mode which prevents any other systems from joining this sysplex.
The sysplex is using couple data sets. The TOD clock of this system is synchronized by simulated ETR.

**MONOPLEX MODE TM=ETR**
The system is running in monoplex mode which prevents any other systems from joining this sysplex.
The sysplex is using couple data sets. The TOD clock of this system is synchronized by stepping to the
ETR Sysplex Timer.

**MONOPLEX MODE TM=STP**
The system is running in monoplex mode which prevents any other systems from joining this sysplex.
The sysplex is using couple data sets. The TOD clock of this system is synchronized by steering to the
ETR Sysplex Timer or to the STP Facility.

**MONOPLEX MODE TM=LOCAL**
The system is running in monoplex mode which prevents any other systems from joining this sysplex.
The sysplex is using couple data sets. The TOD clock of this system is not synchronized to any external
time source.

**PARTITIONING CLEANUP**
XCF is in the process of removing a system from the sysplex.

**ACTIVE**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member.

**ACTIVE TM=ETR**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this system is synchronized by
stepping to the ETR Sysplex Timer.

**ACTIVE TM=SIMETR**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this system is synchronized by
simulated ETR.

**ACTIVE TM=STP**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this system is synchronized by
steering to the ETR Sysplex Timer or to the STP Facility.

```
Sysplex Management task   7
```

##### ACTIVE TM=LOCAL

```
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this systemk is not synchronized
to any external time source.
```
#### View Sysplex

```
The View Sysplex page shows the properties of a sysplex.
```
**Display View Sysplex**

```
To display the View Sysplex page:
```
1. Expand the Sysplex category in the navigation area.
2. Select the Sysplex Management task.
3. Click a sysplex name in the graphic view of the sysplex.

**Fields on the View Sysplex page**

```
Table 4. Fields on the View Sysplex page
```
```
Field Description
```
```
Sysplex name Name of the sysplex.
```
```
Initialization time Date and time that the sysplex was initialized
```
```
Active Policies Table showing the active policies, including the name, type, and date and time that
they were activated. Supported for CFRM, SFM and ARM couple data sets.
```
```
Couple Data Sets Table showing the couple data sets, including the name, type, usage and volume
serial.
```
```
Systems Table showing the systems in the sysplex.
```
```
Coupling Facilities Table showing the coupling facilities in the sysplex, including the name, partition,
and CPC.
```
#### View Coupling Facility

```
The View Coupling Facility page shows the properties of a coupling facility. It includes collapsible sections
for space utilization and storage configuration.
```
**Display the View Coupling Facility page**

```
To see the View Coupling Facility page:
```
1. Expand the Sysplex category in the navigation area.
2. Select the Sysplex Management task.
3. Click a coupling facility name in the graphic view of the sysplex. You can also display it from the
    Coupling Facilities Structures view.

**Fields on the View Coupling Facility page**

```
Table 5. Base fields on the View Coupling Facility page
```
```
Column Description
```
```
Coupling facility name Name of the coupling facility from the CFRM active policy. This field is included
only if you displayed the View Coupling Facility page from the Topology view.
```
**8**   Sysplex Management task


_Table 5. Base fields on the View Coupling Facility page (continued)_

**Column Description**

**Coupling Facility** The value is comprised of node type, node manufacturer, manufacturer plant ID
and sequence number.

**Maintenance Mode** Indicates if the coupling facility is in maintenance mode.

**CPC ID** Central Processor Complex (CPC) ID.

**Partition** Partition number. This field is included only if you displayed the View Coupling
Facility page from the Topology view.

**CF level** Level of the coupling facility control code (CFCC).

**Standalone** Indicates whether the coupling facility is standalone, that is, the coupling facility
resides on a CEC with no general-purpose processors, so that no z/OS image can
run on the CEC.

**CFCC release** Release of the coupling facility control code.

**Service level** Service level.

**Built on** Time and date of the build.

**Volatile** Indicates whether the coupling facility storage is volatile.

**Storage increment size** Storage increment size for this coupling facility.

**Storage-class memory
increment size**

```
Storage-class memory increment size for this coupling facility.
```
**Shared Processors** Number of shared processors defined for the coupling facility. This value is
available if the CF level is greater than 15.

**Dedicated Processors** Number of dedicated processors defined for the coupling facility. This value is
available if the CF level is greater than 15.

**Coupling thin interrupts** Indicates if coupling thin interrupts is available and enabled for the coupling
facility.

**Dynamic CF dispatching** Dynamic CF dispatching setting for the coupling facility. When it is enabled, a
timer driven polling for command dispatching is used. Dynamic CF dispatching
is provided by PR/SM and available to all CF partitions with shared engines. It
allows the installation to limit the impact of polling for CFs with low activity
rates. The amount of CP resource used by the CF is reduced. There is, however,
a performance trade-off when working with dynamic dispatching: though the CPU
resource consumed by the CF is reduced, the responsiveness of the CF partition
is also reduced. In Parallel Sysplex environments with a CFLEVEL 19 or higher,
it is recommended to enable coupling thin interrupts for shared-engine coupling
facilities.

**Coupling facility space utilization**

_Table 6. Allocated Space_

**Column Description**

**Structures** Total amount of facility storage in use by allocated structures.

**Dump space** Total amount of storage assigned to dumping storage.

**Free space** Amount of free storage.

**Total** Total amount of coupling facility space.

```
Sysplex Management task   9
```

```
Table 7. Dump Space Utilization
```
```
Column Description
```
```
Structure dump tables Total amount of facility dump storage that is assigned to dump tables.
```
```
Table count Total number of dump tables.
```
```
Free dump space Total amount of dumping storage that is available for assignment in a dump table.
```
```
Total Total dump space that is defined to the coupling facility.
```
```
Max requested dump
space
```
```
Maximum amount of dump space that is requested to be assigned to dump tables.
```
**Storage Configuration**

```
Table 8. Storage Configuration
```
```
Column Description
```
```
Name Names the type of space for which data is shown.
```
```
Control space Total amount of control space that is allocated.
```
```
Non-control space Total amount of non-control space that is allocated.
```
```
Storage class memory Total storage-class memory that is available.
```
#### View System

```
The View System page shows the properties of a system.
```
```
Display the View System page
To display the View System page:
```
1. Expand the Sysplex category in the navigation area.
2. Select the Sysplex Management task.
3. Click a system name in the graphic view of the sysplex.

**Fields on the View System page**

```
Table 9. Fields on the View System page
```
```
Column Description
```
```
System name Name of the system in the z/OSMF system definition.
```
```
Sysplex Name of the sysplex in the z/OSMF system definition.
```
```
Lpar Number Number of the LPAR in hexadecimal
```
```
Status time Time that the status was recorded.
```
```
System status Status of the system. See “System status values on the View System page” on page
11.
```
**10**   Sysplex Management task


_Table 9. Fields on the View System page (continued)_

**Column Description**

**Timing** The sysplex timing method on the system.

```
Local timing mode
The TOD clock of this system is not synchronized to any external time source.
ETR timing mode
The TOD clock of this system is synchronized by stepping to the ETR Sysplex
Timer.
STP timing mode
The TOD clock of this system is synchronized by steering to the ETR Sysplex
Timer or to the STP Facility.
Unknown
The TOD clock of this system other than LOCAL, ETR or STR is unknown to
z/OSMF.
```
**CPC CPUID** CPU ID for the CPC.

**Serial** Short serial number of the CPC.

**Type** Type of CPC.

```
System status values on the View System page
This topic describes the system status values that are displayed on the View System page.
BEING REMOVED
XCF is removing the system from the sysplex. This can mean that:
```
- A VARY XCF command was entered to remove the system from the sysplex.
- The system lost signalling connectivity to the other systems in the sysplex.
- The system lost access to the common clock being used by the sysplex.
_msysname_ is the system name of the system that is monitoring the removal of system _msysname_ from
the sysplex. If the monitoring system cannot be determined, _msysname_ appears as N/A
**MONITOR-DETECTED STOP**
The system has not updated its status on the couple data set within the time interval specified on that
COUPLExx parmlib member of the system. This can mean that:
- The system is issuing an SVC dump.
- The system is going through reconfiguration.
- A spin loop is occurring.
- The operator pressed stop.
- The system is in a restartable wait state.
- The system lost access to the couple data set.
**PARTITIONING CLEANUP**
XCF is in the process of removing a system from the sysplex.
**ACTIVE TM=UNKNOWN**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member.
**ACTIVE TM=ETR**
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this system is synchronized by
stepping to the ETR Sysplex Timer.

```
Sysplex Management task   11
```

##### ACTIVE TM=STP

```
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this system is synchronized by
steering to the ETR Sysplex Timer or to the STP Facility.
ACTIVE TM=LOCAL
The system is running and has updated its status on the couple data set within the last time interval as
defined in the system's COUPLExx parmlib member. The TOD clock of this systemk is not synchronized
to any external time source.
UNKNOWN
The status is unknown.
```
#### Notifications about the health of the sysplex

```
The Notifications page displays warning and error notifications associated with the sysplex.
The Sysplex Management task checks for the following conditions, and generates warning or error
notifications as appropriate:
```
- Single point of failure for a couple data set
- Channel path is not online
- Coupling facility is in maintenance mode
- CPC is not configured correctly.
The notifications are displayed on the Notifications page, in a table.

**Notifications table**

```
For a description of the columns in the table, see Table 10 on page 12. For a description of the table
actions refer to Table 11 on page 12.
```
```
Table 10. Columns in the Notifications table
```
```
Column Description
```
```
Notification Message Message ID. Click the ID to display help for the message.
```
```
Notification Description Message text. Click the text to open the panel on which the notification originated.
```
```
Sysplex Name of the sysplex.
```
```
System Name of the system the z/OSMF instance is running on and performing the health
check for the sysplex.
```
```
Table 11. Table actions for the Notifications table
```
```
Action Description
```
```
Open Open the panel on which the selected notification originated. You must have
selected a notification.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**12**   Sysplex Management task


```
Table 11. Table actions for the Notifications table (continued)
```
```
Action Description
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear search Clear the search from all of the columns in the table. This action is disabled if no
searching is specified in the table.
```
```
Display the notifications for a sysplex
Perform these steps to see the warning and error notifications for a sysplex.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task. The
    topology view of the sysplex is displayed.
2. If a notification icon, , appears in the graphical view of the sysplex (near the name of the
    sysplex), that means warning or error notifications exist. Click the icon to show information about the
    notifications.
    The following shows a graphical view of a sysplex, with the notifications icon.

### Physical view of a sysplex

```
Use the physical view to see and manage your sysplex.
The physical view shows the major elements in a sysplex: central processor complexes (CPCs), coupling
facilities (CFs), systems, and different types of couple data sets. It includes a graphical and table view.
With both the graphic and table views, you can see and manage sysplex objects, including identifying a
single point of failure condition.
```
```
In the graphical view, single point of failure is indicated by a yellow warning icon ( ) before a couple
data set. Click the warning icon to display details, such as no alternate couple data set is defined, or the
primary couple data set and the alternate couple data set are on the same DASD. For information about
avoiding a single point of failure, see z/OS MVS Setting Up a Sysplex.
From the physical view, you can view coupling facility structures.
If you set a filter in the table, it affects the graphic view:
```
```
Sysplex Management task   13
```

- When you filter the CPC View table, CPCs, along with associated systems and CFs, might be excluded
    from the graphic view. The couple data sets in the graphic view are not affected.
- When you filter the Couple Data Sets View table, couple data sets might be excluded from the graphic
    view based on volume serial. The CPCs in the graphic view are not affected.

```
Preparing to use the physical view
You must perform some setup with the Systems task in the z/OSMF Settings. To prepare for using the
Physical View for the local sysplex, either use the Discover action in the Systems table to automatically
discover CPCs for the sysplex, or use the Add CPC action to manually add all CPC information for the local
z/OSMF instance.
```
**Graphic view**

```
The graphic view includes the following. For an example, see Figure 2 on page 14.
```
- The sysplex, represented by the largest shape of the graphic view, which contains all other shapes.
- CPCs, represented by an object that contains the associated coupling facilities and systems (P59 and
    S92 in the example).
- Coupling facilities that are connected to the systems in the sysplex (SVT6CF4 and SVT6CF2 in the
    example).
- Couple data sets, represented by cylinder shapes, with text identifying the volume serial as well as the
    type for the couple data set, followed by A for alternate or P for primary. For example, this represents a
    CFRM couple data set that is primary on volume serial FDSPKP:

```
Figure 2. Example of a graphical view of the physical view of the sysplex
```
```
For more information, see “Couple data sets” on page 16.
```
**14**   Sysplex Management task


```
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.
- Use **Graphic View** to switch between the physical view and other views. Selecting a different view
    changes the table, too.

```
Actions for the graphic view
Click the right mouse button on the name of an object to display a menu of actions. The actions vary with
the type of object.
```
_Table 12. Actions for the graphic view of the physical view_

**Action Objects Description**

**Duplex All
Structures on CF**

```
CF Start
Start Duplexing for all structures for a selected CF. See “Start
Duplexing (All)” on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop
Duplexing (All)” on page 162 for more information.
```
**Maintenance Mode** CF **Start**

```
Starts maintenance mode for the selected CF. See “Start
Maintenance Mode” on page 164.
Stop
Stops maintenance mode for the selected CF. See “Stop
Maintenance Mode” on page 164.
```
**New Couple Data
Set**

```
Sysplex Create a couple data set by using a newly formatted data set that
has the default capacity.
```
**Open Structures,
Open Structures
View**

```
Sysplex, CF View the coupling facility structures, organized either by type or
coupling facility. For the sysplex, select a desired view.
```
**Policies** Sysplex Display policies.

**Prepare for
Disruptive
Maintenance**

```
CF Prepares the selected CF for disruptive maintenance. See “Prepare
for Disruptive Maintenance” on page 164.
```
**Properties** Sysplex, CPC, CF,
system, couple data
sets

```
View the properties of the selected object.
```
```
Sysplex Management task   15
```

```
Table 12. Actions for the graphic view of the physical view (continued)
```
```
Action Objects Description
```
```
Reallocate All
Structures in
Sysplex
```
```
Sysplex Start
Reallocate structures across all syplexes. See “Start
Reallocate” on page 155 for more information.
Stop
Stop reallocate processing when finished with the structure
currently being processed. See “Stop Reallocate” on page 158
for more information.
```
```
Rebuild All
Structures on CF
```
```
CF Start
Start Rebuild For all structures for a selected CF. See “Start
Rebuild (All)” on page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop
Rebuild (All)” on page 160 for more information.
```
```
Restore after
Disruptive
Maintenance
```
```
CF Restores the selected CF from disruptive maintenance. See
“Restore after Disruptive Maintenance” on page 164.
```
```
Set Primary Couple
Data Set
```
```
Sysplex Set the primary couple data set.
```
```
Set Alternate
Couple Data Set
```
```
Couple data set
(primary and
alternate)
```
```
Set the alternate couple data set.
```
```
Switch Alternate to
Primary
```
```
Couple data set
(alternate)
```
```
Switch the alternate couple data set to the primary couple data
set.
New Alternate
Specify a new alternate couple data set.
No Alternate
Do not replace the alternate couple data set.
```
```
Couple data sets
For information about the types of couple data sets that are displayed in the physical view, see Table 13
on page 16.
```
```
Table 13. Couple data set types. Table showing a column of CDS types and a column of descriptions of
the types.
```
```
CDS type Description
```
```
Sysplex Contains the information that z/OS stores for the
sysplex, systems, XCF groups, and their members.
```
```
CFRM Contains the Coupling Facility Resource
Management (CFRM) policy, and defines how z/OS
manages CF resources.
```
```
SFM Contains the Sysplex Failure Management policy.
The policy is used to define how z/OS manages
the system and signaling connectivity failures, and
PR/SM reconfiguration actions.
```
**16**   Sysplex Management task


```
Table 13. Couple data set types. Table showing a column of CDS types and a column of descriptions of
the types. (continued)
```
```
CDS type Description
```
```
WLM Contains the workload management policy, and
defines service goals for workloads.
```
```
ARM Contains the automatic restart management policy,
and defines how to process restarts for started
tasks and batch jobs that are registered with
automatic restart management.
```
```
LOGR Contains the System Logger (LOGR) policy. The
policy is used to define, update, or delete structure
or log stream definitions.
```
```
LOGRY Contains the System Logger single-system scope
(LOGRY) policy. The policy is used to define,
update, and delete log stream definitions.
```
```
LOGRZ Contains the System Logger single-system scope
(LOGRZ) policy. The policy is used to define,update,
and delete log stream definitions.
```
```
BPXMCDS Used by UNIX System Services to enable a shared
Hierarchical File System (HFS) in a sysplex.
```
```
Table views
You can select a view of CPCs or couple data sets, by using the View field. In the table, click a link in the
first column to show properties.
```
**CPC view**

```
For a description of the columns in the table in the CPC view, see Table 14 on page 17. For a description
of the actions that you can take, refer to “Actions for the table views” on page 18.
```
_Table 14. Columns in the CPC view table_

**Column Description**

**CPC / CF or System
Name**

```
Name of the sysplex. Expand the row to see the name of the associated coupling
facilities and systems.
```
**CPC ID** Central Processor Complex (CPC) ID.

**CPC Serial** CPC serial number.

**CPC CPU ID** CPU ID for the CPC.

**Total Space** Total amount of storage.

**Free Space** Amount of free storage.

**Volatile** Indicates whether the coupling facility storage is volatile.

**Level** Level of the coupling facility control code (CFCC).

**Logical Partition** Partition number.

```
Sysplex Management task   17
```

```
Couple Data Sets view
For a description of the columns in the table in the Couple Data Sets view, see Table 15 on page 18. For a
description of the actions that you can take, refer to “Actions for the table views” on page 18.
```
```
Table 15. Columns in the Couple Data Sets view table
```
```
Column Description
```
```
Volume Serial / CDS Type Volume serial for the couple data set. Expand the row to see the type of couple
data set.
```
```
Message Warning message for the couple data set, if any, describing a single point of failure
condition.
```
```
Name Name of the couple data set.
```
```
Maximum Systems Maximum number of systems that are allowed in the sysplex that use this data set.
```
```
Format TOD(UTC) Date and time.
```
**Actions for the table views**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 16 on page 18.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 17
    on page 19.

```
Table 16. Targeted actions for the table view of the physical view
```
```
Action Objects Description
```
```
Properties CPC, CF, System,
couple data sets
```
```
View the properties of the selected object.
```
```
Open Structures Sysplex, CF View the coupling facility structures, organized either by type or
coupling facility. For the sysplex, select a desired view.
```
```
Rebuild All
Structures on CF
```
```
CF Start
Start Rebuild For all structures for a selected CF. See “Start
Rebuild (All)” on page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop
Rebuild (All)” on page 160 for more information.
```
```
Duplex All
Structures on CF
```
```
CF Start
Start Duplexing for all structures for a selected CF. See “Start
Duplexing (All)” on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop
Duplexing (All)” on page 162 for more information.
```
```
Maintenance Mode CF Start
Starts maintenance mode for the selected CF. See “Start
Maintenance Mode” on page 164.
Stop
Stops maintenance mode for the selected CF. See “Stop
Maintenance Mode” on page 164.
```
**18**   Sysplex Management task


_Table 16. Targeted actions for the table view of the physical view (continued)_

**Action Objects Description**

**Prepare for
Disruptive
Maintenance**

```
CF Prepares the selected CF for disruptive maintenance. See “Prepare
for Disruptive Maintenance” on page 164.
```
**Restore after
Disruptive
Maintenance**

```
CF Restores the selected CF from disruptive maintenance. See
“Restore after Disruptive Maintenance” on page 164.
```
**Switch Alternate to
Primary**

```
CDS Switch the alternate couple data set of a given type to become
the primary couple data set. See “Switch Alternate to Primary
Command” on page 147 for more information.
```
**Set Alternate
Couple Data Set**

```
CDS Set the alternate couple data set.
```
**Set Primary Couple
Data Set**

```
Sysplex Set the primary couple data set.
```
**New Couple Data
Set**

```
Sysplex Create a couple data set by using a newly formatted data set that
has the default capacity.
```
**Expand** CPC, CF, System,
couple data sets

```
Expand the selected parent nodes so that the rows that contain
the corresponding child nodes are visible. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain collapsed
parent nodes..
```
**Collapse** CPC, CF, System,
couple data sets

```
Collapse the selected parent nodes so that the rows that contain
the corresponding child nodes are hidden. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain expanded
parent nodes..
```
_Table 17. Table actions for the physical view table_

**Action Description**

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

**Set Primary Couple Data
Set**

```
Set the primary couple data set.
```
**New Couple Data Set** Create a couple data set by using a newly formatted data set that has the default
capacity.

**Hide Filter Row** Remove the filter row from view.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Show Filter Row** Display the filter row.

```
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
**Export Table Data** Save the table data as a CSV file. Select an option to export either the current view
or all data.

```
Sysplex Management task   19
```

```
Table 17. Table actions for the physical view table (continued)
```
```
Action Description
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
#### View Properties for Couple Data Sets

```
The View Properties for Couple Data Set page shows the properties of a couple data set. The page has
a tab for the primary volume and a tab for the alternate volume. The title of the page indicates the type of
couple data set (ARM, LOGR, and so on).
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open** to display the physical view of the sysplex.
3. In the graphic view, click the link (the type) of a couple data set.
4. Click the Primary or Alternate tab as needed.

**Results**

```
Table 18. Fields on the View Properties for the Couple Data Sets page
```
```
Field Description
```
```
Couple data set name Name of the couple data set.
```
```
Type Type of couple data set.
```
```
Volume serial Volume serial for the location of the couple data set.
```
```
Device number Device number for the location of the couple data set.
```
```
Format TOD Date and time.
```
```
Maximum systems Maximum number of systems that are allowed in the sysplex that use this data set.
```
```
Additional information Additional information for the couple data set.
```
#### Display the physical view

```
Perform these steps to see the physical view of a sysplex.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
3. In the Graphic View field in the control bar for the graphic view, ensure that the value is Physical.

**20**   Sysplex Management task


#### View Properties for Sysplex Couple Data Sets

```
The View Properties for Sysplex Couple Data Sets page shows the properties of a sysplex couple data
set. The page has a tab for the primary volume and a tab for the alternate volume.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
    The physical view of the sysplex is displayed.
3. Click the right mouse button on a Sysplex couple data, then select **View Properties**.

**Results**

```
Table 19. Fields on View Properties for the Sysplex Couple Data Sets page
```
```
Field Description
```
```
Couple Data Set Name Name of the couple data set.
```
```
Type Type of couple data set.
```
```
Volume serial Volume serial for the location of the couple data set.
```
```
Device number Device number for the location of the couple data set.
```
```
Format TOD Date and time.
```
```
Maximum systems Maximum number of systems that are allowed in the sysplex that use this data set.
```
```
Maximum groups Maximum number of XCF groups that the couple data set can support. On the
primary tab, the peak number of groups ever in use in the sysplex is shown in
parentheses.
```
```
Maximum members The maximum number of members per group that the primary couple data set
can support. On the primary tab, the peak number of members ever in use in the
largest group in the sysplex is shown in parentheses.
```
```
Additional information Additional information for the couple data set.
```
#### View CPC

```
The View CPC page shows details about the selected CPC.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
    The physical view of the sysplex is displayed.
3. Click the name of the CPC.

```
Sysplex Management task   21
```

**Results**

```
Table 20. Fields on the View CPC page
```
```
Field Description
```
```
CPC name Name of the CPC.
```
```
CPC ID ID of the CPC.
```
```
CPC serial Serial number of the CPC.
```
```
Machine Type Machine type of the CPC.
```
```
CPC CPU ID CPU ID of the CPC.
```
```
Systems A table showing systems for the CPC. Click a system name to show properties of
the system.
```
```
Coupling facilities A table showing coupling facilities for the CPC. Click a coupling facility name to
show properties of the coupling facility.
```
#### Confirm Prepare for Disruptive Maintenance

```
Use this dialog to confirm or cancel your request.
Click OK to confirm the request and continue.
Click Cancel to cancel the request and return to the previous page.
If you click OK to confirm the request, several MVS commands are issued for you. To see the command
syntax, click Command Preview.
```
**Commands issued**

1. Start Maintenance Mode: SETXCF START, MAINTMODE,CFNAME= _coupling-facility-name_
    **MAINTMODE,CFNAME=(** **_cfname_** **,[** **_cfname_** **...])**
       Sets the specified coupling facility or facilities into maintenance mode. When in maintenance
       mode, a CF is not eligible for CF structure allocation purposes. The XCF structure allocation
       algorithm modifies the CF selection processing accordingly. You can use the SETXCF STOP
       command to turn off MAINTMODE. This setting is kept in control blocks in the storage of the
       ACTIVE sysplex. It is not saved across sysplex wide IPLs, so a sysplex wide IPL will clear the
       setting.
2. Start Reallocate Structures: SETXCF START, REALLOCATE
    **REALLOCATE**
       Specifies that the REALLOCATE process is to be initiated.
       The REALLOCATE process evaluates each allocated structure to recognize the need to make the
       following adjustments:
       - Relocate the structure instance or instances
       - Complete a pending policy change
       - Trigger MVS-initiated duplexing
       The evaluation of each allocated structure uses the XCF structure allocation algorithm and either
       the active or pending CFRM policy definition for the structure. Message IXC574I is written to the
       hardcopy log to show the current location of instances allocated in coupling facilities, the policy
       information used, and the evaluation result. Then it compares the current location with the location
       identified by evaluation to determine what if any adjustments are needed.
3. Set Logical Path Offline: VARY PATH( _path_ ),OFFLINE,FORCE and ROUTE _system_ VARY
    PARTH( _path_ ),OFFLINE,FORCE

**22**   Sysplex Management task


##### OFFLINE

```
Specifies that the system is to take the specified path offline.
For more information, see SETXCF Commands in z/OS MVS System Commands and Vary Commands in
z/OS MVS System Commands.
```
#### Confirm Restore After Disruptive Maintenance

```
Use this dialog to confirm or cancel your request.
Click OK to confirm the request and continue.
Click Cancel to cancel the request and return to the previous page.
If you click OK to confirm the request, several MVS commands are issued for you. To see the command
syntax, click Command Preview.
```
**Commands issued**

1. Set Logical Path Online: VARY PATH( _path_ ),ONLINE,FORCE and ROUTE _system_ VARY
    PARTH( _path_ ),ONLINE,FORCE
    **ONLINE**
       Specifies that the system is to bring the specified path online.
2. Stop Maintenance Mode: SETXCF STOP, MAINTMODE,CFNAME= _coupling-facility-name_
    Turns off MAINTMODE for the specified coupling facility or facilities. When in maintenance mode, a CF
    is not eligible for CF structure allocation purposes.
3. Start Reallocate Structures: SETXCF START, REALLOCATE
    **REALLOCATE**
       Specifies that the REALLOCATE process is to be initiated.
       The REALLOCATE process evaluates each allocated structure to recognize the need to make the
       following adjustments:
       - Relocate the structure instance or instances
       - Complete a pending policy change
       - Trigger MVS-initiated duplexing
       The evaluation of each allocated structure uses the XCF structure allocation algorithm and either
       the active or pending CFRM policy definition for the structure. Message IXC574I is written to the
       hardcopy log to show the current location of instances allocated in coupling facilities, the policy
       information used, and the evaluation result. Then it compares the current location with the location
       identified by evaluation to determine what if any adjustments are needed.
For more information, see SETXCF Commands in _z/OS MVS System Commands_ and Vary Commands in
_z/OS MVS System Commands_.

### Coupling Facility Structures views

```
Use the Coupling Facility Structures views to see and manage your coupling facility structures, for
coupling facilities that are connected to the systems in the sysplex.
You can view coupling facility structures by type and by coupling facility. Each view includes a graphic
view and a table view.
```
```
Sysplex Management task   23
```

#### Display a Coupling Facilities Structures View

```
Perform these steps to see a Coupling Facilities Structures View.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open** to display the physical view.
    In the Graphic View field in the control bar for the graphic view, ensure that the value is Physical.
3. Click the right mouse button on one of the following in the graphic view:
    - The name of the sysplex, then click **Open Structures** and **Coupling Facility View** , to see the
       structures organized by coupling facility, or click **Type View** , to see the structures organized by
       type.
    - The name of a coupling facility, then click **Open Structures**. This displays the structures for the
       selected coupling facility.

#### View Coupling Facility Structures

```
Use the Coupling Facility Structures view to see and manage your coupling facility structures. It includes a
graphic and a table view.
```
```
Graphic view
The graphic view varies shows:
```
- Coupling facilities, and objects contained by the coupling facility, representing the structures.
- With the Type view, the coupling facility structures are grouped by type: List, Lock, Cache, or Serialized
    List.
- Unallocated coupling facility structures, which do not have a type. They are assigned a type when they
    are allocated.
Figure 3 on page 24 shows coupling facility SVT6CF2, with three structures.

```
Figure 3. Example coupling facility structure
```
```
Figure 4 on page 25 shows a group of three LIST-type structures.
```
**24**   Sysplex Management task


```
Figure 4. Example of coupling facility structures, grouped by type
```
```
Click a structure name to view details. Click the right mouse button on a structure name to display a menu
of actions for the object.
If you set a filter in the table, coupling facilities, and their associated coupling facility structures, may be
excluded from the graphic view.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

**Actions for the Coupling Facilities Structures Graphic view**

- For a description of the actions for the CF Object see: Table 21 on page 25.
- For a description of the targeted actions for the CF Structure see: Table 22 on page 26.
- For a description of the targeted actions for the Unallocated CF Structure see: Table 23 on page 27.

_Table 21. Actions for the CF object_

**Action Description**

**Rebuild All Structures on
CF**

```
Start
Start Rebuild For all structures for a selected CF. See “Start Rebuild (All)” on
page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop Rebuild (All)” on
page 160 for more information.
```
```
Sysplex Management task   25
```

```
Table 21. Actions for the CF object (continued)
```
```
Action Description
```
```
Duplex All Structures on
CF
```
```
Start
Start Duplexing for all structures for a selected CF. See “Start Duplexing (All)”
on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop Duplexing (All)” on
page 162 for more information.
```
```
Reallocate All Structures
in Sysplex
```
```
Start
Reallocate structures across all CFs. See “Start Reallocate” on page 155 for
more information.
Stop
Stop reallocate processing when finished with the structure currently being
processed. See “Stop Reallocate” on page 158 for more information.
```
```
Properties Display properties of the object.
```
```
Table 22. Actions for the CF Structure object
```
```
Action Description
```
```
Open Structures
Connectors View
```
```
Displays the CF Structures view. Not available if the CF structure is unallocated.
```
```
Rebuild Start
Start Rebuild for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Stop
Stop Rebuild for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Not available if the CF structure is unallocated.
```
```
Duplex Start
Start Duplex for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Stop
Stop Duplex for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Not available if the CF structure is unallocated.
```
```
Reallocate All Structures
in Sysplex
```
```
Start
Reallocate structures across all CFs. See “Start Reallocate” on page 155 for
more information.
Stop
Stop reallocate processing when finished with the structure currently being
processed. See “Stop Reallocate” on page 158 for more information.
Not available if the CF structure is unallocated.
```
```
Properties View the properties of the selected object.
```
**26**   Sysplex Management task


_Table 23. Actions for the Unallocated CF Structure_

**Action Description**

**Properties** View the properties of the selected object.

```
Table view
For a description of the columns in the table in the Coupling Facilities Structures view, see Table 24 on
page 27. For a description of the actions that you can take, refer to “Actions for the table view” on page
27.
```
_Table 24. Columns in the Coupling Facilities Structures table view_

**Column Description**

**CF Name or Type /
Structure**

```
Coupling facility name or type. Expand the row to see the structures.
```
**CF Name** Coupling facility name.

**Status** Status of the coupling facility structure. For possible values, click **Legend** on the
toolbar.

**Type** Type of the coupling facility structure.

**Allocation Time** Date and time that the strucutre was allocated.

**Actions for the table view**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 25 on page 27.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 26
    on page 28.

_Table 25. Targeted Actions for the Coupling Facilities Structures view_

**Action Object Description**

**Open Structures
View**

```
CF Displays the Coupling Facility Structures view.
```
**Open Structures
Connectors View**

```
CF Structure Displays the CF Structures view. Not available if the CF structure is
unallocated.
```
**Rebuild** CF, CF Structure **Start**

```
Start Rebuild for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Stop
Stop Rebuild for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Not available if the CF structure is unallocated.
```
```
Sysplex Management task   27
```

```
Table 25. Targeted Actions for the Coupling Facilities Structures view (continued)
```
```
Action Object Description
```
```
Duplex CF, CF Structure Start
Start Duplex for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Stop
Stop Duplex for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Not available if the CF structure is unallocated.
```
```
Reallocate All
Structures in
Sysplex
```
```
CF, CF Structure Start
Reallocate structures across all CFs. See “Start Reallocate” on
page 155 for more information.
Stop
Stop reallocate processing when finished with the structure
currently being processed. See “Stop Reallocate” on page 158
for more information.
Not available if the CF structure is unallocated.
```
```
Properties CF, CF Structure View the properties of the selected object.
```
```
Expand CF Expand the selected parent nodes so that the rows that contain
the corresponding child nodes are visible. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain collapsed
parent nodes.
```
```
Collapse CF Collapse the selected parent nodes so that the rows that contain
the corresponding child nodes are hidden. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain expanded
parent nodes.
```
```
Table 26. Table actions for the Coupling Facilities Structures view table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
**28**   Sysplex Management task


_Table 26. Table actions for the Coupling Facilities Structures view table (continued)_

**Action Description**

**Expand All** Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.

**Collapse All** Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.

**Switch to Non-Tree View** Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.

```
View Coupling Facility Structures for a coupling facility
Use the Coupling Facility Structures for a coupling facility view to see and manage your coupling facility
structures. It includes a graphic and a table view.
The Coupling Facility Structures for a coupling facility view includes both a graphic and table view.
```
**Graphic view**

```
The graphic view varies shows the following:
```
- The selected coupling facility.
- Objects contained by the coupling facility, representing the structures.
Figure 5 on page 29 shows coupling facility SVT6CF2, with three structures.

```
Figure 5. Example coupling facility structure
```
```
Click a structure name to view details. Click the right mouse button on a structure name to display a menu
of actions for the object.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.

```
Sysplex Management task   29
```

- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

**Actions for the Coupling Facilities Structures view**

```
Table 27. Actions for the Coupling Facilities Structures view
```
```
Action Objects Description
```
```
Open Structure
Connectors View
```
```
CF, CF structure View the structures view for the CF.
```
```
View Properties CF, CF structure View the properties of the selected object.
```
```
Collapse CF Collapse the selected parent nodes so that the rows that contain
the corresponding child nodes are hidden. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain expanded
parent nodes.
```
```
Expand CF Expand the selected parent nodes so that the rows that contain
the corresponding child nodes are visible. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain collapsed
parent nodes.
```
**Table view**

```
For a description of the columns in the table in the Coupling Facilities Structures view, see Table 28 on
page 30. For a description of the actions that you can take, refer to “Actions for the table view” on page
30.
```
```
Table 28. Columns in the Coupling Facilities Structures table view
```
```
Column Description
```
```
CF Name / Structure Coupling facility name. Expand the row to see the structures.
```
```
CF Name Coupling facility name.
```
```
Status Status of the coupling facility structure.
```
```
Type Type of the coupling facility structure.
```
```
Allocation Time Date and time that the strucutre was allocated.
```
```
Actions for the table view
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 29 on page 30.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 30
    on page 31.

```
Table 29. Actions for the Coupling Facilities Structures view table
```
```
Action Description
```
```
Open View details for the object
```
```
View Properties View the properties of the selected object.
```
**30**   Sysplex Management task


```
Table 29. Actions for the Coupling Facilities Structures view table (continued)
```
```
Action Description
```
```
Expand Expand the selected parent nodes so that the rows that contain the corresponding
child nodes are visible. This action is listed only when you are displaying the tree
view of the table. To enable this action, you must select one or more rows that
contain collapsed parent nodes.
```
```
Collapse Collapse the selected parent nodes so that the rows that contain the corresponding
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table. To enable this action, you must select one or more rows that
contain expanded parent nodes.
```
```
Table 30. Table actions for the Coupling Facilities Structures view table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
#### View Coupling Facility Structures by type

```
Use the Coupling Facility Structures by type view to see and manage your coupling facility structures. It
includes a graphic and a table view.
```
**Graphic view**

```
The graphic view varies shows:
```
- Coupling facility structures grouped by type: List, Lock, Cache, or Serialized List.
- Unallocated coupling facility structures, which do not have a type. They are assigned a type when they
    are allocated.
Figure 6 on page 32 shows a group of three LIST-type structures. Figure 6 on page 32 shows list type
coupling facility structures.

```
Sysplex Management task   31
```

```
Figure 6. Example of a coupling facility structure
```
```
Click a structure name to view details. Click the right mouse button on the name to display a menu of
actions for the object.
If you set a filter in the table, coupling facility structure types, and their associated coupling facility
structures, might be excluded from the graphic view.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

**Actions for the Coupling Facilities Structures view**

```
Table 31. Actions for the CF Structure object
```
```
Action Description
```
```
Open Structures
Connectors View
```
```
Displays the CF Structures view. Not available if the CF structure is unallocated.
```
```
Rebuild Start
Start Rebuild for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Stop
Stop Rebuild for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Not available if the CF structure is unallocated.
```
**32**   Sysplex Management task


_Table 31. Actions for the CF Structure object (continued)_

**Action Description**

**Duplex Start**

```
Start Duplex for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Stop
Stop Duplex for one or more selected structures. See “Start Rebuild” on page
158 for more information.
Not available if the CF structure is unallocated.
```
**Reallocate All Structures
in Sysplex**

```
Start
Reallocate structures across all CFs. See “Start Reallocate” on page 155 for
more information.
Stop
Stop reallocate processing when finished with the structure currently being
processed. See “Stop Reallocate” on page 158 for more information.
Not available if the CF structure is unallocated.
```
**Properties** View the properties of the selected object.

```
Table view
For a description of the columns in the table in the Coupling Facilities Structures view, see Table 32 on
page 33. For a description of the actions that you can take, refer to “Actions for the table view” on page
33.
```
_Table 32. Columns in the Coupling Facilities Structures table view_

**Column Description**

**Type / Structure** Coupling facility type. Expand the row to see the structures.

**CF Name** Coupling facility name.

**Status** Status of the coupling facility structure.

**Type** Type of the coupling facility structure.

**Allocation Time** Date and time that the structure was allocated.

**Actions for the table view**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 33 on page 33.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 34
    on page 34.

_Table 33. Targeted Actions for the Coupling Facilities Structures view_

**Action Object Description**

**Open Structures
View**

```
CF Displays the Coupling Facility Structures view.
```
**Open Structures
Connectors View**

```
CF Structure Displays the CF Structures view. Not available if the CF structure is
unallocated.
```
```
Sysplex Management task   33
```

```
Table 33. Targeted Actions for the Coupling Facilities Structures view (continued)
```
```
Action Object Description
```
```
Rebuild CF, CF Structure Start
Start Rebuild for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Stop
Stop Rebuild for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Not available if the CF structure is unallocated.
```
```
Duplex CF, CF Structure Start
Start Duplex for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Stop
Stop Duplex for all structures for a selected CF, or for one or
more selected structures. See “Start Rebuild” on page 158 for
more information.
Not available if the CF structure is unallocated.
```
```
Reallocate All
Structures in
Sysplex
```
```
CF, CF Structure Start
Reallocate structures across all CFs. See “Start Reallocate” on
page 155 for more information.
Stop
Stop reallocate processing when finished with the structure
currently being processed. See “Stop Reallocate” on page 158
for more information.
Not available if the CF structure is unallocated.
```
```
Properties CF, CF Structure View the properties of the selected object.
```
```
Expand CF Expand the selected parent nodes so that the rows that contain
the corresponding child nodes are visible. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain collapsed
parent nodes.
```
```
Collapse CF Collapse the selected parent nodes so that the rows that contain
the corresponding child nodes are hidden. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain expanded
parent nodes.
```
```
Table 34. Table actions for the Coupling Facilities Structures view table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
**34**   Sysplex Management task


```
Table 34. Table actions for the Coupling Facilities Structures view table (continued)
```
```
Action Description
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
#### CF Structure

```
Use the CF Structure view to see connection details about a CF Structure. It includes a graphic and a table
view.
Use Legend to define colors for the objects and specific statuses that are displayed in that view.
```
**Graphic view**

```
The graphic view shows the following:
```
- The coupling facility structure. Objects representing structures are shown as contained by the coupling
    facility object. The coupling facility type is also shown.
- Systems and connectors (connection name and ASID). Figure 7 on page 35 shows a connector for SY1.

```
Figure 7. Example with system and the associated connector
```
```
Hover the mouse pointer over a structure or connector to show details about it.
You can display a context menu of actions for a sysplex resource by clicking the right mouse button on the
name of the resource (displayed as a link). Click the name to display details about the resource on a new
page.
Filters that you set in the table do not affect the graphic view.
```
```
Sysplex Management task   35
```

**Actions for the CF Structure view**

```
Table 35. Actions for the CF Structure view
```
```
Action Objects Description
```
```
View Properties CF, CF structure,
System
```
```
View the properties of the selected object.
```
**Table view**

```
For a description of the columns in the table in the CF Structure view, see Table 36 on page 36. For a
description of the actions that you can take, refer to “Actions for the table view” on page 36.
```
```
Table 36. Columns in the CF Structure table view
```
```
Column Description
```
```
System / Connector The name of the system that owns the connection. Expand the row to see
information about the connector.
```
```
Connector ID The connection identifier.
```
```
Connector Version The connection version.
```
```
Connector System The name of the system that owns the connection.
```
```
Job Name The name of the job owning the connection
```
```
ASID The identifier of the address space that owns the connection
```
```
State The state of the connection.
```
**Actions for the table view**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 37 on page 36.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 38
    on page 37.

```
Table 37. Actions for the CF Structure view
```
```
Action Objects Description
```
```
View Properties System View the properties of the selected object.
```
```
Expand System Expand the selected parent nodes so that the rows that contain
the corresponding child nodes are visible. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain collapsed
parent nodes.
```
```
Collapse System Collapse the selected parent nodes so that the rows that contain
the corresponding child nodes are hidden. This action is listed only
when you are displaying the tree view of the table. To enable this
action, you must select one or more rows that contain expanded
parent nodes.
```
**36**   Sysplex Management task


```
Table 38. Table actions for the CF Structure view table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
```
Display the CF Structure view
You can display the CF Structure view for a coupling facility structure that you select on the Coupling
Facilities Structures View.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open** to display the physical view.
    In the Graphic View field in the control bar for the graphic view, ensure that the value is Physical.
3. Click the right mouse button on one of the following in the graphic view:
    - The name of the sysplex, then click **Open Structures** and **Coupling Facility View** (to see the
       structures organized by coupling facility) or **Type View** (to see the structures organized by type).
    - The name of a coupling facility, then click **Open Structures**.
4. On the Coupling Facility Structures View, click the right mouse button on a coupling facility structure
    name to display a menu of actions, then select **Open**.

#### View Properties for CF Structure

```
The View Properties for CF Structure page shows details about the selected coupling facility structure.
To view the properties for a coupling facility structure, on the Coupling Facilities Structures page, click the
name of a coupling facility structure.
The properties are organized on tabs. For a description of the fields, see “General tab” on page 38,
“Structure tab” on page 39, and “Connectors tab” on page 42.
```
```
Sysplex Management task   37
```

```
General tab
The general tab includes a collapsible section for policy information.
```
```
Table 39. Fields on the General tab of the View Properties for CF Structure page
```
```
Field Description
```
```
Structure name Name of the structure.
```
```
Type Type of the structure. This is N/A if the status is Not allocated. The coupling facility
structure is assigned a type when it is allocted.
```
```
Duplexed Indicates if the structure is duplexed.
```
```
Status Status of the structure. Click Legend in the toolbar to display a list of values.
```
```
Event management The CFRM event management protocol according to the CFRM active policy.
```
```
Encryption Status Possible values are:
Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is encrypted.
Not Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is not encrypted.
Encryption Mismatch
A coupling facility structure with an encryption state (encrypted or not
encrypted) that does not match the CFRM policy specification. This can identify
the following:
```
- Invalid CFRM policy specification of ENCRYPT(YES) for lock structures that
    do not support encryption.
- Coupling facility structures with a CFRM pending policy change for the
    ENCRYPT attribute. The pending policy change can be resolved through
    deallocation of structure in the coupling facility, structure rebuild processing
    or the REALLOCATE precess.
If pending policy changes exist for a coupling facility structure, this pending
policy information will be used to determine if an encryption state mismatch
exists.

```
Table 40. Fields in the Policy Information section
```
```
Column Description
```
```
Policy size The size of the structure. The units are K (kilobytes), M (megabytes), G (gigabytes),
or T (terabytes).
```
```
Policy initsize The initial amount of space to be allocated for the structure in the coupling facility.
```
```
Policy minsize The the smallest size to which the structure can ever be altered, preventing
allocation of an unusable structure.
```
```
Full threshold The percentage value used by the system to control structure full monitoring and
automatic alter.
```
**38**   Sysplex Management task


_Table 40. Fields in the Policy Information section (continued)_

**Column Description**

**Allow automatic alter** One of the following:

```
YES
System-initiated alter (automatic alter) of the structure is allowed. For
structure alter processing to be started for the structure, connections must
also allow alter.
NO
System-initiated alter (automatic alter) of the structure is not allowed.
```
**Rebuild Percent** This specifies, as a percent of lost connectivity to a structure, when MVS is to
initiate a user-managed rebuild.

**Duplex** Indicates whether the structure is currently duplexed. This specifies the
installation's request for duplexing rebuild of the structure.

**Allow REALLOCATE** The installation's request for REALLOCATE processing when evaluation of the
allocated structure determines that the structure needs rebuild processing.

**Enforce order** When ENFORCEORDER(YES) is specified, allocation attempts will adhere to the
PREFLIST more closely, giving it a higher priority than such factors as system
weight connectivity and optimum size.

**Preference List** Specifies an ordered list of coupling facility names from which the system is to
choose when allocating a structure in a coupling facility.

**Exclusion List** The list of 1 to 8 coupling facility structure names with which this structure should
not share the same coupling facility.

```
Structure tab
The Structure tab includes a collapsible Storage Configuration section.
```
_Table 41. Fields on the Structure tab of the View Properties for CF Structure page_

**Field Description**

**Allocation time** The time and date when the structure was allocated

**CF Name** Name of the coupling facility.

**Coupling Facility** The coupling facility that this system is able to use, identified by the node
descriptor.
**Name**
Name of the coupling facility in as _type_. _manufacture-ID_. _manufacture-plant-
ID_. _sequence-number_.
**Partition**
Node LPAR partition number
**CPC ID**
Node Central Processor Complex (CPC) ID.

**Status** Status of the structure.

**Physical Version** Physical version for the structure. This changes when a new instance of the
structure is allocated, as in a user-managed or system-managed rebuild, and there
is at least one active connector to observe the allocation.

**Logical Version** Logical structure version number that is used for diagnostic purposes.

```
Sysplex Management task   39
```

```
Table 41. Fields on the Structure tab of the View Properties for CF Structure page (continued)
```
```
Field Description
```
```
Disposition The structure disposition.
```
```
Access time The length of time that the connector can tolerate not having access to the
structure.
```
```
Maximum connections The maximum number of connections for this structure.
```
```
Number of connections The current number of connections for this structure.
```
```
System recprty The recovery priority for the structure determined by the system. Recovery
priority specifies the priority to be given to the structure for LOSSCONN recovery
(system loses connectivity to a coupling facility) and policy-initiated duplexing for
DUPLEX(ENABLED) structures.
```
```
Encryption Status Possible values are:
Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is encrypted.
Not Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is not encrypted.
Encryption Mismatch
A coupling facility structure with an encryption state (encrypted or not
encrypted) that does not match the CFRM policy specification. This can identify
the following:
```
- Invalid CFRM policy specification of ENCRYPT(YES) for lock structures that
    do not support encryption.
- Coupling facility structures with a CFRM pending policy change for the
    ENCRYPT attribute. The pending policy change can be resolved through
    deallocation of structure in the coupling facility, structure rebuild processing
    or the REALLOCATE precess.
If pending policy changes exist for a coupling facility structure, this pending
policy information will be used to determine if an encryption state mismatch
exists.

```
A collapsible Storage Configuration section shows allocated storage and space usage.
```
```
Table 42. Fields in the Allocated Storage table
```
```
Column Description
```
```
Allocated The actual size of the structure, in megabytes.
```
```
Maximum The maximum size of the structure, in megabytes.
```
```
Percent Used The percentage of the maximum value (allocated / maximum).
```
```
Table 43. Fields in the Space Usage table
```
```
Column Description
```
```
Name Name for the item being described.
```
```
In Use The number of in-use entries or elements residing in CF real storage.
```
```
Total The total number of entries or elements allocated in CF real storage.
```
**40**   Sysplex Management task


_Table 43. Fields in the Space Usage table (continued)_

**Column Description**

**Percent Used** The percentage of objects that are in-use relative to the total count (in-use/total).

```
Pending Structure tab
The Pending Structure tab includes a collapsible Storage Configuration section.
```
_Table 44. Fields on the Pending Structure tab of the View Properties for CF Structure page_

**Field Description**

**Allocation time** The time and date when the structure was allocated

**CF Name** Name of the coupling facility.

**Coupling Facility** The coupling facility that this system is able to use, identified by the node
descriptor.
**Name**
Name of the coupling facility in as _type_. _manufacture-ID_. _manufacture-plant-
ID_. _sequence-number_.
**Partition**
Node LPAR partition number
**CPC ID**
Node Central Processor Complex (CPC) ID.

**Status** Status of the structure.

**Physical Version** Physical version for the structure. This changes when a new instance of the
structure is allocated, as in a user-managed or system-managed rebuild, and there
is at least one active connector to observe the allocation.

**Logical Version** Logical structure version number that is used for diagnostic purposes.

**Disposition** The structure disposition.

**Access time** The length of time that the connector can tolerate not having access to the
structure.

**Maximum connections** The maximum number of connections for this structure.

**Number of connections** The current number of connections for this structure.

**System recprty** The recovery priority for the structure determined by the system. Recovery
priority specifies the priority to be given to the structure for LOSSCONN recovery
(system loses connectivity to a coupling facility) and policy-initiated duplexing for
DUPLEX(ENABLED) structures.

```
Sysplex Management task   41
```

```
Table 44. Fields on the Pending Structure tab of the View Properties for CF Structure page (continued)
```
```
Field Description
```
```
Encryption Status Possible values are:
Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is encrypted.
Not Encrypted
User structure data written to the coupling facility structure and residing in the
coupling facility structure is not encrypted.
Encryption Mismatch
A coupling facility structure with an encryption state (encrypted or not
encrypted) that does not match the CFRM policy specification. This can identify
the following:
```
- Invalid CFRM policy specification of ENCRYPT(YES) for lock structures that
    do not support encryption.
- Coupling facility structures with a CFRM pending policy change for the
    ENCRYPT attribute. The pending policy change can be resolved through
    deallocation of structure in the coupling facility, structure rebuild processing
    or the REALLOCATE precess.
If pending policy changes exist for a coupling facility structure, this pending
policy information will be used to determine if an encryption state mismatch
exists.

```
A collapsible Storage Configuration section shows allocated storage and space usage.
```
```
Table 45. Fields in the Allocated Storage table
```
```
Column Description
```
```
Allocated The actual size of the structure, in megabytes.
```
```
Maximum The maximum size of the structure, in megabytes.
```
```
Percent Used The percentage of the maximum value (allocated / maximum).
```
```
Table 46. Fields in the Space Usage table
```
```
Column Description
```
```
Name Name for the item being described.
```
```
In Use The number of in-use entries or elements residing in CF real storage.
```
```
Total The total number of entries or elements allocated in CF real storage.
```
```
Percent Used The percentage of objects that are in-use relative to the total count (in-use/total).
```
```
Connectors tab
The Connectors tab has a collapsible section for each connector.
```
```
Table 47. Fields on the Connectors tab
```
```
Field Description
```
```
Connector ID The connection identifier.
```
```
Connector version The connection version number.
```
**42**   Sysplex Management task


```
Table 47. Fields on the Connectors tab (continued)
```
```
Field Description
```
```
Connector system name The name of the system owning the connection.
```
```
Job name The name of the job owning the connection.
```
```
ASID The identifier of the address space owning the connection.
```
```
State The operational state of the connector. The icon for the connector also indicates
the state.
```
### CF Connectivity view

```
Use the CF Connectivity view to view and manage physical connections among systems and CFs.
The CF Connectivity view includes a graphic view and a table view.
```
```
Graphic View
CPCs are represented by objects containing z/OS systems (a number in parentheses indicates the number
of z/OS systems) and coupling facilities. Physical connections are shown as lines. The number of physical
connections is shown in a box on the line connecting CPCs (2 in Figure 8 on page 43). Click the box
to display connection details. You can also click the number of CHPIDs, which is shown in a gray box (4
on CPC P59 in the example below). You can also display connection details by selecting CF Connectivity
Details in the Graphic View field in the tool bar for the graphic view.
```
```
Figure 8. Example of a graphic view of connectivity
```
```
Click a link, such as the sysplex name, to view details. Click the right mouse button on a link to display a
menu of actions for the object.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

```
Sysplex Management task   43
```

**Actions for the graphic view**

```
Table 48. Actions for the CPC connection or number of CHPIDs
```
```
Action Description
```
```
Open Connection Details View the connection details for the connection from CPC to CPC.
```
```
Table 49. Actions for CF Link object and Internal CF Link
```
```
Action Description
```
```
View properties Displays the details view for the object.
```
```
Table 50. Actions for the coupling facility object
```
```
Action Description
```
```
Open Structures View View the coupling facility structures.
```
```
Rebuild All Structures on
CF
```
```
Start
Start Rebuild For all structures for a selected CF. See “Start Rebuild (All)” on
page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop Rebuild (All)” on
page 160 for more information.
```
```
Duplex All Structures on
CF
```
```
Start
Start Duplexing for all structures for a selected CF. See “Start Duplexing (All)”
on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop Duplexing (All)”
on page 162 for more information.
```
```
Maintenance Mode Start
Starts maintenance mode for the selected CF. See “Start Maintenance Mode”
on page 164.
Stop
Stops maintenance mode for the selected CF. See “Stop Maintenance Mode”
on page 164.
```
```
Prepare for Disruptive
Maintenance
```
```
Prepares the selected CF for disruptive maintenance. See “Prepare for Disruptive
Maintenance” on page 164.
```
```
Restore after Disruptive
Maintenance
```
```
Restores the selected CF from disruptive maintenance. See “Restore after
Disruptive Maintenance” on page 164.
```
```
Set Physical Path (Config) Online
Restore all of the channel paths to a CF from all the systems within a sysplex.
Offline
Remove all of the channel paths to a CF from all the systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
**44**   Sysplex Management task


_Table 50. Actions for the coupling facility object (continued)_

**Action Description**

**Set Logical Path (Vary) Online**

```
Restore all of the channel paths to a CF from all the systems within a sysplex.
Offline
Remove all of the channel paths to a CF from all the systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
**Properties** Displays the details view for the object.

```
Table view
For a description of the columns in the table, see Table 51 on page 45. For a description of the actions
that you can take, refer to “Actions” on page 45.
```
_Table 51. Columns in the Connectivity table_

**Column Description**

**CPC/Connected CPC** Name of the CPC. Expand the row to see the name of the connected CPC.

**Connection Type (No. of
Connections)**

```
The type of connection, followed by the number of connections in parentheses.
```
**Coupling Facilities** Coupling facilities for the CPC..

**No. of z/OS Systems** Number of z/OS systems.

**No. of Internal
Connections**

```
Number of internal connections.
```
**Actions**

```
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 52 on page 45.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 53
    on page 45.

_Table 52. Targeted actions for the Connectivity table_

**Action Description**

**Properties** Displays the details view for the object.

**Expand** Expand the row.

**Collapse** Collapse the row.

```
Note: In the graphic view, but not the table, you can use the Open Structures action for a coupling facility
to display the coupling facility structures.
```
_Table 53. Table actions for the Connectivity table_

**Action Description**

**Configure Columns** Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.

```
Sysplex Management task   45
```

```
Table 53. Table actions for the Connectivity table (continued)
```
```
Action Description
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
```
Expand All Expand all of the parent nodes in the table so that all of the rows that contain child
nodes are visible. This action is listed only when you are displaying the tree view of
the table.
```
```
Collapse All Collapse all of the parent nodes in the table so that all of the rows that contain
child nodes are hidden. This action is listed only when you are displaying the tree
view of the table.
```
```
Switch to Non-Tree View Display the non-hierarchical view of the table. This action is listed only when you
are displaying the tree view of the table.
```
#### Display the CF connectivity view

```
Perform these steps to see the CF Connectivity View of a sysplex.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
3. In the Graphic View field in the control bar for the graphic view, select **CF Connectivity**.

### CF Connectivity Details view

```
Use the CF Connectivity Details view to see details of connectivity between a CF and a system. Besides
physical connections for the connectivity, it also shows which Channel Path Identifier (CHPID) and port
are used for connectivity.
The CF Connectivity Details view includes a graphic view and a table view.
```
**Graphic View**

```
The graphic view shows the sysplex as the largest object, containing CPCs (P59 and S92 in Figure 9
on page 47), which in turn contain systems (P00 and P03 in the example) and CFs (SVT6CF2 in the
example). CHIPDs, adapters, and ports are represented to show the connection between systems and
CFs. In the example, the CHPIDs are 8 and 9, and the adapters/ports are 12/2 and 1A/1. A connection can
use only one pair of ports, but it can use several pairs of CHPIDs. There is no mapping, in this view, of the
CHPIDs and adapters/ports and links.
Lines between objects represent links, with the color indicating the link type (CFS, CBS, CBP, and so on),
and the number indicating the number of links of that type. To see the mapping of line color to link type,
click Legend on the graphics view toolbar.
```
**46**   Sysplex Management task


_Figure 9. Example of a graphic view of CF connectivity details_

Clicking a system name (such as P00 in Figure 9 on page 47) shows connection details, including the
mapping between CHPIDs and adapter/ports. Each connection is represented by a single line. The color
again represents the link type. In Figure 10 on page 47, CHPID 8 maps to the adapter/port 12/2, and
CHPID 9 maps to the adapter/port 1A/1.

_Figure 10. Example of dditional detail for connections_

Click other links, such as the coupling facility name, to display details.

Click the right mouse button on a link to display a menu of actions for the object.

**Toolbar:** The graphic view includes a tool bar with several handy functions:

- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,

```
typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.
```
**CF Connectivity Details Graphic View**

Actions for each object are described in the following tables.

- Sysplex: Table 54 on page 48.
- CPC: Table 55 on page 48.
- System: Table 56 on page 48.
- CF: Table 57 on page 48.

```
Sysplex Management task   47
```

```
Table 54. Actions for the Sysplex Object
```
```
Action Description
```
```
Open Structures View the coupling facility structures, organized either by type or coupling facility.
```
```
Reallocate All Structures
in Sysplex
```
```
Start
Reallocate structures across all syplexes. See “Start Reallocate” on page 155
for more information.
Stop
Stop reallocate processing when finished with the structure currently being
processed. See “Stop Reallocate” on page 158 for more information.
```
```
Properties Displays the details view.
```
```
Table 55. Actions for the CPC Object
```
```
Action Description
```
```
Properties Displays the details view.
```
```
Table 56. Actions for the System Object
```
```
Action Description
```
```
Open Connections Display connections
```
```
Set Physical Path
(Config)
```
```
Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Set Logical Path (Vary) Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Properties Displays the details view.
```
```
Table 57. Actions for the CF Object
```
```
Action Description
```
```
Open Structures View View the coupling facility structures, organized either by type or coupling facility.
```
```
Rebuild All Structures on
CF
```
```
Start
Start Rebuild For all structures for a selected CF. See “Start Rebuild (All)” on
page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop Rebuild (All)” on
page 160 for more information.
```
**48**   Sysplex Management task


_Table 57. Actions for the CF Object (continued)_

**Action Description**

**Duplex All Structures on
CF**

```
Start
Start Duplexing for all structures for a selected CF. See “Start Duplexing (All)”
on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop Duplexing (All)” on
page 162 for more information.
```
**Maintenance Mode Start**

```
Starts maintenance mode for the selected CF. See “Start Maintenance Mode”
on page 164.
Stop
Stops maintenance mode for the selected CF. See “Stop Maintenance Mode” on
page 164.
```
**Prepare for Disruptive
Maintenance**

```
Prepares the selected CF for disruptive maintenance. See “Prepare for Disruptive
Maintenance” on page 164.
```
**Restore after Disruptive
Maintenance**

```
Restores the selected CF from disruptive maintenance. See “Restore after
Disruptive Maintenance” on page 164.
```
**Set Physical Path
(Config)**

```
Online
When used with a CF, restores all of the channel paths to a CF from all the
systems within a sysplex.
Offline
When used with a CF, removes all of the channel paths to a CF from all the
systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
**Set Logical Path (Vary) Online**

```
When used with a CF, restores all of the channel paths to a CF from all the
systems within a sysplex.
Offline
When used with a CF, removes all of the channel paths to a CF from all the
systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
**Properties** Displays the details view.

_Table 58. Actions for the CHPID Object_

**Action Description**

**Set Physical Path
(Config)**

```
Online
When used with a CHPID, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a CHPID, resmoves all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Sysplex Management task   49
```

```
Table 58. Actions for the CHPID Object (continued)
```
```
Action Description
```
```
Set Logical Path (Vary) Online
When used with a CHPID, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a CHPID, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Table view
For a description of the columns in the table, see Table 59 on page 50. For a description of the actions
that you can take, refer to “Actions” on page 50.
```
```
Table 59. Columns in the CF Connectivity Details table
```
```
Column Description
```
```
System Name Name of the system.
```
```
CHPID Channel path identifier.
```
```
PCHID Physical channel path identifier.
```
```
Type Type of CHPID.
```
```
Physical Status Channel path status as reported by the hardware. Currently, z/OSMF only
supports and displays ONLINE, OFFLINE, and ONLINE - DEGRADED three status.
When it displays as OFFLINE, the real status could be OFFLINE, FACILITY
PAUSED, PATH NOT AVAILABLE, MISCABLED, NOT OPERATIONAL, or NOT IN
CONFIGURATION.
```
```
Logical Status Software's representation of the channel path's physical status.
```
```
Adapter Adapter that is associated with the CHPID.
```
```
Port Port that is associated with the CHPID.
```
```
CF Name Remotely connected CF.
```
**Actions**

```
The actions are described in the following table:
```
- Targeted actions. Actions that apply to the selected system. See Table 60 on page 51.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 61
    on page 51.

**50**   Sysplex Management task


```
Table 60. Targeted actions for the System Object
```
```
Action Description
```
```
Set Physical Path
(Config)
```
```
Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Set Logical Path (Vary) Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Table 61. Table actions for the CF Connectivity Details table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Search Clear the search.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
#### Display the CF Connectivity Details View

```
Perform these steps to display the CF Connectivity Details View of a sysplex.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
3. In the Graphic View field in the control bar for the graphic view, select **CF Connectivity Details**.

```
Sysplex Management task   51
```

### View Connection Details for CPC to CPC

```
Use the View Connection Details for CPC to CPC view to see every connection of coupling facility to
coupling facility or z/OS image to coupling facility.
The View Connection Details for CPC to CPC view includes a graphic view and a table view.
```
```
Graphic View
The graphic view shows the sysplex as the largest object, containing CPCs, which in turn contain systems
and CFs. CHIPDs, adapters, and ports are represented to show the connection between systems and CFs.
In Figure 11 on page 52, the CHPIDs are 8 and 9, and the adapter/ports are 12/2 and 1A/1.
```
_Figure 11. Example of a graphic view of View Connection Details for CPC to CPC_

```
Click a link, such as the sysplex name, to view details. Click the right mouse button on a link to display
a menu of actions for the object. Use the Open Structures action for a coupling facility to display the
coupling facility structures.
Toolbar: The graphic view includes a tool bar with several handy functions:
```
- Use **Legend** to define colors for the objects that are displayed in that view.
    1. Click **Legend** to display a list of items that you can highlight.
    2. Click in front of an item to display a color menu.
    3. Click a color to use for that item.
- Use **Zoom Level** to zoom in on or out of the graphic. Select a value from a list.
- Use **Export** to save the graphic view as a scalable vector graphics (svg) file. Icons in the graphic view,
    typically appearing before an object to indicate its type, such as for coupling facility, are not included
in the svg file. The exported svg file may not be well formatted when the length of the text is too long.

```
Graphic view actions
Actions for each object are described in the following tables.
```
- Sysplex: Table 62 on page 53.
- CPC: Table 63 on page 53.
- System: Table 64 on page 53.
- CF: Table 65 on page 53.
- CHPID: Table 66 on page 54.

**52**   Sysplex Management task


_Table 62. Actions for the Sysplex Object_

**Action Description**

**Open Structures** View the coupling facility structures, organized either by type or coupling facility.

**Reallocate All Structures
in Sysplex**

```
Start
Reallocate structures across all syplexes. See “Start Reallocate” on page 155
for more information.
Stop
Stop reallocate processing when finished with the structure currently being
processed. See “Stop Reallocate” on page 158 for more information.
```
**Properties** Displays the details view.

_Table 63. Actions for the CPC Object_

**Action Description**

**Properties** Displays the details view.

_Table 64. Actions for the System Object_

**Action Description**

**Open Connections** Display connections

**Set Physical Path
(Config)**

```
Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
**Set Logical Path (Vary) Online**

```
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
**Properties** Displays the details view.

_Table 65. Actions for the CF Object_

**Action Description**

**Open Structures View** View the coupling facility structures, organized either by type or coupling facility.

**Rebuild All Structures on
CF**

```
Start
Start Rebuild For all structures for a selected CF. See “Start Rebuild (All)” on
page 159 for more information.
Stop
Stop Rebuild For all structures for a selected CF. See “Stop Rebuild (All)” on
page 160 for more information.
```
```
Sysplex Management task   53
```

```
Table 65. Actions for the CF Object (continued)
```
```
Action Description
```
```
Duplex All Structures on
CF
```
```
Start
Start Duplexing for all structures for a selected CF. See “Start Duplexing (All)”
on page 161 for more information.
Stop
Stop Duplexing for all structures for a selected CF. See “Stop Duplexing (All)” on
page 162 for more information.
```
```
Maintenance Mode Start
Starts maintenance mode for the selected CF. See “Start Maintenance Mode”
on page 164.
Stop
Stops maintenance mode for the selected CF. See “Stop Maintenance Mode” on
page 164.
```
```
Prepare for Disruptive
Maintenance
```
```
Prepares the selected CF for disruptive maintenance. See “Prepare for Disruptive
Maintenance” on page 164.
```
```
Restore after Disruptive
Maintenance
```
```
Restores the selected CF from disruptive maintenance. See “Restore after
Disruptive Maintenance” on page 164.
```
```
Set Physical Path
(Config)
```
```
Online
When used with a CF, restores all of the channel paths to a CF from all the
systems within a sysplex.
Offline
When used with a CF, removes all of the channel paths to a CF from all the
systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
```
Set Logical Path (Vary) Online
When used with a CF, restores all of the channel paths to a CF from all the
systems within a sysplex.
Offline
When used with a CF, removes all of the channel paths to a CF from all the
systems within a sysplex.
See “Channel Path Commands” on page 163 for more information.
```
```
Properties Displays the details view.
```
```
Table 66. Actions for the CHPID Object
```
```
Action Description
```
```
Set Physical Path
(Config)
```
```
Online
When used with a CHPID, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a CHPID, resmoves all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
**54**   Sysplex Management task


_Table 66. Actions for the CHPID Object (continued)_

**Action Description**

**Set Logical Path (Vary) Online**

```
When used with a CHPID, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a CHPID, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Table view
For a description of the columns in the table, see Table 67 on page 55. For a description of the actions
that you can take, refer to “Actions” on page 55.
```
_Table 67. Columns in the Sysplex View Connection Details for CPC to CPC table_

**Column Description**

**System Name** Name of the system.

**CHPID** Channel path identifier.

**Type** Type of CHPID..

**Adapter** Adapter that is associated with the CHPID.

**Port** Port that is associated with the CHPID.

**Actions**

```
The actions are described in the following table:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 68 on page 55.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 69
    on page 56.

_Table 68. Targeted actions for the Sysplex View Connection Details for CPC to CPC table_

**Action Description**

**Set Physical Path
(Config)**

```
Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Sysplex Management task   55
```

```
Table 68. Targeted actions for the Sysplex View Connection Details for CPC to CPC table (continued)
```
```
Action Description
```
```
Set Logical Path (Vary) Online
When used with a system, restores all of the channel paths to a CF from a
specific z/OS system.
Offline
When used with a system, removes all of the channel paths to a CF from a
specific z/OS system.
See “Channel Path Commands” on page 163 for more information.
```
```
Table 69. Table actions for the Sysplex View Connection Details for CPC to CPC table
```
```
Action Description
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear Search Clear the search.
```
```
Export Table Data Save the table data as a CSV file. Select an option to export either the current view
or all data.
```
#### Display the View Connection Details from CPC to CPC page

```
Perform these steps to display the connection details for a CPC to CPC connection.
```
**Procedure**

1. Expand the Sysplex category in the navigation area, then select the Sysplex Management task to
    display the topology view.
2. Click the right mouse button on the sysplex name in the graphic representation of a sysplex, then
    select **Open**.
3. In the Graphic View field in the control bar for the graphic view, select **CF Connectivity**.
4. In the graphic view of connectivity, click the box showing the number of connections on a line
    connecting CPCs. For example, click 2 in the following view.

**56**   Sysplex Management task


```
The connection details for a CPC to CPC connection are then displayed.
```
### CFRM Administrative Policies

```
A coupling facility resource management (CFRM) policy describes the coupling facilities and structures
that can be used in the sysplex. The CFRM policies reside in the active couple data set. From the CFRM
Administrative Policies page, you can view and manage the CFRM policies for your sysplex.
The CFRM Administrative Policies page identifies the sysplex and its active policy, and indicates the date
on which the policy was activated.
```
```
A yellow warning icon ( ) is displayed for the active policy if the policy was modified in the time since it
was activated. The presence of this icon means that a more recent version of the policy (with outstanding
changes) is not yet in effect on your sysplex.
The CFRM Administrative Policies page contains the CFRM Administrative Policies table. The table
includes a search filter and a Refresh function. To begin working with a policy, select it from the table.
For information about using a CFRM administrative policy, see z/OS MVS Setting Up a Sysplex.
```
**Authorization requirements**

```
Access to the CFRM Policy Editor and Sizer is controlled through the z/OS® Security Server, which includes
RACF®, or your installation's security manager. Your security administrator must define a profile for
resource name MVSADMIN.XCF.CFRM, which is associated with the CFRM policies.
If your system uses the z/OS Security Server (RACF), define the FACILITY class profile, as follows:
```
```
RDEFINE FACILITY MVSADMIN.XCF.CFRM UACC(NONE)
```
```
Assign UPDATE access authority to users who must alter or maintain the policy. Assign READ access
authority to users who can view the policy, but not change it. The FACILITY class profiles are used for
authority checking on an ACTIVE couple data set. When a couple data set is INACTIVE, the rules for
normal data set protection apply.
After access authority is given to the appropriate users, activate the FACILITY class, as follows:
```
```
SETROPTS CLASSACT(FACILITY)
```
**Actions for the CFRM Administrative Policies view**

```
Click a policy name to view its details. Click the right mouse button on a policy name to display a menu of
actions.
If you set a filter in the table, policies might be excluded from the view.
```
```
Sysplex Management task   57
```

```
Table 70. Actions for the CFRM Administrative Policies view
```
```
Action Description
```
```
Open in CFRM Policy
Editor and Sizer
```
```
Opens the selected policy in the CFRM Policy Editor and Sizer, which presents the
policy details in an easy-to-use, graphical user interface (GUI). The CFRM Policy
Editor includes comprehensive error-checking functions to help you avoid common
errors. For more information, see “CFRM Policy Editor and Sizer” on page 58.
```
```
View Content Opens a read-only, text-based view of the selected policy so that you can view its
contents. When viewed in this manner, a policy is presented as a series of CFRM
control statements, parameters, and settings.
```
```
Rename Opens the Rename Administrative Policy window so that you can rename the
selected policy. For more information, see “Rename a CFRM policy” on page 137.
```
```
Copy Opens the Copy Administrative Policy window so that you can create a copy of the
selected policy. For more information, see “Copy a CFRM policy” on page 138.
```
```
Activate Opens the Activate New Policy window so that you can activate the selected
policy. For more information, see “Activate a CFRM policy” on page 138.
```
```
Delete Opens the Confirm Delete Policy window so that you can delete the selected
policy from the couple data set. You can select more than one policy to delete.
Click OK to confirm your choice or Cancel to cancel this action. If you attempt to
delete the active policy, a prompt is displayed for you to confirm this action.
```
```
Import Opens the Import CFRM Administrative Policy window so that you can
import CFRM administrative policies. For more information, see “Import a CFRM
administrative policy” on page 139.
```
```
Export Opens the Export CFRM Administrative Policy window so that you can
export CFRM administrative policies. For more information, see “Export a CFRM
administrative policy” on page 141.
```
```
Export CSV Downloads two CSV files, one for Coupling Facility and one for Structure.
The format of the Coupling Facility file
name is {{Policy}}_CF_{{date}}_{{random}}.csv , for example
ALTERPOL_CF_2022-2-15-10-6-18_8968310295042106567.csv. The format of
the Structure file name is {{Policy}}_Structure_{{date}}_{{random}}.csv , for example
ALTERPOL_Structure_2022-2-15-10-6-18_6567280780785600008.csv.
```
```
Compare Opens comparison tool to preview differences between two selected policies. This
action is only enabled when exactly two policies are selected by the user. For more
information, see “Compare Administrative Policies” on page 142.
```
#### CFRM Policy Editor and Sizer

```
You can use the CFRM Policy Editor and Sizer to modify the CFRM policies in the CFRM couple data set.
With the CFRM Policy Editor and Sizer, you can:
```
- Edit a CFRM policy by using a graphical user interface (GUI). You can add, delete, and modify the control
    statements in a policy without having to know or understand JCL. As you work, the editor checks your
    changes for correct syntax.
- Tailor an existing CFRM policy with for your installation.
- Create a CFRM policy by using a series of dialogs and prompts. On completion, the policy is ready for
    use in your sysplex.
- Perform CF structure sizing by creating CF sizing definitions within the policy.

**58**   Sysplex Management task


**Key features**

The CFRM Policy Editor and Sizer:

- Presents the details of a CFRM policy in a graphical user interface (GUI).
- Provides easy-to-use options for viewing and modifying a CFRM policy.
- Simplifies CF structure sizing methods by minimizing manual input of sizing data across multiple
    structures.

To get started with the CFRM Policy Editor and Sizer, select a policy in the **CFRM Administrative Policies**
view, then select the action **Open in CFRM Policy Editor and Sizer**.

**Authorization requirements for the CFRM Policy Editor and Sizer**

You must have sufficient authorization to use the functions that are available in the CFRM Policy Editor
and Sizer. For more information, see “Authorization requirements” on page 57.

**CFRM Policy Editor and Sizer main page**

The CFRM Policy Editor and Sizermain page is organized into the primary tabs: **Editor** and **CF Sizing**.

The **Editor** tab displays the following information about the selected policy:

- Policy name
- Sysplex name
- Number of CF structures
- Number of coupling facilities
- Tabbed areas for editing the CF structures and coupling facilities for a policy.

The central feature of the **Editor** tab is the objects table, which displays either CF structures or coupling
facilities, depending on which secondary tabbed view is selected for the policy. The **CF Structures** tab
is selected by default. In the table, you select actions for editing the objects (CF structures and coupling
facilities). Select the tab for the section that you want to view or modify.

The central feature of the **CF Sizing** tab is the CF Sizing Definitions table. A CF Sizing Definition is a
z/OSMF managed object that is used for persisting user sizing inputs. In the table, you select actions for
creating and editing the definition objects.

The task-level actions for the CFRM Policy Editor and Sizer are **Add** , **Close** , and **Submit**.

For more information, see the following topics.

**Editor tab**

The CFRM Policy Editor and Sizer opens with the **CF Structures** tab in focus. On this tab, you can view or
edit the selected CFRM policy.

The CFRM Policy Editor and Sizer **Editor** tab displays the following information:

- Policy name
- Sysplex name
- Number of CF structures
- Number of coupling facilities
- Tabbed areas for editing the CF structures and coupling facilities for a policy.
- Task-level actions for the CFRM Policy Editor and Sizer: **Add** , **Submit** , and **Close**.

The central feature of the Editor tab is the objects table, which displays either CF structures or coupling
facilities, depending on which tabbed view is selected for the policy. In the objects table, you select
actions for editing the policy.

```
Sysplex Management task   59
```

```
Tabbed sections for editing
The major sections of a CFRM policy are organized into the primary tabs: CF structures and Coupling
Facilities. Select the tab for the section that you want to view or modify. The Coupling Facilities tab is
selected by default.
```
**Tab-level actions for the Editor tab**

```
The CFRM Policy Editor and Sizer main page includes the task-level actions Add , Close , and Submit.
Table 71 on page 60 describes the tab-level actions for the Editor tab.
```
```
Table 71. Tab-level actions for the CFRM Policy Editor and Sizer Editor tab
```
```
Action Description
```
```
Add Add a policy to the table view for editing.
```
```
Submit Submit updates for the selected policy. This action saves your changes to the
policy. You are prompted to confirm your action. After you submit the policy, you
cannot undo your updates.
```
```
Close Close the CFRM Policy Editor and Sizer. This action returns control to the CFRM
Administrative Policies view.
This action discards any pending (unsaved) updates for the policy. You are
prompted to confirm your request or return to the editor to continue working with
the policy.
```
```
CF Structures tab
The CFRM Policy Editor opens with the CF Structures tab in focus. On this tab, you can create, edit, and
delete CF structures for the selected CFRM policy.
In a CFRM policy, the STRUCTURE statement specifies the definition of a structure within the scope of the
named policy. The limit for the number of structures that can be defined in a policy is established when
the CFRM couple data set is formatted.
```
```
Authorization requirements for the CFRM Policy Editor
You must have sufficient authorization to use the functions that are available in the CFRM Policy Editor.
For more information, see “Authorization requirements” on page 57.
```
**Layout of the CF Structures tab**

```
The CFRM Policy Editor displays the following information about the selected policy:
```
- Policy name, which specifies the 1 - 8 character name of the policy. The valid characters are uppercase
    alphanumeric characters (A-Z and 0-9). The name must begin with an alphabetic character (A-Z).
- Sysplex name, which specifies the 1 - 8 character name of the sysplex in which the couple data set
    is to be used. The valid characters are uppercase alphanumeric characters (A-Z and 0-9) and national
    characters ($,@,#). The name must begin with an alphabetic character (A-Z).
- Number of CF structures
- Number of coupling facilities
The central feature of the **CF Structures** tab is the CF Structures table, which displays the CF structures
and their attributes. In this table, you select actions for editing the CF structures.
For a description of the columns in the CF Structures table, see “Columns in the CF Structures table” on
page 61. For a description of the actions that you can take for CF Structures, see “Actions for the CF
Structures tab” on page 72.

**60**   Sysplex Management task


```
Columns in the CF Structures table
Table 72 on page 61 describes the columns in the CF Structures table. Notice that each field name in
the editor corresponds to a CFRM policy control statement. The CFRM control statements are not visible
in the CFRM policy editor; to see them, use the View Content action in the CFRM Administrative Policies
view. With the CFRM Policy Editor, you can create, update, and delete CFRM policies without having to
write CFRM control statements.
By default, the structure names in the table are sorted in ascending alphabetical order. To sort the table
based on the values in one or more columns, click the column header for the columns you want to sort.
If a sort is defined for a column, the ascending (▴) or descending (▾) sort icon is shown in the column
header.
```
_Table 72. Attributes of CF Structures_

**Column Policy control statement Description**

**Structure
Name**

```
NAME( strname ) Specifies the 1-16 character name of the structure. The
valid characters are numeric characters, uppercase alphabetic
characters, national characters ($,@,#), or an underscore (_).
The name must start with an alphabetic character (A-Z). IBM
names begin with SYS, or the letters A through I.
Structures that are used for XCF signaling must begin with the
letters IXC.
Structure Name is a required parameter.
```
**Maximum Size** SIZE _(size[u]_ ) Specifies the maximum amount of space to be allocated for
the structure in the coupling facility. The number is specified
in an integer unit of u, where u is specified as K (kilobytes), M
(megabytes), G (gigabytes), or T (terabytes). K is the default unit
when no size unit is specified. The number can be 1 - 9 decimal
digits long.
The maximum structure size is the largest to which the structure
can be altered. If a structure size larger than the maximum
is required, you must modify the CFRM policy to specify the
larger size. When you start the modified policy, the system can
reallocate the new structure, which can be disruptive to your
operation.
Specifying too large a maximum structure size can waste
coupling facility resources. Especially when the SIZE is
significantly larger than INITSIZE, it might even cause the
structure to become unallocatable, depending on the coupling
facility and its CFLEVEL.
Maximum Size is a required parameter. The largest size that can
be specified is 1T. Sizes larger than 1T causes message IXC730I
to be displayed indicating that the number specified is not within
the allowable range for the keyword value.

```
Sysplex Management task   61
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
Initial Size INITSIZE( initsize[u]
)
```
```
Specifies the initial amount of space to be allocated for the
structure in the coupling facility. The number is specified in
an integer unit of u, where u is specified as K (kilobytes), M
(megabytes), G (gigabytes), or T (terabytes). K is the default
unit when no size unit is specified. The number must be 1 -
9 decimal digits long. The INITSIZE value must be less than
or equal to the SIZE value. Otherwise, the system issues error
message IXC745I.
Initial Size is an optional parameter. If not specified, the system
uses the Maximum Size parameter. The largest size that can be
specified is 1T. Sizes larger than 1T causes message IXC730I to
be displayed indicating that the number specified is not within
the allowable range for the keyword value.
```
```
Minimum Size MINSIZE( minsize[u] ) Specifies the smallest size to which the structure can ever
be altered, preventing allocation of an unusable structure. The
number is specified in an integer unit of u, where u is specified
as K (kilobytes), M (megabytes), G (gigabytes), or T (terabytes).
K is the default unit when no size unit is specified.
Structure alter can be initiated by operator command,
programming interface, or automatic alter (see
ALLOWAUTOALT). Minimum Size also serves as a minimum
bound for the structure size on all structure allocation requests
with an exception that system-managed rebuild can allocate
the rebuild new structure with a size smaller than the MINSIZE
value. This can occur when there is not enough space in any
of the coupling facilities in the preference list to satisfy the
MINSIZE requirement for the allocation of the rebuild new
structure, but there is enough space in at least one of the
coupling facilities in the preference list to allocate the rebuild
new structure with a size that allows in use objects to be copied
from the rebuild old structure. In this case, instead of stopping
the system-managed rebuild because the MINSIZE requirement
is not satisfied, the system allows the rebuild to continue.
The number can be 1 - 9 decimal digits long. The MINSIZE value
must be less than or equal to the INITSIZE value, or less than or
equal to the SIZE value if INITSIZE is not specified.
Minimum Size is an optional parameter. The largest size that can
be specified is 1T. Sizes larger than 1T cause message IXC730I
to be displayed indicating that the number specified is not within
the allowable range for the keyword value. If not specified and
ALLOWAUTOALT(NO) is specified or defaulted to, the MINSIZE
is 0. If not specified and ALLOWAUTOALT(YES) is specified, the
system sets MINSIZE to 75% of INITSIZE, or to 75% of SIZE if
INITSIZE is not specified.
```
```
CF Sizing
Definition
```
```
Specifies the association of a CF structure to a CF sizing
definition. A CF sizing definition is a z/OSMF-managed object
with a single-policy scope. CF sizing definitions can be
associated with multiple structures, but a structure can only be
associated with one sizing definition.
```
**62**   Sysplex Management task


_Table 72. Attributes of CF Structures (continued)_

**Column Policy control statement Description**

**Preference List** PREFLIST( _cfname1,cfn
ame2,...,cfname8_ )

```
Specifies an ordered list of coupling facility names from which
the system is to choose when allocating a structure in a
coupling facility. If ENFORCEORDER(NO) is specified, the system
attempts to allocate the structure in the first coupling facility in
the preference list that meets the following allocation criteria
that are regulated by the duplex site preference, and listed
in order of relative importance from most important to least
important as described in "How MVS uses the lists" in z/OS MVS
Setting Up a Sysplex.
The system assumes certain criteria when selecting a coupling
facility for new structure allocation in structure duplexing. The
system always assumes LOCATION=OTHER when selecting the
coupling facility. The coupling facility that is chosen by the
system will, if possible, be failure-independent with respect
to the coupling facility containing the old structure. Lastly, if
the level of connectivity to the new structure is less than that
to the old structure, the action that is taken by the system is
LESSCONNACTION=TERMINATE.
In system-managed duplexing rebuild, the system also requires
that the coupling facility for the new structure allocation have
CF-to-CF connectivity to the coupling facility that contains the
structure to be duplexed. See the topic "Selecting a coupling
facility for the duplexed pair of structures" in z/OS MVS Setting
Up a Sysplex for a description of the criteria used by the system
when allocating a duplexed structure in a coupling facility.
If no coupling facility in the preference list meets all of the
criteria, the system determines the coupling facility that most
closely meets the criteria. See z/OS MVS Setting Up a Sysplex for
information about how the system chooses the coupling facility
in the preference list that most closely meets the requirements
of the connect request.
If the structure you are defining can reside only in a coupling
facility with a certain attribute (such as CFLEVEL or non-
volatility), be sure to include only those coupling facilities in
the preference list for the structure. Two or more coupling
facilities are required when you specify DUPLEX(ALLOWED) or
DUPLEX(ENABLED).
If ENFORCEORDER(YES) is specified, the system will not reorder
the coupling facilities in the preference list, which is regulated,
but will attempt to allocate the structure in the exact order
specified in the preference list, by the SAMESITEONLY duplex
site preference. Therefore, when constructing your preference
list, be sure to place the coupling facilities with the preferred
attributes before any coupling facilities without the wanted
attributes.
For more considerations, see “Developing preference and
exclusion lists” in “Understanding Preference and exclusion lists”
in z/OS MVS Setting Up a Sysplex.
ENFORCEORDER(YES) is mutually exclusive with EXCLLIST.
PREFLIST is a required parameter.
```
```
Sysplex Management task   63
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
Exclusion List EXCLLIST( strname1,st
rname2,...,strname8 )
```
```
Specifies the list of 1 to 8 coupling facility structure names with
which this structure should not share the coupling facility. The
system attempts to honor the exclusion request, but will not fail
a request to allocate a structure when all other requirements
for structure allocation are satisfied and the exclusion list
cannot be honored. However, if all other attributes are equal,
a coupling facility containing only one instance of a duplexed
structure from the exclusion list is selected over a coupling
facility containing a simplex structure from the exclusion list.
EXCLLIST is mutually exclusive with ENFORCEORDER(YES).
EXCLLIST is an optional parameter.
```
```
Duplexing
Options
```
```
DUPLEX( options ) Specifies the installation's request for duplexing rebuild of the
structure.
DISABLED
Neither user-managed nor system-managed duplexing
rebuild can be started for the specified structure. If a
duplexing rebuild is in progress, it is stopped.
ALLOWED
The application can initiate its own user-managed or
system-managed duplexing rebuild or an operator can
start either method of duplexing rebuild with the SETXCF
START,REBUILD,DUPLEX command. However, except for
duplexing being stopped for the structure and then duplexed
again within a REALLOCATE process, the system does not
attempt to maintain the duplexed status of the structure.
The application or operator must initiate another duplexing
operation if the current duplexing is stopped.
ENABLED
The system initiates and attempts to maintain a user-
managed or system-managed duplexing rebuild for the
structure. When a duplexing rebuild process is stopped, the
system attempts to initiate duplexing again. If the operator
stops the duplexing operation, the system ensures that, for
the system's first attempt to duplex the structure again,
the coupling facility that is most recently used to contain
the previous instance of the duplexed structure is not used
again to contain the structure. However, for any attempts
thereafter to duplex the structure again, the system might
choose the same coupling facility for allocation that the
structure vacated.
Coupling facility maintenance might require you to move an
instance of a duplexed structure from a coupling facility. See
z/OS MVS Setting Up a Sysplex for more information.
DUPLEX is an optional parameter. DISABLED is the default,
when DUPLEX is not specified.
```
**64**   Sysplex Management task


_Table 72. Attributes of CF Structures (continued)_

**Column Policy control statement Description**

**Allow
Automatic
Alter**

```
ALLOWAUTOALT(NO|YES) Specifies the installation's request to allow system-initiated
alters (automatic alter) for this structure. For structure alter
processing to be started for a structure, alter must be permitted
(see the SETXCF MODIFY command) and the exploiter must also
allow alter. The ALLOWAUTOALT specification affects the default
value for MINSIZE.
See FULLTHRESHOLD and MINSIZE for related information.
ALLOWAUTOALT takes effect immediately with policy activation.
ALLOWAUTOALT is an optional parameter. NO is the default,
when ALLOWAUTOALT is not specified.
```
**Full Threshold
Percentage**

```
FULLTHRESHOLD( value ) Specifies a percentage value that is used by the system
to control structure full monitoring and automatic alter (see
ALLOWAUTOALT). The value specifies a percent full threshold
for the structure. For a cache structure, the percent full is based
on changed coupling facility structure objects. For a list or lock
structure, the percent full is based on in use coupling facility
structure objects. This number is specified as a percentage and
can be 1 - 3 decimal digits long (0-100). The number must be
greater than or equal to 0 and less than or equal to 100.
Specifying 0 results in no structure full monitoring or automatic
alter processing for the structure. If a value other than 0 is
specified or defaulted to for FULLTHRESHOLD, the value is used
as a percent full threshold for structure full monitoring.
If the exploiter allows alter, ALLOWAUTOALT(YES) is specified,
starting alter processing for the structure is permitted, and the
FULLTHRESHOLD value is reached, automatic alter processing
can be initiated. When the FULLTHRESHOLD value is reached,
structure full monitoring alerts the installation through an
IXC585E message and automatically starts structure alter
processing to relieve the storage shortage for the object whose
storage is in short supply. Before starting the structure alter,
automatic alter issues message IXC588I to the system log to
externalize the alter request.
If the exploiter does not allow alter, or starting alter
processing for the structure is not permitted, the
ALLOWAUTOALT specification is ignored and a nonzero value
for FULLTHRESHOLD is only used by structure full monitoring to
alert the installation.
FULLTHRESHOLD takes effect immediately with policy
activation.
FULLTHRESHOLD is an optional parameter. 80% is the default,
when FULLTHRESHOLD is not specified.
```
```
Sysplex Management task   65
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
Encrypt ENCRYPT(YES|NO) Specifies whether list and cache structure entry data and entry
adjunct data that is written to the structure and residing in
the structure should be encrypted. The structure entry and
entry adjunct data is in an encrypted format while the data is
being transferred to and from the coupling facility and while the
data resides in the coupling facility structure. Encrypted data is
decrypted when read from the structure.
XCF uses Advanced Encryption Standard (AES) 256-bit keys
encrypted under an AES primary key to encrypt and decrypt
structure data.
See z/OS MVS Setting Up a Sysplex for information on system
requirements that must be met before you use ENCRYPT on a
structure definition and allocate encrypted structures.
Ensure that users of the CFRM Policy Editor have at least
READ access to defined ICSF CSFSERV CSFKGN and CSFSERV
CSFKYT resource profiles when ENCRYPT(YES) is specified on a
structure definition.
All systems in the sysplex must be at z/OS V2R3 or higher
for this parameter to be fully effective. Before you use the
ENCRYPT parameter, IBM recommends that you make sure that
all systems in the sysplex are running z/OS V2R3 or higher.
Systems running on a lower level of z/OS (V2R2 or earlier) in
the sysplex are unable to encrypt and decrypt structure data.
Connection requests from a lower-level system to an encrypted
structure are not allowed.
```
```
Rebuild
Threshold
Percentage
```
```
REBUILDPERCENT( value
)
```
```
Specifies, as a percent of lost connectivity to a structure,
when MVS™ is to initiate a user-managed rebuild. Use of
REBUILDPERCENT requires that all active connections to the
structure support user-managed rebuild and that the structure
is not being used for XCF signaling.
This number is specified as a nonzero percentage and can be 1 -
3 decimal digits long (1-100).
REBUILDPERCENT takes effect immediately with policy
activation.
REBUILDPERCENT is an optional parameter. When
REBUILDPERCENT is not specified, the default value is 1%.
See z/OS MVS Setting Up a Sysplex for information about MVS-
initiated rebuild.
```
**66**   Sysplex Management task


_Table 72. Attributes of CF Structures (continued)_

**Column Policy control statement Description**

**Recovery
Priority**

```
RECPRTY (value ) This statement specifies the priority to be given to the structure
for LOSSCONN recovery (system loses connectivity to a coupling
facility) and policy-initiated duplexing for DUPLEX(ENABLED)
structures. The system might defer processing for a "less
important" (higher numeric priority value) structure to prevent
the "less important" recovery processing from interfering with
recovery processing for a "more important" (lower numeric
priority value) structure. LOSSCONN recovery for a "more
important" structure might be impacted when that recovery
depends on processing for a "less important" structure. For this
reason, be careful when assigning a RECPRTY value.
This number is specified as a 1-digit decimal value (1-4).
RECPRTY does not apply to XCF signaling structures.
RECPRTY takes effect immediately with policy activation.
RECPRTY is an optional parameter. When RECPRTY is not
specified, the system takes a default. When the structure name
is ISGLOCK, the default is 1. Otherwise, the default is 3.
```
**Maximum SCM
size**

```
SCMMAXSIZE( scmmaxsiz
e[u] )
```
```
Specifies the maximum amount of storage-class ("flash")
memory that is assignable for use by this structure in the
coupling facility. The number is specified in an integer unit
of u, where u is specified as K (kilobytes), M (megabytes), G
(gigabytes), or T (terabytes). K is the default unit when no size
unit is specified. Valid values for the number are 1 - 9 decimal
digits long and greater than 0 if this keyword is specified.
Storage-class memory is not allocated to the structure until
required for use. Therefore, it is possible to over-commit the
storage-class memory that is configured to the coupling facility.
It is possible to define the CFRM policy such that the sum of
the SCMMAXSIZE values for allocated structures exceeds the
total amount of storage-class memory that is available to the
coupling facility.
Note: Do not over-commit storage-class memory. This ensures
that you have the wanted amount of storage available if of an
application failure that causes the structure to fill up.
SCMMAXSIZE is an optional parameter. If not specified, the
coupling facility does not spill excess structure objects into
storage-class memory for this structure. The following values
are the largest values that you can specify:
```
- 15T
- 16383G
- 16777215M
- 999999999K or 999999999
For information about the use of storage-class memory to
reduce the probability of structure-full conditions, see z/OS MVS
Setting Up a Sysplex.

```
Sysplex Management task   67
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
SCM Algorithm SCMALGORITHM( algorit
hm )
```
```
Identifies the algorithm that the coupling facility uses to control
the movement of structure objects between coupling facility real
storage and storage-class memory to mitigate the performance
penalty associated with its use.
The valid values of SCMALGORITHM and the structures that they
support are described in the following table.
Note: Specification of SCMMAXSIZE and the related keywords
for inappropriate structure types might have unpredictable
results, potentially including connect failures or performance
degradation.
```
```
SCMALGORITHM
Value
```
```
Description Structure Types
```
```
KEYPRIORITY1 The high-order byte
of the list entry
key is treated as
a migration priority
indicator for lists 1
```
- 512. Valid values
for the priority byte
are:
- '00'x - '09'x,
    where lower
    values indicate
    higher priority.
- 'F4' - 'F6'x
    are application-
    specific values.

```
IBM MQ application
structure
```
```
SCMALGORITHM is a required parameter when SCMMAXSIZE is
specified and is not allowed for specification otherwise.
```
```
Enforce CF
Order
```
```
ENFORCEORDER(NO|YES) When ENFORCEORDER(YES) is specified, allocation attempts
adhere to the PREFLIST more closely, giving it a higher priority
than such factors as system weight connectivity and optimum
size. Use of this option can help ensure failure-isolation between
a coupling facility and the systems that use it (for example,
when these resources reside on the same CEC).
ENFORCEORDER is an optional parameter. ENFORCEORDER(NO)
is the default, when ENFORCEORDER is not specified.
```
**68**   Sysplex Management task


_Table 72. Attributes of CF Structures (continued)_

**Column Policy control statement Description**

**Allow
Reallocate**

##### ALLOWREALLOCATE(YES|

##### NO)

```
Specifies the installation's request for REALLOCATE processing
when evaluation of the allocated structure determines that the
structure needs rebuild processing. The REALLOCATE process
recognizes the need for rebuild processing when:
```
- There is a change to the policy definition for the structure
    affecting the structure size or location.
- The structure is not optimally located.
The ALLOWREALLOCATE option provides the installation with
a structure-level control to preclude REALLOCATE processing
from targeting structures for relocation or policy change
activation. This can be useful for structures for which rebuild
processing is disruptive based on workload or usage.
By evaluating an allocated structure, the REALLOCATE process
can recognize that the structure is optimally located and
immediately complete a change to the policy definition for the
structure when the change does not affect the size. Specifying
ALLOWREALLOCATE(NO) does not preclude this capability of the
REALLOCATE process because completing the pending policy
change does not require relocation of the structure instances.
See the SETXCF START/STOP command in z/OS MVS System
Commands for a description of the REALLOCATE process.
See the topic _"Using REALLOCATE or POPULATECF to relocate
coupling facility structures"_ in z/OS MVS Setting Up a Sysplex
for information about using REALLOCATE or POPULATECF to
relocate coupling facility structures.
**YES**
    The REALLOCATE process evaluates the allocated structure.
    When a policy change for size or location is pending or
    structure instances are not optimally located, the structure
    is selected as the target of the REALLOCATE process. The
    REALLOCATE process uses structure rebuild processing to
    make the adjustments.
**NO**
    The REALLOCATE process evaluates the allocated structure
    but does not select the structure as the target of the
    REALLOCATE process for relocation or policy change
    activation. When NO is specified, it is still possible for the
    REALLOCATE process to take the following actions if they are
    applicable:
Changes to the ALLOWREALLOCATE specification take effect
immediately with policy activation.
ALLOWREALLOCATE is an optional parameter. When
ALLOWREALLOCATE is not specified, the default value is YES.

```
Sysplex Management task   69
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
Sublist
Notification
Delay Interval
(μs)
```
##### SUBNOTIFYDELAY

```
( delaytime )
```
```
Specifies the number of microseconds for sublist notification
delay time (SLND time). This value refers to delay between the
time when a single selected shared message queue exploiter
instance is notified of sublist transition from the empty to not-
empty state and the time when the other instances are notified.
It can be that the other instances are never notified depending
on the processing that is done by the initial exploiter. See z/OS
MVS Programming: Sysplex Services Guide for an explanation of
the sublist monitoring function.
The value that is specified for SUBNOTIFYDELAY can be 1
```
- 7 decimal digits in a range of 0 to 1000000 (1 million)
microseconds.
SUBNOTIFYDELAY applies only to structures that meet certain
criteria and is ignored for all other structures. The structure
criteria for the SUBNOTIFYDELAY parameter are:
- The structure must be allocated as a keyed list structure.
- The structure must have EMCs allocated.
- The structure must be allocated in a CFLEVEL 16 or higher.
SUBNOTIFDELAY takes effect immediately with policy
activation.
The SUBNOTIFYDELAY value cannot exceed the CF model-
dependent Notification Delay Limit (NDL) value that is
determined by the CF where the structure is allocated.
Therefore, the SUBNOTIFYDELAY value that takes effect is the
smaller of the SUBNOTIFYDELAY value and the CF-dependent
NDL value.
SUBNOTIFYDELAY is an optional parameter. When
SUBNOTIFYDELAY is not specified, the default value is 5000
microseconds.

**70**   Sysplex Management task


_Table 72. Attributes of CF Structures (continued)_

**Column Policy control statement Description**

**List
Notification
Delay Interval
(μs),**

```
LISTNOTIFYDELAY( list
notifydelay )
```
```
Specifies the number of microseconds for the list notification
delay time (LND time). This value refers to the delay between
the time when a single registered list monitor is notified of
a list state transition from the empty to not-empty state and
the time when the other registered list monitor instances of a
list are notified. It can be that the other instances are never
notified, depending on the processing done by the initial notified
monitor. See z/OS MVS Programming: Sysplex Services Guide for
an explanation of the list monitoring function.
The value that is specified for LISTNOTIFYDELAY can be 1
```
- 7 decimal digits, in a range of 0 to 1000000 (1 million)
microseconds. LISTNOTIFYDELAY applies only to structure
meeting certain criteria and is ignored for all other structures.
The structure criteria for the LISTNOTIFYDELAY parameter is as
follows:
- The structure must be allocated as a list structure.
- The structure must be allocated in a CFLEVEL=22 or higher.
LISTNOTIFYDELAY takes effect immediately with policy
activation. The LISTNOTIFYDELAY value cannot exceed the
CF model-dependent NDL (Notification Delay Limit) value that
is determined by the CF where the structure is allocated.
Therefore, the LISTNOTIFYDELAY value that takes effect, is the
smaller of the LISTNOTIFYDELAY value and the CF-dependent
NDL value.
LISTNOTIFYDELAY is an optional parameter. When
LISTNOTIFYDELAY is not specified, the default value is 0
microseconds.

```
Sysplex Management task   71
```

```
Table 72. Attributes of CF Structures (continued)
```
```
Column Policy control statement Description
```
```
Key Range
Notification
Delay Interval
(μs)
```
```
KEYRNOTIFYDELAY( valu
e )
```
```
Specifies the number of microseconds for the keyrange
notification delay time (KRND time). This value refers to the
delay between the time when a single registered keyrange
monitor is notified of a keyrange state transition from the empty
to not-empty state and the time when the other registered
keyrange monitoring instances of a list keyrange are notified.
It can be that the other instances are never notified, depending
on the processing done by the initial notified monitor. See z/OS
MVS Programming: Sysplex Services Guide for an explanation of
the list monitoring by keyrange function.
The value that is specified for KEYRNOTIFYDELAY can be 1
```
- 7 decimal digits, in a range of 0 to 1000000 (1 million)
microseconds. KEYRNOTIFYDELAY applies only to structure
meeting certain criteria and is ignored for all other structures.
The structure criteria for the KEYRNOTIFYDELAY parameter is as
follows:
- The structure must be allocated as a keyed list structure.
- The structure must be allocated in a CFLEVEL=22 or higher.
KEYRNOTIFYDELAY takes effect immediately with policy
activation. The KEYRNOTIFYDELAY value cannot exceed the
CF model-dependent NDL (Notification Delay Limit) value that
is determined by the CF where the structure is allocated.
Therefore, the KEYRNOTIFYDELAY value that takes effect, is the
smaller of the KEYRNOTIFYDELAY value and the CF-dependent
NDL value.
KEYRNOTIFYDELAY is an optional parameter. The default value
is 0 microseconds.

```
Actions for the CF Structures tab
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Tab-level actions. Actions that apply to the entire tab. No selection of table items is required to enable
    these functions.

```
Table 73. Targeted actions for the CF Structures table
```
```
Action Description
```
```
Modify Display the Modify CF Structure page so that you can modify the properties of
the selected structure. To enable this action, select one structure only. For more
information, see “Modify a CF structure” on page 74.
It is possible to modify multiple CF structures at one time. For more information,
see “Modify multiple CF structures” on page 77.
```
```
Rename Display the Rename CF Structure page so that you can change the name of
the selected structure. To enable this action, select one structure only. For more
information, see “Rename a CF structure” on page 75.
```
**72**   Sysplex Management task


_Table 73. Targeted actions for the CF Structures table (continued)_

**Action Description**

**Copy** Display the **Copy CF Structure** page so that you can work with the selected
workflow. To enable this action, select one workflow only. For more information,
see “Copy a CF structure” on page 75.

**Size Structure** Display the **Size Multiple Structures** page so that you can perform sizing or
resizing on multiple structures by modifying the CF sizing definition that the
selected structures are associated to. For more information, see “Size Multiple CF
Structures” on page 77

**Delete** Display the **Delete CF Structure** page so that you can permanently delete the
selected structure. You can select multiple structures. For more information, see
“Delete a CF structure” on page 76.

**Export to CSV** Downloads a CSV file containing the selected structures.

```
The format of the file name is {{Policy}}_Structure_{{date}}_{{random}}.csv ,for
example ALTERPOL_Structure_2022-2-15-10-6-18_6567280780785600008.csv.
```
```
Tab-level actions for the CF Structures tab
The CF Structures tab includes the actions Add , Close , and Submit.
Table 74 on page 73 describes the tab-level actions for the CF Structures tab.
```
_Table 74. Tab-level actions for the CF Structures tab_

**Action Description**

**Add** Display the **Add CF Structure** page so that you can define a CF structure for one or
more coupling facilities.
For more information, see “Add a CF structure” on page 73.

**Close** Exit the CFRM Policy Editor. Any unsaved changes to the policy are discarded.

**Submit** Submit all outstanding updates for the selected policy. This action saves your
policy changes to the CFRM couple data set. You are prompted to confirm your
action. After you submit the policy, you cannot undo your updates.
For more information, see “Submit updates for a policy” on page 138.

```
Add a CF structure
You can create a CF structure for one or more coupling facilities. To do so, use the Add action in the CF
Structures table. Doing so opens a window that you can use to create the new CF structure.
```
**Procedure**

1. In the section **Basic** , specify values for the basic attributes of the new structure.
    You must provide values for the following attributes.
       a) In the **Name** field, specify the 1-16 character name of the structure.
          This value must be unique.
          The valid characters are numeric characters, uppercase alphabetic characters, national characters
          ($,@,#), or an underscore (_). The name must start with an alphabetic character (A-Z). IBM names
          begin with SYS, or the letters A through I.
b) In the **Maximum Size** field, specify the maximum amount of space to be allocated for the structure
in the coupling facility. The number is specified as K (kilobytes), M (megabytes), G (gigabytes), or

```
Sysplex Management task   73
```

```
T (terabytes). K is the default unit when no size unit is specified. The number can be 1 - 9 decimal
digits long.
```
2. Optionally, specify values for the other basic attributes, as appropriate for your sysplex environment.
    For a description of the attributes, see Table 72 on page 61.
3. In the section **Preference List** , create the preference list for the structure.
    Here, you specify an ordered list of coupling facility names from which the system is to choose when
    allocating the structure. You must specify at least one coupling facility name. When constructing your
    preference list, be sure to place the coupling facilities with the preferred attributes before any coupling
    facilities without the desired attributes. The system attempts to allocate the structure in the first
    coupling facility in the preference list that meets the allocation criteria. For more information, see the
    topic _“Understanding Preference and exclusion lists”_ in z/OS MVS Setting Up a Sysplex.
4. In the section **Exclusion List** , you can optionally create the exclusion list for the structure.
    If so, specify a list of 1 to 8 coupling facility structure names with which this structure should not share
    coupling facility. The system attempts to honor the exclusion request, but will not fail a request to
    allocate a structure when all other requirements for structure allocation are satisfied and the exclusion
    list cannot be honored. For more information, see the topic _“Understanding Preference and exclusion_
    _lists”_ in z/OS MVS Setting Up a Sysplex.
5. In the section **Advanced** , you can optionally specify values for the advanced attributes of the new
    structure.
    Table 72 on page 61.
6. Click **OK** to add the structure.

```
Results
On creation of the new structure, the CF Structures table is displayed, showing the new structure.
```
```
Modify a CF structure
You can modify a CF structure for one or more coupling facilities. To do so, use the Modify CF Structure
action in the CF Structures table. Doing so opens a window that you can use to modify a CF structure.
```
**Procedure**

1. In the section **Basic** , you can modify values for any of the basic attributes of the structure, as needed.
    Values must be specified for the following attributes.
       a) In the **Name** field, specify the 1-16 character name of the structure.
          This value must be unique.
          The valid characters are numeric characters, uppercase alphabetic characters, national characters
          ($,@,#), or an underscore (_). The name must start with an alphabetic character (A-Z). IBM names
          begin with SYS, or the letters A through I.
b) In the **Maximum Size** field, specify the maximum amount of space to be allocated for the structure
in the coupling facility. The number is specified as K (kilobytes), M (megabytes), G (gigabytes), or
T (terabytes). K is the default unit when no size unit is specified. The number can be 1 - 9 decimal
digits long.
    For a description of the attributes, see Table 72 on page 61.
2. In the section **Preference List** , you can modify the preference list for the structure.
    The preference list is an ordered list of coupling facility names from which the system is to choose
    when allocating the structure. At least one coupling facility name must be specified. To avoid having
    a single point of failure, it is recommended that two or more coupling facilities are added to the
    preference list. In your preference list, be sure to place the coupling facilities with the preferred
    attributes before any coupling facilities without the desired attributes. The system attempts to allocate
    the structure in the first coupling facility in the preference list that meets the allocation criteria. For
    more information, see the topic _“Understanding Preference and exclusion lists”_ in z/OS MVS Setting Up
    a Sysplex.

**74**   Sysplex Management task


3. In the section **Exclusion List** , you can modify the exclusion list for the structure, if one exists.
    The exclusion list specifies up to eight coupling facility structures with which this structure should not
    share the same coupling facility. The system attempts to honor the exclusion request, but does not fail
    a request to allocate a structure when all other requirements for structure allocation are satisfied and
    the exclusion list cannot be honored. For more information, see the topic _“Understanding Preference_
    _and exclusion lists”_ in z/OS MVS Setting Up a Sysplex.
4. In the section **Advanced** , you can modify values for the advanced attributes of the structure, as
    needed.
    For a description of the attributes, see Table 72 on page 61.
5. Click **OK** to save your changes to the structure.

**Results**

On completion, the **CF Structures** table is displayed.

_Rename a CF structure_
You can rename a CF structure for one or more coupling facilities. To do so, use the **Rename** action in the
CF Structures table. Doing so opens a window that you can use to rename a CF structure.

**Before you begin**

The current name of the CF structure is displayed in the field **Original coupling facility name**.

**About this task**

When you rename a CF structure, the CFRM Policy Editor automatically updates the name in any structure
exclusion lists that reference the original name.

**Procedure**

1. In the **New coupling facility name** field, specify the new name of the structure.
    A valid name is 1 - 16 characters, consisting of numeric characters, uppercase alphabetic characters,
    national characters ($,@,#), or an underscore (_). The name must start with an alphabetic character
    (A-Z). IBM names begin with SYS, or the letters A through I.
2. To modify other attributes of the CF structure, select the option **Modify the renamed coupling facility**.
    Doing so opens the renamed policy in the **Modify a CF Structure** dialog. This option is not selected by
    default.
    For a description of the attributes, see Table 72 on page 61.
3. Click **OK** to save your changes to the structure.

**Results**

On completion, the **CF Structures** table is displayed.

_Copy a CF structure_
You can copy a CF structure for one or more coupling facilities. To do so, use the **Copy** action in the CF
Structures table. Doing so opens a window that you can use to copy a CF structure.

**About this task**

The **Copy CF Structure** dialog displays the name of the structure to be copied.

**Procedure**

1. In the section **Basic** , you can modify values for any of the basic attributes of the structure, as needed.

```
Sysplex Management task   75
```

```
The attributes are preset to the values from the structure to be copied. To ensure uniqueness, the CF
structure name is preset to the value <structure-name> _1.
a) In the Name field, specify a new name for the structure.
This value must be unique.
A valid name is 1 - 16 characters, consisting of numeric characters, uppercase alphabetic
characters, national characters ($,@,#), or an underscore (_). The name must start with an
alphabetic character (A-Z). IBM names begin with SYS, or the letters A through I.
b) Modify values for the other basic attributes of the structure, as needed. For example, you can
specify a new maximum size for the structure.
For a description of the attributes, see Table 72 on page 61.
```
2. In the section **Preference List** , update the preference list for the structure.
    The preference list is preset to the values from the structure to be copied.
    The preference list is an ordered list of coupling facility names from which the system is to choose
    when allocating the structure. At least one coupling facility name must be specified. In your preference
    list, be sure to place the coupling facilities with the preferred attributes before any coupling facilities
    without the desired attributes. The system attempts to allocate the structure in the first coupling
    facility in the preference list that meets the allocation criteria. For more information, see the topic
    _“Understanding Preference and exclusion lists”_ in z/OS MVS Setting Up a Sysplex.
3. In the section **Exclusion List** , you can modify the exclusion list for the structure, if one exists.
    The exclusion list is preset to the values from the structure to be copied.
    The exclusion list specifies up to eight coupling facility structures with which this structure should not
    share the same coupling facility. The system attempts to honor the exclusion request, but does not fail
    a request to allocate a structure when all other requirements for structure allocation are satisfied and
    the exclusion list cannot be honored. For more information, see the topic _“Understanding Preference_
    _and exclusion lists”_ in z/OS MVS Setting Up a Sysplex.
4. In the section **Advanced** , you can modify values for the advanced attributes of the structure, as
    needed.
    For a description of the attributes, see Table 72 on page 61.
5. Click **OK** to save your changes to the new structure.

```
Results
On creation of the new structure, the CF Structures table is displayed, showing the new structure.
```
```
Delete a CF structure
You can delete one or more CF structures. To do so, select the structures in the CF Structures table and
select Delete from the table actions menu. You are prompted to confirm your selection.
```
**About this task**

```
The CF structures to be deleted are displayed in the field Selected CF Structures.
When you delete a CF structure, the CFRM Policy Editor automatically removes the structure name from
any exclusion lists that reference it.
This change is permanent; you are prompted to confirm this action before it is taken.
```
**Procedure**

```
To delete the selected structures, click OK. Otherwise, click Cancel to cancel your request.
```
```
Results
On completion, the deleted structures are removed from the CF Structures table.
```
**76**   Sysplex Management task


_Modify multiple CF structures_
You can apply a modification to a set of CF structures at one time. To do so, follow the steps in this
procedure.

**About this task**

In this procedure, you select a set of CF structures and apply a modification to them. Begin by using a
table filter to locate the set of structures that you want to modify. You can filter by a common attribute, for
example, structure names that share a common string pattern. Then, select the structure attributes to be
changed and apply the changes to the selected structures. This approach can save you time compared to
editing structures one by one.

**Procedure**

1. Filter the set of structures to the set that you want to modify.
    a) Click the filter icon in the CF Structures table taskbar to open the filter pane.
       The filter pane offers drop-downs and field types to help you construct a filter.
b) Use the filter pane to display the set of structures that you want to modify.
For example, if you want to modify structures that contain the string "cache" in the structure
name, and enter **Column: Structure Name** > **Condition: Contains** > **Value: cache** to find the
matching structures.
2. Select the structures that you want to modify.
    Notice that the CF Structures table displays a taskbar with the options **Delete** , **Size Structures** , **Copy** ,
    **Modify** , and **Cancel**.
3. Click **Modify**.
4. In the **Modify Multiple CF Structures** window, enter values for the attributes that you want to modify.
    These values will be applied to the selected CF structures, which are listed under **Selected CF**
    **Structures to Modify**. Fields that you leave empty are not modified.
5. If you are working with numerical values, such as sizes, determine whether to apply your changes as
    absolute values or relative (percentage-based) values.
    By default, your changes are applied as absolute values. If you select the **Relative** option, the
    attributes you modify can increase or decrease by the specified percentage.
    You can apply a relative change to individual fields or all of the selected fields.
    As you work, the CFRM Policy Editor might alert you to incorrect or conflicting input values.
6. Click **OK** to save your modifications to the structures.

**Results**

On completion, the **CF Structures** table is displayed, showing the modified structures.

_Size Multiple CF Structures_
You can perform sizing or resizing on two or more structures in a single action. To do so, follow the steps
in this procedure.

**About this task**

In this procedure, you select a set of CF structures and apply a CF sizing definition to them. Begin by using
a table filter to locate the set of structures that you want to modify. You can filter by a common attribute,
for example, structure names that share a common string pattern. Then, select the structures to be sized
and apply the changes to the selected structures. This approach can save you time compared to sizing
structures one by one.

A CF sizing definition is a z/OSMF-managed object with a single-policy scope. A CF sizing definition can be
used to run sizing across multiple structures as needed.

```
Sysplex Management task   77
```

```
Every CF structure being sized in a bulk action must be associated with a CF sizing definition. You are able
to proceed without that CF structure included in your action.
```
**Procedure**

1. Filter the set of structures to the set that you want to size.
    a) Click the filter icon in the CF Structures table taskbar to open the filter pane.
       The filter pane offers drop-downs and field types to help you construct a filter.
b) Use the filter pane to display the set of structures that you want to modify.
For example, if you want to modify structures that contain the string "Db2" in the structure name,
and enter **Column: Structure Name** > **Condition: Contains** > **Value: Db2** to find the matching
structures.
2. Select the structures that you want to size.
    Notice that the CF Structures table displays a taskbar with the options **Delete** , **Size Structures** , **Copy** ,
    **Modify** , and **Cancel**.
3. Click **Size Structures**.
    If you selected a CF structure that is not associated with a CF sizing definition, a warning modal
    appears to notify you of any CF structures that will not be sized. Click **close** to proceed without that CF
    structure included in your action.
4. In the **Size Multiple Structures** window, review the Size Selected Structure with Sizing Profiles table.
    You can expand each tree table to view more details about the Inputs, Results, and the Structure to
    size.
5. Click **Next** to proceed to the Summary of Updates.
6. Review the **Structure sizings to be updated** table to confirm that you want to proceed with these
    sizing values. Each row displays a field from the associated structures that will be updated. The
    columns include the CF Sizing Definition, Structure Name, the updated Field, the Original Value for
    that Field, and the New Value that the field will be changed to. You can search the table for a specific
    structure or field. The total number of changes will be reflected under the table.
    If the new value for an updated field is smaller than the original value, a warning message and warning
    icons appear in the corresponding rows. You are able to proceed, but make sure that this outcome is
    your intention.
7. Click **Finish** to confirm your selection. Click **Back** to return to the Sizing Details step. Otherwise, click
    **Cancel** to cancel your request.

**Results**

```
On completion, the Maximum Size and Initial Size fields are updated to match the values in the CF sizing
definition.
A notification displays the updated input fields, including the previous and current values for each and the
timestamp for when the action occurred.
```
```
Select a CF sizing definition for a CF structure
You can associate a CF structure with a CF sizing definition. To do so, click the pencil icon in the CF sizing
definition field action in the Basic section of the Add CF structure or Modify CF structure window. Doing
so opens a modal that you can use to add or modify the associated CF sizing definition.
```
**About this task**

```
A CF sizing definition is a z/OSMF-managed object with a single-policy scope. A CF sizing definition can be
used to run sizing across multiple structures as needed.
CF izing definitions can be associated with multiple structures, but a CF structure can be associated with
only one CF sizing definition. Associating a CF structure to a CF sizing definition is not required.
```
**78**   Sysplex Management task


When the CF sizing definition is selected, the **Maximum Size** and **Initial Size** fields are updated to match
the values in the CF sizing definition. You are still able to change the value of these fields manually, but
this action is not recommended. A warning notification displays, and a warning icon persists for the field
on this window and in all tables that this CF structure or CF sizing definition appears.

**Procedure**

1. Use the Select CF Sizing Definition table to locate the CF sizing definition that you want to associate
    the selected CF structure with. You can filter your search or sort the table columns to locate a specific
    CF sizing definition. You can expand the CF sizing definition rows to view additional information such
    as Inputs, Results, and the CF structures that are currently associated with this CF sizing definition.
2. Select the CF sizing definition by clicking the radio button associated with that row.
3. Click **OK** to confirm your selection. Otherwise, click **Cancel** to cancel your request.

**Results**

On completion, the **Maximum Size** and **Initial Size** fields are updated to match the values in the CF sizing
definition. A notification displays the updated input fields, including the previous and current values for
each and the timestamp for when the action occurred.

_Copy multiple CF structures_
You can copy a number of CF structures at one time. To do so, follow the steps in this procedure.

**About this task**

In this procedure, you select a set of CF structures and create copies of them. Begin by using a table
filter to locate the set of structures that you want to copy. You can filter by a common attribute, for
example, structure names that share a common string pattern. Make copies of the structures and assign
new names to the copies by using a naming rule or by assigning names to structures individually. This
approach can save you time compared to copying structures one by one.

**Procedure**

1. Filter the set of structures to the set that you want to copy.
    a) Click the filter icon in the CF Structures table taskbar to open the filter pane.
       The filter pane offers drop-downs and field types to help you construct a filter.
b) Use the filter pane to display the set of structures that you want to copy.
For example, if you want to copy structures that contain the string "cache" in the structure name,
enter Column: Structure Name > Condition: Contains > Value: cache to find the
matching structures.
2. Select the structures that you want to copy.
    Notice that the **CF Structures** table displays a taskbar with the options **Delete** , **Copy** , **Modify** , and
    **Cancel**.
3. Click **Copy**.
4. In the **Copy Multiple CF Structures** window, choose a method for assigning new names to the
    structure copies.
    To ensure uniqueness, "COPY" will be appended to the original name by default. You can bulk modify
    structure names by defining a naming rule for the group or assign names to copies individually. Or, you
    can use a combination of both of these approaches.
    When you bulk modify names, enter a substring of the original name in the **Source name** input box and
    a new string in the **Replace with** input box. All of the structure names containing the substring will be
    replaced with the new string when you click **Apply**.
    The resulting structure names are shown in the **CF Structure Names** table.
5. Accept or deselect the option to update the exclusion list for each new copy.

```
Sysplex Management task   79
```

```
When this option is selected, the exclusion list for each new copy is updated to replace references to
the original CF structures with references to the new copies.
By default, this option is selected; it is recommended when you update a group of related CF
structures.
```
6. Click **OK** to save the copies of structures.

```
Results
On completion, the CF Structures table is displayed, showing the new structures.
```
```
Coupling Facilities tab
On the Coupling Facilities tab, you can create, update, and delete coupling facilities for the selected
CFRM policy.
In a CFRM policy, the CF statement specifies the definition of a coupling facility within the scope of the
named policy. The location of the information that is needed to define the coupling facility in a CFRM
policy depends on the processor on which the coupling facility is installed. The limit for the number
of coupling facilities that can be defined in a policy is established when the CFRM couple data set
is formatted. The coupling facility must appear in the preference list of at least one coupling facility
structure that is defined within the policy.
```
**Authorization requirements for the CFRM Policy Editor**

```
You must have sufficient authorization to use the functions that are available in the CFRM Policy Editor.
For more information, see “Authorization requirements” on page 57.
```
```
Layout of the Coupling Facilities tab
The CFRM Policy Editor displays the following information about the selected policy:
```
- Policy name, which specifies the 1 - 8 character name of the policy. The valid characters are uppercase
    alphanumeric characters (A-Z and 0-9). The name must begin with an alphabetic character (A-Z).
- Sysplex name, which specifies the 1 - 8 character name of the sysplex in which the couple data set
    is to be used. The valid characters are uppercase alphanumeric characters (A-Z and 0-9) and national
    characters ($,@,#). The name must begin with an alphabetic character (A-Z).
- Number of CF structures.
- Number of coupling facilities.
The central feature of the **Coupling Facilities** tab is the Coupling Facilities table, which displays the
coupling facilities and their attributes. In this table, you select actions for editing the coupling facilities.
For a description of the columns in the Coupling Facilities table, see “Columns in the Coupling Facilities
table” on page 80. For a description of the actions that you can take for coupling facilities, see “Actions
for the CF Structures tab” on page 72.

**Columns in the Coupling Facilities table**

```
Table 75 on page 81 describes the columns in the Coupling Facilities table. Notice that each field name
in the editor corresponds to a CFRM policy control statement. The CFRM control statements are not
visible in the CFRM policy editor. To see the control statements, you can use the View Content action in
the CFRM Administrative Policies view. With the CFRM Policy Editor, you can create, update, and delete
CFRM policies without having to write CFRM control statements.
By default, the coupling facility names in the table are sorted in ascending alphabetical order. To sort the
table based on the values in one or more columns, click the column header for the columns you want to
sort. If a sort is defined for a column, the ascending (▴) or descending (▾) sort icon is shown in the column
header.
```
**80**   Sysplex Management task


```
Note: You might notice that the table does not include columns for the Central Processor Complex (CPC)
ID or the physical side (SIDE) of a physically partitioned CPC. These values are not widely used and are
therefore omitted from the table.
```
_Table 75. Attributes of coupling facilities_

**Column Policy control statement Description**

**CF name** NAME( _cfname_ ) Specifies the 1 - 8 character name of the coupling facility.
The valid characters are uppercase alphabetic characters (A-
Z), numeric characters (0-9), national characters ($,@,#), or
an underscore (_). The _cfname_ must start with an alphabetic
character (A-Z).
Consider defining your coupling facility name to match the
name of the LPAR in which the coupling facility is to run.
NAME is a required parameter.
The following set of parameters describe the unique coupling
facility that is defined in the policy.

**Machine type** TYPE( _tttttt_ ) Specifies the 6-character machine type. The valid characters
are uppercase alphabetic characters (A-Z) and numeric
characters (0-9), padded with leading zeros if necessary. TYPE
is a required parameter.

**Manufacturer** MFG( _mmm_ ) Specifies the 3-character manufacturer identification. The
valid characters are uppercase alphabetic characters (A-Z) and
numeric characters (0-9). MFG is a required parameter.

**Plant** PLANT( _pp_ ) Specifies the 2-character plant of manufacture code. The
valid characters are uppercase alphabetic characters (A-Z) and
numeric characters (0-9). PLANT is a required parameter.

**Sequence
number**

```
SEQUENCE( nnnnnnnnnnn
n )
```
```
Specifies the 12-character serial number. The valid characters
are uppercase alphabetic characters (A-Z) and numeric
characters (0-9), padded with leading zeros if necessary.
SEQUENCE is a required parameter.
```
**Partition** PARTITION( _h_ ) or ( _hh_ ) Specifies the 1- or 2-hexadecimal digit qualifier to uniquely
identify and associate a coupling facility to a specific PR/SM
partition. This value can be in the range of 0-F and is the same
as the partition number defined in HCD.
For more information about specifying the partition identifier,
see z/OS MVS Setting Up a Sysplex.
PARTITION is a required parameter.

```
Sysplex Management task   81
```

```
Table 75. Attributes of coupling facilities (continued)
```
```
Column Policy control statement Description
```
```
Dump space DUMPSPACE( size[u] ) Specifies the amount of space to be reserved in the coupling
facility for dumping structures allocated in the coupling facility.
The number is specified in an integer unit of u , where u is
specified as K (kilobytes), M (megabytes), G (gigabytes), or T
(terabytes). K is the default unit when no size unit is specified.
The number can be 1 - 9 decimal digits long. The largest
size that can be specified is 1T. Sizes larger than 1T causes
message IXC730I to be displayed indicating that the number
specified is not within the allowable range for the keyword
value.
DUMPSPACE is an optional parameter. If omitted, no storage in
the coupling facility is reserved for dumping.
For more information about specifying the amount of dump
space, see z/OS MVS Setting Up a Sysplex.
```
```
Site SITE( site ) Specifies the site at which the coupling facility resides. When
specified, this information (along with status information from
a Recovery Manager (for example, GDPS®)), is used in break
duplexing decisions to keep the structure instance at the
recovery site. SITE changes take effect when the policy is
activated.
This keyword should be considered when you specify the
DUPLEX dupsite and dupmode parameters as part of the CF
structure definition.
```
```
Actions for the Coupling Facilities tab
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Tab-level actions. Actions that apply to the entire tab. No selection of table items is required to enable
    these functions.

```
Table 76. Targeted actions for the Coupling Facilities table
```
```
Action Description
```
```
Modify Display the Modify Coupling Facility page so that you can modify the properties of
the selected coupling facility. To enable this action, select one coupling facility only.
For more information, see “Modify a coupling facility” on page 85.
```
```
Rename Display the Rename Coupling Facility page so that you can change the name of
the selected coupling facility. To enable this action, select one coupling facility only.
For more information, see “Rename a coupling facility” on page 86.
```
```
Copy Display the Copy Coupling Facility page so that you can work with the selected
coupling facility. To enable this action, select one coupling facility only.
For more information, see “Copy a coupling facility” on page 87.
```
**82**   Sysplex Management task


_Table 76. Targeted actions for the Coupling Facilities table (continued)_

**Action Description**

**Delete** Display the **Delete Coupling Facility** page so that you can permanently delete the
selected coupling facility. You can select multiple coupling facilities.
For more information, see “Delete a coupling facility” on page 88.

**Export to CSV** Downloads a CSV file containing the selected coupling facilities.

```
The format of the file name is {{Policy}}_CF_{{date}}_{{random}}.csv , for example
ALTERPOL_CF_2022-2-15-10-6-18_8968310295042106567.csv.
```
```
Tab-level actions for the Coupling Facilities tab
The Coupling Facilities tab includes the tab-level actions Add , Close , and Submit.
Table 77 on page 83 describes the tab-level actions for the Coupling Facilities tab.
```
_Table 77. Tab-level actions for the Coupling Facilities tab_

**Action Description**

**Add** Display the **Add Coupling Facility** page so that you can define a coupling facility for
the selected CFRM policy.
For more information, see “Add a CF structure” on page 73.

**Close** Exit the CFRM Policy Editor. Any unsaved changes to the policy are discarded.

**Submit** Submit all outstanding updates for the selected policy. This action saves your
policy changes to the CFRM couple data set. You are prompted to confirm your
action. After you submit the policy, you cannot undo your updates.
For more information, see “Submit updates for a policy” on page 138.

```
Add a coupling facility
You can define a coupling facility for the selected CFRM policy. To do so, use the Add action in the
Coupling Facilities table. Doing so opens a window that you can use to define the new coupling facility.
```
**Procedure**

1. Specify values for the attributes of the new coupling facility.
    You must provide values for the following attributes.
       a) In the **CF name** field, specify the 1 - 8 character length name of the coupling facility.
          The valid characters are uppercase alphabetic characters (A-Z), numeric characters (0-9), national
          characters ($,@,#), or an underscore (_). The name must start with an alphabetic character (A-Z).
b) In the **Machine type** field, specify the 6-character machine type.
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
padded with leading zeros if necessary.
       c) In the **Manufacturer** field, specify the 3-character manufacturer identification.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
d) In the **Plant** field, specify the 2-character plant of manufacture code.
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
       e) In the **Sequence number** field, specify the 12-character serial number.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
          padded with leading zeros if necessary.

```
Sysplex Management task   83
```

```
f) In the Partition field, specify the 1- or 2-hexadecimal digit qualifier to uniquely identify and
associate a coupling facility to a specific PR/SM partition.
This value can be in the range of 0-F and is the same as the partition number defined in HCD.
For more considerations, see Table 75 on page 81.
```
2. Optionally, specify values for the other attributes, as appropriate for your sysplex environment.
    a) In the **Dump space** field, you can optionally specify the amount of space to be reserved in the
       coupling facility for dumping structures allocated in the coupling facility.
       The number is specified in an integer unit of _u_ , where _u_ is specified as K (kilobytes), M (megabytes),
       G (gigabytes) or T (terabytes). K is the default unit when no size unit is specified. The number can
       be 1 - 9 decimal digits long. The largest size that can be specified is 1T.
b) In the **Site** field, you can optionally specify the site at which the coupling facility resides.
This information (along with status information from a Recovery Manager, such as GDPS), is used in
break duplexing decisions to keep the structure instance at the recovery site. This specification take
effect when the policy is activated.
For more considerations, see Table 75 on page 81.
3. In the section **List of CF structures with Coupling Facility in their Preference List** , add the coupling
    facility to one or more CF structure preference lists.
       a) Click **Add** to display a dialog for adding the coupling facility to one or more CF structure preference
          lists.
b) In the list of available CF structures, select at least one structure.
You can select multiple structures.
       c) Select the position for the coupling facility in the preference list for each of the selected structures.
          You can select the first, last, or a random position in the lists.
4. Click **OK** to add the coupling facility.

```
Results
On completion, the Coupling Facilities table is displayed, showing the new coupling facility.
```
```
Add a coupling facility to the CF structure preference list
In the table List of CF structures with Coupling Facility in their Preference List , add the coupling facility
to one or more CF structure preference lists.
```
**Procedure**

1. Click **Add** to display a dialog for adding the coupling facility to one or more CF structure preference
    lists.
2. In the list of available CF structures, select at least one structure.
    You can select multiple structures.
3. Select the position for the coupling facility in the preference list for each of the selected structures.
    You can select the first, last, or a random position in the lists.
4. Click **OK** to add the coupling facility to the structure preference lists.

**Results**

```
On completion, the table is displayed, showing the CF structures with the coupling facility added to their
structure preference lists.
```
**84**   Sysplex Management task


_Modify a coupling facility_
You can modify a coupling facility for the selected CFRM policy. To do so, use the **Modify** action in the
Coupling Facilities table. Doing so opens a window that you can use to modify the coupling facility.

**Procedure**

1. Edit the values for the coupling facility attributes, as needed.
    You must provide values for the following attributes.
       a) In the **CF name** field, specify the 1 - 8 character length name of the coupling facility.
          The valid characters are uppercase alphabetic characters (A-Z), numeric characters (0-9), national
          characters ($,@,#), or an underscore (_). The name must start with an alphabetic character (A-Z).
b) In the **Machine type** field, specify the 6-character machine type.
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
padded with leading zeros if necessary.
       c) In the **Manufacturer** field, specify the 3-character manufacturer identification.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
d) In the **Plant** field, specify the 2-character plant of manufacture code.
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
       e) In the **Sequence number** field, specify the 12-character serial number.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
          padded with leading zeros if necessary.
f) In the **Partition** field, specify the 1- or 2-hexadecimal digit qualifier to uniquely identify and
associate a coupling facility to a specific PR/SM partition.
This value can be in the range of 0-F and is the same as the partition number defined in HCD.
    For more considerations, see Table 75 on page 81.
2. Optionally, specify values for the other attributes, as appropriate for your sysplex environment.
    a) In the **Dump space** field, you can optionally specify the amount of space to be reserved in the
       coupling facility for dumping structures allocated in the coupling facility.
       The number is specified in an integer unit of _u_ , where _u_ is specified as K (kilobytes), M (megabytes),
       G (gigabytes) or T (terabytes). K is the default unit when no size unit is specified. The number can
       be 1 - 9 decimal digits long. The largest size that can be specified is 1T.
b) In the **Site** field, you can optionally specify the site at which the coupling facility resides.
This information (along with status information from a Recovery Manager, such as GDPS), is used in
break duplexing decisions to keep the structure instance at the recovery site. This specification take
effect when the policy is activated.
    For more considerations, see Table 75 on page 81.
3. In the section **List of CF structures with Coupling Facility in their Preference List** , you can add the
    coupling facility to one or more CF structure preference lists, or change the position of the coupling
    facility in the lists.
       a) Click **Add** to display a dialog for adding the coupling facility to one or more CF structure preference
          lists.
b) In the list of available CF structures, select at least one structure.
You can select multiple structures.
       c) Select the position for the coupling facility in the preference list for each of the selected structures.
          You can select the first, last, or a random position in the lists.
4. Click **OK** to add the coupling facility.

```
Sysplex Management task   85
```

```
Results
On completion, the Coupling Facilities table is displayed.
```
```
Modify a coupling facility in the CF structure preference list
In the table List of CF structures with Coupling Facility in their Preference List , you can modify the
coupling facility in one or more CF structure preference lists.
```
**Procedure**

1. Click **Modify** to display a dialog for modifying the coupling facility in one or more CF structure
    preference lists.
2. In the list of available CF structures, select at least one structure.
    You can select multiple structures.
3. Select the position for the coupling facility in the preference list for each of the selected structures.
    You can select the first, last, or a random position in the lists.
4. Click **OK** to save your changes to the coupling facility in the structure preference lists.

**Results**

```
On completion, the table is displayed, showing the CF structures with modified structure preference lists.
```
```
Delete a coupling facility in the CF structure preference list
After choosing to delete a coupling facility from the table List of CF structures with Coupling Facility in
their Preference List , you must confirm your selection.
```
**Procedure**

1. Review your selections in the **Selected CF Structures** table.
    A warning message appears when this will result in one or more structures with only one CF in their
    preference list when two or more are available. Having only one CF in a preference list creates a single
    point of failure and is not recommended.
2. Click **OK** to continue and delete the coupling facility in the selected CF structure preference lists.

**Results**

```
On completion, the table is displayed, showing the CF structures with modified structure preference lists.
```
```
Rename a coupling facility
You can rename a coupling facility for the selected CFRM policy. To do so, use the Rename action in the
Coupling Facilities table. Doing so opens a window that you can use to rename a coupling facility.
```
```
Before you begin
The current name of the coupling facility is displayed in the field Original coupling facility name.
```
**About this task**

```
When you rename a coupling facility, the CFRM Policy Editor automatically updates the name in any
preference lists that reference the original name.
```
**Procedure**

1. In the **New coupling facility name** field, specify the new name of the coupling facility.
    A valid name is 1 - 8 characters, consisting of uppercase alphabetic characters (A-Z), numeric
    characters (0-9), national characters ($,@,#), or an underscore (_). The name must start with an
    alphabetic character (A-Z).

**86**   Sysplex Management task


```
Consider defining your coupling facility name to match the name of the LPAR in which the coupling
facility is to run.
```
2. To modify other attributes of the coupling facility, select the option **Modify the renamed coupling**
    **facility**.
    Doing so opens the renamed policy in the **Modify a Coupling Facility** dialog. This option is not selected
    by default.
    For a description of the attributes, see Table 75 on page 81.
3. Click **OK** to save your changes to the coupling facility.

**Results**

On completion, the **Coupling Facilities** table is displayed.

_Copy a coupling facility_
You can copy a coupling facility in the selected CFRM policy. To do so, use the **Copy** action in the Coupling
Facilities table. Doing so opens a window that you can use to copy the coupling facility.

**Procedure**

1. In the section **List of CF structures with Coupling Facility in their Preference List** , select the position
    of the new coupling facility in the associated CF structure preference lists.
    When you create a new coupling facility based on an existing one, you must specify the position of the
    new coupling facility in relation to the existing (or "source") coupling facility.
       a) Click **Add** to display a dialog for adding the coupling facility to one or more CF structure preference
          lists.
b) In the list of available CF structures, edit the list for the new coupling facility. You must select at
least one structure.
Notice that you can use the **Add** , **Modify** , and **Delete** actions to modify the list of structures.
       c) Select the position for the new coupling facility in the preference list for each of the selected
          structures.
          You can place the coupling facility:
          - Before the source coupling facility
          - After the source coupling facility
          - First in the list
          - Last in the list
          - Any random position in the list.
2. In the **CF name** field, specify the 1 - 8 character length name of the coupling facility.
    The valid characters are uppercase alphabetic characters (A-Z), numeric characters (0-9), national
    characters ($,@,#), or an underscore (_). The name must start with an alphabetic character (A-Z).
3. Edit the values for the other coupling facility attributes, as needed.
    You must provide a unique value for at least one of the following attributes.
       a) In the **Machine type** field, specify the 6-character machine type.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
          padded with leading zeros if necessary.
b) In the **Manufacturer** field, specify the 3-character manufacturer identification.
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
       c) In the **Plant** field, specify the 2-character plant of manufacture code.
          The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9).
d) In the **Sequence number** field, specify the 12-character serial number.

```
Sysplex Management task   87
```

```
The valid characters are uppercase alphabetic characters (A-Z) and numeric characters (0-9),
padded with leading zeros if necessary.
e) In the Partition field, specify the 1- or 2-hexadecimal digit qualifier to uniquely identify and
associate a coupling facility to a specific PR/SM partition.
This value can be in the range of 0-F and is the same as the partition number defined in HCD.
For more considerations, see Table 75 on page 81.
```
4. Optionally, specify values for the other attributes, as appropriate for your sysplex environment.
    a) In the **Dump space** field, you can optionally specify the amount of space to be reserved in the
       coupling facility for dumping structures allocated in the coupling facility.
       The number is specified in an integer unit of _u_ , where _u_ is specified as K (kilobytes), M (megabytes),
       G (gigabytes) or T (terabytes). K is the default unit when no size unit is specified. The number can
       be 1 - 9 decimal digits long. The largest size that can be specified is 1T.
b) In the **Site** field, you can optionally specify the site at which the coupling facility resides.
This information (along with status information from a Recovery Manager, such as GDPS), is used in
break duplexing decisions to keep the structure instance at the recovery site. This specification take
effect when the policy is activated.
For more considerations, see Table 75 on page 81.
5. In the section **List of CF structures with Coupling Facility in their Preference List** , add the coupling
    facility to one or more CF structure preference lists.
       a) Click **Add** to display a dialog for adding the coupling facility to one or more CF structure preference
          lists.
b) In the list of available CF structures, select at least one structure.
You can select multiple structures.
       c) Select the position for the coupling facility in the preference list for each of the selected structures.
          You can select the first, last, or a random position in the lists.
6. Click **OK** to add the coupling facility.

```
Results
On completion, the Coupling Facilities table is displayed.
```
```
Delete a coupling facility
You can delete one or more coupling facilities from the selected CFRM policy. To do so, select them in the
Coupling Facilities table and select Delete from the table actions menu. You are prompted to confirm your
selection.
```
**About this task**

```
The coupling facilities to be deleted are displayed in the field Selected Coupling Facilities.
When you delete a coupling facility, the CFRM Policy Editor automatically removes the coupling facility
name from any structure preference lists that refer to it.
This change is permanent; you are prompted to confirm this action before it is taken.
Note: Before it performs a deletion, the CFRM Policy Editor determines whether deleting any of the
specified coupling facilities would result in a configuration problem, such as a structure left without an
associated coupling facility. If so, the editor displays the dialog Coupling Facility Cannot be Deleted , in
which you are prompted to resolve the issue. In the table column Resolution , select a resolution for the
affected coupling facilities. For example, you can choose not to delete a coupling facility, or delete both
the coupling facility and its structure. Click OK to apply your selected resolution.
```
**88**   Sysplex Management task


```
Procedure
To delete the selected coupling facilities, click OK. Otherwise, click Cancel to cancel your request.
```
**Results**

```
On completion, the deleted coupling facilities are removed from the Coupling Facilities table.
```
```
CF Sizing tab
From the CFRM Policy Editor and Sizer CF Sizing tab, you can perform CF structure sizing for the
selected CFRM policy.
The main function of the CFRM Policy Editor Sizing tab is to perform CF Structure Sizing within a policy.
This function is useful when you introduce a new workload or application, change an existing workload in
some way, or want to modify your current structure sizes.
The CFRM Policy editor uses CF sizing definitions for the persistence of user inputs for structure sizing. A
CF sizing definition is a z/OSMF-managed object with a single-policy scope. CF sizing definitions can be
associated with multiple structures, but a structure can be associated with only one CF sizing definition.
After the object is defined, it can be used to run sizing across multiple structures as needed.
```
**Authorization requirements for the CFRM Policy Editor and Sizer**

```
You must have sufficient authorization to use the functions that are available in the CFRM Policy Editor
and Sizer. For more information, see “Authorization requirements” on page 57.
```
**Layout of the CF Sizing tab**

```
The central feature of the CF Sizing tab is the CF Sizing Definitions table, which displays the CF sizing
definitions and their attributes. In this table, you select actions for creating and modifying CF sizing
definitions.
For a description of the columns in the CF Sizing Definitions table, see “Columns in the CF Sizing
Definitions table” on page 89. For a description of the actions that you can take for CF sizing definitions,
see “Actions for the CF Sizing tab” on page 90.
```
```
Columns in the CF Sizing Definitions table
Table 78 on page 89 describes the columns in the CF Sizing Definitions table.
By default, the Product names in the table are sorted in ascending alphabetical order. To sort the table
based on the values in one or more columns, click the column header for the columns you want to sort.
If a sort is defined for a column, the ascending (▴) or descending (▾) sort icon is shown in the column
header.
```
_Table 78. Attributes of CF Sizing Definitions_

**Column Description**

**Product** Specifies the selected product that is being sized.

**Sizing Definition
Name**

```
A z/OSMF-specific value that specifies the unique name of the CF sizing definition.
Sizing definitions are used for persisting user sizing inputs and can be associated with
multiple structures.
The CF sizing definition name must contain 1-32 characters. This value must be unique.
Blanks are supported. The initial letter should be A-Z or a-z, the others can be
alphanumeric characters (A-Z, a-z, and 0-9), and special characters ($ _ # @). Names
are not case sensitive; for example, DB2TEST and DB2Test are the same CF sizing
definition name.
```
```
Sysplex Management task   89
```

```
Table 78. Attributes of CF Sizing Definitions (continued)
```
```
Column Description
```
```
Function Specifies the product function that is being sized. This selection determines the default
values for the sizing input fields.
```
```
Groups The selected groups that are associated with the CF sizing definition. Groups are z/
OSMF-specific tags that provide the ability to group together multiple related CF sizing
definitions, such as the set of CF sizing definitions that pertain to various structures in
a particular data-sharing group, by their common group specification. You are able to
search and filter on groups in the CF Sizing Definitions table.
The group name must contain 1-32 characters. This value must be unique.
Blanks are supported. The initial letter should be A-Z or a-z, the others can be
alphanumeric characters (A-Z, a-z, and 0-9), and special characters ($ _ # @). Group
names are not case sensitive; for example, DB2TEST and DB2Test are the same group
name.
You can assign multiple Groups to one sizing definition, and a Group can be assigned to
multiple sizing definitions.
Group is an optional parameter.
```
```
CF Level Level of the coupling facility control code (CFCC).
```
```
No. of Structures The number of structures that are currently associated with the CF sizing definition.
```
```
Modified By The last user who modified the CF sizing definition.
```
```
Date Modified The timestamp of the last action that modified the CF sizing definition.
```
```
Actions for the CF Sizing tab
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items.
- Untargeted actions. Actions that apply to the entire table. No selection of table items is required.
- Tab-level actions. Actions that apply to the entire tab. No selection of table items is required to enable
    these functions.

```
Table 79. Targeted actions for the CF Sizing Definitions table
```
```
Action Description
```
```
Modify and Size Display the Modify and Size CF Sizing Definition window so that you can modify
the properties of the selected CF sizing definition. To enable this action, select one
CF sizing definition only. For more information, see “Modify and Size a CF sizing
definition” on page 94.
It is possible to modify and size multiple CF sizing definitions at one time. For more
information, see “Modify and Size multiple CF sizing definitions” on page 97.
```
```
Copy Display the Copy CF Sizing Definition window so that you can copy selected sizing
definition. To enable this action, select one structure only. For more information,
see “Copy a CF Sizing Definition” on page 95.
```
```
Remove Associations Display the Remove Structure Associations window so that you can remove CF
structure associations for the selected CF sizing definitions. You can select multiple
CF sizing definitions. For more information, see “Remove associated structures
from a CF sizing definition” on page 96.
```
**90**   Sysplex Management task


_Table 79. Targeted actions for the CF Sizing Definitions table (continued)_

**Action Description**

**Delete** Display the **Delete CF Sizing Definitions** window so that you can permanently
delete the selected CF sizing definitions. You can select multiple CF sizing
definitions. For more information, see “Delete a CF Sizing Definition” on page 96.

_Table 80. Untargeted actions for the CF Sizing Definitions table_

**Action Description**

**Add** Display the **Add CF Sizing Definition** modal so that you can add a CF sizing
definition. For more information, see “Add a CF Sizing Definition” on page 91.

```
Tab-level actions for the CF Sizing tab
The CFRM Policy Editor and Sizer main page includes the tab-level actions Close and Submit.
Table 81 on page 91 describes the task-level actions for the CF Sizing tab.
```
_Table 81. Tab-level actions for the CFRM Policy Editor CF Sizing tab_

**Action Description**

**Submit** Submit updates for the selected policy. This action saves your changes to the
policy. You are prompted to confirm your action. After you submit the policy, you
cannot undo your updates.

**Close** Close the CFRM Policy Editor and Sizer. This action returns control to the **CFRM
Administrative Policies** view.
This action discards any pending (unsaved) updates for the policy. You are
prompted to confirm your request or return to the editor to continue working with
the policy.

```
Add a CF Sizing Definition
You can add CF Sizing Definitions to your policy to perform CF structure sizing. To do so, use the Add
action in the CF Sizing Definitions table. Doing so opens a window that you can use to add a CF sizing
definition.
```
```
About this task
A CF Sizing Definition is a z/OSMF-managed object with a single-policy scope. CF sizing definitions can be
associated with multiple structures, but a structure can be associated with only one CF sizing definition.
After the object is defined, it can be used to run sizing across multiple structures as needed.
```
**Procedure**

1. In the section **General Input** , define the basic attributes of the sizing definition.
    Values must be specified for the following attributes.
       a) In the **Product** field, select the product to be sized.
          This action enables the other input fields in the **General Input** section.
b) In the **Sizing Definition Name** field, specify the 1-32 character name of the sizing definition. This
value must be unique.
Blanks are supported. The initial letter should be A-Z or a-z, the others can be alphanumeric
characters (A-Z, a-z, and 0-9), and special characters ($ _ # @). Names are not case sensitive; for
example, _DB2TEST_ and _DB2Test_ are the same CF sizing definition name.
       c) In the **CF Level** field, increase or decrease the level number as needed.

```
Sysplex Management task   91
```

```
It is generally good practice to slightly over-specify your peak values to produce a sizing
recommendation slightly larger than necessary. This provides some room for growth, and helps
avoid failures that are caused by insufficient structure sizes.
d) In the Function field, select any one of the available product functions.
Selecting a value for the function field enables the rest of the fields on this modal and populates the
Sizing Input section fields with predetermined defaults.
```
2. Optionally, specify values for the other basic attributes.
    a) In the **Groups** field, you can select one or more groups to associate the CF sizing definition to.
       Groups provide more meaning about CF sizing definitions and help to locate related items that have
       the same tag.
       You can assign multiple Groups to one sizing definition, and a Group can be assigned to multiple
       sizing definitions.
       You can also create or edit existing groups by clicking on the pencil icon above the Groups field.
For a description of all attributes, see Table 78 on page 89.
3. In the section **Sizing Input** , you can modify the default values assigned to the input fields.
    The default values that are provided in these fields are different depending on the **Function** that you
    select.
       a) Click **Calculate** to determine the output based on the number of databases and tables that were
          input.
4. In the section **Sizing Results** , you can see the result of the calculation that is run in the **Sizing Input**
    section for Initial Size and Size.
       a) You can use the Results modifier to adjust the sizing results by percentage. The numerical
          differences that are adjusted from this method are shown as a value next to the current Sizing
          Results values.
          Results can be adjusted only to be higher than the recommended number for the selected product.
5. In the section **Associated Structures** , you can add the CF structures to be associated with this CF
    sizing definition.
    For a description of the attributes, see Table 72 on page 61
       a) Click **Add** to display a dialog for adding one or more structures to the Associated Structures list.
   .
6. Click **OK** to proceed to the **Sizings Summary** page.
7. Review the table on the **Sizings Summary** page, which displays all of the fields from the associated
    structures to be updated.
8. Click **OK** to add this CF sizing definition and update the associated structure sizings.

```
Results
On completion, the CF Sizing Definitions table is displayed, showing the new CF sizing definition.
Notifications display the success of creating the CF sizing definition and updating the associated structure
sizing, including a brief description message and the timestamp for when each action occurred.
```
```
Modify Available Groups for CF sizing definitions
The Modify Available Groups window shows the available Group objects that have been created. From
here you can add new group objects or modify existing groups. Use Groups to create tags that provide
additional meaning about CF sizing definitions and make it easier to locate related items that have the
same tag from the CF Sizing Definitions table.
```
**Procedure**

1. To add a new Group, click the **Add** button at the top of the table.
    a) A new row will appear with a blank Name field and a color randomly assigned.

**92**   Sysplex Management task


```
The tag color will default to a color that has not been used. If all colors have been used, it will
default to least used color. If all colors have been equally used, a random color is selected by
default.
b) Give the Group a name and use the color picker to select which tag color you would like to associate
it with.
Specify a 1-32 character name for the group. This value must be unique.
Blanks are supported. The initial letter should be A-Z or a-z, the others can be alphanumeric
characters (A-Z, a-z, and 0-9), and special characters ($ _ # @). Names are not case sensitive; for
example, DB2TEST and DB2Test are the same group name.
```
2. To modify an existing group, click into the **Name** cell or **Color** cell.
    a) Click into the **Name** cell and edit the text as needed.
b) Click into the **Color** cell to bring up the color picker. Select the one you would like to associate the
Group with.
3. To delete one or multiple Groups, select the row using the checkbox. From the action toolbar, select
    **Delete** or **Cancel**.
4. Click **OK** to save your changes. Otherwise, click **Cancel** to cancel your request.

**Results**

On completion, the Groups field displays the changes that you have implemented.

_Add Associated Structures to a CF Sizing Definition_
You can add CF structures to a CF sizing definition to size the structures according to the values in that
definition. To do so, use the **Add** action in the Sizing Definitions table. Doing so opens the **Add Associated
Structures to CF Sizing Definition** window that you can use to add a CF sizing definition.

**Procedure**

1. Filter the set of structures to the set that you want to add to the CF sizing definition.
    a) Click the filter icon in the Select Structures to Add taskbar to open the filter pane.
       The filter pane offers drop-downs and field types to help you construct a filter.
b) Use the filter pane to display the set of structures that you want to modify.
For example, if you want to modify structures that contain the string "Db2" in the structure name,
and enter **Column: Structure Name** > **Condition: Contains** > **Value: Db2** to find the matching
structures.
2. Select at least one structure that you want to add to the CF sizing definition. You can select multiple
    structures.
    For a description of the attributes, see Table 72 on page 61
    If you select a structure that is associated to another CF sizing definition, a message appears to
    indicate this circumstance. You can proceed, and the association switches to this CF sizing definition,
    since a structure can be associated with only one sizing definition. Make sure that this outcome is your
    intention before proceeding.
3. Click **Add** to associate the selected structures. Otherwise, click **Cancel** to cancel your request.

**Results**

On completion, the **Associated Structures** table is displayed on the **Add CF Sizing Definition** modal,
showing the new structures that were added.

```
Sysplex Management task   93
```

```
Sizing Summary
The Sizings Summary window shows the selected structure that to be updated by adding or modifying a
CF Sizing Definition.
```
**Procedure**

1. Review the table of structure sizings to be updated. Each row displays a field from the associated
    structures to be updated. The columns include the Structure Name, the updated Field, the Original
    Value for that Field, and the New Value that the field will be changed to.
    You can search the table for a specific structure or field. The total number of changes is reflected
    under the table.
2. Click **OK** to add this CF sizing definition and update the associated structure sizings. Otherwise, click
    **Cancel** to cancel your request.

**Results**

```
On completion, the CF Sizing Definitions table is displayed, showing the new CF sizing definition.
Notifications display the success of creating the CF sizing definition and updating the associated structure
sizing, including a brief description message and the timestamp for when each occurred.
```
```
Modify and Size a CF sizing definition
You can modify a CF sizing definition to adjust the CF Level and resize all associated structures. To do so,
use the Modify and Size action in the CF Sizing Definitions table. Doing so opens a window that you can
use to modify a sizing definition.
```
**Procedure**

1. In the section **General Input** , you can modify values for any of the basic attributes of the CF sizing
    definition, as needed.
    Values must be specified for the following attributes.
       a) In the **Product** field, you can edit the product to size.
          Selecting a new product field resets the **Function** field and **Sizing Input** section to blank fields.
b) In the **Sizing Definition Name** field, you can modify the 1-32 character name of the sizing
definition. This value must be unique.
Blanks are supported. The initial letter should be A-Z or a-z, the others can be alphanumeric
characters (A-Z, a-z, and 0-9), and special characters ($ _ # @). Names are not case sensitive; for
example, _DB2TEST_ and _DB2Test_ are the same CF sizing definition name.
       c) In the **CF Level** field, increase or decrease the level number as needed.
          It is generally good practice to slightly over-specify your peak values to produce a sizing
          recommendation slightly larger than necessary. This provides some room for growth, and helps
          avoid failures that are caused by insufficient structure sizes.
d) In the **Function** field, select any one of the available product functions.
2. Optionally, specify values for the other basic attributes.
    a) In the **Groups** field, you can select one or more groups to associate the CF sizing definition to.
       Groups provide more meaning about CF sizing definitions and help to locate related items that have
       the same tag.
       You can assign multiple Groups to one sizing definition, and a Group can be assigned to multiple
       sizing definitions.
       You can also create or edit existing groups by clicking on the pencil icon above the Groups field.
    For a description of all attributes, see Table 78 on page 89.
3. In the section **Sizing Input** , you can modify the default values assigned to the input fields.

**94**   Sysplex Management task


```
The default values that are provided in these fields are different depending on the Function that you
select.
a) Click Calculate to determine the output based on the number of databases and tables that were
input.
```
4. In the section **Sizing Results** , you can see the result of the calculation that is run in the **Sizing Input**
    section for Initial Size and Size.
       a) You can use the Results modifier to adjust the sizing results by percentage. The numerical
          differences that are adjusted from this method are shown as a value next to the current Sizing
          Results values.
          Results can be adjusted only to be higher than the recommended number for the selected product.
5. In the section **Associated Structures** , you can modify the structures that are associated with this CF
    sizing definition.
    For a description of the attributes, see Table 72 on page 61
       a) To add CF structures to the CF sizing definition, click **Add** to display a dialog for adding associated
          structures.
b) To remove an associated CF structure from the CF sizing definition, click **Remove** in the overflow
menu of the table row.
6. Click **OK** to proceed to the **Sizings Summary** page.
7. Review the table on the **Sizings Summary** page, which displays all of the fields from the associated
    structures to be updated.
8. Click **OK** to add this CF sizing definition and update the associated structure sizings. Otherwise, click
    **Cancel** to cancel your request.

**Results**

On completion, the **CF Sizing Definitions** table is displayed, showing the modified CF sizing definition.
Notifications display the success of modifying the CF sizing definition and updating the associated
structure sizing, including a brief description message and the timestamp for when each occurred.

**_Copy a CF Sizing Definition_**
You can copy an existing CF sizing definition. To do so, use the **Copy** action in the CF Sizing Definitions
table. Doing so opens a modal that you can use to copy a sizing definition.

**About this task**

When you copy a CF sizing definition, all fields from the **General Input** and **Sizing Input** sections are
copied over to the new CF sizing definition.

The associated CF structures from the copied CF sizing definition are brought over, since a CF structure
can be associated with only one CF sizing definition.

**Procedure**

1. Click the overflow menu in the row of the CF sizing definition that you want to delete. Click **Copy** in the
    menu to proceed.
2. Modify the values for any of the attributes in the **General Input** and **Sizing Input** sections as needed.
3. In the section **Associated Structures** , add the CF structures that you want to be associated with this
    CF sizing definition.
4. Click **OK** to create the copied CF sizing definition and update the associated structure sizings.
    Otherwise, click **Cancel** to cancel your request.

**Results**

On completion, the **CF Sizing Definitions** table is displayed, showing the new CF sizing definition.

```
Sysplex Management task   95
```

```
A notification displays the success of copying the CF sizing definition, including a brief description
message with both CF sizing definition names and the timestamp for when the action occurred.
```
```
Remove associated structures from a CF sizing definition
You can remove one or multiple CF sizing definitions from your policy. To do so, use the Remove
Associations action in the CF Sizing Definitions table. Doing so opens a modal that you can use to remove
the selected structure associations.
```
**About this task**

```
You can choose to remove all of the associated CF structures from an individual CF sizing definition or
multiple CF sizing definitions.
This action does not delete the selected CF sizing definitions, but it clears all CF structure associations.
This action is generally not recommended unless all CF Sizer to CF Structure associations are no longer
valid.
This change is permanent; you are prompted to confirm this action before it is taken.
```
**Procedure**

1. Select the CF sizing definitions that you would like to remove associated CF structures from.
    a) To select one CF sizing definition, click the overflow menu in the row of the sizing definition that you
       want to remove associated CF structures from. Click **Remove Associations** in the menu to proceed.
b) To select multiple CF sizing definitions, click the checkbox that is associated with the row of each
CF sizing definition to remove associated CF structures from. Click **Remove Associations** in the
action bar to proceed.
2. The **Remove Structure Associations** modal appears to confirm the action. The number of structure
    associations is shown for the selected CF sizing definitions. The selected CF sizing definitions are
    displayed in a table, including the product and name of each CF sizing definition and any CF structures
    are currently associated with that CF sizing definition. Review the information to make sure you want
    to proceed.
3. To remove the structure associations, click **OK**. Otherwise, click **Cancel** to cancel your request.

```
Results
On completion, the selected CF sizing definitions have a value of zero in the No. of Structures column of
the CF Sizing Definitions table.
A notification displays the success of removing the CF structure associations, including a brief description
message with the number of associations that were removed, and the timestamp for when the action
occurred.
```
```
Delete a CF Sizing Definition
You can delete one or multiple CF sizing definitions from your policy. To do so, use the Delete action in
the CF Sizing Definitions table. Doing so opens a modal that you can use to remove the selected CF sizing
definitions.
```
```
About this task
You can select an individual CF sizing definition or multiple CF sizing definitions to delete.
When you delete a CF sizing definition, any CF structures that are associated with it will no longer have a
CF sizing definition.
This change is permanent; you are prompted to confirm this action before it is taken.
```
**96**   Sysplex Management task


**Procedure**

1. Select the CF sizing definitions to delete.
    a) To select one CF sizing definition, click the overflow menu in the row of the CF sizing definition that
       you want to delete. Click **Delete** in the menu to proceed.
b) To select multiple CF sizing definitions, click the checkbox that is associated with the row of each
CF sizing definition to be deleted. Click **Delete** in the action bar to proceed.
2. A modal appears to confirm the action. The selected CF sizing definitions are displayed in a table,
    including the name of each CF sizing definitions and any CF structures are currently associated with
    that CF sizing definition. Review the information to make sure you want to proceed.
3. To delete the selected CF sizing definitions, click **OK**. Otherwise, click **Cancel** to cancel your request.

**Results**

On completion, the deleted CF sizing definitions are removed from the **CF Sizing Definitions** table.

A notification displays the success of deleting the CF sizing definitions, including a brief description
message and the timestamp for when the action occurred.

**_Modify and Size multiple CF sizing definitions_**
You can apply modifications and sizing to a set of CF sizing definitions at one time. To do so, follow the
steps in this procedure.

**About this task**

In this procedure, you select a set of CF sizing definitions and apply modifications and sizing to them.
Begin by using a table filter to locate the set of CF sizing definitions that you want to modify. You can
filter by a common attribute, for example, structure names that share a common string pattern. Then,
select the CF sizing definition attributes to be changed and apply the changes to the selected CF sizing
definitions. This approach can save you time compared to editing sizing definitions one by one.

**Procedure**

1. Filter the set of CF sizing definitions to the set that you want to modify.
    a) Click the filter icon in the CF Sizing Definitions table taskbar to open the filter pane.
       The filter pane offers drop-downs and field types to help you construct a filter.
b) Use the filter pane to display the set of CF sizing definitions that you want to modify.
For example, if you want to modify CF sizing definitions that contain the string "Db2" in the CF
sizing definition name, and enter **Column: Sizing Definition Name** > **Condition: Contains** > **Value:
Db2** to find the matching CF sizing definitions.
2. Select the CF sizing definitions that you want to modify.
    Notice that the CF Sizing Definitions table displays a taskbar with the options **Delete** , **Modify and Size** ,
    and **Cancel**.
3. Click **Modify and Size**.
4. In the **Modify and Size Multiple CF Sizing Definitions** window, enter values for the attributes that you
    want to modify.
    These values are applied to the selected CF sizing definitions, which are listed under **Modify and Size**
    **Structures in Selected Selected CF Sizing Definitions**. You can expand each table row to view more
    details about the CF sizing definition Inputs, Results, and associated CF Structure to Size. Fields that
    you leave empty are not modified.
5. Click **Next** to proceed to the Summary of Updates.
6. Review the **Structure sizings to be updated** table to confirm that you want to proceed with these
    sizing values. Each row displays a field from the associated structures to be updated. The columns
    include the CF Sizing Definition, Structure Name, the updated Field, the Original Value for that Field,

```
Sysplex Management task   97
```

```
and the New Value that the field will be changed to. You can search the table for a specific CF sizing
definition, structure, or field.
```
7. Click **Finish** to confirm your selection. Click **Back** to return to the Sizing Details step. Otherwise, click
    **Cancel** to cancel your request.

```
Results
On completion, the CF Sizing Definitions table is displayed, showing the modified CF sizing definitions.
Notifications display the success of modifying and sizing, including the number of CF sizing definitions and
CF structure sizings that were updates and the timestamps for when these actions occurred.
```
```
CF structure size parameters
This information contains the context necessary to alter the structure size parameters in the Sizing Input
section of the CF Sizing tab for each available product function.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
The inputs that you supply should correspond to your expected peak usage of the selected product. It
is generally good practice to slightly overspecify your peak values to produce a sizing recommendation
slightly larger than necessary. This provides some room for growth, and help avoid failures that are
caused by insufficient structure sizes.
```
```
Calculate the size of an APPC log structure
Coupling facility selection parameters for an APPC structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of protected conversations
For each local Logical Unit that supports SYNCLVL=SYNCPT, calculate the maximum anticipated
number of partner LUs that communicate by using protected conversations. Identify the number of
partners for each local LU, then add all the values together.
For example, assume that there are 8 local LUs on system SC61, 3 of which are defined with
SYNCLVL=SYNCPT.
```
- SCSIMS8IA communicates with up to 15000 partner LUs, but only 20% of those partners
    communicate by using protected conversations.
- SC61IMAR communicates with up to 5000 partner LUs and all of them might use protected
    conversations.
- SC61IMSA communicates with 2000 partner LUs, of which about 50% use protected conversations.
Based on these conditions, the number of unique Partner Logical Units that support Projected
Conversations is (3000 + 5000 + 1000) = 9000.

```
Calculate the size of a BatchPipes structure
Coupling facility selection parameters for a BatchPipes structure.
BatchPipe uses a list structure in a Coupling Facility to enable cross system BatchPipes. Cross-system
BatchPipes are also known as Pipeplex.
It is possible to have multiple Pipelexes within a single Parallel Sysplex by using different subsystems
names, but each Pipeplex must have its own list structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
```
**98**   Sysplex Management task


**Maximum Number of Concurrent Pipes**
Number of concurrent pipes.

**Systems**
The number of systems in a Pipeplex.

**Buffers**
The average number of buffers per pipe.

_Calculate the size of a CICS Temporary Storage list structure_
Coupling facility selection parameters for CICS Temporary Storage list structure.

CICS shared temporary storage uses list structures to provide access to unrecoverable temporary storage
queues from multiple CICS regions that run on any image in a Parallel SYSPLEX. CICS stores a set of
temporary storage (TS) queues that you want to share in a TS pool. Each TS pool corresponds to a
Coupling Facility CICS TS list structure.

You can create a single TS pool or multiple TS pools within a single sysplex. For example, you might
create separate pools for specific purposes, such as a TS pool for production or a TS pool for test and
development.

The size of the TS pool list structure is a function of the number of list entries (Total List Entries) and the
number of data elements that are associated with each entry. This value is calculated from MAXQUEUES
and Average Item Size.

The name of the list structure for a TS data sharing pool is created by appending the TS pool name to the
prefix DFHXQLS_, giving DFHXQLS_poolname.

Refer to the CICS Transaction Server for z/OS System Definition Guide SC34-6428 for a detailed
description of the CICS TS list structure.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Maximum number of queues (max large Qs)**
Specifies the maximum number of data lists to be reserved when the structure list is allocated by
CICS, which determines the maximum number of large queues that can be stored in the structure.
This number corresponds to the MAXQUEUES server parameter. Though it is necessary to specify a
large enough number for your needs, specifying an excessively large number uses up an unnecessary
amount of coupling facility storage for unused preallocated list headers.
The valid range is 1 - 999999. The default is 1000.

**Average rounded item size**
Average amount of storage needed for each TS queue item, considering that each item has a 2-byte
length prefix and is stored as one or more 256-byte elements. This value determines the entry to
element ratio that is used to calculate the required structure size.
The valid range is 1 - 32768.
If all queue items are around the same size, this is the average data size plus two rounded up to the
next multiple of 256. If queue items are different sizes, it might be more accurate to round each size
first before taking the average. For example, if half of the items are 100 bytes and half are 300, then
the rounded sizes are 256 and 512. The average rounded item size is halfway between, 384, which is
much more accurate than taking the overall average item size 200 and rounding that up to 256.

**Total number of items in all queues**
The total number of entries in all of the TS queues.

**Target usage percent**
The percentage of the structure space that the given total number of items are expected to use.
Specify a number in the range 1 - 100. The default is 75. This value leaves space for temporary
expansion, and to give time to expand the structure in response to warning messages if the initial free
space is not enough. Warning messages typically begin to display at 80% capacity used.

```
Sysplex Management task   99
```

```
Maximum expansion percent
The percentage by which the structure can be expanded. If a nonzero value is specified, the maximum
structure size is greater than the initial structure size to allow for expansion of the total amount of
data by this percentage. For example, if the value 200 is specified, the initial size is enough to store
the specified total number of items, but the maximum size is enough to store three times that number
of items.
```
```
Calculate the size of a CICS Named Counter list structure
Coupling facility selection parameters for a CICS Named Counter list structure.
CICS provides a facility for generating unique sequence numbers for use by application programs in
a Parallel Sysplex environment. This facility is provided by a named counter server, which generates
each sequence of numbers by using a named counter. The counter name is an identifier of up to 16
characters. Each time a sequence number is assigned, the corresponding named counter is incremented
automatically.
A named counter is stored in a named counter pool, which resides in a list structure in a coupling facility.
The list structure name is of the form DFHNCLS_ poolname. You can create different pools to suit
your needs, for example if different sets of counters have different security requirements. You might, for
example, create a pool for use by production CICS regions that are called DFHNCPRD and others for test
and development regions that are called DFHNCTST and DFHNCDEV.
A named counter pool name can be any valid identifier of up to 8 characters, but by convention pool
names use the form DFHNCxxx. The default that is named counter options table assumes that when an
application specifies a pool selector of this form it is referring to that physical named counter pool. Any
other pool selector with no specific option table entry is mapped to the default named counter pool for
the current region. If no default is set for the current region, it is mapped to the standard default pool
name DFHNC001. Applications can use their own logical pool names to refer to their named counters, but
the counters are normally stored in the default pool unless the installation specifically adds an option
table entry to map that logical pool name to a different physical pool.
The structure size for a named counter pool depends on the number of different named counters that you
need. The minimum size of 256 KB is enough for most needs, as it holds hundreds of counters. You can
allocate a larger structure, which can hold many thousands of counters if necessary.
This calculation determines the size of a structure that would be sufficiently large to contain at least
the exact specified number of counters. However, for practical operation a reasonable proportion of free
space must be available to minimize the risk of running out of space and avoid triggering low space
warning messages. Aim for the maximum normal usage to be less than 75% of the structure size. When
you estimate the maximum number of counters that you require, increase that number by about one-third
to allow for free space when you specify the number of counters to be used.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of counters
Number of counters for which space is to be allocated in the named counter pool structure.
```
```
Calculate the size of a CICS Data Tables structure
Coupling facility selection parameters for a CICS Data Tables structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Maximum number of tables
The maximum number of data tables that can be stored in the Data Tables structure.
This number corresponds to the MAXQUEUES server parameter. Though it is necessary to specify a
large enough number for your needs, specifying an excessively large number uses up an unnecessary
amount of coupling facility storage for unused preallocated list headers.
```
**100**   Sysplex Management task


```
The default number is 1000.
```
**Average rounded item size**
Average amount of storage needed for each TS queue item, considering that each item has a 2-byte
length prefix and is stored as one or more 256-byte elements. This value determines the entry to
element ratio that is used to calculate the required structure size.
The valid range is 1 - 32768.
If all queue items are around the same size, this is the average data size plus two rounded up to the
next multiple of 256. If queue items are different sizes, it might be more accurate to round each size
first before taking the average. For example, if half of the items are 100 bytes and half are 300, then
the rounded sizes are 256 and 512. The average rounded item size is halfway between, 384, which is
much more accurate than taking the overall average item size 200 and rounding that up to 256.
As a special case, records in a contention model data table with a record length of up to 63 bytes
are stored in the entry adjunct area. For average record length purposes, the data length is effectively
zero.

**Total records**
Total number of records to be stored in all data tables.

**Target usage percent**
The percentage of the structure space that the given total number of items are expected to use.
Specify a number in the range 1 - 100. The default is 75. This value leaves space for temporary
expansion, and to give time to expand the structure in response to warning messages if the initial free
space is not enough. Warning messages typically display at 80% capacity used.

**Maximum expansion percent**
The percentage by which the structure can be expanded. If a nonzero value is specified, the maximum
structure size is greater than the initial structure size to allow for expansion of the total amount of
data by this percentage. For example, if the value 200 is specified, the initial size is enough to store
the specified total number of items, but the maximum size is enough to store three times that number
of items.

_Calculate the size of CICS DFHLOG and DFHSHUNT log structures_
Coupling facility selection parameters for CICS DFHLOG and DFHSHUNT log structures.

System logger is a set of services that allows an application to write, browse, and delete log data. You
can use system logger services to merge data from multiple instances of an application, including merging
data from different systems across a sysplex. List structures are used to hold the logstream data from
exploiters of the system logger.

In CICS/ESA 4.1 and earlier, CICS logging and journaling is performed by the CICS journal control
management function, which uses sequential data sets supported by an automatic archiving facility. In
CICS TS, the earlier journal control management function is replaced by the CICS log manager. The MVS
System Logger is used instead of sequential data sets for all logging and journaling requirements. Using
services provided by the MVS System Logger, the CICS log manager supports:

- The CICS system log, which is used for transaction backout, emergency restart, and preserving
    information for resynchronizing in-doubt units-of-work, even on a cold start. There is no internal
    dynamic login CICS TS as in earlier releases of CICS. The system log is used for all transaction backout.
- Forward recovery logs, auto-journals, user journals, and a log of logs. These logs are collectively
    referred to as general logs to distinguish them from system logs.

**Note:** For CICS logging, you can use either coupling facility-based logstreams, DASD-only log streams,
or a combination of both. However, all connections to DASD-only logstreams must come from the same
z/OS image, which means you cannot use a DASD-only logstream for a user journal that is accessed by
CICS regions running on different z/OS images. For CF-based logstreams, you should place logstreams
only with similar characteristics (frequency and size of data that is written to the logstream) in the same
structure. For more recommendations for grouping of CF-based log streams, refer toto z/OS MVS Setting
Up a Sysplex.

```
Sysplex Management task   101
```

```
Migrating CICS TS requires careful planning to define all your existing CICS logging and journal
requirements to the MVS system logger and CICS log manager. If you have an existing CICS 4.1 journal,
you can use the DFHLSCU utility to generate the definitions for the CICS TS logstreams and their
associated structures.
For monitoring and tuning an existing CICS TS logstream, you need to gather the SMF 88 records and use
the sample program IXGRPT1 or IXGRPT1J to format the data.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Maximum buffer size
The maximum buffer size is the largest buffer size that is expected to be written.
Maximum buffer size is a parameter at the structure level for CF-based logstreams. The other
remaining parameters are logstream that is related.
Average buffer size
The average size of the data buffers written. This input is used to determine the list structure's initial
entry to element ratio. This number is available in the IXGRPT1 and IXGRPT1J output.
HighoffLoad
When a coupling facility list structure is filled to its high offload threshold point or beyond, the MVS
system logger begins the removal of data from the coupling facility. This process is accomplished by
either deleting log blocks that are no longer needed by CICS or by moving data to the DASD logstream
offload data sets.
A value of 80% to 85% is recommended for CICS logstreams. See z/OS MVS Setting Up a Sysplex for
additional information about the offload threshold parameter.
This value is specified as a percentage. Enter this value as a whole number. For example, if the
threshold is 80 percent, enter 80.
Number of write requests per interval
The number of log blocks that are written to the logstream during the data collection interval. This
includes the total from all systems that use the logstream. The number of log blocks that are written
to the logstream can be determined by using the #WRITES INVOKED data from an IXGRPT1 or
IXGRPT1J report. If CICS Transaction Server R2.2 is being used, the value is available in a DFH0STAT
report (obtained by running the STAT transaction for each region).
Length of interval in seconds
The time interval in seconds over which the number of writes was collected. The longer the interval,
the more writes are collected. Select an interval during peak writes.
Longest running task in seconds
The duration in seconds of the longest running transaction during the data collection interval.
Note: This is NOT equivalent to the average response time.
Log tail deletes
The number of times CICS has performed log tail deletion during the interval. This number can be
obtained from the job log of the region by counting the number of DFHLG0743 messages that were
issued during the interval. You can also format the CICS statistics and use the number that is reported
for STREAM DELETES.
```
```
Calculate the size of a CICS Journal and User Log
Coupling facility selection parameters for a CICS Journal and User Log.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
```
**102**   Sysplex Management task


**Maximum number of tables**

```
In general, CICS regions refer to their system logs and general logs by an internal 8-character journal
name. For example, the internal name for the CICS system log is DFHLOG, and general logs are
identified by journal names that use DFHJnn, where nn is a number in the range 01 - 99. CICS maps
its internal 8-character journal names to MVS logstreams by user-defined JOURNALMODEL resource
definitions, in which you specify the journal name and the corresponding logstream name.
The JOURNALMODEL resource definition replaces entries in the journal control table, which is
obsolete.
System logger is a set of services that allows an application to write, browse, and delete log data.
You can use system logger services to merge data from multiple instances of an application, including
merging data from different systems across a sysplex. It uses list structures to hold the logstream
data from exploiters of the system logger.
logstreams are sequence of data blocks, with each logstream identified by its own logstream
identifier, the logstream name (LSN). Each logstream is written by the MVS system logger to a
specified list structure in the coupling facility.
The CICS system log, forward recovery logs, autojournals, log of logs, and user journals map onto
specific MVS logstreams.
MVS logstreams replace the CICS journal data sets.
The system logger component manages logstreams based on the LOGR policy in the LOGR couple
data set. The LOGR policy includes:
```
- Log steam definitions
- Coupling facility list structure definitions
- Keywords
Keywords such as MAXBUFFSIZE, AVGBUFFSIZE, and LOGSNUM are defined in the LOGR policy. The
following defaults are used for sizing a log structure when you click **Calculate**.
**LOWOFFLOAD**
    Specifies the point, in percent value of space that is consumed, where logger will stop offloading
    coupling facility log data to the DASD log data sets for this logstream. The default is 0.
**HIGHOFFLOAD**
    Specifies the point, in percent value of space that is consumed, where logger will begin offloading
    coupling facility log data to the DASD log data sets for this logstream. The default is 80.

**Writes per second**
The number of log blocks that are written to the logstream per second from a single system.
Refer to IBM publication _z/OS MVS Setting up a Sysplex_ SA23-1399 for more detailed information.

**Maximum buffer size**
Specifies the size in bytes of the largest log block that can be written to logstreams.
The valid range is 1 - 65532.

**Average buffer size**
Specifies the average size in bytes of log blocks that are written to all logstreams.

**Number of logstreams**
Specifies the number of logstreams that are allocated to a list structure. The valid range is 1 - 512.

_Calculate the size of a CommServer EZBEPORT structure_
Coupling facility selection parameters for a CommServer EZBEPORT structure.

The TCP/IP Sysplexports function uses the Coupling Facility list structure EZBEPORT to allow TCP/IP
applications to share a pool of ephemeral ports using the same DVIPA (Dynamic Virtual IP address) as a
source IP address. The size of the EZBEPORT structure depends on the number of DVIPAs expected to be
used for ephemeral port allocation sharing, and the average number of TCP/IP stacks per DVIPA.

```
Sysplex Management task   103
```

```
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
DVIPAS
The number of Dynamic Virtual IP addresses that are expected to participate in ephemeral port
allocation sharing across the sysplex.
TCPIP Stacks
The average number of TCP/IP stacks per DVIPA that are expected to participate in ephemeral
port allocation sharing across the sysplex, including those using the EXPLICITBINDPORTRANGE
parameter of the GLOBALCONFIG statement in the TCP/IP profile. For each DVIPA, calculate the
total number of TCP/IP stacks in the sysplex that is using that DVIPA as a source IP address. Add the
totals for all DVIPAs together and divide by the number of DVIPAs. For example, if you have 3 DVIPAs
that participate in ephemeral port allocation sharing across the sysplex, and the first DVIPA will have
3 TCP/IP stacks that use it as a source IP address, the second DVIPA has 5 TCP/IP stacks that use it
as a source IP address, and the third DVIPA has 4 TCP/IP stacks that use it as a source IP address,
then the total number of TCP/IP stacks is 12 and the average is 4.
```
```
Calculate the size of a CommServer Sysplex-wide Security Associations structure
Coupling facility selection parameters for a CommServer Sysplex-wide Security Associations (SWSA)
structure.
The TCP/IP Sysplex Wide Security Associations (SWSA) function uses the coupling facility list structure
EZBDVIPA to store information about IPsec tunnels addressed to Distributed Dynamic Virtual IP
addresses (DRVIPAs) within the sysplex. TCP/IP uses the information that is stored to allow for
renegotiation of the IPsec tunnels for DRVIPA takeover, either planned or unplanned.
A DRVIPA takeover can occur if the TCP/IP stack or host node goes down, which is an unplanned
takeover, or if you want to change the ownership of the DRVIPA, which is a planned takeover. The size
of the EZBDVIPA structure depends on the number of dynamic IPsec tunnels that are expected to be
established by using DRVIPAs in the sysplex.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Dynamic IPSec tunnels
The number of dynamic IPsec tunnels expected to be established by using DRVIPAs in the sysplex.
Algorithm
The algorithm to be used in computing the structure size and allocating the structure itself.
z/OS V2R3
The structure is allocated by using the z/OS V2R3 algorithm, which supports a variable number
of lists as specified by the DVLSTCNT VTAM start option. Use this option only when all systems
connecting to the EZBDVIPA structure are at z/OS V2R3 or higher.
Pre-z/OS V2R3
The structure is allocated by using the pre-z/OS V2R3 algorithm, with a fixed number of lists.
Input type
The type of input on which the sizing calculation is based. This input option is displayed only when the
z/OS V2R3 algorithm is selected. See the usage scenarios to determine which of the following to use:
DVIPAs
The number of DVIPAs expected to be established in the sysplex. Use this input option when the
DVLSTCNT VTAM start option is not determined.
List count
Number of lists to be allocated in the structure. The z/OS V2R3 algorithm supports only the listed
values. Select the value equal to the DVLSTCNT VTAM start option.
```
**104**   Sysplex Management task


**Usage scenarios for the z/OS V2R3 algorithm**

- When there is only one EZBDVIPA structure in use in the VTAM configuration, select DVIPAs as the input
    type. The computed size recommendations are accompanied by a message that indicates the number of
    lists appropriate for the specified inputs. Use that list count as the DVLSTCNT VTAM start option.
- When the VTAM configuration consists of subplexes each connecting to a separate EZBDVIPA structure,
    use the following procedure to determine structure sizes and DVLSTCNT. The DVLSTCNT specification
    applies to the entire VTAM configuration, so all structures are allocated with the same number of lists.
       1. Run the sizing calculation separately for each EZBDVIPA structure in the VTAM configuration,
          specifying the number of tunnels and DVIPAs as input. For each structure, note the output list count
          value.
       2. Use the highest output list count as DVLSTCNT.
       3. For each structure that generated a list count equal to the recommended DVLSTCNT, use the SIZE /
          INITSIZE returned by the original calculation.
       4. For the remaining structures, repeat the sizing calculation and specify the number of tunnels and a
          list count equal to DVLSTCNT as input.

_Calculate the size of a CommServer VTAM Generic Resources structure_
Coupling facility selection parameters for a CommServer VTAM Generic Resources structure.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of sessions**
Maximum number of sessions anticipated to be active for all generic resources at any one time.
For example, if you define generic resource GRCICS with an anticipated maximum of 10,000 sessions,
and generic resource GRIMS with an anticipated maximum of 15,000 sessions, enter a value of
25000.
To determine the actual number of sessions for a resource, issue the VTAM command D
NET,SESSIONS,LU1=applname,LIST=COUNT for each applname that is an instance of a generic
resource.
For example, if applications CICS1, CICS2, and CICS3 are all instances of the generic resource
GRCICS, issue the D NET, SESSIONS command for each application. The total of session counts is
the actual current number of sessions. Perform this evaluation during a period of peak usage for each
resource to estimate the maximum number of concurrent sessions required.

_Calculate the size of a CommServer VTAM MNPS structure_
Coupling facility selection parameters for a CommServer VTAM MNPS structure.

VTAM multinode persistent sessions (MNPS) support provides a means for sessions running on a failing
VTAM node to be recovered on another VTAM node.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of MNPS-capable applications**
The number of MNPS-capable applications in the sysplex that uses the RAPI interface or APPCCMD
interface.

**Number of MNPS-capable applications using APPCCMD**
The number of MNPS-capable applications in the sysplex that uses the APPCCMD interface.

**Number of RAPI sessions**
The number of MNPS sessions that use the RAPI interface.

**Number of APPCCMD sessions**
The number of MNPS sessions that use the APPCCMD interface.

```
Sysplex Management task   105
```

```
Avg number of APPCCMD session partners
The average number of session partners, per MNPS application, for sessions that use the APPCCMD
interface.
Avg number of COS entries
The average number of different class-of-service (COS) entries used by each MNPS application
program application.
Number of HPR endpoint nodes
The number of nodes in the network that can be the endpoint of HPR connections involving MNPS
applications.
NLP average size
The average outbound NLP size. This value can be calculated by using the VTAM Tuning Statistics
function. The display for Tuning Statistics shows the number of bytes sent for each WRITE
subchannel. The values are displayed in the BYTECTO and BYTECT fields. The number of bytes
for each subchannel is 9999999999 * BYTECTO + BYTECT. Sum this value over all the Write
subchannels, and divide by the number of Outbound PDUs, which are displayed as OPDU in the Tuning
Statistics display.
Rate of outbound NLPs
The aggregate outbound NLP rate, or the average number of NLPs sent per second, across all write
subchannels carrying MNPS data traffic. This value can be calculated by using the VTAM Tuning
Statistics function. For each write subchannel, the display for Tuning Statistics shows the number of
Outbound PDUs displayed in the OPDU field. Sum this value across all the write subchannels, and
divide that number by the Tuning Statistics interval in seconds.
Average NLP round trip time
The average number of time NLPs stay in the system. Three seconds is considered an average value
for the NLP round-trip time. Round-trip delay can be returned by using the performance monitor
application (PMI), in the RTP data vector.
```
```
Calculate the size of a Db2 IRLM lock structure
Coupling facility selection parameters for a Db2 IRLM lock structure.
The Db2 IRLM coupling facility lock structure contains information that is used to determine cross-system
contention on a particular resource. Locking is controlled by one lock structure per data sharing group,
containing information about locks that are used to control changes to shared resources. The size of the
lock structure must reflect the total number of concurrent locks that are held by all members in the Db2
data sharing group.
The size of the Db2 IRLM lock structure is a function of the number of systems that share the lock
structure, the number of table spaces associated with the data sharing group, and the lock rate.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Lock Rate
The maximum locking rate per second. The lock rate information should be obtained from a Db2
Performance Monitor or equivalent batch statistics report under the Locking Section. It is the sum of
the Lock Requests, Unlock Requests, and Change Requests. The statistics report should be run for a
peak online hour and peak batch hour to come up with the capacity value.
Number of Systems
The maximum number of systems expected to be active in the sysplex at any one time.
Number of Table Spaces
The total number of table spaces that are associated with all of the databases that are managed by
the data sharing group.
Max Number of Users
The maximum number of users of the lock structure, from the MAXUSRS value specified in the
IRLMPROC procedure.
```
**106**   Sysplex Management task


**Max Number of Connectors**
The maximum number of connectors per structure specified when the primary CFRM couple data
set was formatted (ITEM NAME(CONNECT) NUMBER(xx)). The sizing calculation uses the smaller
of this number or the release-specific maximum number of systems in a sysplex. If you use a new
primary CFRM couple data set formatted for a greater number of connectors per structure, you must
repeat this calculation, since the new value is applied whether you rebuild the structure or restart the
sysplex.

**Asynchronous Duplexing**
Indicates if the structure is eligible for asynchronous duplexing. If the CFRM policy description for this
structure specifies DUPLEX(ALLOWED|ENABLED,dupoptions) where dupoptions includes ASYNC
or ASYNCONLY, then specify YES. Otherwise, specify NO.
The lock structure storage is allocated partly to lock table entries (LTEs) and partly to record list
entries (RLEs). Database operations can fail if the structure contains an insufficient number of either
type. IRLM reserves space for functions that must complete, such as rollbacks or commit processing,
so that a shortage of storage does not cause a Db2 subsystem failure. IBM recommends that
installations specify the number of LTEs to be contained by the structure on the procedure that is used
to start IRLM (irlmproc). Specifying a CFRM policy size much larger than CFSizer's recommendation
without specifying the number of LTEs on the irlmproc can cause the structure to be allocated without
sufficient RLEs. The sizing calculation models the number of LTEs as (lock rate + (number of
systems) * (number of table spaces)) * 200. The system rounds the calculated number of
LTEs up to the next highest power of 2.
For more information, see Installing, migrating and enabling Db2 data sharing.

_Calculate the size of a Db2 Shared Communication Area structure_
Coupling facility selection parameters for a Db2 Shared Communication Area (SCA) structure.

The Db2 Shared Communication Area (SCA) is a list structure in the coupling facility that contains:

- Member names.
- BSDS names.
- Database exception status conditions about objects in the database.
- Recovery information, such as log data set names and the list of in doubt XA transactions.

The sizing calculation estimates the size of a Db2 SCA List structure based on the total number of
database tables in your environment.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Total number of databases**
Use this input parameter to specify the total number of databases in your Db2 environment for the
coupling facility Db2 SCA list structure. The number must be greater than zero.

**Total number of tables**
Use this input parameter to specify the total number of tables in your Db2 environment for the
coupling facility Db2 SCA list structure. The number must be greater than zero.

For more information, see Installing, migrating and enabling Db2 data sharing.

_Calculate the size of Db2 group buffer pool structures_
Coupling facility selection parameters for Db2 group buffer pool structures.

Cache structures are used as group buffer pools for the Db2 data sharing group. Db2 uses a group buffer
pool to cache data that is of interest to more than one Db2 in the data sharing group. Group buffer pools
are also used to maintain the consistency of data across the buffer pools of members of the group by
using a cross-invalidating mechanism.

```
Sysplex Management task   107
```

```
One group buffer pool is used for all buffer pools of the same name in the Db2 group. For example,
a buffer pool 0 (BP0) must exist on each member to contain the catalog and directory table spaces.
Therefore, a group buffer pool 0 (GBP0) must exist in the coupling facility.
If any member creates table space X and associates it with buffer pool 1, and the data in X is to be shared,
you must define a group buffer pool 1 (GBP1) cache structure in the CF.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Page Size
The size of the page to cache. Valid values are 4, 8, 16 or 32.
Number of Buffers
The sum of the buffers associated with all local buffer pools, both virtual and hiperpool, across all
the data sharing members in this group buffer pool. This number is specified in logical pages. For
example, for two members in a data sharing group that have 1000 pages each for local buffer pool 3,
enter the value 2000.
GBPCACHE type
The GBPCACHE attribute that is associated with the group buffer pool through the CREATE or ALTER
TABLESPACE statements or the ALTER GROUPBUFFERPOOL command.
```
- CHANGED indicates that only changed data is cached.
- ALL indicates that all data is cached.
- NONE indicates that no data is cached (directory-only cache).
**Sharing Environment**
A qualitative estimate of the degree of sharing among the Db2 instances in the group, for example,
how often pages are in use by multiple data sharing members simultaneously. The environment can
be characterized as typically shared or heavily shared.
For more information, see Installing, migrating and enabling Db2 data sharing.

```
Calculate the size of a DFSHShsm Common Recall Queue
Coupling facility selection parameters for a DFSHShsm Common Recall Queue.
The DFSMShsm common recall queue enables all hosts in an HSMplex to place their recall requests onto
a single queue. This allows the recall requests to be balanced across the HSMplex. It also enables tape
mount and priority optimization.
Size the common recall queue to contain the maximum number of concurrent recalls that might occur.
Due to the dynamic nature of recall activity, there is no exact way to determine what the maximum
number of concurrent recall requests might be. IBM recommends that you use a structure size large
enough to manage at least 3900 concurrent recall requests, which is enough for most environments. The
sizing calculation enforces a minimum structure size sufficient to manage at least 1700 concurrent recall
requests.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Maximum number of concurrent recalls
Specifies the number of concurrent recalls.
Average percentage of recalls from ML2 tape
Specify the average fraction of recalls from tape.
```
```
Calculate the size of an Enhanced catalog sharing structure
Coupling facility selection parameters for an Enhanced catalog sharing (ECS) structure.
Enhanced catalog sharing (ECS) requires a coupling facility cache structure named SYSIGGCAS_ECS. All
systems in the sysplex that share catalogs through ECS must have connectivity to SYSIGGCAS_ECS in the
coupling facility.
```
**108**   Sysplex Management task


All systems must be at the DFSMS/MVS 1.5 level to share catalogs through ECS. The systems that share
a catalog must use the same method for sharing. Mixed-mode sharing between ECS and non-ECS is
not permitted. Explicit action must be taken to enable a catalog for ECS; by default, catalogs are not
ECS-eligible.

All systems in the sysplex sharing catalogs through ECS must be in the same GRS complex. ECS uses
GRS major name SYSZCATS to preserve the integrity of the catalog by preventing mixed-mode (ECS
and non-ECS) sharing. This GRS enqueue specifies RNL=NO to ensure that an integrity exposure is not
inadvertently created by being included in an inappropriate RNL.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number Of Active ECS Catalogs**
The expected total number of catalogs that use ECS on all systems in the sysplex.

_Calculate the size of a Global resource serialization lock structure_
Coupling facility selection parameters for a Global resource serialization lock structure.

Global resource serialization uses a lock structure, named ISGLOCK, to serialize global resources across
the sysplex and record which systems have requesters for particular resources. At least one coupling
facility must be installed and defined to MVS before you can configure a star complex. However, IBM
recommends that you do not use the star method of serializing global resources if only one coupling
facility is available for use in your installation. In this case, failure of the coupling facility causes all of the
systems in the sysplex to terminate with an X'0A3' wait state.

The IGSLOCK structure size is dependent upon the following factors:

- The size and type of systems in the sysplex.
- The type of workload performed.

Global resource serialization requires that the lock structure contains at least 32767 (32k) locks.
Typically, a small sysplex, made up of smaller processors, running a transaction processing workload
uses a smaller structure size than a larger sysplex, which is composed of large processors, running a
batch/TSO workload combination.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Peak global resources**
The number of peak global resources equals the number of unique globally managed resources
(SYSTEMS ENQs and converted RESERVEs) outstanding, measured at a peak load time.
The utility program ISGCGRS, available in SYS1.LINKLIB, can be used to obtain the number of
outstanding global requests. The number of outstanding requests is shown in the third column of
the report. To run the utility, use the sample JCL found in SYS1.SAMPLIB member ISGCGRS.

```
//IANWAIT JOB (999,POK),CLASS=A,MSGCLASS=X,TIME=440
//STEP001 EXEC PGM=ISGSCGRS
12:11:49:06 IANWAIT 00000090 IEF403I IANWAIT - STARTED - TIME=12:11:49
12:11:49:14 IANWAIT 00000090 +Number of global resources outstanding
12:11:59:20 IANWAIT 00000090 +Number of global resources outstanding
12:12:09:26 IANWAIT 00000090 +Number of global resources outstanding
12:12:19:32 IANWAIT 00000090 +Number of global resources outstanding
12:12:29:37 IANWAIT 00000090 +Number of global resources outstanding
```
**Max Number of Connectors**
The maximum number of connectors per structure specified when the primary CFRM couple data
set was formatted (ITEM NAME(CONNECT) NUMBER(xx)). The sizing calculation uses the smaller
of this number or the release-specific maximum number of systems in a sysplex. If you use a new
primary CFRM couple data set formatted for a greater number of connectors per structure, you must

```
Sysplex Management task   109
```

```
repeat this calculation, since the new value is applied whether you rebuild the structure or restart the
sysplex.
```
```
Calculate the size of a Health Checker structure
Coupling facility selection parameters for a Health Checker structure.
Health Checker provides a structure for checks to gather system information and mechanisms to report
their findings. The checks compare the system environment and parameters to established settings to
uncover potential problems.
Health Checker uses the system logger to create one or more logstreams for Health Checker records. The
amount of coupling facility storage needed to support the Health Checker structure depends on the rate
at which records are generated in the sysplex and how many records you want to keep in the structure at
any point in time.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of Logstreams
The number of logstreams associated with the sized structure corresponding to the LOGSNUM keyword
of the Logger policy. IBM recommends that you define either one logstream per system or a single
logstream for all systems. The sizing calculation assumes that data is written to all logstreams at an
equal rate.
Number of Systems
The number of systems whose Health Checker logstreams are written to the sized structure.
Writes per Hour
The number of Health Checker logstream writes per hour for the most active system in the sysplex.
This value can be determined from the Type 88 SMF record for one or more Health Checker
logstreams by summing the SMF88SC1, SMF88SC2, and SMF88SC3 fields and dividing by the length
of the global SMF monitoring interval.
Average Buffer Size
The average buffer size (AVGBUFSIZE) from the System Logger policy for one or more Health Checker
logstreams. This value can be determined from the Type 88 SMF record by dividing the SMF88SWB
field by the number of writes to one or more Health Checker logstreams during the global SMF
monitoring interval.
```
```
Calculate the size of an IBM Sessions Manager structure
Coupling facility selection parameters for an IBM Sessions Manager structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Maximum number of signed on users
The maximum number of signed on users is 99999. The current number of active signed on users
can be determined by issuing the command QACTUSER. In Session Manager SHARE, SHAREDISC, and
SHARESESS environments, each user with the same userid will count as a different signed on user.
```
```
Calculate the size of an IMS OSAM structure
Coupling facility selection parameters for an IMS OSAM structure.
An OSAM structure can be used for caching data. If data caching is not used, the structure contains only
directory entries. If data caching is used, the structure contains directory entries and data elements. In
this case, the size of the structure must allow for data elements. OSAM data is stored in the structure as
multiples of 2 KB data elements.
IMS/ESA OSAM uses directory-only cache structures to maintain local buffer consistency. Buffer pool
coherency guarantees that each data hit in the local buffer pool accesses a valid copy of this particular
```
**110**   Sysplex Management task


data. Specifying Cached Buffers as 0 and Average Cached Buffer Size as 0 will size for directory-only
usage.

IMS/ESA OSAM Store-through cache structure can be used for caching data in addition to buffer
invalidation. The structure size has to be large enough to hold directory entries for all buffers and data
entries for all cached buffers.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Total buffers**

```
Sum of the local buffers across all IMS systems that share the coupling facility. Include the peak
number of OSAM buffers used at one time by IMS batch jobs. Tally the subpool numbers from all
IMS instances that used a DFSVSMxx member that specifies the structure of interest on its CFNAMES
CFOSAM keyword. It should include an estimate of the number of sequential buffering buffers in
use. The default is 40 buffers per online dependent region plus 40 for each batch job that might be
running.
For example:
```
- IMS1: 3000 2K buffers, 4000 4K buffers, 40 sequential buffering buffers.
- IMS2: 1000 2K buffers, 6000 4K buffers, 40 sequential buffering buffers.
- IMS Batch cache (peak) 4000 4K buffers, 80 sequential buffering buffers, assuming a max of 2
    batch jobs running simultaneously with 40 sequential buffering buffers each.
- Total as input = 3000 + 4000 + 40 + 1000 + 6000 + 40 + 4000 + 80 = 18160

**Cached buffers**
A subset or all of the OSAM buffers used by IMS Online subsystems and IMS Batch jobs may be
stored in a Coupling Facility structure using the "IMS OSAM Data Caching" feature. Provide the peak
number of buffers expected to be cached in the CF at one time. This number will be used with the
Average Cached Buffer size to determine the size of the cache portion of the structure. Specifying a 0
for Cached Buffers along with specifying a 0 for Average Cached Buffer Size will size for directory-only
usage.

**Average cache data size**
To find the average cache data size, calculate the total amount of storage used across all IMS Online
and Batch (peak) systems for OSAM data caching buffers. Divide the total size by the total number of
buffers, rounded up to the next 2K multiple. Specifying a 0 for Average Cached Buffer Size along with
specifying a 0 for Cached Buffers will size for directory-only usage. Ignore sequential buffering buffers
for purpose of this calculation.
For example:

- IMS1 OSAM cache: 1,000 2K buffers, 2000 4K buffers = 10,000K size
- IMS2 OSAM cache: 1,000 2K buffers, 2500 4K buffers = 12,000K size
- IMS Batch cache (peak): 2000 4K buffers = 8,000K size
- Total size (31,000K) divided by total number (8,500 buffers) = 3647
- Average cached buffer size equals 4096 (rounded up).

_Calculate the size of an IMS VSAM structure_
Coupling facility selection parameters for an IMS VSAM structure.

IMS/ESA VSAM uses directory only cache structures to maintain local buffer consistency. Buffer pool
coherency guarantees that each data hit in the local buffer pool accesses a valid copy of this particular
data.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

```
Sysplex Management task   111
```

```
Total buffers
Sum of the local buffers across all IMS systems that share the coupling facility.
For example:
```
- IMS1: 3000 2k buffers, 4000 4K buffers
- IMS2: 1000 2K buffers, 6000 4K buffers
- Total as input = 3000 + 4000+ 1000 + 6000 = 14000

```
Calculate the size of an IMS IRLM LOCK structure
Coupling facility selection parameters for an IMS IRLM LOCK structure.
The IMS IRLM coupling facility lock structure contains information that is used to determine cross-system
contention on a particular resource. One lock structure is used by IRLM per data sharing group to
control locking. It contains information about locks that are currently used to control changes to shared
resources. The size of the lock structure must reflect the total number of concurrent locks that are held by
all members in the IMS data sharing group.
The size of the IMS IRLM lock structure is a function of the number of systems that share the lock
structure and the number of concurrent locks held.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of Locks Held
The maximum number of locks held concurrently. With IRLM in nonsysplex local mode, you can use
the MVS command Modify "IRLMPROC,Status" to report on the number of locks held. Select a
peak batch processing window and monitor the number of locks held returned by this command to
input into the sizing calculation.
Max Number of Users
The maximum number of users of the lock structure from the MAXUSRS value specified in the
IRLMPROC procedure.
Max Number of Connectors
The maximum number of connectors per structure specified when the primary CFRM couple data
set was formatted (ITEM NAME(CONNECT) NUMBER(xx)). The sizing calculation uses the smaller
of this number or the release-specific maximum number of systems in a sysplex. If you use a new
primary CFRM couple data set formatted for a greater number of connectors per structure, you must
repeat this calculation, since the new value is applied whether you rebuild the structure or restart the
sysplex.
Asynchronous Duplexing
Indicates if the structure is eligible for asynchronous duplexing. If the CFRM policy description for this
structure specifies DUPLEX(ALLOWED|ENABLED,dupoptions) where dupoptions includes ASYNC
or ASYNCONLY, then specify YES. Otherwise, specify NO.
The lock structure storage is allocated partly to lock table entries (LTEs) and partly to record list
entries (RLEs). Database operations can fail if the structure contains an insufficient number of either
type. IRLM reserves space for functions that must complete, such as rollbacks or commit processing,
so that a shortage of storage does not cause a Db2 subsystem failure. IBM recommends that
installations specify the number of LTEs to be contained by the structure on the procedure that is used
to start IRLM (irlmproc). Specifying a CFRM policy size much larger than CFSizer's recommendation
without specifying the number of LTEs on the irlmproc can cause the structure to be allocated without
sufficient RLEs. The sizing calculation models the number of LTEs as (lock rate + (number of
systems) * (number of table spaces)) * 200. The system rounds the calculated number of
LTEs up to the next highest power of 2.
For more information, see Installing, migrating and enabling Db2 data sharing.
```
**112**   Sysplex Management task


_Calculate the size of an IMS Shared Message Queue structure_
Coupling facility selection parameters for an IMS Shared Message Queue (SMQ) structure.

IMS uses Coupling Facility list structures for shared queues. There are two types of IMS list structures:
the full-function (MSGQ) structure and the Fast Path (EMHQ) structure. The MSGQ is always required. The
EMHQ is only required if IMS is generated as a Fast Path system, which includes the FPCTRL macro.

The primary list structure contains the shared queues. The overflow list structure, if defined, contains
shared queues that overflow after the primary reaches a predefined threshold.

The IMS shared message queue (SMQ) solution uses the coupling facility to store and share the IMS
message queues among multiple IMS Transaction Management systems. Incoming messages from an
IMS TM on one central processor complex (CPC) in the sysplex might be placed on a shared queue in
the coupling facility by IMS Common Queue Server (CQS) for processing by an IMS TM on another in the
sysplex. This can provide increased capacity and availability in IMS systems.

The IMS SMQ solution uses the sysplex environment, enabling increased capacity and incremental
horizontal growth.

SMQ structures are persistent and remain allocated even if all CQSs disconnect, or all IMSs and their
associated CQSs cold start.

All logical records include the full message prefix. The size of the prefix depends on the IMS release
and the functions that are available within this IMS. It is recommended that the sizings used for this
calculation come from an IMS Version 6 system. Prefixes change size from version to version and can
influence the stored length of the message.

For IMS conversations, the SPA is stored as the first segment of the message on the message queue
when destined for a transaction program. This can affect the structure size for installations with many
conversations since the SPA can be large and remains in the structure during interactions of the
conversation. A conversation can remain for days at a time in some cases.

Event Monitor Controls - an EMC entry is a control block in the CF list structure that is used to represent
a CQS that has a registered interest in a queue. Each EMC entry occupies 64 bytes of storage. CQS
reserves 20% of the total structure for EMCs. If CFCC level 4 or higher is being used, the area dynamically
increases in 5% increments up to a maximum of 50%, if required. The sizing calculation uses CFCC level
8.

Available data elements are used to create more storage for EMCs. If the EMC area is increased, the
amount of structure space available for list entries decreases. If EMC area runs out space, any attempt to
register an interest in a queue fails.

Therefore, the size of the IMS SMQ list structure is asizeofthe function of the number of list headers, list
elements, data elements, message size, conversational messages, SPA and EMCs.

The space that you want to allocate for the storage of the data elements is calculated as the amount
that would be occupied by the data content of the transactions and messages in the coupling facility list
structure.

The IMSPARS Internal Resource Usage Report can be used to find the short-message and long-message
high water marks.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Short Message High Water Mark**
The maximum number of messages placed on the short message queue during the time period that
the data is captured. The IMSPARS Internal Resource Usage Report is used to find the short-message
high water mark. If IMSPARS or IMSPA is not available, the short and high water marks can be derived
from the IMS system checkpoint record 4502.

**Long Message High Water Mark**
The maximum number of messages placed on the long message queue during the time period that the
data is captured. The IMSPARS Internal Resource Usage Report is used to find the high-message high

```
Sysplex Management task   113
```

```
water mark. If IMSPARS or IMSPA is not available, the high water marks can be derived from the IMS
system checkpoint record 4502.
SHMSG LRECL
The short message logical record length. This value can be obtained from the logical record length of
the short-message data set.
LGMSG LRECL
Long message logical record length. This can be obtained from the logical record length of the
long-message data set.
```
```
Calculate the size of an IMS Shared Message Queue structure
Coupling facility selection parameters for an IMS Shared Message Queue (SMQ) structure.
When running in an IMS Shared Queues environment, with Fast Path transactions defined (FPATH=YES
on the APPLCTN or TRANSACT macros), IMS uses CQS to put globally queued input and output messages
on a shared EMHQ structure on the coupling facility. There are several differences between shared queue
support for Fast Path transactions and full function transactions that are important to understand to size
the EMHQ structure.
For each input message, the Fast Path Input Edit and Routing Exit (DBFHAGU0) can specify one of three
Sysplex Processing Codes (SPCs). The SPCs determine whether the input message is to be queued locally
(LOCAL ONLY), queued globally (GLOBAL ONLY), or queued globally only if the number of messages
queued locally is already more than six (LOCAL FIRST). To size the EMHQ structure, it is necessary to
understand which of these options is being used, and for LOCAL FIRST, an approximation of how often a
message is queued globally because of the length of the local queue.
All Fast Path transactions are defined as single segment response mode transactions. Any input device
can have at most only one transaction in progress. For example, a network with 10,000 terminals can
have a maximum total of 10,000 input and output messages on the EMHQ, though it is unlikely that every
terminal would have a transaction in progress.
Each terminal in the network is allocated an EMH buffer whose size cannot exceed some system defined
maximum. This maximum size is the largest of the FPBUF=size parameter on the TERMINAL macro, the
FPATH=size parameter on the APPLCTN or TRANSACT macro, or the EMHL=size parameter in DFSPBxxx.
As Fast Path messages arrive from a terminal, the initial buffer size can be increased to hold a larger
message size. Not every message is that large, and it is unlikely that most are. For example, an input
message might be only 600 bytes, while the output message might be 1200 bytes. Only one message is
on the queue at any time. The actual size of the message determines what is put on the EMHQ, not the
size of the buffer. Each message, including its EMH prefix and CQS prefix, uses one or more 512-byte data
elements. A 600-byte message and a 1000-byte message both require two data elements.
Beginning with IMS V4, ALL IMS terminals are eligible to enter Fast Path transactions. However, not all
terminals enter Fast Path transactions.
```
```
EMHQ structures
Shared EMH, like its full-function counterpart, requires a primary structure in the coupling facility. You can
also choose to allocate an extra overflow structure to prevent the primary structure from filling up. Each
structure must be defined in the CFRM policy with a maximum size (SIZE), and optionally an initial size
(INITSIZE) and a minimum size (MINSIZE). CQS identifies long queues and moves them to the overflow
structure when the primary structure reaches a system defined full threshold (OVFLWMAX in CQSSGxxx).
If INITSIZE is specified, CQS attempts to ALTER the size of the primary structure in increments up to the
maximum SIZE before using overflow. CQS does not ALTER the size of the overflow structure, although
you can choose to with the SETXCF ALTER command.
CQS overflow threshold processing is based solely on the number of data elements in use and does not
consider the number of list entries in use. If the entry-to-element ratio is wrong, the structure might
become full due to running out of list entries before the overflow threshold is reached. CQS does not
ALTER this ratio.
If either the primary or overflow structure is defined with INITSIZE and ALLOWAUTOALT(YES), the
allocated size and entry-to-element ratio is adjusted automatically by the system in increments up to
```
**114**   Sysplex Management task


the maximum size when FULLTHRESHOLD defined in the CFRM policy is reached. The default value is
80%. Threshold processing by the system considers both the list entries in use and data elements in use
and adjusts the ratio if necessary.

**DEDB-only systems**

You can include the FPCTRL macro in the sysgen to enable Fast Path only for access to DEDBs
without ever using the Expedited Message Handler for Fast Path transactions. However, since Fast Path
transactions can be added dynamically by using online change, a minimum size EMHQ structure is still
required. The sizing calculation determines what this minimum size is. Since the structure is not used,
only a primary structure must be defined, not an overflow structure.

**Sizing the structures**

Determining the correct size specifications for the primary EMHQ structure depends on the ability to
accurately estimate the number and size of the messages on that structure at any one time. A maximum
SIZE should be selected, so that the overflow structure needs to be used only under extreme conditions,
for example, if all scheduling stops but messages continue to be queued. The size of the overflow
structure should be large enough to accommodate those extreme conditions.

The sizing calculation provides sizing recommendations based on user-provided input. The user must
estimate the number of messages on the structure at one time, and the number of data elements that
are associated with those messages, and provide those numbers to the tool. The calculation then returns
a recommendation for the SIZE (or INITSIZE) parameter for the EMHQ Structure definition in the CFRM
policy. Run this calculation with the maximum number of messages and data elements possible and then
with the average number of messages and data elements. The two values that are returned can then be
used as the SIZE and INITSIZE values for the CFRM policy definition. In a tuned system, the average
number of messages on the shared EMHQ are small. You can also estimate the number of messages and
data elements that are required when messages are queued due to high volumes during peak periods and
use this number as the INITSIZE.

CQS puts some control list entries on the EMHQ structure to help it manage the structure. CQS puts at
least three list entries and three data elements on the EMHQ structure. These numbers can increase,
based on the number of CQSs in the sysplex and the number of structure processes that are in progress
or were performed, such as structure checkpoint, structure rebuild, and overflow processing. The sizing
calculation factors these numbers into the formula.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**How many messages will be on the EMHQ at on time (EMH Message Number)**
The EMH Message Number is the total number of input and output messages on the EMHQ at any
one time. Each message requires exactly one list entry. It is up to the user to decide how many
messages to allow for, but the absolute maximum is the total amount of unique static and dynamic
(ETO) terminals that are defined to all the IMSs in the IMSplex.
One or more of the following methods can be used to calculate the value for the EMH.

- Define an EMH Message Number of 1 if your IMS system is a DEDB-only Fast Path system.
- Calculate the absolute maximum EMH Message Number from the number of TERMINAL macros in
    the SYSGEN plus the maximum number of dynamically allocated (ETO) terminals that might ever
    enter a Fast Path transaction. This EMHQ structure would accommodate the situation where all of
    the terminals entered a Fast Path transaction that might not be processed locally and were all on
    the EMHQ at the same time.
- Calculate the realistic maximum EMH Message Number by multiplying the peak transaction rate
    (transactions per second) by an arbitrary time period. For example, if the peak transaction rate were
    200tps, and you wanted to be able to hold 15 seconds of message traffic on the EMHQ structure
    (representing a period of 15 seconds where no work was processed), then the EMH Message
    Number would be 200*15=3000.

```
Sysplex Management task   115
```

- Alternatively, if a high volume test environment is available, the realistic maximum can be
    determined by running at projected peak volumes for an extended period. Periodically monitor
    the CQS structure statistics to determine what the maximum number of list entries in use is. You
    can introduce simulated problems to cause the queues to build up, such as too few IFP regions to
    process the work.
The current list entries in use value can be determined by the following methods.
- Issue the command /CQQUERY STATISTICS STRUCTURE(emhq-structure-name).
- Issue the CQS query CQSQUERY FUNC=STATISTICS (QSPNTRC field in DSECT CQSQRYST)
    from a user-written CQS client.
In IMS V8 (and later) the list entry high water mark can be extracted from CQS statistics from one of
the following:
- CQS structure checkpoint log record (x'6001').
- CQS statistics user exit (defined in BPE configuration proclib members).
- CSLZQRY macro issued from a user-written Automated Operator Program (AOP) that registers to
    SCI.
Sizing the EMHQ structure based on the average number of messages is not useful as the average
number of messages can be very close to zero. Size the structure for periods when there are more
than the average number of messages on the queue.
**How many data elements will those messages require (Data Element Number)? Data Element
Number**
The input and output message, which includes a 32-byte CQS prefix, the EMHB global header or
IMS prefix (252 bytes for IMS V6 & V7 and 352 bytes for IMS V8), plus the actual message text
(llzz+trancode+data), is referred to as a data object. CQS stores each data object in one or more
512-byte data elements that are associated with a single list entry. A 600-byte message and a
1000-byte message both require two data elements, whereas a 1025-byte message requires three
data elements. Factor this in to calculate the data element number.
Use one of the following methods to calculate the value to use for the Data Element Number:
- Define a Data Element Number of 1 if your IMS system is a DEDB-only Fast Path system and you do
not intend to use the EMH.
- Determine the average number of data elements that are used by each input and output message.
This can be done either by knowledge of the application, or by examining existing IMS log records. If
applying knowledge of the application, don't forget to add in the IMS prefix.
- Fast Path input transactions are logged as type x'5901' log records and output responses as type
x'5903' log records. An examination of enough these log records shows what the average message
size is (the IMS prefix is part of the log record). From the size of the message, determine the average
number of data elements that are required for the message (avgelemnum). DO NOT use the average
message size, as this can be misleading. For example, the average of 600 and 1200 is 900, which
would imply two data elements. However, only the 600-byte message would use two data elements;
the 1200-byte message would require three. The number of data elements required to hold a
number of messages equal to the EMH Message Number would then be: emhnum * avgelemnum.
Using the same techniques that are described for extracting list entry usage when a stress test system
(or existing production shared queue system) is available, look at the actual usage of data elements
for input and output messages. Use this number to determine the average number of data elements
per message.
There are several other factors to consider when specifying the parameters in the structure definition
of the CFRM policy and in CQSSGxxx.
In the CFRM policy:
- SIZE determines the maximum size that the structure can ever be. If the space is not needed,
assuming an INITSIZE has been specified, then it is not allocated.

**116**   Sysplex Management task


- INITSIZE specifies the initial structure size when first allocated by CQS. Both CQS and the system
    can increase this size if it reaches a user-defined threshold, through OVFLWMAX in CQSSGxxx and
    FULLTHRESHOLD in the CFRM policy.
- ALLOWAUTOALT(YES) enables the system to monitor a structure and when the structure reaches
    a structure full threshold to automatically adjust the size of the structure and the entry-to-element
    ratio.
- FULLTHRESHOLD(nn) sets a percentage structure full threshold at which the structure is
    automatically altered by the system. The default value is 80%. This value applies to both list entries
    and data elements. Since the system can alter not only the structure size but the entry-to-element
    ratio, this is a better technique for monitoring structure size than CQS overflow processing, which
    can only alter the size. CQS does not catch a problem with running out of list entries, which can
    result in a structure full condition before overflow processing takes effect. This value should be set
    lower than the CQS OVFLWMAX value so that CQS overflow processing takes effect only when the
    structure has reached its maximum size.
- MINSIZE determines the minimum size to which a structure can be reduced by automatic structure
    alter. This is important because if the structure becomes too small, Event Monitor Controls (EMCs)
    are eliminated from the structure and notification to IMS of messages on the queue cease. The
    sizing calculation provides a MINSIZE for the EMHQ structure which if specified in the CFRM policy,
    sets a lower limit on structure size, which would guarantee that EMCs are not deleted. However, you
    might want to set this value higher since you don't want the structure to be reduced too much during
    periods when actual usage is small and then not have enough room in the coupling facility later to
    increase its size if needed.
In CQSSGxxx:
- OBJAVGSZ is used by CQS to determine the entry-to-element ratio. The average message size is not
    necessarily a good tool to determine how many data elements are needed for the average message.
    Instead, use the technique described previously to determine the average number of data elements
    required per message, and set OBJAVGSZ. Since running out of list entries is worse than running
    out of data elements, as CQS doesn't monitor list entries, it is better to round this number down.
    For example, if the average message requires 2.5 data elements, a ratio of 1:2 is better than 1:3, so
    OBJAVGSZ should be set to provide this ratio. Any number 512 - 1024 is valid.
- OVFLWMAX determines the percentage of data elements in use that will trigger CQS overflow
    processing. If running with ALLOWAUTOALT enabled, this number should be higher than
    FULLTHRESHOLD specified in the CFRM policy, allowing the system to adjust not only the size of
    the structure but also the entry-to-element ratio.
- OVFLWSTR defines an overflow structure. This value should be large enough to accommodate the
    overflow from the primary structure. If the primary structure has an absolute maximum SIZE, then
    an overflow structure is probably not needed, but if it is sized at something below the absolute
    maximum, then it is wise to have an overflow structure.
A quicker alternative is to let the system CQS and OS adjust the structure size for you. Use a large SIZE
and a small INITSIZE and then let the system find its own level.

_Calculate the size of an IMS VSO structure_
Coupling facility selection parameters for an IMS VSO structure.

The size of the VSO DEDB coupling facility structure assumes the PRELOAD option. Therefore, the size
of the VSO DEDB structure must be large enough to hold the direct portion plus the directory of any
PRELOAD VSO DEDB Areas.

The size of a PRELOAD VSO DEDB structure depends on the size of the VSO DEDB Area as defined by the
AREA statement in the DBDGEN utility.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**UOW from DBDGEN area**
The number of UOWs from the DBDGEN area.

```
Sysplex Management task   117
```

```
Root from DBDGEN Area
The number of roots from the DBDGEN area.
Size from DBDGEN Area
The size from the DBGEN area.
```
```
Calculate the size of an IMS CQS Log structure
Coupling facility selection parameters for an IMS CQSS Log structure.
The IMS Log structure estimate always returns 50 mb. There are no formulas for generating the IMS log
structure.
For any IMS message (SMQ or EMH), the message is passed to IMS CQS. Before CQS puts the message in
the structure, CQS creates a log entry. Once the data is in the logstream, CQS will then put the message
into an SMQ or EMH structure. CQS does not care about the entry in the log structure after that unless a
failure occurs. If a failure occurs, then CQS needs to recover structures from the log records.
When the log structure reaches a certain percentage, the log is offloaded to DASD. Once the data is
written to a data set, it is deleted from the CF structure. Therefore, the structure should never get full.
The smaller the structure, the more frequently the MVS logger needs to offload.
To size the IMS log structure, two factors need to be considered: the size of the log structure that is
combined with the threshold of when to offload to a data set and the frequency of offloads. Based on this
information, the log structure can be smaller or larger than 50 mb.
```
```
Calculate the size of an IMS Resource structure
Coupling facility selection parameters for an IMS Resource structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Input Type
The sizing calculation provides two methods for calculating the IMS Resource Structure size. It is
important to choose the proper method to ensure that you receive the best sizing estimate. If the
CQSSGxxx proclib member specifies ENTRY and ELEMENT, select the input type Resource counts and
ratio. Otherwise, select the input Resource and element counts.
Resource Number
The total number of resources expected to be in the Resource Structure at one time. One resource
is stored on the Resource Structure as one list entry, which may contain zero, one, or more data
elements, depending upon the amount of resource data. Use one of the following methods to
calculate the value to use.
```
- Define a Resource Number of 1 if your installation is DBCTL-only and you plan to use the Resource
    Structure only for Global Online Change.
- Calculate an initial Resource Number by using the Resource Table and sum all of the numbers in the
    Resource Number column.
- Adjust the Resource Number by running workloads with the Resource Structure enabled and
    querying CQS statistics periodically to extract the list entry high water mark. Size the structure large
    enough to accommodate the list entry high water mark, or an amount larger than the high water
    mark. The list entry high water mark field is SS3ENTHI in mapping macro CQSSSTT3. Structure
    statistics may be gathered through the CQS statistics user exit or the CSLZQRY macro interface. This
    requires a user-written Automation Program (AOP) that registers to SCI to issue the CSLZQRY macro
    and to return the results.
The QUERY STRUCTURE command also displays the list entries allocated, the list entries in use,
the data elements allocated, and the data elements in use. You can issue the QUERY STRUCTURE
command periodically to get an idea of the maximum list entries that have been in use over a period
of time. QUERY STRUCTURE output may also be used to determine how many more resources the
Resource Structure can accommodate.

**118**   Sysplex Management task


**Number of Data Elements**
A _data element_ is a piece of storage on the Coupling Facility associated with a resource list entry.
Resource entries may have zero, one, or more 512-byte data elements, depending on the amount of
resource data stored. One of the following methods may be used to calculate the value to use for the
Data Element Number.

- Define a Data Element Number of 1 if your installation is DBCTL-only and you plan to use the
    Resource Structure for only Global Online Change.
- Calculate an initial Data Element Number by using the Resource Table and sum all of the numbers
    in the Data Element Number column that apply to your installation. The Data Element Number
    is rarely more than 1, unless there is an exceptional amount of significant status associated with
    the resources. For example, if there are hundreds of lterms assigned to a user, hundreds of held
    conversations associated with a user, or a very large number of IMSs, none of which is likely.
- Tune the Data Element Number by running workloads with the Resource Structure enabled and
    querying CQS statistics periodically to extract the data element high water mark. The data element
    high water mark field is SS3ELMHI in mapping macro CQSSSTT3. Structure statistics may be
    gathered through the CQS statistics user exit or the CSLZQRY macro interface. This requires a
    user-written Automation Program (AOP)that registers to SCI to issue the CSLZQRY macro and return
    the results.
The QUERY STRUCTURE command can be used periodically to get an idea of the maximum data
elements that have been in use over a period of time. QUERY STRUCTURE output may also be used to
determine how many more resource data elements the Resource Structure can accommodate.
Enter the Data Element Number only if the CQSSGxxx proclib member does not specify the ENTRY
and ELEMENT keywords.

**Entry Ratio, Element Ratio**

```
These two inputs compose the entry-to-element ratio to be used in calculating the size of the
structure. The entry-to-element ratio represents the average number of data elements for each
list entry in the structure. The Entry Ratio represents the numerator of the ratio, and the Element
Ratio is the denominator. For example, an Entry Ratio of 1 and an Element Ratio of 2 indicates an
entry-to-element ratio of 1:2.
The Entry and Element ratios should only be specified if the CQSSGxxx proclib member specifies the
ENTRY and ELEMENT keywords.
```
**What is the resource type (node, lterm, user, userid)?**

Userids have list entries only if single sign on is being enforced. Lterms have list entries but no data
elements. Parallel session ISC nodes are the only nodes that have data elements. The most significant of
the list entries in terms of size is the user (or static node user) entry which contains the majority of the
significant status. End-user significant status, when it exists, is always kept in a data element in the (static
node) user entry. A (static node) user resource entry always has at least one data element.

What is the Status Recovery Mode (SRM) and Recoverability (RCVYxxxx) settings of the terminal? Defaults
for these are defined in DFSDCxxx, and can be overridden by the Logon Exit or Signon Exit. They
determine whether end-user significant status is maintained, and if so, where. If SRM=GLOBAL and
RCVYxxxx=YES, then end-user significant status will be kept in the user entry data element in the
resource structure. If SRM=LOCAL or NONE, end-user status is not kept in the user entry. Command
significant status is always kept in the Resource Structure when the structure exists, but (usually) doesn't
require a data element.

Does the terminal/user have significant status and what type of significant status is it? This determines
whether the resource list entry has data elements with it and if it is deleted when the resource becomes
inactive.

```
Sysplex Management task   119
```

```
Resource types
The following are the types of resources on the Resource Structure, including when they are created and
deleted, and whether or not they have data elements associated with them. Use these descriptions along
with the Resource Table shown later in this document when providing input to the CFSIZER tool.
IMSplex global resources contain information about the IMSplex itself or its individual members and are
created as the IMSplex is initialized, as members join the IMSplex, or as global processes are initiated.
Some of these resources are created and then remain for the life of the structure. Others are created
when a global process initiates and deleted when a global process terminates. CFSIZER factors IMSplex
global resources into its calculations.
Static transaction and msname resources are created during IMS initialization. Transactions may also be
created by online change. They are never deleted and remain on the Resource Structure as long as the
structure exists. Calculate the number of transaction and msname resources by counting the number of
"unique" TRANSACT and MSNAME statements in the IMS system definition STAGE1 input. These resource
list entries never have data elements.
CPI-C transaction resources are created when the CPI-C transaction is first entered and are deleted when
all IMSs defining that transaction have terminated. Calculate the number of CPI-C transaction resources
by counting the number of "unique" TRANCODEs in the TP_PROFILE data sets. These resource list entries
only have data elements when the number of IMSs defining them is greater than two.
APPC descriptor resources are created during IMS initialization and are deleted when all IMSs defining
that resource terminate. Calculate the number of APPC descriptor resources by counting the number of
"unique" APPC descriptors in DFS62DTx. These resource list entries only have data elements when the
number of IMSs defining them is greater than two.
Sysplex terminal resources such as nodes, lterms, users, and userids are created when the resource first
becomes active (e.g., terminal logon or user signon). They are deleted from the Resource Structure when
the resource becomes inactive (e.g., terminal logoff or user signoff) and the resource has no recoverable
significant status. Note that userids are always deleted when the user becomes inactive. These resource
list entries are the most variable in number and size since they exist only when a resource is active, or
when inactive but with significant status. The number and size of sysplex terminal resources depends on a
number of factors:
IMS may (optionally) use a Coupling Facility List structure, called the Resource Structure, to share
information about IMSplex resources among all members of the IMSplex. Transactions, msnames, nodes,
lterms, (static node) users, userids, APPC descriptors, Areas, Databases, Global Online Changes, System
Resources and IMSplex global resources may all have list entries on the Resource Structure. Each list
entry may contain zero, one, or more 512 byte data elements, depending on the resource type and its
status.
The Resource Structure must be defined in the CFRM policy with a maximum size (SIZE) and
optionally an initial size (INITSIZE) and a minimum size (MINSIZE). If defined with INITSIZE and
ALLOWAUTOALT(YES), the allocated size and/or the entry-to-element ratio will be adjusted automatically
by the system in increments up to the maximum size when the FULLTHRESHOLD (default is 80%) is
reached. Determining the correct size specifications for the Resource Structure depends on the ability to
accurately estimate the number and size of the resources.
The sizing calculation provides sizing recommendations based on user-provided input. The user must
estimate the number of resources on the structure, and the number of data elements associated with
those resources, and provide those numbers to the tool. The calculation then returns a recommendation
for the SIZE (or INITSIZE) parameter for the Resource Structure definition in the CFRM policy. You might
want to run this tool several times, once with the maximum number of resources and data elements
possible and once with the expected average number of resources and data elements. The two values
returned can then be used as the SIZE and INITSIZE values for the CFRM policy definition. Calculating an
average may be especially useful when a large number of the potential terminals/users are not logged on
at the same time. By defining the CFRM policy with ALLOWAUTOALT(YES), the size of the structure and
the entry-to-element ratio can be dynamically altered by the system as conditions warrant.
```
**120**   Sysplex Management task


**Resource Table**

```
Sysplex Management task   121
```

```
Table 82. Resource table to
```
```
define
```
```
an initial resource structure
```
```
Resource Type
```
```
System
```
```
Definition
```
```
Status
```
```
Resource Number
```
```
Data Element Number
```
```
APPC descriptor
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#APPC descriptors (Total uniquelydefined
```
```
APPC descriptors in entire
```
```
IMSplex)
```
```
0 (if #IMSs less than 3) -or- if #IMSsgreater than 2 #APPC descriptors *#IMSs-2)/29 (rounded up)
```
```
Area
```
##### GSTSAREA=(N)

##### 0

##### 0

##### GSTSAREA=(Y)

```
Number of Fast Path Areas
```
##### 0

```
Database
```
##### GSTSDB=(N)

##### 0

##### 0

##### GSTSDB=(Y)

```
Number of Databases
```
##### 0

```
Global Online Change
```
##### OLC=LOCAL

##### 0

##### 0

##### OLC=GLOBAL

##### 1

##### 1

```
Lterm
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
Number of Lterms
```
##### 0

```
Msname
```
##### STM=NO

##### 0

##### 0

```
Node
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#nodes (Total uniquely gennednodes + maximum dynamic nodes)
```
```
#ISC nodes with multiple parallelsessions * #IMSs-1)/29 (roundedup)
```
```
Transaction (static)
```
```
#trans (Total unique static (genned)transactions in entire IMSplex)
```
##### 0

```
Serial Program
```
```
Number of serial programs
```
##### 0

```
System Resources
```
```
8 + (x * 3) + (y) + (z) +(q^3)
```
```
14 + (x * 2)^4 (x = The number ofIMS systems ; y = The number ofCQSs; z = The number of RMs; q =The number of structures)
```
```
Transactions
```
```
Number of Transactions
```
##### 0

**122**   Sysplex Management task


_Table 82. Resource table to_

_define_

_an initial resource structure (continued)_

```
Resource Type
```
```
System
```
```
Definition
```
```
Status
```
```
Resource Number
```
```
Data Element Number
```
```
Transaction (CPIC)
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#CPICtrans (Total unique CPICtransactions invoked by APPC)
```
```
0 (if #IMSs less than 3), -or- if #IMSsgreater than 2, then (#CPICtrans *(#IMSs-2))/29 rounded up)
```
```
User ID
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#userids (Maximum number ofuserids signed on, if single signonenforced with SGN= not G, M or Z)
```
##### 0

```
User
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#users (Maximum number ofdynamic users + total unique staticISC subpools)
```
```
#users * 1
```
```
User (for static node)
```
##### STM=NO

##### 0

##### 0

##### STM=YES

```
#staticusers (Total unique staticsingle-session terminals)
```
```
#staticusers * 1
```
```
Sysplex Management task   123
```

```
Adjusting the size of the Resource Structure
Once the structure has been sized and is in production, it may become necessary to change the maximum
size upward due to unexpected volumes or initial miscalculation. This can be done by changing the SIZE
parameter in the CFRM policy, activating the new policy, and rebuilding the structure using the command:
```
```
SETXCF START,REBUILD,STRNM=structurename
The size can be adjusted downward in the same way, but the alter command can also be used to
make the structure smaller. This might be done following an unusual period where the structure was
autoaltered upward due to a high number of concurrent logons which are not expected to continue. Use
the command:
SETXCF START,ALTER,STRNM=structurename,SIZE=size
```
```
Calculate the size of an OM Audit Trail structure
Coupling facility selection parameters for an OM Audit Trail structure.
For all type 1 and type 2 commands that are entered through OM, OM logs the command input before
calling the OM Input user exit, and after calling the OM Input user exit only if the exit altered the
command input. OM also logs the command response output before calling the OM Output user exit,
and after calling the OM Output user exit only if the exit altered the command response output. OM
logs any unsolicited output messages that are received through the CSLOMOUT API. For example, IMS
starts CSLOMOUT to send MTO and system console related system messages to OM, such as DFS system
messages. OM does not care about the entry in the log structure after the log information is written. The
log information can be formatted and viewed by using any of three IBM supplied utilities: CSLOERA3,
CSLULALE, TSO SPOC Audit Trail Viewer.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Operation managers per log stream
IBM recommends that you do not have more than two OMs share the audit trail log data stream.
Writes per second
The number of log blocks that are written to the log stream per second from a single system.
LowOffLoad
Specifies the percent value that you want to use as the low offload threshold for the coupling facility
for this log stream. The low offload threshold is the point in the coupling facility, in percent value of
space that is consumed, where system logger stops offloading coupling facility log data to log stream
DASD data sets. The value of LOWOFFLOAD is the percent of log data system logger leaves in the
coupling facility.
For more information about the offload threshold parameter, see z/OS MVS Setting Up a Sysplex.
The value that is specified for LOWOFFLOAD must be less than the HIGHOFFLOAD value.
This value is specified as a percentage. Enter this value as a whole number. For example, if the
threshold is 20 percent, enter 20.
HighOffLoad
When a coupling facility list structure is filled to its high offload threshold point or beyond, the MVS
system logger begins the removal of data from the coupling facility by either deleting log blocks that
are no longer needed by OM or by moving data to the DASD log stream offload data sets. For OM log
streams a value of 50% is recommended.
For more information about the offload threshold parameter, see z/OS MVS Setting Up a Sysplex.
This value is specified as a percentage. Enter this value as a whole number. For example, if the
threshold is 50 percent, enter 50.
```
**124**   Sysplex Management task


_Calculate the size of an Infosphere Control Table structure_
Coupling facility selection parameters for an Infosphere Control Table structure.

A Classic control table is required for each correlation server on a system (LPAR). Change capture agents
and correlation services use the control table to maintain state information about change capture.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of Entries**

```
To calculate the number of list entries, see InfoSphere Classic Information Center: Configuring Name
Services
```
_Calculate the size of an Infosphere Filter Table structure_
Coupling facility selection parameters for an Infosphere Filter Table structure.

A Classic filter table is required for each group of related correlation services. A Classic filter table
contains information about the database objects a change capture agent needs to capture changes
against.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of Entries**

```
To calculate the number of list entries, see InfoSphere Classic Information Center: Configuring Name
Services.
```
_Calculate the size of a JES structure_
Coupling facility selection parameters for a JES structure.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number 4k checkpoint records from $HASP37 msg**

```
JES2 uses a list structure for its checkpoint data set structure. The JES2 checkpoint function performs
two separate functions.
```
- Job and output queue back up to ensure ease of JES2 restart.
- Multi-access spool (MAS) member-to-member workload communication to ensure efficient
    independent JES2 operations.
The functions that the checkpoint data set performs in your configuration depends on whether you
have a JES2 single-member MAS, or a multi-member MAS with up to 32 members.
An installation can place checkpoint primary or secondary data sets on a coupling facility structure,
DASD, or a combination of both. Placing the primary checkpoint on a coupling facility structure
provides more equitable access for all members of a MAS than that available through DASD because
of the coupling facility lock. JES2 uses the coupling facility lock to serialize access to the checkpoint
data set. When the checkpoint resides on a coupling facility, the first-in, first-out (FIFO) method of
queuing ensures that all MAS members can have equal access to the data.
    **Attention:** IBM does not recommend placing both checkpoints on coupling facility structures
    or placing the primary checkpoint on DASD and the secondary checkpoint on a coupling facility
    structure. If both checkpoints reside on coupling facilities that become volatile (a condition
    where, if power to the coupling facility device is lost, the data is lost), your data is less secure
    than when a checkpoint data set resides on DASD. If no other active MAS member exists, you
    can lose all checkpoint data and require a JES2 cold start. Placing the primary checkpoint on
    DASD while the secondary checkpoint resides on a coupling facility provides no benefit to an
    installation.

```
Sysplex Management task   125
```

```
IBM recommends initializing JES2 with the checkpoint data sets defined on DASD, and then
forwarding them to a previously defined coupling facility through the checkpoint reconfiguration
dialog.
Adequately determining the size of your checkpoint data set is critical to JES2's ability to initialize,
and should be large enough for future expansion.
To calculate the number of list entries, see InfoSphere Classic Information Center: Configuring Name
Services.
Number 4K checkpoint records from $HASP537 msg
During JES2 initialization, JES issues the $HASP537 message that displays the number of 4K records
in your checkpoint. This number will not allow for any increase to these parameters nor expansion by
the $ACTIVATE command which is necessary to enable new functions at the current JES2 level. Use
this number plus any increase you might need for future expansion as input to this field. A numeric
value in 4K records is expected. If the value from the $HASP message is 100 4K records, enter 100
plus some percent for future expansion.
```
```
Calculate the size of a LOGREC structure
Coupling facility selection parameters for a LOGREC structure.
System logger is a set of services that allows an application to write, browse and delete log data. You
can use system logger services to merge data from multiple instances of an application, including merging
data from different systems across a sysplex. List structures are used to hold the logstream data from
exploiters of the system logger.
The system logger component manages log streams based on the LOGR policy in the LOGR couple data
set. The LOGR policy includes the following elements.
```
- Log stream definitions
- Coupling facility list structure definitions
- Keywords
Keywords such as MAXBUFFSIZE, AVGBUFFSIZE, LOGSNUM, etc. are defined in the LOGR policy. The
following defaults are used for sizing a log structure when you click **Calculate**.
**MAXBUFFSIZE**
    Specifies the size, in bytes, of the largest log block that can be written to log streams. The value must
    be between 1 and 65532. The default value used for LOGREC, OPERLOG, CQS, and RRS is 4068. The
    default value used for CICS is 64000.
**AVGBUFFSIZE**
    Specifies the average size in bytes of log blocks written to all log streams. The IBM default is 0. The
    logger uses the average buffer size to control the entry to element ratio.
**LOGSNUM**
    Specifies the number of log streams allocated to a list structure. logsnum must be a value from 0 to
    512. The default value is 1.
**LOWOFFLOAD**
    Specifies the point, in percent value of space consumed, where logger will stop offloading coupling
    facility log data to the DASD log data sets for this log stream. The default value is 0.
**HIGHOFFLOAD**
    Specifies the point, in percent value of space consumed, where logger will begin offloading coupling
    facility log data to the DASD log data sets for this log stream. The default value is 80.
**RESIDENCY TIME**
    Desired residency time for log data in the coupling facility structure (i.e. the amount of time you want
    a log block to stay in the CF between the time it is written to the CF and being offloaded to DASD). The
    default value is 10.
Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**126**   Sysplex Management task


**Writes per second**
The number of log blocks written to the log stream per second from all systems. Calculate the
projected writes per second using the current logrec data sets (obtain an EREP report).
For additional information, refer to IBM publication _Setting up a Sysplex SA23-1399_ for more detailed
information.

_Calculate the size of a MQSeries administrative structure_
Coupling facility selection parameters for a MQSeries administrative structure.

For each queue sharing group (QSG), there is one MQSeries administrative structure. A QSG consists of
queue managers defined to the group by submissions of the CSQ5PQSG batch utility.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of Members in the Queue Sharing Group**
The number of queue managers in the queue sharing group. This value can obtained from the output
of an MQ Script Command (MQSC) DISPLAY GROUP command issued from any member of the group.

**Entry Ratio, Element Ratio**
These two inputs compose the entry-to-element ratio to be used in calculating the size of the
structure. The entry-to-element ratio represents the average number of data elements for each
list entry in the structure. The Entry Ratio represents the numerator of the ratio, and the Element
Ratio is the denominator. For example, an Entry Ratio of 1 and an Element Ratio of 2 indicates an
entry-to-element ratio of 1:2.
IBM recommends that you do not modify the default values for these inputs unless you have reason
to believe that your workload will cause your structure to operate with a ratio other than the default.
For an allocated structure, you can determine the current entry-to-element ratio by issuing the D
XCF,STRUCTURE,STRNAME=surname command.

_Calculate the size of a MQSeries application structure_
Coupling facility selection parameters for a MQSeries application structure.

Messages reside in an MQSeries application structure only long enough for the application to retrieve
them. However, if the application suffers an outage that prevents it from retrieving messages from the
structure, the structure must be large enough to retain any messages that might be written to it during the
outage. Therefore, you must consider:

- The number of queues that map to the structure.
- The average put rate for each queue, for example, the rate at which messages are written to the
    structure.
- The maximum outage duration to be tolerated.

Messages greater than 63 kb (64512 bytes) reside in Db2 LOB structures rather than in the application
structure itself. The application structure still requires some amount of storage for each such message, so
queues for which the average message size exceeds 63 kb receive special treatment in determining the
inputs for the sizing calculation.

The WebSphere MQ SupportPacs Performance Reports might be of assistance.

- MP16 Capacity Planning and Tuning, section _Shared Queue Set up Considerations_
- MP1B Interpreting Accounting and Statistics Data, Appendix B _Detail Layout of MQSeries Accounting and_
    _Statistics Records_

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

```
Sysplex Management task   127
```

```
Average arrival rate of MQ messages with average size < 63KB (messages / minute), Average size
of those messages, Average arrival rate of MQ messages with average size >= 63KB (messages /
minute)
```
1. For each queue mapped to the structure, calculate the average message size from SMF type 116
    Subtype 1 records by dividing the total number of bytes put successfully by the number of MQPUTs
    writing data.
2. Over all queues with an average message size less than 63 KB:
    a. Sum the total number of bytes put successfully.
    b. Sum the total number of MQPUTs writing data.
3. Determine the average arrival rate of MQ messages with an average size less than 63 KB by
    dividing the result from step 2b by the duration of the measurement interval.
4. Determine the average size of those messages by dividing the results from step 2a by the results
    from step 2b.
5. Over all queues with an average message greater than or equal to 63 KB, sum the total number of
    MQPUTs writing data.
6. Determine the average arrival rate of MQ messages with average size greater than or equal to 63
    KB by dividing the result from step 5 by the duration of the measurement interval.
**Entry Ratio, Element Ratio**
These two inputs compose the entry-to-element ratio to be used in calculating the size of the
structure. The entry-to-element ratio represents the average number of data elements for each
list entry in the structure. The Entry Ratio represents the numerator of the ratio, and the Element
Ratio is the denominator. For example, an Entry Ratio of 1 and an Element Ratio of 2 indicates an
entry-to-element ratio of 1:2.
IBM recommends that you do not modify the default values for these inputs unless you have reason
to believe that your workload causes your structure to operate with a ratio other than the default.
For an allocated structure, you can determine the current entry-to-element ratio by issuing the D
XCF,STRUCTURE,STRNAME=surname command.
**CF real storage message capacity (minutes)**
The length of time for which the structure should be able to store incoming messages assuming
that they are not processed and deleted, without overflowing into storage-class memory (SCM). This
determines how much CF real storage should be allocated for the structure.
**Overflow (SCM) message capacity (minutes)**
The length of time for which the structure's storage-class memory (SCM) should be able to store
incoming messages as long as they are not processed and deleted. This determines how much SCM
should be allocated for the structure.
**Note:** Use of any amount of SCM at all requires a significant increase in the minimum structure size.
At CFLEVEL 19, the smallest structure size that supports SCM is approximately 280 M. When you
specify a nonzero value for overflow capacity, the sizing calculation recommends sizes that meet
this requirement. If you specify a smaller value in your CFRM policy, the system might succeed in
allocating the structure, but the structure is not capable of using SCM.

```
Calculate the size of an OEM lock structure
Coupling facility selection parameters for an OEM lock structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of lock entries
Specifies the number of lock entries to be allocated for the coupling facility lock structure. If the value
for LOCKENTRIES is not a power of 2, it is rounded upward to the nearest power of 2. If the lock
structure supports record data, a value of zero for LOCKENTRIES is not valid.
```
**128**   Sysplex Management task


```
If the lock structure does not support record data, a value of zero indicates that the system should
obtain the largest possible number of lock entries given the allocated size of the structures.
```
**Max Number of Connectors**
The maximum number of connectors per structure specified when the primary CFRM couple data
set was formatted (ITEM NAME(CONNECT) NUMBER(xx)). The sizing calculation uses the smaller
of this number or the release-specific maximum number of systems in a sysplex. If you use a new
primary CFRM couple data set formatted for a greater number of connectors per structure, you must
repeat this calculation, since the new value is applied whether you rebuild the structure or restart the
sysplex.

**Max number of record data entries**
Specifies the maximum number of record data entries for the coupling facility lock structure. If the
value for the maximum number of record data entries is 0, the system assumes a pure lock structure
with no record table. If the value for the maximum number of record data entries is 0, then the
structure is not alterable.

**Alterable**

```
Use this input parameter to specify whether the lock structure is alterable or not alterable.
ALTERABLE=YES
The lock structure can be altered.
ALTERABLE=NO
The lock structure cannot be altered.
If the maximum number of record data entries is 0, then alterable must be NO.
```
**Asynchronous Duplexing**
Indicates whether the structure is eligible for asynchronous duplexing. If the CFRM policy description
for this structure specifies DUPLEX(ALLOWED|ENABLED,dupoptions) where _dupoptions_ includes
ASYNC or ASYNCONLY, then specify YES. Otherwise, specify NO.

_Calculate the size of an OEM list structure_
Coupling facility selection parameters for an OEM list structure.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**List headers**
Specifies the number of lists or list headers for the coupling facility list structure. The number must be
greater than zero.

**Lock table entry count**
Specifies the number of lock entries for the coupling facility list structure. If the value for the number
of lock entries is not a power of 2, it is rounded upward to the nearest power of 2. A value of zero
indicates an unserialized list.

**Adjunct data**

```
Specifies whether adjunct data areas are associated with each list entry in the coupling facility list
structure. Each adjunct data area is 64 bytes.
ADJUNCT=YES
Indicates that there are no adjunct data areas that are specified for the list structure.
ADJUNCT=NO
Indicates that each list entry in the list structure has an associated adjunct data area of 64 bytes.
Adjunct data is required if you use secondary keys.
```
**Alterable**

```
Use this input parameter to specify whether the lock structure is alterable or not alterable.
```
```
Sysplex Management task   129
```

##### ALTERABLE=YES

```
The lock structure can be altered.
ALTERABLE=NO
The lock structure cannot be altered.
Max number of list entries
Specifies the maximum number of list entries, or ENTRYCOUNT.
Max number of data elements
Specifies the maximum number of data elements for the structure, or ELEMENTCOUNT.
Max number of data elements per entry
Specifies a value to determine the maximum number of elements for each list entry in the coupling
facility list structure. You can specify a value in the range of 1 - 255 for MAXELEMNUM.
Reference option
Specifies how to reference list entries in the coupling facility list structure. The requestor can specify
one of the following:
REFOPTION=NONE
Indicates that the list entry can be located by the list entry identifier (LEID). The system assigns an
LEID for each list entry that is in use in the coupling facility list structure. Neither keys nor names
are used to reference list entries.
REFOPTION=KEY
Indicates that the list entry can be located by a key value. When you create the entry, the
requestor can assign a key value to one or more list entries on the macro.
REFOPTION=NAME
Indicates that the list entry can be located by a unique name. When you create the entry, the
requestor can assign a unique name to each list entry on the list services macro.
Data element size descriptor
Use this input parameter to specify either an element characteristic (ELEMCHAR), an element
increment number (ELEMINCRNUM), or NONE for element size determination.
DESCRIPTOR=ELEMCHAR
The element size is calculated with the formula 256*(2**ELEMCHAR), where ELEMCHAR is used
as the power of 2. For example, if ELEMCHAR=0, then the size of each element is 256 bytes.
Valid size values for ELEMCHAR range from 0 to a maximum, which is based on a model-
dependent limit on the size of the data elements in the coupling facility.
DESCRIPTOR=ELEMINCRNUM
The element size is calculated with the formula 256*ELEMINCRNUM. For example, if
ELEMINCRNUM=1, then the size of each element is 256 bytes.
Valid size values for ELEMINCRNUM range from 1 to a maximum, which is determined by a
model-dependent limit on the size of data elements in the coupling facility. ELEMINCRNUM must
be a power of 2.
NONE
Neither an element characteristic or element increment number will be used for element size
determination.
If the size value is nonzero, then either ELEMCHAR or ELEMINCRNUM must be specified as the
descriptor.
Data element size value
Use this input parameter to specify a size value for the size descriptors ELEMCHAR or ELEMINCRNUM.
```
**130**   Sysplex Management task


_Calculate the size of an OEM cache structure_
Coupling facility selection parameters for an OEM cache structure.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Max number of cache directory entries**
Specifies the number of lists or list headers for the coupling facility list structure. The number must be
greater than zero.

**Max number of data elements**
Specifies the maximum number of data elements for the structure, or ELEMENTCOUNT.

**Max number of data elements per entry**

```
Specifies a value to determine the maximum number of elements for each data entry in the coupling
facility cache structure. You can specify a value in the range 1 - 255 for MAXELEMNUM.
```
**Alterable**

```
Use this input parameter to specify whether the lock structure is alterable or not alterable.
ALTERABLE=YES
The lock structure can be altered.
ALTERABLE=NO
The lock structure cannot be altered.
```
**Number of castout classes**
Specifies the number of castout classes for named data entries that are used with the coupling facility
cache structure. You must specify at least one castout class.

**Number of storage classes**
Specifies the number of storage classes for named data entries that are used with the coupling facility
cache structure. You must specify at least one storage class.

**Name class mask pattern**
Specifies whether the name class mask pattern definition should be applied to entry names for
assigning entries to name classes in the structure.
**VALUE=YES**
Indicates that a name class mask pattern definition should be applied to entry names.
**VALUE=NO**
Indicates that a name class mask pattern definition should not be applied to entry names.

**Adjunct data**

```
Specifies whether adjunct data areas are associated with each list entry in the coupling facility list
structure. Each adjunct data area is 64 bytes.
ADJUNCT=YES
Indicates that each cache entry in the cache structure has an associated adjunct data area of 64
bytes.
ADJUNCT=NO
Indicates that there are no adjunct data areas that are specified for the cache structure.
Adjunct data is required if you use secondary keys.
```
**User data field order**

```
Use this input parameter to indicate whether a user data field (UDF) order queue should be
maintained for each castout class for the structure.
UDFORDER=YES
Indicates that user data field order queue is maintained for each castout class.
UDFORDER=NO
Indicates that user data field order queue is not maintained for each castout class.
```
```
Sysplex Management task   131
```

```
Data element size descriptor
Use this input parameter to specify either an element characteristic (ELEMCHAR), an element
increment number (ELEMINCRNUM), or NONE for element size determination.
DESCRIPTOR=ELEMCHAR
The element size is calculated with the formula 256*(2**ELEMCHAR), where ELEMCHAR is used
as the power of 2. For example, if ELEMCHAR=0, then the size of each element is 256 bytes.
Valid size values for ELEMCHAR range from 0 to a maximum, which is based on a model-
dependent limit on the size of the data elements in the coupling facility.
DESCRIPTOR=ELEMINCRNUM
The element size is calculated with the formula 256*ELEMINCRNUM. For example, if
ELEMINCRNUM=1, then the size of each element is 256 bytes.
Valid size values for ELEMINCRNUM range from 1 to a maximum, which is determined by a
model-dependent limit on the size of data elements in the coupling facility. ELEMINCRNUM must
be a power of 2.
NONE
Neither an element characteristic or element increment number will be used for element size
determination.
If the size value is nonzero, then either ELEMCHAR or ELEMINCRNUM must be specified as the
descriptor.
Data element size value
Use this input parameter to specify a size value for the size descriptors ELEMCHAR or ELEMINCRNUM.
```
```
Calculate the size of an operation log structure
Coupling facility selection parameters for an operations log (OPERLOG) structure.
System logger is a set of services that allows an application to write, browse, and delete log data. You
can use system logger services to merge data from multiple instances of an application, including merging
data from different systems across a sysplex. List structures are used to hold the logstream data from
exploiters of the system logger.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Writes per second
The number of log blocks that are written to the log stream per second from all systems.
For OPERLOG, you can calculate projected writes per second using current SYSLOGS. The IBM
recommendation for calculating writes per second is over an interval of 2000 messages, which are
calculated for each participating system.
```
```
Calculate the size of a RACF structure
Coupling facility selection parameters for a RACF structure.
RACF uses the Coupling Facility to improve performance with a cache structure to keep frequently used
information. The structure is located in the RACF database and is quickly accessible. You must have one
cache structure for each data set specified in your data set name table (ICHRDSNT). For example, if you
have one primary data set and one backup data set, you need to define two cache structures. The RACF
backup structure needs only about 20% of the data capacity of the primary structure.
At a minimum, the RACF primary structure must be large enough to accommodate the data written
from the instorage I/O buffers. More performance benefits can be gained by increasing the size of the
structure to permit RACF to cache frequently referenced profiles. Caching infrequently used profiles does
not improve performance. The amount of CF storage needed to cache frequently used profiles vary from
installation to installation. It should not exceed the size of the data set containing the RACF database, as
this simply wastes CF storage.
```
**132**   Sysplex Management task


```
Attention: RACF does not support the ALTER function of coupling facility structures. Do not specify
the INITSIZE operand in the structure statement of the CFRM policy. If you do, the size of the
structure is limited to the INITSIZE value instead of the SIZE value. If the INITSIZE value is less
than the SIZE value, RACF issues an informational message IRRX012I. If this message is followed
by IRRX013A , the structure size does not meet the minimum requirements for RACF, and the
system enters read-only mode.
```
Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Max number of instorage local buffers**
Specifies the number of local ECSA-resident buffers that the installation defines for each data set that
comprises the database. The maximum number of local buffers is 255. IBM recommends that you
define the maximum 255 buffers.

**Number of additional blocks to buffer in CF**

```
Specifies the additional number of 4 K buffers to be contained in the structure to improve caching
performance. Specify for this value the estimated number of profiles in frequent use in the RACF
database. Calculate this input as follows:
```
1. Determine the number of cylinders occupied by the RACF database data set.
2. Determine the percentage of the data set in use, from the output of **IRRUT200**.
3. The number of 4 K blocks in use is (total cylinders) * (% cylinders used) * (15
    tracks / cylinder) * (12 4K blocks / track) (for 3390 geometry).
4. Enter (number of 4K blocks in use) * (30%), where 30% is an initial estimate of the
    typical percentage of profiles in frequent use. If caching performance is not satisfactory, gradually
    increase this percentage until no further performance improvement is observed.

**Number of MVS images in the RACF sharing parallel sysplex**
Specifies the number of systems in the RACF data sharing group.

_Calculate the size of an RRS log structure_
Coupling facility selection parameters for an RRS log structure.

RRS uses six log streams, one for each of its six logs. Only 4 are required. The archive and metadata logs
are optional, although the archive log is recommended.

Each non-DASD-only log stream must be mapped to a coupling facility structure in the LOGR policy. A
basic structure mapping would assign each of the RRS log streams to a separate structure. You can map
multiple log streams to a single structure, but log streams sharing a structure should have similar write
rates to ensure that structure resources are shared equitably between the streams. IBM recommends
that each RRS log stream reside in its own coupling facility structure. This recommendation is important
for the archive log. Allowing the RRS archive log stream to share its coupling facility structure with another
log stream is likely to result in suboptimal use of the storage in the coupling facility structure, which might
affect system performance.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Log stream**
Select the log streams that you want to assign to a single log structure. For example, clicking MAIN.UR
and RM.DATA sizes a single log structure large enough to contain these two log streams. Submit a
separate sizing request for each log structure.
**MAIN.UR**
The UR is logged multiple times during its processing. Use SMF type 88 records to estimate writes
per second at peak transaction rates, and add some room for growth.

```
Sysplex Management task   133
```

##### DELAYED.UR

```
The UR is logged multiple times during its processing. Use SMF type 88 records to estimate writes
per second at peak transaction rates, and add some room for growth.
ARCHIVE
Use monitor reports or SMF records that indicate the number of writes per second for all resource
managers that use RRS. Set Writes Per Second for the ARCHIVE log equal to the sum plus
some room for growth. In general, it is recommended that you use data from monitor reports
from an interval with high logging activity to accommodate spikes in the workload. For example,
suppose that SMF type 88 records (SMF88LWI) show that 5000 IXGWRITEs were issued during
the busiest expiring SMF interval for this log stream. If the expiring SMF interval is 30 minutes,
then the following calculation yields the value for writes per second: (5000 writes/ 30 minutes)
x (1 minute / 60 seconds) = 2.78 writes / second Leaving some room for growth, the Writes Per
Second might be set to 5. For additional information on reviewing SMF type 88 records, review the
z/OS MVS System Management Facilities (SMF) manual under topic Record Type 88 (58) - System
Logger Data.
RM.DATA
Because this log is infrequently updated, use 10.
RESTART
This log contains only the information about a UR that a resource manager would need at restart.
Set Writes Per Second to the same value that you set for ARCHIVE.
RM.METADATA
This log is infrequently updated, so use 10 as the value.
Writes per second
Enter your estimate of the number of times that RRS writes to the log stream each second. All the
systems in the sysplex can share the RRS log streams, so you must take all the systems into account.
Also, RRS writes to each log stream at different rates, so you might have different estimates for
different log streams.
```
```
Calculate the size of an SMF structure
Coupling facility selection parameters for an SMF structure.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Stream
SMF uses the system logger to create one or more logstreams for SMF records. The amount of storage
needed to support SMF logstream depends on the rate at which records are generated in the sysplex.
This value is determined by how many records that you want to keep in the structure at any point in
time.
Writes per second
The number of log blocks that are written to the log stream per second from all systems. If you are
migrating from data set recording to logstream recording, run IFASMFDP against the SMF data set to
obtain data for a fixed amount of time. The IFASMFDP report shows how many records of what types
are in that interval. Then, for each logstream, determine the total number of writes for all SMF records
associated with that logstream and divide by the duration of the interval. If you are already using
logstreams but need to tune your structure, you can use the IFASMFDL program and follow the same
procedure against a group of logstreams that map to a structure.
Maximum buffer size
Specifies the maximum size in bytes of log blocks that are written to all log streams, corresponding
to the MAXBUFSIZE parameter of the Logger policy. The Maximum Buffer Size must be in the range
33024 - 65532.
```
**134**   Sysplex Management task


_Calculate the size of a tape structure_
Coupling facility selection parameters for a tape (IEFAUTOS) structure.

Tape allocation uses a list structure (IEFAUTOS) to provide multisystems management of tape devices
without operator intervention. The systems in a sysplex store status of online automatically switchable
devices in the IEFAUTOS structure.

The size of the IEFAUTOS structure depends on the number of MVS systems that are connected to the
structure and the number of automatically switchable devices that are online to those systems.

Inadequate storage for the IEFAUTOS structure can cause one of the following conditions:

- Automatically switchable devices cannot be allocated, deallocated, or varied online.
- New systems cannot connect to the structure.
- Accurate status information about the structure is not available.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

_Calculate the size of a VSAM RLS Lock structure_
Coupling facility selection parameters for a VSAM RLS Lock structure.

The Coupling facility lock structure contains information that is used to determine cross-system
contention on a particular resource. It also contains information about locks that are currently used to
control changes to shared resources.

Default values are provided for all the input data fields in the **Sizing Input** section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click **Calculate** to view sizing results.

**Number of Systems**
The maximum number of systems expected to be active in the sysplex at any one time.

**Max Number of Systems**
The maximum number of systems that can join the sysplex, which is determined from the number of
systems for which the primary sysplex couple data set was formatted.

**Max Number of Connectors**
The maximum number of connectors per structure specified when the primary CFRM couple data
set was formatted (ITEM NAME(CONNECT) NUMBER(xx)). The sizing calculation uses the smaller
of this number or the release-specific maximum number of systems in a sysplex. If you use a new
primary CFRM couple data set formatted for a greater number of connectors per structure, you must
repeat this calculation, since the new value is applied if you rebuild the structure or restart the
sysplex.

**Asynchronous Duplexing**
Use this input parameter to indicate whether the structure is eligible for asynchronous
duplexing. If the CFRM policy description for this structure specifies DUPLEX(ALLOWED |
ENABLED,dupoptions) where dupoptions includes ASYNC or ASYNCONLY, then specify YES.
Otherwise, specify NO.

_Calculate the size of a VSAM RLS Cache structure_
Coupling facility selection parameters for a VSAM RLS Cache structure.

Coupling facility cache structures provide a level of storage hierarchy between local storage and DASD
cache. They are also used as a system buffer pool for VSAM RLS data when that data is modified on other
systems.

You can assign one or more CF cache structures to each cache set associated with a storage class. Having
multiple cache sets allows you to provide different performance attributes for data sets with differing
performance requirements. When more than one CF cache structure is assigned to a cache set, data set
within that storage class is cached in each CF structure in turn, to balance the load.

```
Sysplex Management task   135
```

```
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Sum of Buffer Pool in MBs
The size of the CICS RLS cache structure should be sufficient to contain the total of the local VSAM
LSR buffer pool sizes. This value is expected in MBs.
The local VSAM Local Shared Resources (LSR) buffer pool size is the sum of the LSR pool size and, if
used, the corresponding hiperspace pool size. The Table 83 on page 136 table shows examples of this
calculation.
```
```
Table 83. Calculating the local VSAM LSR buffer pool size
```
```
File Owning Region LSR Pool Size Hiperpool Size Sum Total
```
```
FOR_1 20 MB 30 MB 50 MB
```
```
FOR_2 50 MB No pool 50 MB
```
```
FOR_3 30 MB 50 MB 80 MB
```
```
Total 100 MB 80 MB 180 MB
```
```
To size the cache structure for this example, specify 180 MB as the value. The sizing calculation
determines the additional control storage that is required and returns the structure size to specify in
the CFRM policy.
```
```
Calculate the size of a WLM Enclaves structure
Coupling facility selection parameters for a WLM Enclaves structure.
Some work managers split large transactions across multiple systems in a parallel sysplex, improving
the transaction's overall response time. These work managers can use multisystem enclaves to provide
consistent management and reporting for these types of transactions.
All parts of a split transaction are managed to the same service class. If the service class has multiple
periods, the CPU usage of the entire transaction is used to switch periods. The enclave owner's SMF 30
record includes CPU time that is accumulated by all of its split transactions, for all systems that were run
on.
WLM requires a structure that is named SYSZWLM_WORKUNIT to support multisystem enclaves. You
only need to create this structure if you have products that use multisystem enclave services. The size
of the structure depends on the peak number of transactions that the using products can simultaneously
process that use multisystem enclaves.
The SYSZWLM_WORKUNIT structure requires a coupling facility with CFLEVEL 9 control code or higher.
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of multisystem enclaves
The number of enclaves can be obtained by estimating from the workload that is run.
```
```
Calculate the size of a WLM IRD structure
Coupling facility selection parameters for a WLM IRD structure.
The Intelligent Resource Director (IRD) log structure always returns a 10MB size recommendation. This is
a general rule of thumb size and not a size that is returned from the real coupling facility.
```
```
Calculate the size of an XCF signaling structure
Coupling facility selection parameters for an XCF signaling structure.
Implementing signaling through coupling facility structures provides significant advantages in systems
management and recovery and thus provides enhanced availability for sysplex systems.
```
**136**   Sysplex Management task


```
Default values are provided for all the input data fields in the Sizing Input section. The recommended
default values from IBM product groups may or might not be reflective of your environment. Modify the
defaults and then click Calculate to view sizing results.
Number of Systems
The maximum number of systems for which the primary sysplex couple data set was formatted. For
example, the MAXSYSTEM value that was specified when the couple data set was formatted by using
IXCL1DSU.
Classlen
CLASSLEN for the transport class to which the customer assigned the structure for pathout.
CLASSLEN default is 956, but its value can range in the range 1 - 62464.
Specify the length of the messages for which the signaling service should optimize in a transport class
on the CLASSLEN keyword of the CLASSDEF statement in the Couplexx parmlib member or after IPL,
on the SETXCF START,CLASSDEF or the SETXCF MODIFY,CLASSDEF command.
Transport classes are defined independently for each system in the sysplex.
```
```
CLASSDEF
CLASS(class-name)
CLASSLEN(class-length)
GROUP(group-name ,group-name ...)
MAXMSG(max-messages)
```
```
The class length determines the size of the XCF message buffers used to hold messages sent in
that transport class. The system selects the smallest buffer that holds messages of the size that is
specified on the CLASSLEN keyword. In general, specify a class length equal to the length of the
messages most frequently sent by the groups in the transport class.
Specify the length of the messages (CLASSLEN) for a transport class based on the groups that you
assign to the transport class. Therefore, you must know the characteristics of the messages the
groups send.
Selecting an appropriate class length involves making compromises between storage use and
signaling performance. If messages are usually shorter than the message buffer, storage is wasted; if
longer, performance is degraded.
A message whose length does not exceed the buffer length receives the best performance the
signaling service can provide. Messages longer than the buffer length might require more processing,
such as the preparation of more message buffer space or sending of more signals to deliver the
oversized messages.
If there are many messages longer than the buffer length and the message traffic patterns warrant it,
the signaling service dynamically increases the size of the buffers in the class to avoid the additional
processing overhead to deliver these messages. This dynamic adjustment of buffer sizes means that
specifying a small class length does not necessarily mean that larger signals suffer performance
degradation. However, if increasing the buffer size would cause the signaling service to exceed the
maximum message buffer space that is allowed for messages in a particular transport class for a
particular receiving system, these adjustments are not made.
If a message buffer is too small for a particular message request, the request incurs more overhead
because XCF must format a larger message buffer. If a message buffer is too large for a particular
message request, central storage is wasted. XCF adjusts the size of the buffers in a particular
transport class on a system by system basis based on the actual message traffic.
The RMF XCF Activity Report provides data that can be useful for evaluating message buffer sizes.
This report provides data about the message buffer size for each remote system, by transport class.
```
#### Rename a CFRM policy

```
You can use this window to rename a CFRM policy.
Specify the 1 - 8 character name of the policy. The valid characters are uppercase alphabetic characters
(A-Z) and numeric characters (0-9). The name must start with an alphabetic character (A-Z).
```
```
Sysplex Management task   137
```

```
This window includes an option to open the policy in the CFRM Policy Editor.
To save your change, click OK. Otherwise, click Cancel to return to the CFRM Administrative policies
page.
If you attempt to rename an active policy, this window displays a warning message.
If you specify a policy name that is already in use, the input text box changes to red with an error
message. You cannot click OK to save your change until you specify a unique name.
Renaming a policy is considered to be an update. On return to the CFRM Administrative Policies page,
notice that the "Last Updated" information is incremented for this change.
```
#### Copy a CFRM policy

```
You can use this window to copy a CFRM policy.
This window includes option to open the policy in the CFRM Policy Editor.
To save your change, click OK. Otherwise, click Cancel to return to the CFRM Administrative policies
page.
If you specify a policy name that is already in use, the input text box changes to red with an error
message. You cannot click OK to save your change until you specify a unique name.
On return to the CFRM Administrative Policies page, notice that the new policy is displayed in the table.
```
#### Submit updates for a policy

```
You can use this window to save your policy updates to the CFRM couple data set.
The policy with unsaved updates is displayed for your reference.
After the updates are submitted, this action cannot be undone. You can preview your changes by selecting
the option View Text Contents. Doing so opens a comparison tool in an Angular based dialog. The content
of the dialog is separated into two parts, which correspond to the original version and the updated version
of the policy. You can click the arrows in the upper left corner of the dialog to view previous and next
differences.
You can optionally select Return to the CFRM Policy Editor after submitting updates.
To submit the policy updates, click OK. Otherwise, click Cancel to return to the CFRM Administrative
Policies page.
Your changes do not take effect until you activate the policy. For more information, see “Activate a CFRM
policy” on page 138.
```
```
View text contents of policy versions
You can use this dialog to compare the original content of a CFRM administrative policy to the updated
version of that policy before you submit the changes.
The content of the Angular-based dialog is separated into two parts, which correspond to the original text
content of a selected policy and the updated version of the policy.
To view previous or next differences in the versions, click the arrows in the upper left of the dialog.
Close the dialog to return to the CFRM Administrative policies page.
```
#### Activate a CFRM policy

```
You can use this window to activate a CFRM policy.
The currently active policy is displayed for your reference.
This window includes option to open the policy in the CFRM editor.
```
**138**   Sysplex Management task


```
To activate the policy, click Activate. Otherwise, click Cancel to return to the CFRM Administrative
Policies page.
This action includes a warning message that you are activating the policy in the sysplex. Be aware that
activating the policy will effect sysplex operations.
```
#### Delete a CFRM policy

```
You can use this window to delete one or more CFRM policies.
To delete the selected policies, click OK. Otherwise, click Cancel to return to the CFRM Administrative
policies page.
If you attempt to delete the active policy, a prompt is displayed for you to confirm this action.
On return to the CFRM Administrative Policies page, notice that the policies are no longer displayed in
the table.
```
#### Import a CFRM administrative policy

```
You can use this window to import CFRM administrative policies.
```
1. Select your policy input file format. The default value is JCL. For additional information on the two
    supported formats, see “CFRM Policy Import Formats” on page 140.
       a. If you select the **JCL, Policy is in SYSIN DD* statement** format:
          i) Select the system location in the **System location** field.
             **Note:** The options for the **System location** field are retrieved from the system table. You can
             select a local or remote system, where the data set file is located. If this field is empty, the
             default value is local system.
ii) Enter a valid data set name (e.g. LEO.JCL(DEMO)), or select one from the history in the drop-
down list in the required **Data set name** field.
**Note:** To search for a data set or Unix file, click on the magnifying glass icon. The **Data set
file search** window is displayed. You can then enter a name, click **Go** to search, and select
a result to use. Click **OK** to use the selected name or **Cancel** to return to the **Import CFRM
Administrative Policy** window.
       b. If you select the **Policy is in a data set or Unix file** format:
          i) Select the system location in the **System location** field.
             **Note:** The options for the **System location** field are retrieved from the system table. You can
             select a local or remote system, where the data set or Unix file is located. If this field is empty,
             the default value is local system.
ii) Enter a valid data set name (e.g. LEO.JCL(DEMO)) or Unix file name (e.g. /var/zosmf/data/
policy.data), or select one from the history in the drop-down list in the required **Data set or
Unix file name** field.
**Note:** To search for a data set or Unix file, click on the magnifying glass icon. The **Data set
file search** window is displayed. You can then enter a name, click **Go** to search, and select
a result to use. Click **OK** to use the selected name or **Cancel** to return to the **Import CFRM
Administrative Policy** window.
2. To view the contents of the data set or Unix file, click **View Contents**. When you are finished, click
    **Close**.
3. To import the CFRM policy (or policies), click **OK**. Otherwise, click **Cancel** to return to the **CFRM**
    **Administrative Policies** window.
4. If you click **OK** , the **Confirm Import CFRM Administrative Policy** window is displayed. You need to
    confirm the actions that may occur to the policy (or policies) listed in the table if the import action is
    executed successfully.

```
Sysplex Management task   139
```

```
Note:
```
- This action includes a warning message that you are about to import or delete administrative
    policies. If an administrative policy contains a REPLACE option, it will overwrite policies that are
    already defined. If an administrative policy contains a DELETE keyword, it will delete policies that are
    already defined.
- The import action may fail if the policy content to be imported is not correct or you did not select
    the correct policy input file format. For example, if you select the **Policy is in a data set or Unix file**
    policy input file format, however, you input a JCL format data set name, the action will fail. In this
    case, if you select **Policy is in a data set or Unix file** , you need to input a data set or Unix file with
    pure policy data (see “CFRM Policy Import Formats” on page 140 for a sample policy data).
If you would like to proceed, click **OK**. Otherwise, click **Cancel** to return to the **Import CFRM
Administrative Policy** window.

```
CFRM Policy Import Formats
You can use this window to learn more about the two supported policy import file formats.
JCL, Policy is in SYSIN DD* statement
PS data set and PDS member are supported JCL format data sets.
The data set must follow these rules:
```
1. It must contain PGM=IXCMIAPU.
2. It must contain "//SYSIN DD *", and the data between "//SYSIN DD *" and the data end will be
    extracted.
3. Only one EXEC statement section that contains PGM=IXCMIAPU is supported.

```
//STEP20 EXEC PGM=IXCMIAPU
//SYSPRINT DD SYSOUT=A
//SYSABEND DD SYSOUT=A
//SYSIN DD *
DATA TYPE(CFRM) REPORT(YES)
DEFINE POLICY NAME(POLICY1) REPLACE(YES)
CF NAME(FACIL01)
TYPE(123456)
MFG(IBM)
PLANT(PK)
SEQUENCE(123456789012)
PARTITION(01)
DUMPSPACE(98M)
CF NAME(FACIL02)
TYPE(123456)
MFG(IBM)
PLANT(PK)
SEQUENCE(123456789012)
PARTITION(2)
DUMPSPACE(78M)
STRUCTURE NAME(LIST_01)
SIZE(147M)
INITSIZE(117M)
MINSIZE(73M)
ALLOWAUTOALT(YES)
FULLTHRESHOLD(85)
PREFLIST(FACIL01,FACIL02)
EXCLLIST(CACHE_01)
STRUCTURE NAME(CACHE_01)
SIZE(1G)
REBUILDPERCENT(25)
DUPLEX(ENABLED)
PREFLIST(FACIL02,FACIL01)
EXCLLIST(LIST_01)
/*
```
```
Figure 12. Sample JCL format data set.
```
```
Policy is in a data set or Unix file
A policy data set contains policy data only.
PS data set, PDS member, and Unix file are supported policy format data sets.
```
**140**   Sysplex Management task


```
DATA TYPE(CFRM) REPORT(YES)
DEFINE POLICY NAME(POLICY1) REPLACE(YES)
CF NAME(FACIL01)
TYPE(123456)
MFG(IBM)
PLANT(PK)
SEQUENCE(123456789012)
PARTITION(01)
DUMPSPACE(98M)
CF NAME(FACIL02)
TYPE(123456)
MFG(IBM)
PLANT(PK)
SEQUENCE(123456789012)
PARTITION(2)
DUMPSPACE(78M)
STRUCTURE NAME(LIST_01)
SIZE(147M)
INITSIZE(117M)
MINSIZE(73M)
ALLOWAUTOALT(YES)
FULLTHRESHOLD(85)
PREFLIST(FACIL01,FACIL02)
EXCLLIST(CACHE_01)
STRUCTURE NAME(CACHE_01)
SIZE(1G)
REBUILDPERCENT(25)
DUPLEX(ENABLED)
PREFLIST(FACIL02,FACIL01)
EXCLLIST(LIST_01)
```
```
Figure 13. Sample policy format data set.
```
#### Export a CFRM administrative policy

```
You can use this window to export CFRM administrative policies.
```
1. Select the system location in the **System location** field.
    **Note:** The options for the **System location** field are retrieved from the system table. You can select
    a local or remote system, where the data set or Unix file is located. If this field is empty, the default
    value is local system.
2. Enter a valid data set name (e.g. LEO.JCL(DEMO)) or Unix file name (e.g. /var/zosmf/data/policy.data),
    or select one from the history in the drop-down list in the required **Data set** or **Data set or Unix file**
    **name** field.
    **Note:** To search for a data set or Unix file, click on the magnifying glass icon. The **Data set file search**
    window is displayed. You can then enter a name, click **Go** to search, and select a result to use. Click **OK**
    to use the selected name or **Cancel** to return to the **Import CFRM Administrative Policy** window.
3. To view the contents of the data set or Unix file, click **View Contents**. When you are finished, click
    **Close**.
4. To export the CFRM policy (or policies), click **OK**. Otherwise, click **Cancel** to return to the **CFRM**
    **Administrative Policies** window.
5. If you click **OK** , the **Confirm Export CFRM Administrative Policy** window will appear.
    Click the **View file differences** link to open the content comparison tool. This allows you to view the
    differences between the content of the policy (or policies) you selected and the current content of the
    data set or Unix file you select to export to.
    **Note:** This action includes a warning message that any data that the data set or Unix file currently
    contains will be overwritten and lost. This action cannot be undone.
    If you would like to proceed, click **OK**. Otherwise, click **Cancel** to return to the **Export CFRM**
    **Administrative Policy** window.

```
Sysplex Management task   141
```

#### Compare Administrative Policies

```
You can use this dialog to compare two CFRM administrative policies.
The content of the Angular-based dialog is separated into two parts, which correspond to the two policies
selected by the user.
To view previous or next differences in the policies, click the arrows in the upper left corner of the dialog.
Close the dialog to return to the CFRM Administrative policies page.
```
### Commands Log

```
Use the commands log to see and manage your sysplex commands. All main views have the link to the
commands log.
The commands log displays the commands used in sysplex management and their relationship between
sysplexes, objects, and systems. It displays the status and output of each command, as well as the user
that issued the command. The number next to commands log indicates how many commands have been
updated or added since you last visited the commands log page. The commands that have been updated
or added appear in bold type. Use the filter bar to search the commands table. Click Refresh to refresh
the commands log. Click Close to close the commands list and return to the previous page.
```
```
Commands Log table
For a description of the columns in the table, see Table 84 on page 142. For a description of the actions
that you can take, refer to “Actions” on page 143.
```
```
Table 84. Columns in the Commands Log table
```
```
Column Description
```
```
Command Name of the command used.
```
```
Objects Name of the objects.
```
```
Sysplex Name of the sysplex.
```
```
System Name of the system.
```
```
Status Status of the command.
Completed
Command completed normally.
Completed with error
Command completed but an error was encountered.
Failed
Command failed.
Input Required
WTOR message requires a reply. Click the link to display a dialog for providing
the response to the WTOR.
Not Started
Multiple commands were submitted in sequence, and a required command for
that command is not yet complete.
Submitted
Processing of a command has started and is not yet complete.
Timeout
A response for a command was not available within the expected time. This
may be because z/OS console services are not available or the command was
stopped or canceled.
```
**142**   Sysplex Management task


_Table 84. Columns in the Commands Log table (continued)_

**Column Description**

**Output** Output of the command. Click **Summary** to view the commands summary page.

**Date updated** Date that the command was last updated.

**Date submitted** Date that the command was submitted.

**User** The user ID who invoked the command.

```
Actions
The actions are described in the following tables:
```
- Targeted actions. Actions that apply to the selected items. To use a targeted action, you must select one
    or more items. See Table 85 on page 143.
- Untargeted actions. Actions that apply to the entire table. No selection of table items is required. See
    Table 86 on page 144.
- Table actions. Actions that apply to the entire table. No selection of table items is required. See Table 87
    on page 144.

_Table 85. Targeted actions for the Commands Log table_

**Action Description**

**Delete** If you are the commands log administrator select this action to delete command
logs. If you are not the commands log administrator than you can use this action to
delete the command logs you own. The table consists of:
**Command**
The command that you are about to delete.
**Objects**
The objects that the command effects.
**Sysplex**
The sysplex that the command was initiated on.
**User**
The user who initiated this command.
If you are a commands log administrator, you can always delete any objects. In the
Delete Confirmation panel, you can see all the objects you selected. Click **Ok** to
confirm the deletion of the commands in the table or click **Cancel** to return to the
commands log page.
**Note:** The Delete Action is enabled even when a your selection list includes an
object you are not authorized to delete. In the Delete Confirmation panel, the
objects that you are not authorized to delete are filtered out. The Delete action is
disabled if your selection list only includes objects you are not authorized to delete.

**View Output** View the command output.

```
Sysplex Management task   143
```

```
Table 86. Untargeted actions for the Commands Log table
```
```
Action Description
```
```
Delete all If you are the commands log administrator select this action to delete all command
logs. If you are not the commands log administrator than you can use this action
to delete all of the command logs you own. In the Delete Confirmation panel, you
can see all of the objects to be deleted. Click Ok to confirm the deletion of the
commands in the table or click Cancel to return to the commands log page.
Note: The Delete Action is enabled even when a your selection list includes an
object you are not authorized to delete. In the Delete Confirmation panel, the
objects that you are not authorized to delete are filtered out. The Delete action is
disabled if your selection list only includes objects you are not authorized to delete.
```
```
Table 87. Table actions for the Commands Log table
```
```
Action Description
```
```
Cleanup Settings Select this action to go to the Cleanup Settings page. The Cleanup Settings is
editable when you are a commands log administrator, otherwise, you can only view
the settings.
```
```
Select All Select all of the rows in the table.
```
```
Deselect All Deselect all of the selected rows in the table.
```
```
Configure Columns Select the columns to display in the table, specify the order of those columns,
and designate which columns are fixed in position when the table is scrolled
horizontally.
```
```
Hide Filter Row Remove the filter row from view.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Show Filter Row Display the filter row.
If the filter row is displayed in the table, the Hide Filter Row action is listed.
Otherwise, the Show Filter Row action is listed.
```
```
Clear sorts Clear the sort from all of the columns in the table. This action is disabled if no
sorting is specified in the table.
```
```
Clear search Clear the search from all of the columns in the table. This action is disabled if no
searching is specified in the table.
```
#### Write to Operator with Reply (WTOR) Message

```
Use this dialog to reply to a write-to-operator-with-reply (WTOR) message that was issued in response to
a command.
You can use the Write to Operator with Reply (WTOR) Message dialog to reply to a WTOR message that
was issued in response to a command.
See the Console Output field for messages that provide information on the command and possible
responses. Then, type the response in the input field, and click OK.
For more information about a WTOR message, see IBM Documentation for z/OS. Type the message ID in
the search field, or select a z/OS release to display the IBM Documentation for that release, then type the
message ID in the search field.
```
**144**   Sysplex Management task


#### Commands Output

```
Use the Commands Output to view the output of your command.
The Commands Output page displays the console output of commands used in sysplex management.
Click Close to close the commands list and return to your previous page.
```
```
Commands Output Page
Command
The name of the command that was initiated.
Objects
The objects that the command effects.
Sysplex
The syspex that the command was initiated on.
Status
The status of the command. Shows if the command was submitted, failed, or was completed.
Console Output
Shows the date that the command was initiated, the system that the command was initiated on,
and the message that the command produced. You can click the message ID to view help for that
message.
```
#### Cleanup Settings

```
Use the commands summary to view the output of your command. The Cleanup Settings is editable
when you are a commands log administrator, otherwise, you can only view the settings.
The cleanup settings page displays the settings for log entry maintenance and automatic deletion settings
for the Commands Log. Click Ok to save your settings or click Cancel to close the cleanup settings and
return to your previous page.
```
```
Cleanup Settings Page
Maximum number of log entries
You can choose between keeping 50 to 1000 log entries on the Commands Log page. When your
maximum setting is reached log entries are deleted starting from the oldest entries. Use the arrows to
toggle how many entries you would like to choose or type in a number between 50 and 1000.
Automatic deletion
If you enable this setting by checking the check box you can choose how many days an entry is stored
on the Commands Log page. Once an entry becomes older than your selected date it is deleted. You
can use the arrows to toggle how many days you would like to keep an entry or you can type it in.
```
#### Sysplex Management Commands

```
Through Sysplex Management in z/OSMF you can use these commands on your Sysplex.
```
**Commands**

```
Table 88. Commands in Sysplex Management
```
```
Command Name Description
```
```
PSWITCH Switch the alternate couple dataset of a given type
to become the primary couple dataset. See “Switch
Alternate to Primary Command” on page 147.
```
```
Set Primary Couple Data Set Command Set the primary couple data set. See “Set Primary
Couple Data Set Command” on page 150.
```
```
Sysplex Management task   145
```

```
Table 88. Commands in Sysplex Management (continued)
```
```
Command Name Description
```
```
Set Alternate Couple Data Set Command Set the alternate couple data set. See “Set
Alternate Couple Data Set Command” on page
151.
```
```
New Couple Data Set Command Create a new couple data set, using a newly-
formatted data set that has the default capacity.
See “New Couple Data Set Command” on page
151.
```
```
.Reallocate Reallocate structures across all CFs. See
“Reallocate Command” on page 155.
```
```
Start Rebuild (All) Start Rebuild For all structures for a selected CF.
See “Start Rebuild (All)” on page 159.
```
```
Start Rebuild Start Rebuild For one or more selected structures.
See “Start Rebuild” on page 158.
```
```
Stop Rebuild (All) Stop Rebuild for all structures for a selected CF.
See “Stop Rebuild (All)” on page 160.
```
```
Stop Rebuild Stop Rebuild for one or more selected structures.
See “Stop Rebuild” on page 160.
```
```
Start Duplexing (All) Start Duplexing for all structures for a selected CF.
See “Start Duplexing (All)” on page 161.
```
```
Start Duplexing Start Duplexing for one or more selected
structures. See “Start Duplexing” on page 161.
```
```
Stop Duplexing (All) Stop Duplexing for all structures for a selected CF.
See “Stop Duplexing (All)” on page 162.
```
```
Stop Duplexing Stop Duplexing for one or more selected
structures. See “Stop Duplexing” on page 162.
```
```
Set Physical Path Restore or remove a physical path for a selected
structure. See “Set Physical Path” on page 163
```
```
Set Logical Path Restore or remove a logical path for a selected
structure. See “Set Logical Path” on page 163.
```
```
Start Maintenance Mode Starts maintenance mode for the selected CF. See
“Start Maintenance Mode” on page 164.
```
```
Stop Maintenance Mode Stops maintenance mode for the selected CF. See
“Stop Maintenance Mode” on page 164.
```
```
Prepare for Disruptive Maintenance Prepares the selected CF for disruptive
maintenance. See “Prepare for Disruptive
Maintenance” on page 164.
```
```
Restore after Disruptive Maintenance Restores the selected CF from disruptive
maintenance. See “Restore after Disruptive
Maintenance” on page 164.
```
**146**   Sysplex Management task


**Switch Alternate to Primary Command**

Use this command to switch the alternate couple dataset (of a given type) to become the primary couple
dataset.

The options on the Switch Alternate to Primary command are **New Alternate** (specify a new alternate
couple data set) and **No Alternate** (do not replace the alternate couple data set).

For either option, a confirmation window is displayed.

On the confirmation window, specify values, then click **OK** to continue or **Cancel** to return to the previous
page. Click **Command Preview** to see the commands that will be issued.

**Specify the new alternate couple data set**

With **New Alternate** , you specify the new alternate couple data set on the confirmation window.

- **Selecting an existing data set.** Select this option, type a data set name qualifier, volume, or both, and
    then click **Search**. The associated table is then populated. Select an alternate couple data set in the
    table.
- **Formatting a new data set.** Select this option, then supply values for the new data set.

**Formatting a new data set: Additional information fields**

The additional information fields for each type of couple data set are described below.

**ARM:** The values for an ARM couple data set are as follows.

**Policies**
Specifies the number of user-defined administrative policies that can be defined. (Default=3,
Minimum=1. Maximum=65535.)

**Element definitions**
Specifies the maximum number of elements per policy. (Default=10, Minimum=1. Maximum=65535.)

**Elements**
Specifies the maximum number of elements that can be registered in the sysplex at once.
(Default=500, Minimum=1. Maximum=65535.)

**BPXCMDS:** The values for a BPXCMDS couple data set are as follows.

**Mounts**
Specifies the number of mounts that can be supported. (Default=100, Minimum=10,
Maximum=35000)

**Automount rules**
Specifies the number of automount rules that can be supported. (Default=50, Minimum=50,
Maximum=5000)

**CFRM:** The values for a CFRM couple data set are as follows.

**Policies**
Specifies the number of administrative policies that can be defined within the data set. (Default=6,
Minimum=1, Maximum=32)

**Coupling facilities**
Specifies the number of coupling facilities that can be defined within a policy. (Default=8, Minimum=1,
Maximum=16)

**Structures**
Specifies the number of coupling facility structures that can be defined in one policy. This number
refers to structure definitions, not to the number of allocated structure instances. One structure
definition can refer to more than one allocated structure instance, as would be the case for a structure
that was being rebuilt or duplexed. (Default=50, Minimum=1, Maximum=4096)

```
Sysplex Management task   147
```

```
Connections
Specifies the number of connections that can be defined for a coupling facility structure. (Default=32,
Minimum=1, Maximum=255)
System-managed rebuild
Specifies that this CFRM couple data set supports the system-managed rebuild process.
System-managed duplexing rebuild processing
Specifies that this CFRM couple data set supports the system-managed duplexing rebuild process.
Use this statement only when formatting a CFRM couple data set for systems at z/OS Release 2
or later. Specifying SMDUPLEX implies support for SMREBLD, regardless of whether SMREBLD was
explicitly specified.
Message-based event and confirmation processing
Specifies that this CFRM couple data set supports message-based event and confirmation processing.
Use this statement only when formatting a CFRM couple data sets at systems at z/OS Release 8 and
later. Specifying MSGBASED implies support for SMREBLD and SMDUPLEX, regardless of whether they
were explicitly specified.
System-managed asynchronous structure duplexing
Specifies that this CFRM couple data set supports system-managed asynchronous structure
duplexing. Use this statement only when formatting a CFRM couple data set for systems at V2R2 with
the PTF for APAR OA47796 applied, or later. Specifying ASYNCDUPLEX implies support for SMREBLD,
SMDUPLEX, and MSGBASED, regardless of whether they were explicitly specified.
LOGR: The values for a LOGR couple data set are as follows.
Log streams
Specifies the maximum number of log streams that can be defined to the LOGR policy. Each LSR
record consumes one track in the LOGR couple data set. (Default=1, Minimum=1, Maximum=32767)
Structure names
Specifies the maximum number of structure names that can be defined to the LOGR policy.
Each LSTRR record consumes one track in the LOGR couple data set. (Default=1, Minimum=1,
Maximum=32767)
Directory extents
Specifies the number of additional log stream data set directory extents to define for log stream
offload data sets. Use this parameter to increase the potential log data set directory capacity for
a sysplex. Each additional directory extent specified goes into a common pool available to any log
stream in the sysplex. System logger allocates these directory extents as needed when a log stream
runs out of DASD log stream offload data set directory space. Each directory extent allows a log
stream to extend by 168 log data sets.
When a DSEXTENT record is assigned to a log stream, that particular DSEXTENT record is only used
for that specific log stream until it is no longer needed. Logger then removes the DSEXTENT record
from that specific log stream use and put the DSEXTENT record back into the common pool.
Each DSEXTENT record consumes one track in the LOGR couple data set. (Default=0, Minimum=0,
Maximum=65535)
System-managed duplexing
Specifies whether Logger should support system-managed duplexing rebuild. This specification can
also affect the LOGR couple data set format level.
SFM: The values for an SFM couple data set are as follows.
Policies
Specifies the number of administrative policies that can be defined. (Default=9, Minimum=1,
Maximum=50)
System definitions
Specifies the number of systems for which actions and weights can be defined. This should be the
maximum number of systems that will be in the sysplex that the policy will govern. Note that the
number specified does not need to include those systems identified by NAME(*), for which policy
default values are applied. (Default=8, Minimum=0, Maximum=32)
```
**148**   Sysplex Management task


**Reconfigurations**
Specifies the number of reconfigurations involving PR/SM partitions that can be specified. (Default=0,
Minimum=0, Maximum=50)

**Sysplex:** The values for a Sysplex couple data set are as follows.

**Groups**
Specifies that the sysplex couple data set supports group data. Include not only the number of XCF
groups needed for multisystem applications, but also the number of XCF groups that MVS system
components need. (To determine the number of MVS system groups, issue the DISPLAY XCF,G
command.) It is also advisable to add a contingency number of groups for future growth.

**Members**
Specifies that the sysplex couple data set supports member data. Determine which group has the
largest number of members that can exist on systems in a sysplex and specify a value at least as large.
(Default=number of members that can be supported on one track of the device type for which the
sysplex couple data set is being formatted, Minimum=8, Maximum=2047.

**Global resource serialization data**
Specifies that the sysplex couple data set supports global resource serialization data.

**Cluster function**
Specifies that the sysplex couple data set supports cluster functions. There must be at least one z/OS
system at release level V1R9 or higher to enable the system to process this parameter. You will need
to specify the ITEM NAME(CLUSTER) parameter in your primary sysplex couple data set in order to
enable any of the operations that report or act on cluster resources. For a consistent view of cluster
resources across the sysplex, all the systems in the sysplex should be at the z/OS V1R9 level or
higher.

**System status detection partitioning protocol**
Specifies that the sysplex couple data set is formatted with the larger system records required by the
system status detection partitioning protocol. To use a sysplex couple data set formatted with this
keyword, all systems in the sysplex must be at z/OS V1R11 or higher, or have installed the PTFs for
toleration APAR OA26037.

**WLM:** The values for a WLM couple data set are as follows.

**Policies**
Specifies that an increment of space large enough to accommodate the specified number of policies
be allocated in the WLM couple data set. (Default=5, Minimum=1, Maximum=99)

**Workloads**
Specifies that an increment of space large enough to accommodate the specified number of
workloads be allocated in the WLM couple data set. (Default=32, Minimum=1, Maximum=999)

**Service classes**
Specifies that an increment of space large enough to accommodate the specified number of service
classes be allocated in the WLM couple data set. (Default=128, Minimum=1, Maximum=999)
**Note:** WLM allows no more than 100 service classes to be defined in a service definition. The default,
however, remains at the value of 128. This will set aside as much space as you will ever need for
service classes, as well as a little extra for other WLM objects.

**Service definition space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
(IWMSVDEF) be allocated in the WLM couple data set. (Default=0, Minimum=0, Maximum=8092)

**Service definition classification rules space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Classification Rules (IWMSVDCR) be allocated in the WLM couple data set. (Default=0, Minimum=0,
Maximum=8092)

**Application environments**
Specifies that an increment of space large enough to accommodate the specified number of
application environments be allocated in the WLM couple data set. (Default=100, Minimum=1,
Maximum=3000)

```
Sysplex Management task   149
```

```
Service definition application environment area space
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Application Environment Area (IWMSVAEA) be allocated in the WLM couple data set. (Default=0,
Minimum=0, Maximum=8092)
Scheduling environments
Specifies that an increment of space large enough to accommodate the specified number of
scheduling environments be allocated in the WLM couple data set. (Default=100, Minimum=1,
Maximum=999)
Service definition scheduling environment area space
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Scheduling Environment Area (IWMSVSEA) be allocated in the WLM couple data set. (Default=0,
Minimum=0, Maximum=8092)
```
```
Command details
The command issues a SETXCF COUPLE command with a PSWITCH parameter. PSWITCH is described as
follows:
PSWITCH
Switches the current alternate sysplex couple data set to become the primary sysplex couple data
set. The command is complete when systems in the sysplex acknowledge the switch. This command
removes the current primary sysplex couple data set from service.
Note: If the new primary sysplex couple data set has been formatted to support greater than eight
systems in the sysplex, the following occurs:
```
- If the current RMAX value is less than 99, the system automatically increases the RMAX value to 99.
    The system issues message IEA403I to indicate this change. You cannot lower the value of RMAX. A
    minimum RMAX value of 99 is enforced for performance reasons.
For more information, see SETXCF COUPLE Commands in _z/OS MVS System Commands_.

```
Set Primary Couple Data Set Command
Use this command to set the primary couple data set. For more information, see SETXCF COUPLE
Commands in z/OS MVS System Commands.
A confirmation window is displayed. On the confirmation window, click OK to continue or Cancel to return
to the previous page. Click Command Preview to see the command that will be issued.
On the confirmation window, specify the primary couple data set by doing either of the following:
```
- **Select an existing couple data set.**
    1. Type one or more qualifiers in the Primary couple data set name qualifier field.
    2. Specify the volume if the data set is not cataloged.
    3. Click **Search**. Select a data set from the resulting list.
- **Format a new data set.** If you select this option, z/OSMF creates a new CDS with the same attributes of
    the primary CDS and the same capacity.
       1. Specify the data set name. The data set name can have one or more name segments, which are
          separated by periods, and cannot exceed a total length of 44 characters. Each name segment is
          one to eight alphanumeric, hyphen (-), and national ($,#,@) characters, but must begin with an
          alphabetic or national character.
       2. Specify the volume or storage class. The volume must be specified as one to six alphanumeric or
          national characters, and can begin with any of these characters.
The command issues a SETXCF COUPLE command with an PCOUPLE parameter. PCOUPLE is described as
follows:

**150**   Sysplex Management task


##### PCOUPLE

```
Specifies the data set to use as the primary sysplex couple data set. This data set must be defined and
formatted with the XCF format utility and for each parameter specified in the utility, the parameter
values must be equal to or greater than the parameter values that were used to format the current
primary couple data set.
```
**Set Alternate Couple Data Set Command**

Use this command to set the alternate couple data set. For more information, see SETXCF COUPLE
Commands in _z/OS MVS System Commands_.

A confirmation window is displayed. On the confirmation window, click **OK** to continue or **Cancel** to return
to the previous page. Click **Command Preview** to see the command that will be issued.

On the confirmation window, specify the alternate couple data set by doing either of the following:

- **Select an existing couple data set.**
    1. Type one or more qualifiers in the Alternate couple data set name qualifier field.
    2. Specify the volume if the data set is not cataloged.
    3. Click **Search**. Select a data set from the resulting list.
- **Format a new data set.** If you select this option, z/OSMF creates a new CDS with the same attributes of
    the primary CDS and the same capacity.
       1. Specify the data set name. The data set name can have one or more name segments, which are
          separated by periods, and cannot exceed a total length of 44 characters. Each name segment is
          one to eight alphanumeric, hyphen (-), and national ($,#,@) characters, but must begin with an
          alphabetic or national character.
       2. Specify the volume or SMS storage class. Observe the following details:
          - Volume name must be specified as one to six alphanumeric or national characters, and can begin
             with any of these characters.
          - Storage class must be a valid SMS storage class name for the SMS-managed volume where the
             data set is to reside.

The command issues a SETXCF COUPLE command with an ACOUPLE parameter. ACOUPLE is described as
follows:

**ACOUPLE**
Specifies the data set to use as an alternate sysplex couple data set. This data set must be
defined and formatted with the XCF format utility and for each parameter specified in the utility,
the parameter values must be equal to or greater than the parameter values that were used to format
the current primary couple data set.

**New Couple Data Set Command**

Use this command to create a couple data set by using a newly formatted data set with the default
capacity. You can select the following couple data set types: ARM, BPXCMDS, CFRM, LOGR, LOGRY,
LOGRZ, SFM, SYSPLEX, or WLM.

A confirmation window is displayed. On the confirmation window, click **OK** to continue or **Cancel** to return
to the previous page. Click **Command Preview** to see the command that will be issued.

On the confirmation window, the values are initialized with from your existing primary couple data set, or
default values. Examine the values and determine whether you need to change them for your system.

**Creating a new data set: Additional information fields**

The additional information fields for each type of couple data set are described in the sections that follow.

**ARM:** The values for an ARM couple data set are as follows.

```
Sysplex Management task   151
```

```
Policies
Specifies the number of user-defined administrative policies that can be defined. (Default=3,
Minimum=1. Maximum=65535.)
Element definitions
Specifies the maximum number of elements per policy. (Default=10, Minimum=1. Maximum=65535.)
Elements
Specifies the maximum number of elements that can be registered in the sysplex at once.
(Default=500, Minimum=1. Maximum=65535.)
BPXCMDS: The values for a BPXCMDS couple data set are as follows.
Mounts
Specifies the number of mounts that can be supported. (Default=100, Minimum=10,
Maximum=35000)
Automount rules
Specifies the number of automount rules that can be supported. (Default=50, Minimum=50,
Maximum=5000)
CFRM: The values for a CFRM couple data set are as follows.
Policies
Specifies the number of administrative policies that can be defined within the data set. (Default=6,
Minimum=1, Maximum=32)
Coupling facilities
Specifies the number of coupling facilities that can be defined within a policy. (Default=8, Minimum=1,
Maximum=16)
Structures
Specifies the number of coupling facility structures that can be defined in one policy. This number
refers to structure definitions, not to the number of allocated structure instances. One structure
definition can refer to more than one allocated structure instance, as would be the case for a structure
that was being rebuilt or duplexed. (Default=50, Minimum=1, Maximum=4096)
Connections
Specifies the number of connections that can be defined for a coupling facility structure. (Default=32,
Minimum=1, Maximum=255)
System-managed rebuild
Specifies that this CFRM couple data set supports the system-managed rebuild process.
System-managed duplexing rebuild processing
Specifies that this CFRM couple data set supports the system-managed duplexing rebuild process.
Use this statement only when formatting a CFRM couple data set for systems at z/OS Release 2
or later. Specifying SMDUPLEX implies support for SMREBLD, regardless of whether SMREBLD was
explicitly specified.
Message-based event and confirmation processing
Specifies that this CFRM couple data set supports message-based event and confirmation processing.
Use this statement only when formatting a CFRM couple data sets at systems at z/OS Release 8 and
later. Specifying MSGBASED implies support for SMREBLD and SMDUPLEX, regardless of whether they
were explicitly specified.
System-managed asynchronous structure duplexing
Specifies that this CFRM couple data set supports system-managed asynchronous structure
duplexing. Use this statement only when formatting a CFRM couple data set for systems at V2R2 with
the PTF for APAR OA47796 applied, or later. Specifying ASYNCDUPLEX implies support for SMREBLD,
SMDUPLEX, and MSGBASED, regardless of whether they were explicitly specified.
LOGR: The values for a LOGR couple data set are as follows.
Log streams
Specifies the maximum number of log streams that can be defined to the LOGR policy. Each LSR
record consumes one track in the LOGR couple data set. (Default=1, Minimum=1, Maximum=32767)
```
**152**   Sysplex Management task


**Structure names**
Specifies the maximum number of structure names that can be defined to the LOGR policy.
Each LSTRR record consumes one track in the LOGR couple data set. (Default=1, Minimum=1,
Maximum=32767)

**Directory extents**
Specifies the number of additional log stream data set directory extents to define for log stream
offload data sets. Use this parameter to increase the potential log data set directory capacity for
a sysplex. Each additional directory extent specified goes into a common pool available to any log
stream in the sysplex. System logger allocates these directory extents as needed when a log stream
runs out of DASD log stream offload data set directory space. Each directory extent allows a log
stream to extend by 168 log data sets.
When a DSEXTENT record is assigned to a log stream, that particular DSEXTENT record is only used
for that specific log stream until it is no longer needed. Logger then removes the DSEXTENT record
from that specific log stream use and put the DSEXTENT record back into the common pool.
Each DSEXTENT record consumes one track in the LOGR couple data set. (Default=0, Minimum=0,
Maximum=65535)

**System-managed duplexing support**
Specifies whether Logger should support system-managed duplexing rebuild. This specification can
also affect the LOGR couple data set format level.

**LOGRY / LOGRZ** The values for a LOGRY or LOGRZ couple data set are as follows.

**Log streams**
Specifies the maximum number of log streams that can be defined to the LOGR policy. Each LSR
record consumes one track in the LOGR couple data set. (Default=1, Minimum=1, Maximum=32767)

**Directory extents**
Specifies the number of additional log stream data set directory extents to define for log stream
offload data sets. Use this parameter to increase the potential log data set directory capacity for
a sysplex. Each additional directory extent specified goes into a common pool available to any log
stream in the sysplex. System logger allocates these directory extents as needed when a log stream
runs out of DASD log stream offload data set directory space. Each directory extent allows a log
stream to extend by 168 log data sets.
When a DSEXTENT record is assigned to a log stream, that particular DSEXTENT record is only used
for that specific log stream until it is no longer needed. Logger then removes the DSEXTENT record
from that specific log stream use and put the DSEXTENT record back into the common pool.
Each DSEXTENT record consumes one track in the LOGR couple data set. (Default=0, Minimum=0,
Maximum=65535)

**Format level**
Specifies the format level of the single-system scope LOGRY or LOGRZ couple data set. For an
explanation of the different versions or levels of the single-system LOGRY or LOGRZ couple data sets
and the system logger functions that are supported, see LOGRY or LOGRZ couple data set versioning -
new format levels in _z/OS MVS Setting Up a Sysplex_.
The value of the NUMBER parameter is described as follows.

```
Table 89. LOGRY and LOGRZ CDS format level
```
```
Value Description
```
```
1 The resulting format level of the respective
single-system scope LOGRY or LOGRZ couple
data set is HBB77C0 and is supported on z/OS
V2R4 and later releases.
```
```
When this item is omitted from the IXCL1DSU format utility, System Logger uses the value of 1 by
default.
```
```
Sysplex Management task   153
```

```
This specification does not consume any space in the respective LOGRY or LOGRZ couple data set.
(Default=1, Minimum=1, Maximum=1)
SFM: The values for an SFM couple data set are as follows.
Policies
Specifies the number of administrative policies that can be defined. (Default=9, Minimum=1,
Maximum=50)
System definitions
Specifies the number of systems for which actions and weights can be defined. This should be the
maximum number of systems that will be in the sysplex that the policy will govern. Note that the
number specified does not need to include those systems identified by NAME(*), for which policy
default values are applied. (Default=8, Minimum=0, Maximum=32)
Reconfigurations
Specifies the number of reconfigurations involving PR/SM partitions that can be specified. (Default=0,
Minimum=0, Maximum=50)
Sysplex: The values for a Sysplex couple data set are as follows.
Groups
Specifies that the sysplex couple data set supports group data. Include not only the number of XCF
groups needed for multisystem applications, but also the number of XCF groups that MVS system
components need. (To determine the number of MVS system groups, issue the DISPLAY XCF,G
command.) It is also advisable to add a contingency number of groups for future growth.
Members
Specifies that the sysplex couple data set supports member data. Determine which group has the
largest number of members that can exist on systems in a sysplex and specify a value at least as large.
(Default=number of members that can be supported on one track of the device type for which the
sysplex couple data set is being formatted, Minimum=8, Maximum=2047.
Global resource serialization data
Specifies that the sysplex couple data set supports global resource serialization data.
Cluster function
Specifies that the sysplex couple data set supports cluster functions. There must be at least one z/OS
system at release level V1R9 or higher to enable the system to process this parameter. You will need
to specify the ITEM NAME(CLUSTER) parameter in your primary sysplex couple data set in order to
enable any of the operations that report or act on cluster resources. For a consistent view of cluster
resources across the sysplex, all the systems in the sysplex should be at the z/OS V1R9 level or
higher.
System status detection partitioning protocol
Specifies that the sysplex couple data set is formatted with the larger system records required by the
system status detection partitioning protocol. To use a sysplex couple data set formatted with this
keyword, all systems in the sysplex must be at z/OS V1R11 or higher, or have installed the PTFs for
toleration APAR OA26037.
WLM: The values for a WLM couple data set are as follows.
Policies
Specifies that an increment of space large enough to accommodate the specified number of policies
be allocated in the WLM couple data set. (Default=5, Minimum=1, Maximum=99)
Workloads
Specifies that an increment of space large enough to accommodate the specified number of
workloads be allocated in the WLM couple data set. (Default=32, Minimum=1, Maximum=999)
Service classes
Specifies that an increment of space large enough to accommodate the specified number of service
classes be allocated in the WLM couple data set. (Default=128, Minimum=1, Maximum=999)
```
**154**   Sysplex Management task


```
Note: WLM allows no more than 100 service classes to be defined in a service definition. The default,
however, remains at the value of 128. This will set aside as much space as you will ever need for
service classes, as well as a little extra for other WLM objects.
```
**Service definition space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
(IWMSVDEF) be allocated in the WLM couple data set. (Default=0, Minimum=0, Maximum=8092)

**Service definition classification rules space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Classification Rules (IWMSVDCR) be allocated in the WLM couple data set. (Default=0, Minimum=0,
Maximum=8092)

**Application environments**
Specifies that an increment of space large enough to accommodate the specified number of
application environments be allocated in the WLM couple data set. (Default=100, Minimum=1,
Maximum=3000)

**Service definition application environment area space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Application Environment Area (IWMSVAEA) be allocated in the WLM couple data set. (Default=0,
Minimum=0, Maximum=8092)

**Scheduling environments**
Specifies that an increment of space large enough to accommodate the specified number of
scheduling environments be allocated in the WLM couple data set. (Default=100, Minimum=1,
Maximum=999)

**Service definition scheduling environment area space**
Specifies that an exact amount of space (in K bytes) for extension areas to the WLM Service Definition
Scheduling Environment Area (IWMSVSEA) be allocated in the WLM couple data set. (Default=0,
Minimum=0, Maximum=8092)

**Command details**

The command issues a SETXCF COUPLE command with a PSWITCH parameter.

For more information, see SETXCF COUPLE Commands in _z/OS MVS System Commands_.

**Reallocate Command**

Use this command to reallocate structures across all CFs. For more information on SETXCF commands
see SETXCF Commands in _z/OS MVS System Commands_.

**Start Reallocate**

A confirmation window is displayed, which shows information about the coupling facility structures. On
the confirmation window, specify values, then click **OK** to continue or **Cancel** to return to the previous
page. Click **Command Preview** to see the commands that will be issued.

The Start Reallocate command is described as follows:

**REALLOCATE** **_or_** **REALLOC**
Specifies that the REALLOCATE process is to be initiated.
The REALLOCATE process evaluates each allocated structure to recognize the need to make the
following adjustments:

- Relocate the structure instance or instances
- Complete a pending policy change
- Trigger MVS-initiated duplexing
The evaluation of each allocated structure uses the XCF structure allocation algorithm and either the
active or pending CFRM policy definition for the structure. Message IXC574I is written to the hardcopy

```
Sysplex Management task   155
```

```
log to show the current location of instances allocated in coupling facilities, the policy information
used, and the evaluation result. Then it compares the current location with the location identified by
evaluation to determine what if any adjustments are needed.
By evaluating the allocated structure, the REALLOCATE process can recognize that the structure is
optimally located and immediately complete a change to the policy definition for the structure when
the change does not affect the size. In addition, REALLOCATE processing is a triggering event for
MVS-initiated duplexing rebuild when it finds the structure is not duplexed and DUPLEX(ENABLED) is
specified for the structure in the CFRM policy.
The REALLOCATE process recognizes the need to relocate structure instances when one of the
following conditions is detected:
```
- There is a change to the policy definition for the structure affecting the structure size or location.
- The structure is not optimally located.
To control the relocation of a specific structure by the REALLOCATE process, you can specify the
ALLOWREALLOCATE(YES|NO) keyword for the structure in the CFRM policy.
- If you specify or default to ALLOWREALLOCATE(YES) for the structure in the CFRM policy:
    When the REALLOCATE process recognizes the need to relocate structure instances (see the
    preceding description of such conditions), the structure is selected as the target of the REALLOCATE
    process and the structure rebuild process is used to make the adjustments. Structure rebuild
    process supports the following:
    - User-managed rebuild
    - User-managed duplexing rebuild
    - System-managed rebuild
    - System-managed duplexing rebuild
    Multiple steps may need to be taken to complete the relocation of a selected structure. The
    steps are accomplished using structure rebuild processing (for example, user-managed rebuild)
    to adjust the location or activate a pending policy change for the structure that is the target of the
    REALLOCATE process. Messages to the operator document the steps being taken for each structure
    that is examined.
    - For a simplex structure, one step (rebuild) is used to adjust the location or to activate a pending
       policy change.
    - For a duplexed structure, two or three steps are used. The first step stops duplexing and one
       or more subsequent steps are used as needed to adjust the location, activate a pending policy
       change, and to reduplex the structure. If a subsequent step cannot be started, the system issues
       message IXC546I with an explanation.
    - A duplexed structure can also be converted to simplex structure when one of the duplexed
       structure instances is allocated in a coupling facility that does not permit structure allocation (for
       example, maintenance mode) and it is not possible to reduplex the structure. In this case, one or
       two steps are used. The first step stops duplexing and a second step might be needed to relocate
       the simplex structure or activate a pending policy change.
- If you specify ALLOWREALLOCATE(NO) for the structure in the CFRM policy:
    The REALLOCATE process evaluates the allocated structure but does not select the structure as
    the target of the REALLOCATE process. However, when NO is specified it is still possible for the
    REALLOCATE process to do the following adjustments if applicable:
    - Complete a pending policy update when the pending change does not affect the size or location.
    - Trigger an MVS-initiated duplexing rebuild when DUPLEX(ENABLED) is specified for the structure
       and the structure is not duplexed.
When the REALLOCATE process does not select an allocated structure, message IXC544I is issued
with an explanation.

**156**   Sysplex Management task


When the start request is accepted, the DISPLAY XCF,STR or the DISPLAY XCF,CF command shows
THE REALLOCATE PROCESS IS IN PROGRESS. For a summary of allocated structure status, use
the DISPLAY XCF,STR,STATUS=ALLOCATED command:

- The structure that is the current target indicates TARGET OF REALLOCATE PROCESS.
- Allocated structures which have not been evaluated indicate REALLOCATE EVALUATION
    PENDING.
- Structures which have been processed do not have additional status indicators displayed but the log
    can be examined to determine the action taken.

When the entire process completes for all structures, the processing provides a report (message
IXC545I) summarizing the actions that were taken as a whole. The REALLOCATE process evaluates all
allocated structures, in a serial (one structure at a time) fashion. Each selected structure is processed
to completion before the next structure is evaluated. The serial nature of this processing allows even
XCF signaling structures to be selected for relocation.

REALLOCATE processing evaluates a structure based on the CFRM policy and on the current
conditions (for example, available coupling facilities, coupling facility attributes, and connection
attributes), and for each structure selected for processing, takes the necessary steps to adjust the
location of the structure's allocated instances. From the time a structure is evaluated to the time when
the steps using structure rebuild processing cause a new instance to be allocated, it is possible for
the conditions to have changed. The result is that the current conditions are used when the structure
allocation algorithm is applied. The REALLOCATE process does not validate the resulting location of
the allocated instances but relies on the result of applying the XCF allocation criteria. Because of
this, it is possible that the coupling facilities shown as preferred when message IXC574I was written
to the hardcopy log with the evaluation information are not the coupling facilities containing the
allocated instances when the necessary steps finish. Where REALLOCATE processing intersects with
other environmental changes (for example, starting or stopping a structure rebuild process due to a
policy change, a coupling facility failure, or loss of connectivity to a coupling facility), the other ongoing
process will take precedence with REALLOCATE processing issuing messages IXC544I or IXC546I as
appropriate. For some environmental changes (for example, a coupling facility failure), the installation
may choose to stop the REALLOCATE process.

Consider the following when you use the SETXCF START,REALLOCATE command:

- Move structures out of a coupling facility following a CFRM policy change that deletes/changes that
    coupling facility (for example, in preparation for a coupling facility upgrade).
- Move structures back into a coupling facility following a CFRM policy change that adds/restores the
    coupling facility (for example, following a coupling facility upgrade/add).
- Clean up pending CFRM policy changes that may have accumulated for whatever reason, even in the
    absence of any need for structure "relocation" per se.
- Clean up simplex or duplexed structures that were allocated in or moved into the "wrong" coupling
    facilities, for whatever reason (for example, the "right" coupling facility was inaccessible at the time
    of allocation).
- Clean up duplexed structures that have primary and secondary "reversed" because of a
    prior condition which resulted in having duplexing stopped with KEEP=NEW and the structure
    reduplexed.

**Note:**

1. The REALLOCATE process is mutually exclusive with the POPULATECF function, which can be
    started either by the SETXCF operator command or the IXLREBLD programming interface.
2. The REALLOCATE process can only be started or stopped using the SETXCF command.
3. Support for the REALLOCATE process is provided by APAR OA03481.
    - The REALLOCATE process cannot be started if there exists an active system in the sysplex that
       does NOT have the APAR installed. The SETXCF START,REALLOCATE command is rejected.
    - An in-progress REALLOCATE process is stopped immediately when an active system without
       the APAR installed is discovered in the sysplex. The SETXCF START,REALLOCATE command was

```
Sysplex Management task   157
```

```
accepted but subsequently an active system without the APAR installed was discovered by an
up-level system which immediately stopped the process.
In both cases, message IXC543I is issued with explanatory text.
```
4. Enhancements for the REALLOCATE process are provided by APAR OA08688.
    - A structure-level control is provided to prevent REALLOCATE processing from selecting particular
       structures while allowing it to initiate structure rebuilds for others. This control is achieved
       by providing an option on the CFRM STRUCTURE parameter to the XCF Administrative Policy
       Utility (IXCMIAPU). The option is ALLOWREALLOCATE. See _z/OS MVS Setting Up a Sysplex_ ,
       Appendix C under section Coding the Administrative Data Utility for topic CFRM Parameters for
       Administrative Data Utility.
    - For a simplex structure with DUPLEX(ENABLED) specified, the REALLOCATE process is a
       triggering event. Message IXC536I is issued when MVS is able to initiate a duplexing rebuild
       for the structure identified by REALLOCATE processing.
    - When a pending policy change does not affect size, REALLOCATE processing avoids structure
       rebuild processing when evaluation with the pending policy shows that the structure does
       NOT need relocating. It completes the pending change. Message IXC544I is issued indicating
       ALLOCATED IN PREFERRED CF AND POLICY CHANGE MADE.
    - With this enhancement, REALLOCATE processing will ignore a specified exclusion list in some
       cases, so as to avoid anomalies when honoring the exclusion list would have precluded
       structures from relocating to the optimal location.

```
Stop Reallocate
A confirmation window is displayed, which allows you to select None or Force in the Commands option
field. Force causes the reallocate operation to end immediately. On the confirmation window, specify
values, then click OK to continue or Cancel to return to the previous page. Click Command Preview to
see the commands that will be issued.
The Stop Reallocate command is described as follows:
REALLOCATE[,FORCE] or REALLOC[,FORCE]
Specifies that an in-progress REALLOCATE process is to be stopped.
When stopping without specifying FORCE, REALLOCATE processing completes the steps for the
current target structure then finishes. The status of the REALLOCATE processing will be "STOPPING"
as shown by either the DISPLAY XCF,STR or the DISPLAY XCF,CF operator command.
When stopping with FORCE specified, REALLOCATE processing finishes immediately AND the step(s)
for the current target structure might NOT be completed. Use the FORCE option when structure
rebuild processing for the structure which is the target of the REALLOCATE process is not making
progress.
When the process finishes, for the structures selected prior to the operator stopping the process, the
processing provides a report (message IXC545I) summarizing the actions that were taken up to the
time that processing was stopped.
To stop the REALLOCATE process does NOT require issuing the command without FORCE specified
before issuing with FORCE specified.
```
```
Rebuild Commands
Use the rebuild commands to start or stop rebuilds. For more information on SETXCF commands see
SETXCF Commands in z/OS MVS System Commands.
```
```
Start Rebuild
The Start Rebuild command starts a rebuild for one or more selected structures.
```
**158**   Sysplex Management task


A confirmation window is displayed, which allows you to specify where your new structure can be built.
The default is Normal, which is applied to all structures if multiple structures are selected. When multiple
structures are selected, a table shows the name, CF, and status of those coupling facility structures. On
the confirmation window, specify values, then click **OK** to continue or **Cancel** to return to the previous
page. Click **Command Preview** to see the commands that will be issued.

**Start Rebuild (All)**

The Start Rebuild (All) command starts a rebuild for all structures for a selected CF.

A confirmation window is displayed, which allows you to specify where your new structure can be built.
The default is Normal. A table shows the name and status of those coupling facility structures. On the
confirmation window, specify values, then click **OK** to continue or **Cancel** to return to the previous page.
Click **Command Preview** to see the commands that will be issued.

The Start Rebuild command is described as follows:

**REBUILD** **_or_** **RB,POPULATECF** **_or_** **POPCF=** **_cfname_**
Specifies the name of the coupling facility that is to be populated with structures selected from the set
of allocated structures in the active CFRM policy.
A structure rebuild will be attempted for each allocated structure in the policy that contains the
specified coupling facility in its preference list, if the specified coupling facility is at a higher position
in the preference list than the coupling facility in which the structure currently is allocated. If the
structure is allocated in a more preferable coupling facility already, the rebuild will not continue.
POPULATECF rebuild processing assumes LOCATION=OTHER. LOCATION and LESSCONN options
cannot be specified.
Each structure that contains the specified coupling facility at a higher position in its preference list
will be processed serially to completion (either stopped or completed) before the next structure is
selected. The serial nature of this processing allows even XCF signaling structures to be selected for
coupling facility population.
The coupling facility name can be up to 8 alphanumeric characters long and must begin with an
uppercase alphabetic character. The name can contain numeric characters, uppercase alphabetic
characters, national characters ($, @, #), or an underscore (_).

**REBUILD** **_or_** **RB,STRNAME** **_or_** **STRNM=(** **_strname_** **[,** **_strname_** **]...)**
Specifies the name of one or more coupling facility structures that are to be rebuilt in the same
coupling facility or another coupling facility. The structure name can be up to 16 alphanumeric
characters long and must begin with an uppercase alphabetic character. IBM® names begin with SYS,
or letters A-I. If you specify only one structure name, you do not need to enter the parentheses.

**REBUILD** **_or_** **RB,CFNAME** **_or_** **CFNM=(** **_cfname_** **[,** **_cfname_** **]...)**
Specifies the name of one or more coupling facilities for which all structures other than XCF signaling
structures are to be rebuilt. The coupling facility name can be up to 8 alphanumeric characters long
and must begin with an uppercase alphabetic character. If you specify only one coupling facility name,
you do not need to enter the parentheses.
For any given structure, the system might not start rebuild. _z/OS MVS Programming: Sysplex Services
Guide_ lists the requirements for rebuild initiation. For example, if the named coupling facility contains
one or more XCF signaling structures, the system does not start rebuild for them. To rebuild an XCF-
signaling structure, issue the SETXCF START,REBUILD,STRNAME=... command for one structure
at a time.
**LOCATION=NORMAL** **_or_** **OTHER**
Specifies the location where the new structure or structures can be rebuilt. If you specify
LOCATION=NORMAL, the new structure can be allocated in any coupling facility in the preference
list, following the normal allocation rules. If you specify LOCATION=OTHER, the new structure
cannot be allocated for rebuild in the same coupling facility as the original structure. The new
structure can be allocated in any other coupling facility in the preference list, following the normal
allocation rules.

```
Sysplex Management task   159
```

```
Duplexing rebuild and POPULATECF processing assume LOCATION=OTHER.
Note that before the rebuild process begins, you might need to change the administrative policy
to specify where the structure can reside and then activate the policy. The CFRM administrative
policy contains the preference list that specifies coupling facilities where a structure can reside.
LESSCONN or LC=TERMINATE or CONTINUE
Specifies the action the system is to take when rebuilding the structure results in a new structure
that has poorer connectivity relative to the set of active structure connectors than the old
structure does.
```
- With LESSCONN=TERMINATE, the system stops the rebuild processing for the new structure if
    connectivity relative to the set of active connectors to the structure is not equal or better than it
    was to the current structure.
    LESSCONN=TERMINATE is the default system action. This protects active connectors against
    inadvertently losing connectivity to the structure as a result of rebuilding the structure.
    Duplexing rebuild processing assumes LESSCONN=TERMINATE.
- With LESSCONN=CONTINUE, the system allows the rebuild processing for the new structure
    even if connectivity relative to the set of active connectors to the structure is poorer than it was
    to the current structure.

```
Attention: Because this might cause active connectors to lose connectivity to the
structure, do not use this keyword unless you understand the impact to the application or
subsystem.
Some connectors stop the rebuild if a loss of connectivity is observed, but most
connectors disconnect from the structure to allow the rebuild to complete. For many
exploiters, disconnecting from the structure is likely to result in losing the sysplex-
related functionality (for example, loss of data sharing capability) on that system. For
critical system exploiters, this may result in a system wait state. See the application or
subsystem documentation for recommendations.
```
**Stop Rebuild**

```
The Stop Rebuild command stops a rebuild for one or more selected structures.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
```
```
Stop Rebuild (All)
The Stop Rebuild (All) command stops a rebuild for all structures for a selected CF.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
The Stop Rebuild command is described as follows:
REBUILD or RB,POPULATECF or POPCF= cfname
Specifies the name of the coupling facility in which structure population is to stop. All structure
rebuilds that were initiated by a SETXCF START,REBUILD,POPULATECF command will be stopped.
Note that you also can use the SETXCF STOP,REBUILD,CFNAME or SETXCF STOP,REBUILD,STRNAME
to stop structure rebuilds that were initiated by a SETXCF START,REBUILD,POPULATECF command.
REBUILD or RB,STRNAME or STRNM=( strname [, strname ]...)
Specifies the name of one or more coupling facility structures for which rebuild processing is to stop.
The structure name can be up to 16 alphanumeric characters long and must begin with an uppercase
```
**160**   Sysplex Management task


```
alphabetic character. IBM names begin with SYS, or letters A-I. If you specify only one structure
name, you do not need to enter the parentheses.
```
**REBUILD** **_or_** **RB,CFNAME** **_or_** **CFNM=(** **_cfname_** **[,** **_cfname_** **]...)**
Specifies the name of one or more coupling facilities for which rebuild processing is to stop for all
structures. The coupling facility name can be up to 8 alphanumeric characters long and must begin
with an uppercase alphabetic character. If you specify only one coupling facility name, you do not
need to enter the parentheses.

**Duplexing Commands**

Use the duplexing commands to start or stop duplexing. For more information, see SETXCF Commands in
_z/OS MVS System Commands_.

**Start Duplexing**

The Start Duplexing command starts a duplex for one or more selected structures.

A confirmation window is displayed. On the confirmation window, specify values, then click **OK** to
continue or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that
will be issued.

**Start Duplexing (All)**

The Start Duplexing (All) command starts a duplex for all structures for a selected CF.

A confirmation window is displayed. On the confirmation window, specify values, then click **OK** to
continue or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that
will be issued.

The Start Duplexing Command is described as follows:

**REBUILD** **_or_** **RB,DUPLEX,STRNAME** **_or_** **STRNM=(** **_strname_** **[,** **_strname_** **]...)**
Specifies the name of one or more coupling facility structures that are to be duplexed in another
coupling facility.
If structure duplexing is not supported for the target structure, the duplexing operation will not be
started and the system issues a message to the operator.
Duplexing rebuild processing assumes LOCATION=OTHER and LESSCONN=TERMINATE. Other
LOCATION and LESSCONN options cannot be specified.
The structure name can be up to 16 characters long and can contain numeric characters, uppercase
alphabetic characters, national characters ($, @, #), or an underscore (_). The name must begin with
an uppercase alphabetic characters. IBM names begin with SYS, or letters A-I.
If you specify only one structure name, you do not need to enter the parentheses.

**REBUILD** **_or_** **RB,DUPLEX,CFNAME=(** **_cfname_** **[,** **_cfname_** **]...)**
Specifies the name of one or more coupling facilities for which all structures are to be duplexed in a
different coupling facility.
The system attempts to start a duplexing operation for each structure that is currently allocated in the
specified coupling facility.
If structure duplexing is not supported for a particular structure, the system issues a message to the
operator.
The coupling facility name can be up to 8 alphanumeric characters long and can contain numeric
characters, uppercase alphabetic characters, national characters ($, @, #), or an underscore (_). It
must begin with an uppercase alphabetic character.
If you specify only one coupling facility name, you do not need to enter the parentheses.

```
Sysplex Management task   161
```

```
Stop Duplexing
The Stop Duplexing command stops a duplex for one or more selected structures.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
```
**Stop Duplexing (All)**

```
The Stop Duplexing (All) command stops a duplex for all structures for a selected CF.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
The Stop Duplexing Command is described as follows:
REBUILD or RB,DUPLEX,STRNAME or STRNM=( strname [, strname ]...)
Specifies the name of one or more coupling facility structures for which duplexing is to be stopped.
You must also specify with the KEEP keyword which of the duplexed structures should remain after
the duplexing operation has stopped.
The structure name can be up to 16 alphanumeric characters long and must begin with an uppercase
alphabetic character. IBM names begin with SYS, or letters A-I. If you specify only one structure
name, you do not need to enter the parentheses.
KEEP=NEW|OLD
Specifies which of the duplexed structures should remain after duplexing has stopped.
KEEP=NEW specifies that processing should switch to the new structure.
KEEP=OLD specifies that processing should fall back to the old structure.
Note:
```
1. If the CFRM active policy specifies DUPLEX(ENABLED) for the structure and IXLREBLD
    IGNOREDUPLEX=YES is not used, the system might immediately reduplex the structure after the
    completion of the stop processing. There might be a delay before reduplexing when only two
    coupling facilities are available for duplexing the structure. Reduplexing will occur immediately in
    configurations with three or more coupling facilities available for duplexing the structure.
2. To prevent the system from immediately reduplexing the structure or reduplexing the structure
    at a later time, change the DUPLEX specification for the structure to DUPLEX(ALLOWED)
    or DUPLEX(DISABLED). Change the DUPLEX setting for the structure in the CFRM policy to
    DUPLEX(ALLOWED) before stopping duplexing, or change the DUPLEX setting for the structure
    to DUPLEX(DISABLED), which will cause XCF to initiate the stop processing. Change the DUPLEX
    setting back to DUPLEX(ENABLED) when you no longer need to prevent the system from
    reduplexing.
**REBUILD** **_or_** **RB,DUPLEX,CFNAME=(** **_cfname_** **[,** **_cfname_** **]...)**
Specifies the name of one or more coupling facilities in which structure duplexing is to stop.
Duplexing will be stopped for each structure in each specified coupling facility so that no structures
involved in structure duplexing processing remain in the coupling facility. When more than one
coupling facility is specified, a separate request is made to stop duplexing for each coupling facility
specified. The order of making the requests is the same order as the coupling facilities are listed in the
command.
- If the specified coupling facility contains the new structure in the duplexed pair of structures, the
system will fall back to the old structure.
- If the specified coupling facility contains the old structure in the duplexed pair of structures, the
system will switch to the new structure.

**162**   Sysplex Management task


```
The coupling facility name can be up to 8 alphanumeric characters long and must begin with an
uppercase alphabetic character. If you specify only one coupling facility name, you do not need to
enter the parentheses.
See the same notes in the REBUILD or RB,DUPLEX,STRNAME or STRNM=( strname [, strname ]...)
parameter.
```
**Channel Path Commands**

Use these commands to restore or remove channel paths to a CF from either a CHPID, system, or a CF.

**Set Physical Path**

**From CHPID**
A confirmation window is displayed. It includes the command options and a table for every system
on the corresponding CHPID. On the confirmation window, specify values, then click **OK** to continue
or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that will be
issued.

**From System**
A confirmation window is displayed. It includes the command options and a table for every channel
path on the corresponding system. On the confirmation window, specify values, then click **OK** to
continue or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that
will be issued.

**From CF**
A confirmation window is displayed. It includes the command options and a table for the name and
channel paths of every system corresponding to that CF. On the confirmation window, specify values,
then click **OK** to continue or **Cancel** to return to the previous page. Click **Command Preview** to see
the commands that will be issued.

For more information, see Config Commands in _z/OS MVS System Commands_.

**Set Logical Path**

**From CHPID**
A confirmation window is displayed. It includes the command options and a table for every system
on the corresponding CHPID. On the confirmation window, specify values, then click **OK** to continue
or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that will be
issued.

**From System**
A confirmation window is displayed. It includes the command options and a table for every channel
path on the corresponding system. On the confirmation window, specify values, then click **OK** to
continue or **Cancel** to return to the previous page. Click **Command Preview** to see the commands that
will be issued.

**From CF**
A confirmation window is displayed. It includes the command options and a table for the name and
channel paths of every system corresponding to that CF. On the confirmation window, specify values,
then click **OK** to continue or **Cancel** to return to the previous page. Click **Command Preview** to see
the commands that will be issued.

For more information, see Vary Commands in _z/OS MVS System Commands_

```
Sysplex Management task   163
```

```
Maintenance Commands
Use the Maintenance Mode commands on a selected CF to start or stop Maintenance Mode as well as
prepare for or restore after disruptive maintenance. For more information see, SETXCF Commands in z/OS
MVS System Commands.
```
**Start Maintenance Mode**

```
The Start Maintenance Mode command starts maintenance mode for the selected CF.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
The Start Maintenance Mode command is described as follows:
MAINTMODE,CFNAME=( cfname ,[ cfname ...])
Sets the specified coupling facility or facilities into maintenance mode. When in maintenance mode,
a CF is not eligible for CF structure allocation purposes. The XCF structure allocation algorithm
modifies the CF selection processing accordingly. You can use the SETXCF STOP command to turn off
MAINTMODE. This setting is kept in control blocks in the storage of the ACTIVE sysplex. It is not saved
across sysplex wide IPLs, so a sysplex wide IPL will clear the setting.
```
```
Stop Maintenance Mode
The Stop Maintenance Mode command stops maintenance mode for the selected CF.
A confirmation window is displayed. On the confirmation window, specify values, then click OK to
continue or Cancel to return to the previous page. Click Command Preview to see the commands that
will be issued.
The Start Maintenance Mode command is described as follows:
MAINTMODE,CFNAME=( cfname ,[ cfname ...])
Removes the maintenance mode indication from the specified coupling facility or facilities. When in
maintenance mode, a CF is not eligible for CF structure allocation purposes. When the coupling facility
is out of maintenance mode, the XCF allocation algorithm can select the CF for allocating a coupling
facility structure.
```
**Prepare for Disruptive Maintenance**

```
Use the Prepare for Disruptive Maintenance action for a selected CF. A confirmation window is
displayed. On the confirmation window, specify values, then click OK to continue or Cancel to return
to the previous page. Click Command Preview to see the commands that will be issued.
```
**Restore after Disruptive Maintenance**

```
A confirmation window is displayed, showing the commands that are going to be issued, as well as the
selected systems. On the confirmation window, specify values, then click OK to continue or Cancel to
return to the previous page. Click Command Preview to see the commands that will be issued.
```
**164**   Sysplex Management task


## Index

**C**

CFRM Compare Policies 138, 142
CFRM Export Policy 141
CFRM Import Policy 139
CFRM Import Policy Formats 140
CFRM Policy Editor 57, 58, 60, 80, 137–139
CFRM Policy Editor and Sizer 59
CFRM Policy Editor Sizing Tab 89

**P**

planning
availability 2

**S**

sysplex
couple data set requirement 2
description 2
hardware requirements 2
software requirements 2
Sysplex Timer 2
XCF 2
Sysplex Management task 1
Sysplex Timer
description 3

**X**

XCF (cross-system coupling facility)
component 2

```
Index   165
```

IBM®


## z/OS® Classic Interfaces

# IBM


## Contents

**z/OS® Classic Interfaces........................................................................................ 1**

**Index.................................................................................................................... 2**

**ii**


**z/OS® Classic Interfaces**

```
This section, when the appropriate plugins are installed, describes the z/OSMF task that you can use to
access traditional ISPF applications.
```
```
z/OS® Classic Interfaces   1
```

## Index

**C**

classic interfaces 1

**2**   z/OS Classic Interfaces



IBM®


## z/OSMF Administration

# IBM


## Contents

**Consolidating your z/OS system management applications.....................................1**

**Index.................................................................................................................... 2**

**ii**


**z/OSMF Administration**

```
In a typical z/OSMF installation, one or more users are authorized to access z/OSMF as administrators.
A z/OSMF administrator can log into z/OSMF and perform administration tasks, as needed. This section,
when the appropriate plugins are installed, describes the z/OSMF administration tasks.
```
**Consolidating your z/OS system management applications**

```
To perform traditional system management tasks in z/OS, you might interact with several different
interfaces, such as the TSO command line, graphical user interfaces, and web-style interfaces. z/OSMF
provides a modular framework that you can use to bring these tasks and external applications together for
a smoother user experience.
This framework supports different levels of integration ranging from adding a resource link to creating
context-sensitive launch points between tasks and applications to creating your own z/OSMF plug-ins.
This section describes how to use these capabilities to make z/OSMF the central facility for managing your
z/OS systems.
Linking to frequently used web resources
To help you bring together the web resources your installation commonly uses when managing your
z/OS systems, z/OSMF provides the Links task, which you can use to add links to external sites for
system management tools and information.
Creating context-sensitive launch points between applications
To help you link or connect your z/OSMF tasks and external applications, z/OSMF provides the
Application Linking Manager task, which allows you to create context-sensitive launch points between
applications.
Importing installation-specific function into z/OSMF
To assist you with consolidating your system management tools, z/OSMF provides the Import Manager
task, which you can use to add installation-specific function to z/OSMF in the form of plug-ins.
```
```
z/OSMF Administration   1
```

## Index

**A**

administration 1
application linking manager 1

**I**

import manager 1

**L**

links 1

**2**   z/OSMF Administration



IBM®


## z/OSMF Diagnostic Assistant

# IBM


## Contents

```
z/OSMF Diagnostic Assistant................................................................................. 1
Collect z/OSMF diagnostic data...................................................................................................................1
Update the z/OSMF log level........................................................................................................................2
Space management..................................................................................................................................... 4
```
**Index.................................................................................................................... 6**

**ii**


**z/OSMF Diagnostic Assistant**

```
You can use the z/OSMF Diagnostic Assistant to set the log levels for z/OSMF error data collection. Collect
diagnostic data about z/OSMF and download it as a compressed file package to your workstation. Set a
space management policy to remove old log files.
```
### Collect z/OSMF diagnostic data

```
To collect diagnostic data from z/OSMF, select the z/OSMF Diagnostic Assistant icon in the z/OSMF
desktop.
```
**About this task**

```
You must be a system administrator to collect diagnostic data.
```
**Procedure**

1. Select the z/OSMF Diagnostic Assistant icon in the z/OSMF desktop.
2. Ensure that the option **z/OSMF default diagnostic data** is selected.
3. If you want to limit data collection to runtime and server-side logs, select **Only include runtime and**
    **server side logs**.
    If so, the diagnostic data is obtained from the following directory:

```
<USER_DIR>/data/logs
```
```
Where <USER_DIR> is /global/zosmf by default. Your installation might use another name for
<USER_DIR>, such as /var/zosmf.
```
4. To include the z/OSMF server job log in the data collected, select **z/OSMF server job log**.
    If so, you must specify the job name and job ID for the z/OSMF server. By default, the **Job Name** and
    **Job ID** fields are filled with the current system values.
5. Click **Export** to export the diagnostic data as a compressed ( **.zip** ) file.
    The file name is based on the date and time on which it was generated, for example:

```
2019-6-18-22-28-10.zip
```
6. Open the file or save it to your workstation.

**What to do next**

```
Extract the compressed file and examine its contents.
z/OSMF diagnostic data is stored in the following log files. By checking these log files, you can locate any
of the messages that are written by z/OSMF.
IZUGx.log
Contains the runtime messages, including the standard output and standard error streams from the
JVM process.
The IZUGx.log files are contained in the following directory:
```
```
<USER_DIR> /data/logs/zosmfServer/logs
```
```
z/OSMF Diagnostic Assistant   1
```

```
z/OSMF names the log files IZUG n .log, where n is a numeral in the range 0 - 9. z/OSMF creates
log files in a "cascading" manner. The most current log file is always named IZUG0.log. When
this log file reaches its predefined limit, z/OSMF saves it as IZUG1.log and begins writing to a
new IZUG0.log file. When the IZUG0.log file is again full, z/OSMF saves it as IZUG1.log after it
renames the existing IZUG1.log file to IZUG2.log. z/OSMF continues this process, saving each log
file under the next available name, up to a maximum of ten log files. Thereafter, z/OSMF discards the
oldest log file (IZUG9.log) whenever a new log file is to be created.
If the current IZUG0.log file becomes unavailable, z/OSMF writes its runtime data to the z/OSMF
server logs directory (trace.log and messages.log) until the problem is resolved.
For examples of z/OSMF runtime log data, and a description of the log file format, see z/OSMF
Configuration Guide.
FFDC log files
Contains the WebSphere Liberty first failure data capture (FFDC) log files. FFDC log files include the
exception stack and optional additional data that is recorded when an unexpected exception occurs.
The FFDC log files are contained in the following directory:
```
```
<USER_DIR> /data/logs/zosmfServer/logs/ffdc
```
```
messages.log
Contains the WebSphere Liberty startup and runtime messages. Messages that are written to this file
begin with CWW and include information such as the message time stamp and the ID of the thread
that wrote the message. The messages.log does not contain messages that are written by the JVM
process.
For example:
```
```
[9/6/13 20:52:21:569 GMT] 0000001f
com.ibm.ws.app.manager.internal.statemachine.StartAction A CWWKZ0001I:
Application IzuManagementFacilityWorkloadManagement started in 4.121
seconds.
```
```
The messages log is written to the following location:
```
```
<USER_DIR> /data/logs/zosmfServer/logs/messages.log
```
```
trace.log
Contains the same entries as found in messages.log. In addition, this file contains trace entries when
additional tracing is enabled. This file does not contain messages that are written by the JVM process.
WebSphere Liberty defines this file as stderr. For example, JSSE tracing enabled with the z/OSMF
advanced setting –Djavax.net.debug=all.
The trace log is written to the following location:
```
```
<USER_DIR> /data/logs/zosmfServer/logs/trace.log
```
### Update the z/OSMF log level

```
To change the log level for one or more z/OSMF services, select the z/OSMF Diagnostic Assistant icon in
the z/OSMF desktop.
```
**About this task**

```
For diagnostic purposes, you might be asked by IBM® Support to modify the trace state for one or more
z/OSMF services. The trace settings are read when the server is started. The trace output is written to files
in the z/OSMF logs directory.
You must be a system administrator to change the level of error log for the z/OSMF services.
```
**2**   z/OSMF Diagnostic Assistant


**Procedure**

1. Select the z/OSMF Diagnostic Assistant icon in the z/OSMF desktop.
2. Select the tab **Set the z/OSMF logging level**.
    The services table shows the z/OSMF services for which the log level can be set. Initially, the table is
    empty. To modify the log level for a particular z/OSMF service, you must first add the service to this
    table.
3. To add a z/OSMF service to the table, select **Add service**.
    The **Add service** option displays when all service checkboxes are cleared. A filter function is provided
    for string searches.
    If a z/OSMF service is not displayed in the list, the service is not enabled on your system. To enter the
    name of a z/OSMF service that you plan to enable later, select **Others**.
4. In the **Add Service** window, select the z/OSMF services for which you want to modify the log level.
5. Click **OK**.
    The services table is updated to show the package name and current log level for the z/OSMF services
    that you selected.
    You can edit the package names to include multiple packages for a service. Use a colon (':') to separate
    each package name. For example:

```
com.ibm.zoszmf.cp.a : com.ibm.zoszmf.cp.b
```
6. For each z/OSMF service, specify the log level that you want to enable.
    - Select the z/OSMF service, then select a log level from the Log Level column. The valid log levels are
       described in Table 1 on page 3. When you finish setting log levels for the services, click **Set** to
       apply your changes for the selected services. A notification message is displayed to confirm that the
       log levels are changed. Notice that a count of notification messages is displayed to the right of the
       bell icon in the upper right corner of the page. To view your notification messages, click the bell icon.
    - To deselect a z/OSMF service, click **Cancel**.
    - To remove a service from the table, select the service and click **Delete**.
    - To restore all of the z/OSMF service log levels to the IBM default values, click **Restore Defaults**. For
       more information about the z/OSMF default log levels, see the description of the LOGGING option of
       the IZUPRMxx parmlib member in IBM z/OS Management Facility Configuration Guide.

```
Table 1. Valid log levels for the z/OSMF server.
```
```
Log level Content / Significance
```
```
INFO General information outlining overall task
progress.
```
```
FINE Trace information - General trace.
```
```
FINER Trace information - Detailed trace, which includes
general trace plus method entry, exit, and return
values.
```
```
FINEST Trace information - A more detailed trace that
includes all the detail that is needed to debug
problems.
```
```
SEVERE Task cannot continue but component,
application, and server can still function.
This level can also indicate an impending
unrecoverable error.
```
```
z/OSMF Diagnostic Assistant   3
```

```
Table 1. Valid log levels for the z/OSMF server. (continued)
```
```
Log level Content / Significance
```
```
WARNING Potential error or impending error. This level can
also indicate a progressive failure (for example,
the potential leaking of resources).
```
```
ALL All events are logged. If you create custom levels,
ALL includes those levels, and can provide a
more detailed trace than finest.
```
```
CONFIG Configuration change or status.
```
```
OFF Logging is turned off.
```
7. When you are done with your selections, click **Save**.
    z/OSMF sets all of the enabled services to INFO, then applies your selections to the selected services.

```
What to do next
With the new log levels in effect, you can collect the required diagnostic data. Here, you can re-create the
problem, then use the Collect z/OSMF diagnostic data tab of the z/OSMF Diagnostic Assistant to collect
the data. To view the diagnostic data, export the data as a compressed file and save it to your workstation.
The log levels consume varying amounts of storage and CPU. When you are done collecting diagnostic
data, it is recommended that you restore the z/OSMF service log levels to their default values. To do so,
return to the services table and click Restore Defaults.
```
### Space management

```
To manage the removal of old z/OSMF log files, select the Space management tab in the z/OSMF
Diagnostic Assistant icon in the z/OSMF desktop.
```
**About this task**

```
You must be a system administrator to set space management policies.
```
**Procedure**

1. Select the z/OSMF Diagnostic Assistant icon in the z/OSMF desktop.
2. Select the **Space management** tab.
3. Enter the age criterion for removing files.
    Enter a number of days. When a file's age is greater than the age criterion, the file is a candidate for
    removal. Files that meet the age criterion are removed only if you specify the daily removal policy or if
    you specify immediate removal.
    - A value of 0 means that files can be removed any time after they are created.
    - A value of 1 means that files that are older than 1 day can be removed.
    - The maximum value is 99,999,999.
4. Select the log file types that you want to remove.
5. Set the **Activate this policy (log files will be removed every 24 hours based on your selections)**
    checkbox if you want to every day check for and remove log files that meet the age criteria.
6. Set the **Remove immediately** checkbox if you want to immediately remove log files that meet the age
    criteria.

**4**   z/OSMF Diagnostic Assistant


7. If you don't want to remove any files, clear the **Activate this policy (log files will be removed every**
    **24 hours based on your selections)** and **Remove immediately** check boxes.
8. Click **Set**.

**Results**
At the appropriate time interval, the Diagnostic Assistant checks for and removes log files that meet the
age and file type criteria.

**What to do next**

Monitor the space usage of the z/OSMF log files. Before you run out of space, consider the following
options to reduce the space that is occupied by log files:

- Reduce the age criteria for removing log files.
- Use the **Collect z/OSMF diagnostic data** tab to deselect some kinds of data that you collect.
- Use the **Set the z/OSMF logging level** tab to reduce the fineness of the data that is logged.

```
z/OSMF Diagnostic Assistant   5
```

## Index

**D**

diagnostic data 1, 4
Diagnostics 1

**L**

log level 2

**6**   z/OSMF Diagnostic Assistant



IBM®


## z/OSMF Settings

# IBM


## Contents

**z/OSMF Settings....................................................................................................1**

**Index.................................................................................................................... 2**

**ii**


**z/OSMF Settings**

```
This section, when the appropriate plugins are installed, describes the settings that you can specify for
z/OSMF tasks.
```
```
z/OSMF Settings   1
```

## Index

**S**

settings 1

**2**   z/OSMF Settings



IBM®


## Tools and techniques for troubleshooting

# IBM


## Contents

**Verifying your workstation with the environment checker.......................................1**

**Finding information about z/OSMF.........................................................................2**

**Working with z/OSMF runtime log files...................................................................3**

**Enabling tracing and logging for z/OSMF................................................................ 4**

**Index.................................................................................................................... 6**

**ii**


**Tools and techniques for troubleshooting**

```
This section, when the appropriate plugins are installed, describes the tools and techniques available for
troubleshooting problems with z/OSMF.
```
**Verifying your workstation with the environment checker**

```
To work with z/OSMF, your web browser and workstation require a number of settings for proper
functioning. z/OSMF includes an environment checker tool to help you verify these settings. The
environment checker tool inspects your web browser and workstation operating system for compliance
with z/OSMF requirements and recommended settings.
```
```
Before running the tool
Ensure that your workstation is set up correctly and that your Web browser is enabled for JavaScript. For
more details, see the topic about preparing your workstation for z/OSMF in IBM z/OS Management Facility
Configuration Guide.
```
**Running the tool**

```
To run the tool, do the following:
```
1. Open a web browser to the environment checker tool:

```
https://hostname:port/zosmf/IzuUICommon/environment.jsp
```
```
where:
```
- _hostname_ is the hostname or IP address of the system on which z/OSMF is installed
- _port_ is the secure application port.
2. Follow the instructions for your particular browser in the online help for the tool.

```
Understanding the results of the tool
Table 1 on page 1 describes the layout of the environment checker report.
```
```
Table 1. Columns in the environment checker tool results page
```
```
Column Description
```
```
Environment Option Browser setting that was examined by the environment checker tool.
```
```
Tools and techniques for troubleshooting   1
```

```
Table 1. Columns in the environment checker tool results page (continued)
```
```
Column Description
```
```
Settings as of date-time Findings from the most recent invocation of the tool. This column indicates
potential problems with your browser.
In the column heading, the date and time ( date-time ) is represented in ISO 8601
format, a standard provided by the International Organization for Standardization
(ISO). In this format:
```
- Calendar date is represented in year-month-day format ( _yyyy-mm-dd_ ).
- Time of day ( _T_ ) is based on the 24-hour clock: _hh:mm:ss:mmm_.
- _Z_ indicates zero offset from coordinated universal time (UTC).
In the report, the status of each setting is indicated, as follows:
**Items marked with a critical icon X**
    Setting is not correct for z/OSMF. You must fix this problem before continuing
    with z/OSMF.
**Items marked with a warning symbol!**
    Setting is not optimal for z/OSMF. It is recommended that you update the
    setting before continuing with z/OSMF.
**No error indication**
    Setting is correct for z/OSMF.

```
Requirements Recommended setting for your environment.
```
```
For the steps to resolve a problem, see the appropriate entry in the tool's online help. After updating a
setting, use the browser reload button to run the environment checker again. Repeat this process until
you have resolved all of the errors and warnings.
```
**Finding information about z/OSMF**

```
z/OSMF includes an About page to display the product version details that can be useful to IBM® Support
during the diagnosis of a problem.
```
**Procedure**

1. To access the **About** page for z/OSMF, click the menu in the z/OSMF desktop.
    The menu contains links to **What's New** , **Getting started** , **About z/OSMF** , and **Help**.
2. Click **About z/OSMF**.

```
Results
A new browser window opens to display details, such as the z/OSMF build level, and the SMP/E-installed
plug-ins and versions (FMIDs).
```
**2**   Tools and techniques for troubleshooting


**Working with z/OSMF runtime log files**

```
During normal operations, z/OSMF collects its runtime data (log messages and trace data) in log files.
z/OSMF runtime data is created on the server ( server side ) or sent to the server by the client ( client side ).
Both types of messages are written to the z/OSMF runtime log files.
z/OSMF creates the log files in the product logs directory, which is, by default, /global/zosmf/data/
logs. z/OSMF names the log files IZUG n .log, where n is a numeral from 0 to 9.
z/OSMF creates log files in a "cascading" manner. The most current log file is always named IZUG0.log.
When this log file reaches its predefined limit, z/OSMF saves it as IZUG1.log and begins writing to a new
IZUG0.log file. When the IZUG0.log file is again full, z/OSMF saves it as IZUG1.log after renaming
the existing IZUG1.log file to IZUG2.log. z/OSMF continues this process, saving each log file under
the next available name, up to a maximum of ten log files. Thereafter, z/OSMF discards the oldest log file
(IZUG9.log) whenever a new log file is to be created.
The z/OSMF runtime log files are written in English only, and are tagged as ASCII, using the ISO8859-1
code page. You can view the log files in ASCII format through ISPF option 3.17, using the VA action (View
an ASCII file). Other viewing options, such as OBROWSE, or tools such as vi, emacs, or grep, might require
that you first convert the files to EBCDIC. To have ASCII files converted to EBCDIC automatically prior to
browsing, set the z/OS® UNIX System Services environment variable _BPXK_AUTOCVT to "ON".
To work with the logs, you require a user ID with z/OSMF administrator authority (that is, a user ID
defined to the z/OSMF administrator group). Changing the level of logging and activating trace are
performed through the IZUPRMxx parmlib member. For information, see IBM z/OS Management Facility
Configuration Guide.
For examples of z/OSMF runtime log data, and a description of the log file format, see IBM z/OS
Management Facility Configuration Guide.
```
**Managing log lock files**

```
When z/OSMF initializes, the log file handler creates a file named IZUG0.log.lck. This file represents a
"lock" on the log data. Usually, lock files are cleaned up automatically as part of application shutdown.
If the z/OSMF server ends abnormally, however, the lock files might remain. If so, the log file handler
appends numbers to the normal lock file name to find a file that is free.
If the server ends abnormally, inspect the log directory and delete the lock files. If additional locks and
log files were created, you can sort the files in the directory by timestamp to determine which files are the
most recent. Back up these files if you want to preserve them, then clear the logs directory to conserve
space.
```
**If the IZUG0.log file cannot be accessed**

```
If the current IZUG0.log file becomes unavailable, z/OSMF writes its runtime data to the z/OSMF server
logs directory until the problem is resolved. Specifically, z/OSMF writes log messages and trace data to
the following locations:
```
- Messages are written to the message.log file, which is located in /global/zosmf/data/logs/
    zosmfServer/logs/messages.log
- Trace data is written to the trace.log file, which is located in /global/zosmf/data/logs/
    zosmfServer/logs/trace.log

**If client data cannot be written to the server**

```
Working with z/OSMF runtime log files 3
```

```
If a communication problem prevents the client's critical error log data from being written to the z/OSMF
logs directory, the unlogged client data is displayed to the end user in a separate browser window. This
failover action allows for the client data to be retained until the communication with the z/OS system
can be restored. In some situations, IBM Support might request this data for diagnostic purposes. If the
browser window is closed, the client data is not retained.
```
**Other log files in z/OSMF**

```
Do not confuse the z/OSMF runtime log file with the job log files that are created during the configuration
process. In contrast to runtime data, configuration log data is written to a file in the z/OSMF user file
system, which is, by default /global/zosmf. If a problem occurs with the configuration log file, the log
data is written instead to the directory specified by the /tmp parmlib statement.
```
**Enabling tracing and logging for z/OSMF**

```
For diagnostic purposes, you might be asked by IBM Support to enable tracing and logging for z/OSMF.
You can configure the z/OSMF server to start in a trace-enabled state, or you can enable tracing and
logging dynamically for the running server. The trace output is written to files in the z/OSMF logs directory.
Setting the level of logging can be done through the IZUPRMxx parmlib member, or dynamically, by using
the MODIFY command with the LOGGING option.
This topic contains the following information:
```
- “Enabling tracing and logging at server startup” on page 4
- “Enabling tracing and logging on a running server” on page 4.
Understand that tracing carries a performance cost. Do not activate tracing for z/OSMF unless directed to
do so by IBM Support.

**Enabling tracing and logging at server startup**

```
The z/OSMF server configuration settings are used to configure tracing and logging for z/OSMF. These
settings, which are read when the server is started, determine the initial trace state for the server.
If there is a problem with starting the server, you might be asked by IBM Support to configure the server
to start in a trace-enabled state. If so, you specify the trace specification on the LOGGING parameter of
the IZUPRMxx parmlib member.
To do this:
```
1. Stop the z/OSMF server. For instructions on starting and stopping the z/OSMF server, see _IBM z/OS_
    _Management Facility Configuration Guide_.
2. Modify the LOGGING parameter of the IZUPRMxx parmlib member, as described in IBM z/OS
    Management Facility Configuration Guide.
3. Start the z/OSMF server.
Your changes take effect immediately and are maintained across z/OSMF server restarts.

**Enabling tracing and logging on a running server**

```
You might be asked by IBM Support to enable tracing and logging for z/OSMF dynamically. If so, use
the MODIFY command with the LOGGING option to set the appropriate tracing specification. To run this
command, your user ID must be permitted to enter operator commands.
The command has the following format:
```
**4**   Tools and techniques for troubleshooting


```
f server-name ,logging=' trace_specification '
```
Where:

**_server-name_**
Is the server for your z/OSMF configuration. Set this value to the job name of the z/OSMF server, which
is IZUSVR1, by default.

**_trace_specification_**
Is the level of tracing to be used. This value is provided by IBM Support. To reset the trace
specification to the previous setting, specify "reset" as the trace specification.

Enter the command from the operator console. The command output is displayed in the operator console
and in the z/OS system log.

Your changes take effect immediately and remain in effect while the server is running. Your changes are
discarded when the server is restarted, and the previous settings are used. To have your changes saved
across server restarts, you must enable tracing and logging at server start-up, as described in “Enabling
tracing and logging at server startup” on page 4.

The following MODIFY command sets the trace specification to all:

f izusvr1,logging='*=warning:com.ibm.zoszmf.util.data.*=all'

Figure 1 on page 5 shows an example of the command output.

```
00- SY1 f izusvr1,logging='*=warning:com.ibm.zoszmf.util.data.*=all'
SY1 +CWWKB0005I: COMMAND RESPONSES COMPLETED SUCCESSFULLY FROM Logging
Command Handler.
SY1 +CWWKB0002I: MODIFY COMMAND
LOGGING='*=warning:com.ibm.zoszmf.util.data.*=all' COMPLETED
SUCCESSFULLY.
```
```
Figure 1. Sample results from the MODIFY LOGGING operator command
```
The following MODIFY command resets the trace specification:

f izusvr1,logging='reset'

Figure 2 on page 5 shows an example of the command output.

```
00- SY1 f izusvr1,logging='reset'
SY1 +CWWKB0005I: COMMAND RESPONSES COMPLETED SUCCESSFULLY FROM Logging
Command Handler.
SY1 +CWWKB0002I: MODIFY COMMAND LOGGING='reset' COMPLETED SUCCESSFULLY.
```
```
Figure 2. Sample results from the MODIFY LOGGING RESET operator command
```
```
Enabling tracing and logging for z/OSMF   5
```

## Index

**Special Characters**

_BPXK_AUTOCVT environment variable 3
(managing log lock files 3
/tmp directory 4

**A**

About page
description 2

**C**

client side log data 3

**E**

environment checker tool
using 1
error logging
enabling at server startup 4
enabling on a running server 4

**I**

IZUG0.log.lck file 3
IZUGn.log file 3

**L**

log data 3
log file
working with 3
log lock file 3
logging error data for z/OSMF 4

**R**

runtime log
using 3

**S**

server log files 3

**T**

tools for troubleshooting 1
trace data
using 4
troubleshooting
browser problems 1
checking the About page 2
enabling tracing 4
using the runtime logs 3

```
troubleshooting (continued)
workstation problems 1
```
**Z**

```
z/OSMF server
changing the logging level 4
```
**6**   Tools and techniques for troubleshooting



IBM®


